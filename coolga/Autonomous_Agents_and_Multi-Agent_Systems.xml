<?xml version="1.0" encoding="UTF-8" standalone="no"?><documents><document><year>2004</year><authors>Peter McBurney1 | Rogier M. Van Eijk2 | Simon Parsons3  | Leila Amgoud4 </authors><title>A Dialogue Game Protocol for Agent Purchase Negotiations</title><content>We propose a dialogue game protocol for purchase negotiation dialogues which identifies appropriate speech acts, defines constraints on their utterances, and specifies the different sub-tasks agents need to perform in order to engage in dialogues according to this protocol. Our formalism combines a dialogue game similar to those in the philosophy of argumentation with a model of rational consumer purchase decision behaviour adopted from marketing theory. In addition to the dialogue game protocol, we present a portfolio of decision mechanisms for the participating agents engaged in the dialogue and use these to provide our formalism with an operational semantics. We show that these decision mechanisms are sufficient to generate automated purchase decision dialogues between autonomous software agents interacting according to our proposed dialogue game protocol.</content></document><document><year>2004</year><authors>Barney Pell1 | Edward B. Gamble2 | Erann Gat2 | Ron Keesing3 | James Kurien4 | William Millar5 | Christian Plaunt5  | Brian C. Williams4 </authors><title>A Hybrid Procedural/Deductive Executive for Autonomous Spacecraft</title><content>The New Millennium Remote Agent (NMRA) will be the first AI system to control an actual spacecraft. The spacecraft domain places a strong premium on autonomy and requires dynamic recoveries and robust concurrent execution, all in the presence of tight real-time deadlines, changing goals, scarce resource constraints, and a wide variety of possible failures. To achieve this level of execution robustness, we have integrated a procedural executive based on generic procedures with a deductive model-based executive. A procedural executive provides sophisticated control constructs such as loops, parallel activity, locks, and synchronization which are used for robust schedule execution, hierarchical task decomposition, and routine configuration management. A deductive executive provides algorithms for sophisticated state inference and optimal failure recovery planning. The integrated executive enables designers to code knowledge via a combination of procedures and declarative models, yielding a rich modeling capability suitable to the challenges of real spacecraft control. The interface between the two executives ensures both that recovery sequences are smoothly merged into high-level schedule execution and that a high degree of reactivity is retained to effectively handle additional failures during recovery.</content></document><document><year>2004</year><authors>John Grant1 | Sarit Kraus2| 3  | Donald Perlis4 </authors><title>A Logic for Characterizing Multiple Bounded Agents</title><content>We describe a meta-logic for characterizing the evolving internal reasoning of various families of agents. We view the reasoning of agents as ongoing processes rather than as fixed sets of conclusions. Our approach utilizes a strongly sorted calculus, distinguishing the application language, time, and various syntactic sorts. We have established soundness and completeness results corresponding to various families of agents. This allows for useful and intuitively natural characterizations of such agents' reasoning abilities. We discuss and contrast consistency issues as in the work of Montague and Thomason. We also show how to represent the concept of focus of attention in this framework.</content></document><document><year>2004</year><authors>Michael Luck1 | Peter McBurney2  | Chris Preist3 </authors><title>A Manifesto for Agent Technology: Towards Next Generation Computing</title><content>The European Commission's eEurope initiative aims to bring every citizen, home, school, business and administration online to create a digitally literate Europe. The value lies not in the objective itself, but in its ability to facilitate the advance of Europe into new ways of living and working. Just as in the first literacy revolution, our lives will change in ways never imagined. The vision of eEurope is underpinned by a technological infrastructure that is now taken for granted. Yet it provides us with the ability to pioneer radical new ways of doing business, of undertaking science, and, of managing our everyday activities. Key to this step change is the development of appropriate mechanisms to automate and improve existing tasks, to anticipate desired actions on our behalf (as human users) and to undertake them, while at the same time enabling us to stay involved and retain as much control as required. For many, these mechanisms are now being realised by agent technologies, which are already providing dramatic and sustained benefits in several business and industry domains, including B2B exchanges, supply chain management, car manufacturing, and so on. While there are many real successes of agent technologies to report, there is still much to be done in research and development for the full benefits to be achieved. This is especially true in the context of environments of pervasive computing devices that are envisaged in coming years. This paper describes the current state-of-the-art of agent technologies and identifies trends and challenges that will need to be addressed over the next 10 years to progress the field and realise the benefits. It offers a roadmap that is the result of discussions among participants from over 150 organisations including universities, research institutions, large multinational corporations and smaller IT start-up companies. The roadmap identifies successes and challenges, and points to future possibilities and demands; agent technologies are fundamental to the realisation of next generation computing.</content></document><document><year>2004</year><authors>H. Van Dyke Parunak1 </authors><title>A Practitioners' Review of Industrial Agent Applications</title><content>ERIM's1 Center for Electronic Commerce (CEC) hosted a two-day Workshop on Industrial Agents (WINA) in Ann Arbor, MI on Nov. 12&amp;#x2013;13, 1998. Participation in the workshop was by invitation only, and was restricted to companies with whom the CEC is doing business or developing collaborations in agent technologies. Because of its industrial focus, the workshop's objectives have a rather different emphasis than research-oriented workshops and conferences. The projects discussed at the workshop and summarized in this report fall into three areas of increasing generality: focused applications, broadly applicable tools, and methodological guidelines.</content></document><document><year>2004</year><authors>Nicholas R. Jennings1 | Katia Sycara2  | Michael Wooldridge1 </authors><title>A Roadmap of Agent Research and Development</title><content>This paper provides an overview of research and development activities in the field of autonomous agents and multi-agent systems. It aims to identify key concepts and applications, and to indicate how they relate to one-another. Some historical context to the field of agent-based computing is given, and contemporary research directions are presented. Finally, a range of open issues and future challenges are highlighted.</content></document><document><year>2004</year><authors>Olga Pacheco1  | Jos&amp;eacute  Carmo2 </authors><title>A Role Based Model for the Normative Specification of Organized Collective Agency and Agents Interaction</title><content>In this article we propose a role based model for the specification of organized collective agency, based on the legal concept of artificial person and on the normative perspective of organizational systems. We focus on the analysis of groups of agents (humans or not) that want to act collectively in a (more or less) permanent basis, and in a stable and organized way, as it is the typical case of organizations. We argue that in those cases such groups of agents should give rise to a new agent, that we call of institutionalized agent, with its own identity, whose structure is essentially defined through the characterization of a set of roles and whose behavior is determined by the acts of the agents that play such roles. We also present a deontic and action modal logic that captures the concept of acting in a role and relates it with the deontic notions of obligation, permission and prohibition. This logic is used in the formal specification of institutionalized agents and of societies of agents and in the rigorous analysis of them. We pay particular attention to the interaction between agents through contracts or other normative relations. A high level specification language is also suggested.</content></document><document><year>2004</year><authors>Manoj Lal1  | Raju P|ey1 </authors><title>A Scheduling Scheme for Controlling Allocation of CPU Resources for Mobile Programs</title><content>There is considerable interest in developing runtime infrastructures for programs that can migrate from one host to another. Mobile programs are appealing because they support efficient utilization of network resources and extensibility of information servers. In this paper, we present a scheduling scheme for allocating resources to a mix of real-time and non real-time mobile programs. Within this framework, both mobile programs and hosts can specify constraints on how CPU should be allocated. On the basis of the constraints, the scheme constructs a scheduling graph on which it applies several scheduling algorithms. In case of conflicts between mobile program and host specified constraints, the schemes implements a policy that resolves the conflicts in favor of the host. The resulting scheduling scheme is adaptive, flexible, and enforces both program and host specified constraints.</content></document><document><year>2004</year><authors>Rogier M. Van Eijk1 | Frank S. De Boer1 | Wiebe Van Der Hoek1  | John-Jules Ch. Meyer1 </authors><title>A Verification Framework for Agent Communication</title><content>In this paper, we introduce a verification method for the correctness of multiagent systems as described in the framework of ACPL (Agent Communication Programming Language). The computational model of ACPL consists of an integration of the two different paradigms of CCP (Concurrent Constraint Programming) and CSP (Communicating Sequential Processes). The constraint programming techniques are used to represent and process information, whereas the communication mechanism of ACPL is described in terms of the synchronous handshaking mechanism of CSP. Consequently, we show how to define a verification method for ACPL in terms of an integration of the verification methods for CCP and CSP. We prove formally the soundness of the method and discuss its completeness.</content></document><document><year>2004</year><authors>Michael J. Pazzani1  | Daniel Billsus1 </authors><title>Adaptive Web Site Agents</title><content>We discuss the design and evaluation of a class of agents that we call adaptive web site agents. The goal of such an agent is to help a user find additional information at a particular web site, adapting its behavior in response to the actions of the individual user and the actions of other visitors to the web site. The agent recommends related documents to visitors and we show that these recommendations result in increased information read at the site. It integrates and coordinates among different reasons for making recommendations including user preference for subject area, similarity between documents, frequency of citation, frequency of access, and patterns of access by visitors to the web site. We argue that this information is best used not to change the structure or content of the web site but rather to change the behavior of an animated agent that assists the user.</content></document><document><year>2004</year><authors>Koen V. Hindriks1 | Frank S. De Boer1| Wiebe Van der Hoek1 | John-Jules Ch. Meyer1</authors><title>Agent Programming in 3APL</title><content>An intriguing and relatively new metaphor in the programming community is that of an intelligent agent. The idea is to view programs as intelligent agents acting on our behalf. By using the metaphor of intelligent agents the programmer views programs as entities which have a mental state consisting of beliefs and goals. The computational behaviour of an agent is explained in terms of the decisions the agent makes on the basis of its mental state. It is assumed that this way of looking at programs may enhance the design and development of complex computational systems.To support this new style of programming, we propose the agent programming language 3APL. 3APL has a clear and formally defined semantics. The operational semantics of the language is defined by means of transition systems. 3APL is a combination of imperative and logic programming. From imperative programming the language inherits the full range of regular programming constructs, including recursive procedures, and a notion of state-based computation. States of agents, however, are belief or knowledge bases, which are different from the usual variable assignments of imperative programming. From logic programming, the language inherits the proof as computation model as a basic means of computation for querying the belief base of an agent. These features are well-understood and provide a solid basis for a structured agent programming language. Moreover, on top of that 3APL agents use so-called practical reasoning rules which extend the familiar recursive rules of imperative programming in several ways. Practical reasoning rules can be used to monitor and revise the goals of an agent, and provide an agent with reflective capabilities.</content></document><document><year>2004</year><authors>Carles Sierra1 </authors><title>Agent-Mediated Electronic Commerce</title><content>Electronic commerce has been one of the traditional arenas for agent technology. The complexity of these applications has been a challenge for researchers that have developed methodologies, products, and systems, having in mind the specificities of trade, the interaction particularities of commerce, the strict notion of commitment and contract, and the clearly shaped conventions and norms that structure the field. In this paper I survey some key areas for agent technology which, although general, are of special importance in electronic commerce, namely, solid development methodologies, negotiation technologies and trust-building mechanisms. I give examples of systems in which I have directly participated, although I also try to refer to the work of other AgentLink Special Interest Group members over the last few years.</content></document><document><year>2004</year><authors>Tuomas S|holm1 </authors><title>Agents in Electronic Commerce: Component Technologies for Automated Negotiation and Coalition Formation</title><content>Automated negotiation and coalition formation among self-interested agents are playing an increasingly important role in electronic commerce. Such agents cannot be coordinated by externally imposing their strategies. Instead the interaction protocols have to be designed so that each agent is motivated to follow the strategy that the protocol designer wants it to follow. This paper reviews six component technologies that we have developed for making such interactions less manipulable and more efficient in terms of the computational processes and the outcomes: 1. OCSM-contracts in marginal cost based contracting, 2. leveled commitment contracts, 3. anytime coalition structure generation with worst case guarantees, 4. trading off computation cost against optimization quality within each coalition, 5. distributing search among insincere agents, and 6. unenforced contract execution. Each of these technologies represents a different way of battling self-interest and combinatorial complexity simultaneously. This is a key battle when multi-agent systems move into large-scale open settings.</content></document><document><year>2004</year><authors>Makoto Yokoo1  | Katsutoshi Hirayama2 </authors><title>Algorithms for Distributed Constraint Satisfaction: A Review</title><content>When multiple agents are in a shared environment, there usually exist constraints among the possible actions of these agents. A distributed constraint satisfaction problem (distributed CSP) is a problem to find a consistent combination of actions that satisfies these inter-agent constraints. Various application problems in multi-agent systems can be formalized as distributed CSPs. This paper gives an overview of the existing research on distributed CSPs. First, we briefly describe the problem formalization and algorithms of normal, centralized CSPs. Then, we show the problem formalization and several MAS application problems of distributed CSPs. Furthermore, we describe a series of algorithms for solving distributed CSPs, i.e., the asynchronous backtracking, the asynchronous weak-commitment search, the distributed breakout, and distributed consistency algorithms. Finally, we show two extensions of the basic problem formalization of distributed CSPs, i.e., handling multiple local variables, and dealing with over-constrained problems.</content></document><document><year>2004</year><authors>Alex|ros Moukas1  | Pattie Maes1 </authors><title>Amalthaea: An Evolving Multi-Agent Information Filtering and Discovery System for the WWW</title><content>Amalthaea is an evolving, multi-agent ecosystem for personalized filtering, discovery, and monitoring of information sites. Amalthaea's primary application domain is the World Wide Web and its main purpose is to assist its users in finding interesting information. Two different categories of agents are introduced in the system: filtering agents that model and monitor the interests of the user and discovery agents that model the information sources.A market-like ecosystem where the agents evolve, compete, and collaborate is presented: agents that are useful to the user or other agents reproduce, while low-performing agents are destroyed. Results from various experiments with different system configurations and varying ratios of user interests versus agents in the system are presented. Finally issues like fine-tuning the initial parameters of the system and establishing and maintaining equilibria in the ecosystem are discussed.</content></document><document><year>2004</year><authors>Mark Ginsburg1</authors><title>An Agent Framework for Intranet Document Management</title><content>Document management inside an organization is a complex and broadly scoped problem. This paper approaches the technical and social issues of Intranet document management by developing a straightforward document lifecycle model consisting of five phases: creation, publication, organization, access, and destruction. A document management system (DMS) which encompasses these areas should also have an evaluation component so its effectiveness can be measured.The document lifecycle is visualized as a waterfall model to help explore the discrete phases of an idealized Intranet DMS. The discussion of this model pinpoints where traditional DMS have fallen short, most notably in the areas of user-to-user and user-to-evaluator communication and coordination.</content></document><document><year>2004</year><authors>David V. Pynadath1  | Milind Tambe1 </authors><title>An Automated Teamwork Infrastructure for Heterogeneous Software Agents and Humans</title><content>Agent integration architectures enable a heterogeneous, distributed set of agents to work together to address problems of greater complexity than those addressed by the individual agents themselves. Unfortunately, integrating software agents and humans to perform real-world tasks in a large-scale system remains difficult, especially due to three main challenges: ensuring robust execution in the face of a dynamic environment, providing abstract task specifications without all the low-level coordination details, and finding appropriate agents for inclusion in the overall system. To address these challenges, our Teamcore project provides the integration architecture with general-purpose teamwork coordination capabilities. We make each agent team-ready by providing it with a proxy capable of general teamwork reasoning. Thus, a key novelty and strength of our framework is that powerful teamwork capabilities are built into its foundations by providing the proxies themselves with a teamwork model.Given this teamwork model, the Teamcore proxies addresses the first agent integration challenge, robust execution, by automatically generating the required coordination actions for the agents they represent. We can also exploit the proxies' reusable general teamwork knowledge to address the second agent integration challenge. Through team-oriented programming, a developer specifies a hierarchical organization and its goals and plans, abstracting away from coordination details. Finally, KARMA, our Knowledgeable Agent Resources Manager Assistant, can aid the developer in conquering the third agent integration challenge by locating agents that match the specified organization's requirements. Our integration architecture enables teamwork among agents with no coordination capabilities, and it establishes and automates consistent teamwork among agents with some coordination capabilities. Thus, team-oriented programming provides a level of abstraction that can be used on top of previous approaches to agent-oriented programming. We illustrate how the Teamcore architecture successfully addressed the challenges of agent integration in two application domains: simulated rehearsal of a military evacuation mission and facilitation of human collaboration.</content></document><document><year>2004</year><authors>Samir Aknine1 | Suzanne Pinson2  | Melvin F. Shakun3 </authors><title>An Extended Multi-Agent Negotiation Protocol</title><content>This article presents a task allocation protocol that is efficient in time and tolerates crash failures in multi-agent systems. The protocol is an extension of the negotiation protocol defined by Smith and Davis [25, 26] for task allocation. Our extension of the Contract Net Protocol (1) enables an agent to manage several negotiation processes in parallel; (2) optimizes the length of the negotiation processes among agents; (3) reduces the contractors' decommitment situations; (4) enables the detection of failures of an agent participating in a negotiation process and prevents a negotiation process with blocked agents.</content></document><document><year>2004</year><authors>Barbara Hayes-Roth1| 2 | Patrick Doyle1</authors><title>Animate Characters</title><content>The world of everyday interactions is filled with characters, real or fictitious, and human knowledge of how to make these interactions satisfying and productive relies upon an understanding of character. As agents become more intelligent and more ubiquitous, we may naturally ask how we can endow them with life and personality to make them easier and more gratifying to use. This paper offers a broad definition of animate character, and examines the technical and artistic issues involved both in the creation and the evaluation of such systems. We provide example interactions with several character types. The paper concludes with an annotated bibliographic survey of work done in this area.</content></document><document><year>2004</year><authors>A. Drogoul1  | A. Collinot1 </authors><title>Applying an Agent-Oriented Methodology to the Design of Artificial Organizations: A Case Study in Robotic Soccer</title><content>The multi-agent paradigm is widely used to provide solutions to a number of organizational problems related to the collective achievement of one or more tasks. All these problems share a common difficulty of design: how to proceed from the global specification of a collective task to the specification of the local behaviors to be provided to the agents? We have defined the Cassiopeia method whose specificity is to articulate the design of a multi-agent system around the notion of organization. This paper reports the use of this method for designing and implementing the organization of a soccer-playing robotic team. We show why we chose this application and how we designed it, and we discuss its interest and inherent difficulties in order to clearly express the needs for a design methodology dedicated to DAI.</content></document><document><year>2004</year><authors>Ranjit Nair1 | Milind Tambe2 | Stacy Marsella3  | Taylor Raines3 </authors><title>Automated Assistants for Analyzing Team Behaviors</title><content>Multi-agent teamwork is critical in a large number of agent applications, including training, education, virtual enterprises and collective robotics. The complex interactions of agents in a team as well as with other agents make it extremely difficult for human developers to understand and analyze agent-team behavior. It has thus become increasingly important to develop tools that can help humans analyze, evaluate, and understand team behaviors. However, the problem of automated team analysis is largely unaddressed in previous work. In this article, we identify several key constraints faced by team analysts. Most fundamentally, multiple types of models of team behavior are necessary to analyze different granularities of team events, including agent actions, interactions, and global performance. In addition, effective ways of presenting the analysis to humans is critical and the presentation techniques depend on the model being presented. Finally, analysis should be independent of underlying team architecture and implementation.We also demonstrate an approach to addressing these constraints by building an automated team analyst called ISAAC for post-hoc, off-line agent-team analysis. ISAAC acquires multiple, heterogeneous team models via machine learning over teams' external behavior traces, where the specific learning techniques are tailored to the particular model learned. Additionally, ISAAC employs multiple presentation techniques that can aid human understanding of the analyses. ISAAC also provides feedback on team improvement in two novel ways: (i) It supports principled what-if reasoning about possible agent improvements; (ii) It allows the user to compare different teams based on their patterns of interactions. This paper presents ISAAC's general conceptual framework, motivating its design, as well as its concrete application in two domains: (i) RoboCup Soccer; (ii) software agent teams participating in a simulated evacuation scenario. In the RoboCup domain, ISAAC was used prior to and during the RoboCup '99 tournament, and was awarded the RoboCup Scientific Challenge Award. In the evacuation domain, ISAAC was used to analyze patterns of message exchanges among software agents, illustrating the generality of ISAAC's techniques. We present detailed algorithms and experimental results from ISAAC's application.</content></document><document><year>2004</year><authors>Chi Keen Low1 | T. Y. Chen1 | Ralph R&amp;oacute nnquist2 </authors><title>Automated Test Case Generation for BDI Agents</title><content>We propose a coverage oriented test case generation methodology for BDI multi-agent systems. The coverage criteria involve plans and nodes within plans of multi-agent systems. We organise the criteria into a subsumption hierarchy to show the coverage relationships between the criteria. Then we apply the criteria on multi-agent systems to analyse some empirical data. The data analysed is the effect on the number of test cases generated automatically for each criterion. We use a tool, BDITESTER, to obtain the empirical data and to show that our proposal is pragmatic. Finally, we suggest some guidelines to select a criterion to automatically generate test cases for BDI agents.</content></document><document><year>2004</year><authors>Andrew Garl|1  | Richard Alterman1 </authors><title>Autonomous Agents that Learn to Better Coordinate</title><content>A fundamental difficulty faced by groups of agents that work together is how to efficiently coordinate their efforts. This coordination problem is both ubiquitous and challenging, especially in environments where autonomous agents are motivated by personal goals.Previous AI research on coordination has developed techniques that allow agents to act efficiently from the outset based on common built-in knowledge or to learn to act efficiently when the agents are not autonomous. The research described in this paper builds on those efforts by developing distributed learning techniques that improve coordination among autonomous agents.</content></document><document><year>2004</year><authors>Jiming Liu1  | Hong Qin1 </authors><title>Behavioral Self-Organization in Lifelike Synthetic Agents</title><content>Modern computer graphics technology has enjoyed rapid development in recent years, attracting researchers and practitioners to explore a wide spectrum of applications ranging from computer-aided graphical design to artificial life and virtual reality. This paper is concerned with the animation-based entertainment use of computer graphics, i.e., to create digitally synthetic agents that can self-animate themselves, adapt to their virtual environments, and learn new behaviors to attain some specific goals. Here we propose a synthetic agent computational architecture called inter-threaded motif-based behavioral self-organization architecture, in which one motif acquires a conditioned association from the presently sensed state of the environment to the requirement of a desired motion as well as a plausible behavioral pattern to enable such a motion, whereas another computes the optimal parameters for the identified behavior in fulfilling the motion requirement. This architecture will enable animated behaviors to be automatically programmed based on the concurrent self-organization of individual motifs as well as their crisscrossing interactions.</content></document><document><year>2004</year><authors>Jos&amp;eacute  M. Vidal1 </authors><title>Book Review</title><content>Without Abstract</content></document><document><year>2009</year><authors>Andrea Giovannucci1| 2 | JesГєs Cerquides3| 4 | Ulle Endriss5  | Juan A. RodrГ­guez-Aguilar2 </authors><title>A graphical formalism for mixed multi-unit combinatorial auctions      </title><content>Mixed multi-unit combinatorial auctions are auctions that allow participants to bid for bundles of goods to buy, for bundles         of goods to sell, and for transformations of goods. The intuitive meaning of a bid for a transformation is that the bidder         is offering to produce a set of output goods after having received a set of input goods. To solve such an auction the auctioneer         has to choose a set of bids to accept and decide on a sequence in which to implement the associated transformations. Mixed         auctions can potentially be employed for the automated assembly of supply chains of agents. However, mixed auctions can be         effectively applied only if we can also ensure their computational feasibility without jeopardising optimality. To this end,         we propose a graphical formalism, based on Petri nets, that facilitates the compact represention of both the search space         and the solutions associated with the winner determination problem for mixed auctions. This approach allows us to dramatically         reduce the number of decision variables required for solving a broad class of mixed auction winner determination problems.         An additional major benefit of our graphical formalism is that it provides new ways to formally analyse the structural and         behavioural properties of mixed auctions.      </content></document><document><year>2009</year><authors>Mary-Anne Williams1 | John McCarthy2 | Peter GГ¤rdenfors3 | Christopher Stanton1  | Alankar Karol1 </authors><title>A grounding framework      </title><content>In order for an agent to achieve its objectives, make sound decisions, communicate and collaborate with others effectively         it must have high quality representations. Representations can encapsulate objects, situations, experiences, decisions and behavior just to name a few. Our interest         is in designing high quality representations, therefore it makes sense to ask of any representation; what does it represent; why is it represented; how is it represented; and importantly how well is it represented. This paper identifies the need to develop a better understanding of the grounding process as key to answering         these important questions. The lack of a comprehensive understanding of grounding is a major obstacle in the quest to develop         genuinely intelligent systems that can make their own representations as they seek to achieve their objectives. We develop         an innovative framework which provides a powerful tool for describing, dissecting and inspecting grounding capabilities with         the necessary flexibility to conduct meaningful and insightful analysis and evaluation. The framework is based on a set of         clearly articulated principles and has three main applications. First, it can be used at both theoretical and practical levels         to analyze grounding capabilities of a single system and to evaluate its performance. Second, it can be used to conduct comparative         analysis and evaluation of grounding capabilities across a set of systems. Third, it offers a practical guide to assist the         design and construction of high performance systems with effective grounding capabilities.      </content></document><document><year>2009</year><authors>Louis-Philippe Morency1 | Iwan de Kok2  | Jonathan Gratch1 </authors><title>A probabilistic multimodal approach for predicting listener backchannels      </title><content>During face-to-face interactions, listeners use backchannel feedback such as head nods as a signal to the speaker that the         communication is working and that they should continue speaking. Predicting these backchannel opportunities is an important         milestone for building engaging and natural virtual humans. In this paper we show how sequential probabilistic models (e.g.,         Hidden Markov Model or Conditional Random Fields) can automatically learn from a database of human-to-human interactions to         predict listener backchannels using the speaker multimodal output features (e.g., prosody, spoken words and eye gaze). The         main challenges addressed in this paper are automatic selection of the relevant features and optimal feature representation         for probabilistic models. For prediction of visual backchannel cues (i.e., head nods), our prediction model shows a statistically         significant improvement over a previously published approach based on hand-crafted rules.      </content></document><document><year>2009</year><authors>Patrick Doherty1 | Jonas KvarnstrГ¶m1  | Fredrik Heintz1 </authors><title>A temporal logic-based planning and execution monitoring framework for unmanned aircraft systems      </title><content>Research with autonomous unmanned aircraft systems is reaching a new degree of sophistication where targeted missions require         complex types of deliberative capability integrated in a practical manner in such systems. Due to these pragmatic constraints,         integration is just as important as theoretical and applied work in developing the actual deliberative functionalities. In         this article, we present a temporal logic-based task planning and execution monitoring framework and its integration into         a fully deployed rotor-based unmanned aircraft system developed in our laboratory. We use a very challenging emergency services         application involving body identification and supply delivery as a vehicle for showing the potential use of such a framework         in real-world applications. TALplanner, a temporal logic-based task planner, is used to generate mission plans. Building further         on the use of TAL (Temporal Action Logic), we show how knowledge gathered from the appropriate sensors during plan execution         can be used to create state structures, incrementally building a partial logical model representing the actual development         of the system and its environment over time. We then show how formulas in the same logic can be used to specify the desired         behavior of the system and its environment and how violations of such formulas can be detected in a timely manner in an execution         monitor subsystem. The pervasive use of logic throughout the higher level deliberative layers of the system architecture provides         a solid shared declarative semantics that facilitates the transfer of knowledge between different modules.      </content></document><document><year>2009</year><authors>Christian Becker-Asano1| 2  | Ipke Wachsmuth1 </authors><title>Affective computing with primary and secondary emotions in a virtual human      </title><content>We introduce the WASABI ([W]ASABI [A]ffect [S]imulation for [A]gents with [B]elievable [I]nteractivity) Affect Simulation         Architecture, in which a virtual human&amp;#8217;s cognitive reasoning capabilities are combined with simulated embodiment to achieve         the simulation of primary and secondary emotions. In modeling primary emotions we follow the idea of &amp;#8220;Core Affect&amp;#8221; in combination         with a continuous progression of bodily feeling in three-dimensional emotion space (PAD space), that is subsequently categorized         into discrete emotions. In humans, primary emotions are understood as onto-genetically earlier emotions, which directly influence         facial expressions. Secondary emotions, in contrast, afford the ability to reason about current events in the light of experiences         and expectations. By technically representing aspects of each secondary emotion&amp;#8217;s connotative meaning in PAD space, we not         only assure their mood-congruent elicitation, but also combine them with facial expressions, that are concurrently driven         by primary emotions. Results of an empirical study suggest that human players in a card game scenario judge our virtual human         MAX significantly older when secondary emotions are simulated in addition to primary ones.      </content></document><document><year>2009</year><authors>Nikolaos Dimakis1 | John Soldatos2 | Lazaros Polymenakos2 | Axel BГјrkle3 | Uwe Pfirrmann3  | Gerhard Sutschet3 </authors><title>Agent-based architectural framework enhancing configurability, autonomy and scalability of context-aware pervasive services      </title><content>Multi-agent software architectures have gained in popularity due to their beneficial behavior in designing and implementing         sophisticated applications. However, current approaches in implementing such architectures have led to application-specific,         non-scalable implementations which limit the reusablity and improvement of the whole architecture. Moreover, these attempts         lack features to enhance the user experience, thus slowing the adoption of the resulting services. In this paper we describe         a fully-fledged multi-agent architecture covering a large variety of preferred features including capabilities of &amp;#8216;plugging&amp;#8217;         ubiquitous services, servicing mobile users, interconnecting remote similar architectures and interfacing with advanced software         components such as knowledge bases. This framework exploits a wide-range of context-aware components making it essentially         context-aware, allowing for the development of ubiquitous context-aware human-centric services, which are the focus of our         research. To illustrate the flexibility of this architectural framework, we present four services which were built using this         architectural paradigm by different development teams and elaborate on their overall behavior.      </content></document><document><year>2009</year><authors>Bo Yang1 | Jiming Liu2  | Dayou Liu1 </authors><title>An autonomy-oriented computing approach to community mining in distributed and dynamic networks      </title><content>A network community refers to a special type of network structure that contains a group of nodes connected based on certain         relationships or similar properties. Our ability to mine communities hidden inside networks will readily enable us to effectively         understand and exploit such networks. So far, various methods and algorithms have been developed to perform the task of community         mining, where it is often required that the networks are processed in a centralized manner, and their structures will not         dynamically change. However, in the real world, many applications involve distributed and dynamically evolving networks, in         which resources and controls are not only decentralized but also updated frequently. It would be difficult for the existing         methods to deal with these types of networks since their global topological representations are either not available or too         hard to obtain due to their huge size, decentralization, and/or dynamic updates. The aim of our work is to address the problem         of mining communities from a distributed and dynamic network. It differs from the previous ones in that here we introduce         the notion of self-organizing agent networks, and provide an autonomy-oriented computing (AOC) approach to distributed and         incremental mining of network communities. The AOC-based method utilizes reactive agents that can collectively detect and         update community structures in a distributed and dynamically evolving network, based only on their local views and interactions.         While providing detailed formulations, we present the results of our systematic validations using real-world benchmark networks         as well as synthetic networks that include a distributed intelligent Portable Digital Assistant (iPDA) network example.      </content></document><document><year>2009</year><authors>Yoram Bachrach1 | Evangelos Markakis2| 3| Ezra Resnick1| Ariel D. Procaccia1| Jeffrey S. Rosenschein1 | Amin Saberi4</authors><title>Approximating power indices: theoretical and empirical analysis      </title><content>Many multiagent domains where cooperation among agents is crucial to achieving a common goal can be modeled as coalitional         games. However, in many of these domains, agents are unequal in their power to affect the outcome of the game. Prior research         on weighted voting games has explored power indices, which reflect how much &amp;#8220;real power&amp;#8221; a voter has. Although primarily used         for voting games, these indices can be applied to any simple coalitional game. Computing these indices is known to be computationally         hard in various domains, so one must sometimes resort to approximate methods for calculating them. We suggest and analyze         randomized methods to approximate power indices such as the Banzhaf power index and the Shapley&amp;#8211;Shubik power index. Our approximation         algorithms do not depend on a specific representation of the game, so they can be used in any simple coalitional game. Our methods are based on testing the game&amp;#8217;s value for several sample coalitions. We show that no         approximation algorithm can do much better for general coalitional games, by providing lower bounds for both deterministic         and randomized algorithms for calculating power indices. We also provide empirical results regarding our method, and show         that it typically achieves much better accuracy and confidence than those required.      </content></document><document><year>2009</year><authors>Massimo Cossentino1| 2 | Nicolas Gaud1 | Vincent Hilaire1 | StГ©phane Gall|1  | AbderrafiГўa Koukam1 </authors><title>ASPECS: an agent-oriented software process for engineering complex systems         How to design agent societies under a holonic perspective</title><content>Holonic multiagent systems (HMAS) offer a promising software engineering approach for developing complex open software systems. However the process of building         Multi-Agent Systems (MAS) and HMAS is mostly different from the process of building more traditional software systems as it introduces new design and development         challenges. This paper introduces an agent-oriented software process for engineering complex systems called ASPECS. ASPECS is based on a holonic organisational metamodel and provides a step-by-step guide from requirements to code allowing the modelling         of a system at different levels of details using a set of refinement methods. This paper details the entire ASPECS development process and provides a set of methodological guidelines for each process activity. A complete case study is also         used to illustrate the design process and the associated notations. ASPECS uses UML as a modelling language. Because of the specific needs of agents and holonic organisational design, the UML semantics and notation are used as reference points, but they have been extended by introducing new specific profiles.      </content></document><document><year>2009</year><authors>Michael Brenner1  | Bernhard Nebel1 </authors><title>Continual planning and acting in dynamic multiagent environments      </title><content>In order to behave intelligently, artificial agents must be able to deliberatively plan their future actions. Unfortunately,         realistic agent environments are usually highly dynamic and only partially observable, which makes planning computationally         hard. For most practical purposes this rules out planning techniques that account for all possible contingencies in the planning         process. However, many agent environments permit an alternative approach, namely continual planning, i.e. the interleaving         of planning with acting and sensing. This paper presents a new principled approach to continual planning that describes why         and when an agent should switch between planning and acting. The resulting continual planning algorithm enables agents to         deliberately postpone parts of their planning process and instead actively gather missing information that is relevant for         the later refinement of the plan. To this end, the algorithm explictly reasons about the knowledge (or lack thereof) of an         agent and its sensory capabilities. These concepts are modelled in the planning language (MAPL). Since in many environments         the major reason for dynamism is the behaviour of other agents, MAPL can also model multiagent environments, common knowledge         among agents, and communicative actions between them. For Continual Planning, MAPL introduces the concept of of assertions,         abstract actions that substitute yet unformed subplans. To evaluate our continual planning approach empirically we have developed         MAPSIM, a simulation environment that automatically builds multiagent simulations from formal MAPL domains. Thus, agents can         not only plan, but also execute their plans, perceive their environment, and interact with each other. Our experiments show         that, using continual planning techniques, deliberate action planning can be used efficiently even in complex multiagent environments.      </content></document><document><year>2009</year><authors>Adriaan ter Mors1| 2 | Chetan Yadati1 | Cees Witteveen1  | Yingqian Zhang1 </authors><title>Coordination by design and the price of autonomy      </title><content>We consider a multi-agent planning problem as a set of activities that has to be planned by several autonomous agents. In         general, due to the possible dependencies between the agents&amp;#8217; activities or interactions during execution of those activities,         allowing agents to plan individually may lead to a very inefficient or even infeasible solution to the multi-agent planning         problem. This is exactly where plan coordination methods come into play. In this paper, we aim at the development of coordination by design techniques that (i) let each agent construct its plan completely independent of the others while (ii) guaranteeing that the         joint combination of their plans always is coordinated. The contribution of this paper is twofold. Firstly, instead of focusing         only on the feasibility of the resulting plans, we will investigate the additional costs incurred by the coordination by design method, that means, we propose to take into account the price of autonomy: the ratio of the costs of a solution obtained by coordinating selfish agents versus the costs of an optimal solution. Secondly,         we will point out that in general there exist at least two ways to achieve coordination by design: one called concurrent decomposition and the other sequential decomposition. We will briefly discuss the applicability of these two methods, and then illustrate them with two specific coordination         problems: coordinating tasks and coordinating resource usage. We also investigate some aspects of the price of autonomy of         these two coordination methods.      </content></document><document><year>2009</year><authors>Paolo Turrini1 | John-Jules Ch. Meyer1 | Cristiano Castelfranchi2</authors><title>Coping with shame and sense of guilt: a Dynamic Logic Account      </title><content>Aim of this work is to provide a formal characterization of those emotions that deal with normative reasoning, such as shame         and sense of guilt, to understand their relation with rational action and to ground their formalization on a cognitive science         perspective. In order to do this we need to identify the factors that constitute the preconditions and trigger the reactions         of shame and sense of guilt in cognitive agents, that is when agents feel ashamed or guilty and what agents do when they feel so. We will also investigate how agents can induce and silence these feelings in themselves, i.e.         the analysis of defensive strategies they can employ. We will argue that agents do have control over their emotions and we         will analyze some operations they can carry out on them.      </content></document><document><year>2009</year><authors>Shimon Whiteson1 | Matthew E. Taylor2  | Peter Stone3 </authors><title>Critical factors in the empirical performance of temporal difference and evolutionary methods for reinforcement learning      </title><content>Temporal difference and evolutionary methods are two of the most common approaches to solving reinforcement learning problems.         However, there is little consensus on their relative merits and there have been few empirical studies that directly compare         their performance. This article aims to address this shortcoming by presenting results of empirical comparisons between Sarsa         and NEAT, two representative methods, in mountain car and keepaway, two benchmark reinforcement learning tasks. In each task,         the methods are evaluated in combination with both linear and nonlinear representations to determine their best configurations.         In addition, this article tests two specific hypotheses about the critical factors contributing to these methods&amp;#8217; relative         performance: (1) that sensor noise reduces the final performance of Sarsa more than that of NEAT, because Sarsa&amp;#8217;s learning         updates are not reliable in the absence of the Markov property and (2) that stochasticity, by introducing noise in fitness         estimates, reduces the learning speed of NEAT more than that of Sarsa. Experiments in variations of mountain car and keepaway         designed to isolate these factors confirm both these hypotheses.      </content></document><document><year>2009</year><authors>Brent Lance1  | Stacy Marsella1 </authors><title>Glances, glares, and glowering: how should a virtual human express emotion through gaze?      </title><content>Gaze is an extremely powerful expressive signal that is used for many purposes, from expressing emotion to regulating human         interaction. The use of gaze as a signal has been exploited to strong effect in hand-animated characters, greatly enhancing         the believability of the character&amp;#8217;s simulated life. However, virtual humans animated in real-time have been less successful         at using expressive gaze. One reason for this is that we lack a model of expressive gaze in virtual humans. A gaze shift towards         any specific target can be performed in many different ways, using many different expressive manners of gaze, each of which         can potentially imply a different emotional or cognitive internal state. However, there is currently no mapping that describes         how a user will attribute these internal states to a virtual character performing a gaze shift in a particular manner. In         this paper, we begin to address this by providing the results of an empirical study that explores the mapping between an observer&amp;#8217;s         attribution of emotional state to gaze. The purpose of this mapping is to allow for an interactive virtual human to generate         believable gaze shifts that a user will attribute a desired emotional state to. We have generated a set of animations by composing         low-level gaze attributes culled from the nonverbal behavior literature. Then, subjects judged the animations displaying these         attributes. While the results do not provide a complete mapping between gaze and emotion, they do provide a basis for a generative         model of expressive gaze.      </content></document><document><year>2009</year><authors>Rafael H. Bordini1  | Mehdi Dastani2 </authors><title>Guest editorial: Special issue on the European Workshop on Multi-Agent Systems (EUMAS)      </title><content>Without Abstract</content></document><document><year>2009</year><authors>Stefan Kopp1 | Ruth Aylett1| Jonathan Gratch1| Patrick L. Olivier1 | Catherine Pelachaud1</authors><title>Guest editorial of the special issue on intelligent virtual agents      </title><content>Without Abstract</content></document><document><year>2009</year><authors>Jomi F. HГјbner1 | Olivier Boissier1 | Rosine Kitio1  | Aless|ro Ricci2 </authors><title>Instrumenting multi-agent organisations with organisational artifacts and agents         &amp;#8220;Giving the organisational power back to the agents&amp;#8221;</title><content>The social and organisational aspects of agency have led to a good amount of theoretical work in terms of formal models and         theories. However, the conception and engineering of proper organisational infrastructures embodying such models and theories         are still an open issue. The introduction of normative concerns with requirements of openness and adaptation stresses this         issue. The corresponding mechanisms for the current infrastructures appear to be not appropriate for managing distributed         and open normative organisations. There is still the need of proper abstractions and tools to facilitate application agents         taking part in the monitoring of the organisation on one hand, and in the adaptation and definition of the organisation in         which they are situated on the other hand. In this paper we present and discuss ORA4MAS (Organisational Artifacts for Multi-Agent Systems), a proposed approach aiming at these issues. Based on the Agents and Artifacts         meta-model (A&amp;amp;A), it introduces organisational artifacts as first class entities to instrument the organisation for supporting agents activities         within it.      </content></document><document><year>2009</year><authors>Masahiro Fujita1 </authors><title>Intelligence Dynamics: a concept and preliminary experiments for open-ended learning agents      </title><content>We propose a novel approach that aims to realize autonomous developmental intelligence called Intelligence Dynamics. We emphasize         two technical features of dynamics and embodiment in comparison with the symbolic approach of the conventional Artificial         Intelligence. The essential conceptual idea of this approach is that an embodied agent interacts with the real world to learn         and develop its intelligence as attractors of the dynamic interaction. We develop two computational models, one is for self-organizing         multi-attractors, and the other provides a motivational system for open-ended learning agents. The former model is realized         by recurrent neural networks with a small humanoid body in the real world, and the later is realized by hierarchical support         vector machines with inverted pendulum agents in a virtual world. Although they are preliminary experiments, they take important         first steps towards demonstrating the feasibility and value of open-ended learning agents with the concept of Intelligence         Dynamics.      </content></document><document><year>2009</year><authors>Xiaoping Chen1| Wei Liu2  | Mary-Anne Williams3</authors><title>Introduction: Practical Cognitive Agents and Robots      </title><content>Without Abstract</content></document><document><year>2009</year><authors>Stefan Gruner1 </authors><title>Mobile agent systems and cellular automata      </title><content>The purpose of this article (based on an earlier draft available as technical report: Gruner S, Mobile agent systems and cellular automata. LaBRI Research Reports, 2006) is to make a step towards uniting the paradigms of cellular automata and mobile agents, thus         consequentially the fields of artificial life and multi agent systems, which have significant overlap but are still largely         perceived as separate fields. In Chalopin et;al. (Mobile agent algorithms versus message passing algorithms, pp. 187&amp;#8211;201,         2006) the equivalent power of classical distributed algorithms and mobile agent algorithms was demonstrated for asynchronous         systems with interleaving semantics under some further constraints and assumptions. Similar results are still being sought         about mobile agent systems and distributed systems under other constraints and assumptions in search of a comprehensive general         theory of these topics. This article investigates the relationship between mobile agent systems and a generalized form of         cellular automata. With a particular notion of local equivalence, a cellular automaton can be translated into a mobile agent         system and vice versa. The article shows that if the underlying network graph is finite, then the degree of pseudo-synchrony         of the agent system simulating the cellular automaton can be made arbitrarily high, even with an only small number of active         agents. As a possible consequence of this theoretical result, the Internet might be used in the future to implement large         cellular automata of almost arbitrary topology.      </content></document><document><year>2009</year><authors>Mei Si1 | Stacy C. Marsella1  | David V. Pynadath1 </authors><title>Modeling appraisal in theory of mind reasoning      </title><content>Cognitive appraisal theories, which link human emotional experience to their interpretations of events happening in the environment,         are leading approaches to model emotions. Cognitive appraisal theories have often been used both for simulating &amp;#8220;real emotions&amp;#8221;         in virtual characters and for predicting the human user&amp;#8217;s emotional experience to facilitate human&amp;#8211;computer interaction. In         this work, we investigate the computational modeling of appraisal in a multi-agent decision-theoretic framework using Partially         Observable Markov Decision Process-based (POMDP) agents. Domain-independent approaches are developed for five key appraisal         dimensions (motivational relevance, motivation congruence, accountability, control and novelty). We also discuss how the modeling         of theory of mind (recursive beliefs about self and others) is realized in the agents and is critical for simulating social         emotions. Our model of appraisal is applied to three different scenarios to illustrate its usages. This work not only provides         a solution for computationally modeling emotion in POMDP-based agents, but also illustrates the tight relationship between         emotion and cognition&amp;#8212;the appraisal dimensions are derived from the processes and information required for the agent&amp;#8217;s decision-making         and belief maintenance processes, which suggests a uniform cognitive structure for emotion and cognition.      </content></document><document><year>2009</year><authors>Jonathan Y. Ito1 | David V. Pynadath1  | Stacy C. Marsella1 </authors><title>Modeling self-deception within a decision-theoretic framework      </title><content>Computational modeling of human belief maintenance and decision-making processes has become increasingly important for a wide         range of applications. In this paper, we present a framework for modeling the human capacity for self-deception from a decision-theoretic         perspective in which we describe an integrated process of wishful thinking which includes the determination of a desired belief         state, the biasing of internal beliefs towards or away from this desired belief state, and the final decision-making process.         Finally, we show that in certain situations self-deception can be beneficial.      </content></document><document><year>2009</year><authors>Cagatay Undeger1  | Faruk Polat1 </authors><title>Multi-agent real-time pursuit      </title><content>In this paper, we address the problem of multi-agent pursuit in dynamic and partially observable environments, modeled as         grid worlds; and present an algorithm called Multi-Agent Real-Time Pursuit (MAPS) for multiple predators to capture a moving         prey cooperatively. MAPS introduces two new coordination strategies namely Blocking Escape Directions and Using Alternative         Proposals, which help the predators waylay the possible escape directions of the prey in coordination. We compared our coordination         strategies with the uncoordinated one against a prey controlled by Prey A*, and observed an impressive reduction in the number         of moves to catch the prey.      </content></document><document><year>2009</year><authors>Paulo Roberto Ferreira Jr.1| 2 | Fern|o dos Santos1 | Ana L. C. Bazzan1 | Daniel Epstein1  | Samuel J. Waskow1 </authors><title>RoboCup Rescue as multiagent task allocation among teams: experiments with task interdependencies      </title><content>This paper addresses distributed task allocation among teams of agents in a RoboCup Rescue scenario. We are primarily concerned         with testing different mechanisms that formalize issues underlying implicit coordination among teams of agents. These mechanisms         are developed, implemented, and evaluated using two algorithms: Swarm-GAP and LA-DCOP. The latter bases task allocation on         a comparison between an agent&amp;#8217;s capability to perform a task and the capability demanded by this task. Swarm-GAP is a probabilistic         approach in which an agent selects a task using a model inspired by task allocation among social insects. Both algorithms         were also compared to another one that allocates tasks in a greedy way. Departing from previous works that tackle task allocation         in the rescue scenario only among fire brigades, here we consider the various actors in the RoboCup Rescue, a step forward         in the direction of realizing the concept of extreme teams. Tasks are allocated to teams of agents without explicit negotiation         and using only local information. Our results show that the performance of Swarm-GAP and LA-DCOP are similar and that they         outperform a greedy strategy. Also, it is possible to see that using more sophisticated mechanisms for task selection does         pay off in terms of score.      </content></document><document><year>2009</year><authors>Yann Chevaleyre1 | Ulle Endriss2  | Nicolas Maudet3 </authors><title>Simple negotiation schemes for agents with simple preferences: sufficiency, necessity and maximality      </title><content>We investigate the properties of an abstract negotiation framework where agents autonomously negotiate over allocations of         indivisible resources. In this framework, reaching an allocation that is optimal may require very complex multilateral deals.         Therefore, we are interested in identifying classes of valuation functions such that any negotiation conducted by means of         deals involving only a single resource at a time is bound to converge to an optimal allocation whenever all agents model their         preferences using these functions. In the case of negotiation with monetary side payments amongst self-interested but myopic         agents, the class of modular valuation functions turns out to be such a class. That is, modularity is a sufficient condition         for convergence in this framework. We also show that modularity is not a necessary condition. Indeed, there can be no condition         on individual valuation functions that would be both necessary and sufficient in this sense. Evaluating conditions formulated         with respect to the whole profile of valuation functions used by the agents in the system would be possible in theory, but         turns out to be computationally intractable in practice. Our main result shows that the class of modular functions is maximal         in the sense that no strictly larger class of valuation functions would still guarantee an optimal outcome of negotiation,         even when we permit more general bilateral deals. We also establish similar results in the context of negotiation without         side payments.      </content></document><document><year>2009</year><authors>Loizos Michael1 | David C. Parkes2  | Avi Pfeffer2 </authors><title>Specifying and monitoring economic environments using rights and obligations      </title><content>We provide a formal scripting language to capture the semantics of economic environments. The language is based on a set of         well-defined design principles and makes explicit an agent&amp;#8217;s rights, as derived from property, and an agent&amp;#8217;s obligations,         as derived from restrictions placed on its actions either voluntarily or as a consequence of other actions. Coupled with the         language is a run-time system that is able to monitor and enforce rights and obligations in an agent-mediated economic environment.         The framework allows an agent to formally express guarantees (obligations) in relation to its actions, and the run-time system         automatically checks that these obligations are met and verifies that an agent has appropriate rights before executing an         action. Rights and obligations are viewed as first-class goods that can be transferred from one agent to another. This treatment makes it easy to define natural and expressive recursive         statements, so that, for instance, one may have rights or obligations in selling or trading some other right or obligation.         We define fundamental axioms about well-functioning markets in terms of rights and obligations, and delineate the difference between ownership and possession, arguably two of the most important notions in economic markets. The framework provides a rich set of action-related constructs         for modeling conditional and non-deterministic effects, and introduces the use of transactions to safely bundle actions, including         the issuing of rights and taking on of obligations. By way of example, we show that our language can represent a variety of         economic mechanisms, ranging from simple two-agent single-good exchanges to complicated combinatorial auctions. The framework,         which is fully implemented, can be used to formalize the semantics of markets; as a platform for prototyping, testing and         evaluating agent-mediated markets; and also provide a basis for deploying an electronic market.      </content></document><document><year>2009</year><authors>Anja Austermann1  | Seiji Yamada2 </authors><title>Teaching a pet-robot to understand user feedback through interactive virtual training tasks      </title><content>In this paper, we present a human-robot teaching framework that uses &amp;#8220;virtual&amp;#8221; games as a means for adapting a robot to its         user through natural interaction in a controlled environment. We present an experimental study in which participants instruct         an AIBO pet robot while playing different games together on a computer generated playfield. By playing the games and receiving         instruction and feedback from its user, the robot learns to understand the user&amp;#8217;s typical way of giving multimodal positive         and negative feedback. The games are designed in such a way that the robot can reliably predict positive or negative feedback         based on the game state and explore its user&amp;#8217;s reward behavior by making good or bad moves. We implemented a two-staged learning         method combining Hidden Markov Models and a mathematical model of classical conditioning to learn how to discriminate between         positive and negative feedback. The system combines multimodal speech and touch input for reliable recognition. After finishing         the training, the system was able to recognize positive and negative reward with an average accuracy of 90.33%.      </content></document><document><year>2008</year><authors>Mehdi Dastani1 </authors><title>2APL: a practical agent programming language      </title><content>This article presents a BDI-based agent-oriented programming language, called 2APL (A Practical Agent Programming Language).         This programming language facilitates the implementation of multi-agent systems consisting of individual agents that may share         and access external environments. It realizes an effective integration of declarative and imperative style programming by         introducing and integrating declarative beliefs and goals with events and plans. It also provides practical programming constructs         to allow the generation, repair, and (different modes of) execution of plans based on beliefs, goals, and events. The formal         syntax and semantics of the programming language are given and its relation with existing BDI-based agent-oriented programming         languages is discussed.      </content></document><document><year>2008</year><authors>Danny Weyns1 | Nelis BouckГ©1  | Tom Holvoet1 </authors><title>A field-based versus a protocol-based approach for adaptive task assignment      </title><content>Task assignment in multi-agent systems is a complex coordination problem, in particular in systems that are subject to dynamic         and changing operating conditions. To enable agents to deal with dynamism and change, adaptive task assignment approaches         are needed. In this paper, we study two approaches for adaptive task assignment that are characteristic for two classical         families of task assignment approaches. FiTA is a field-based approach in which tasks emit fields in the environment that         guide idle agents to tasks. DynCNET is a protocol-based approach that extends Standard Contract Net (CNET). In DynCNET, agents         use explicit negotiation to assign tasks. We compare both approaches in a simulation of an industrial automated transportation         system. Our experiences show that: (1) the performance of DynCNET and FiTA are similar, while both outperform CNET; (2) the         complexity to engineer DynCNET is similar to FiTA but much more complex than CNET; (3) whereas task assignment with FiTA is         an emergent solution, DynCNET specifies the interaction among agents explicitly allowing engineers to reason on the assignment         of tasks, (4) FiTA is inherently robust to message loss while DynCNET requires substantial additional support. The tradeoff         between (3) and (4) is an important criteria for the selection of an adaptive task assignment approach in practice.      </content></document><document><year>2008</year><authors>Silvio Lago Pereira1  | Leliane Nunes de Barros1 </authors><title>A logic-based agent that plans for extended reachability goals      </title><content>Planning to reach a goal is an essential capability for rational agents. In general, a goal specifies a condition to be achieved         at the end of the plan execution. In this article, we introduce nondeterministic planning for extended reachability goals (i.e., goals that also specify a condition to be preserved during the plan execution). We show that, when this kind of goal is         considered, the temporal logic ctl turns out to be inadequate to formalize plan synthesis and plan validation algorithms. This is mainly due to the fact that         the ctl&amp;#8217;s semantics cannot discern among the various actions that produce state transitions. To overcome this limitation, we propose         a new temporal logic called &amp;#945;-ctl. Then, based on this new logic, we implement a planner capable of synthesizing reliable plans for extended reachability goals,         as a side effect of model checking.      </content></document><document><year>2008</year><authors>Christian Hahn1 | CristiГЎn Madrigal-Mora1  | Klaus Fischer1 </authors><title>A platform-independent metamodel for multiagent systems      </title><content>Various agent-oriented methodologies and metamodels exist to design and develop multiagent systems (MAS) in an abstract manner.         Frequently, these frameworks specialise on particular parts of the MAS and only few works have been invested to derive a common         standardisation. This limits the impact of agent-related systems in commercial applications. In this paper, we present a metamodel         for agent systems that abstracts from existing agent-oriented methodologies, programming languages, and platforms and could         thus be considered as platform-independent. This metamodel defines the abstract syntax of a proposed domain-specific modelling         language for MAS that is currently under development and provides furthermore the base to generate code out of the generated         designs. This is done by applying the principles of model-driven development (MDD) and providing two model transformations         that allow transforming the generated models into textual code that can be executed with JACK and JADE.      </content></document><document><year>2008</year><authors>Marius C. Silaghi1  | Makoto Yokoo2 </authors><title>ADOPT-ing: unifying asynchronous distributed optimization with asynchronous backtracking      </title><content>This article presents an asynchronous algorithm for solving distributed constraint optimization problems (DCOPs). The proposed         technique unifies asynchronous backtracking (ABT) and asynchronous distributed optimization (ADOPT) where valued nogoods enable         more flexible reasoning and more opportunities for communication, leading to an important speed-up. While feedback can be         sent in ADOPT by COST messages only to one predefined predecessor, our extension allows for sending such information to any         relevant agent. The concept of valued nogood is an extension by Dago and Verfaille of the concept of classic nogood that associates         the list of conflicting assignments with a cost and, optionally, with a set of references to culprit constraints. DCOPs have         been shown to have very elegant distributed solutions, such as ADOPT, distributed asynchronous overlay (DisAO), or DPOP. These         algorithms are typically tuned to minimize the longest causal chain of messages as a measure of how the algorithms will scale         for systems with remote agents (with large latency in communication). ADOPT has the property of maintaining the initial distribution         of the problem. To be efficient, ADOPT needs a preprocessing step consisting of computing a Depth-First Search (DFS) tree         on the constraint graph. Valued nogoods allow for automatically detecting and exploiting the best DFS tree compatible with         the current ordering. To exploit such DFS trees it is now sufficient to ensure that they exist. Also, the inference rules         available for valued nogoods help to exploit schemes of communication where more feedback is sent to higher priority agents.         Together they result in an order of magnitude improvement.      </content></document><document><year>2008</year><authors>Lawrence Henesey1 | Paul Davidsson2  | Jan A. Persson1 </authors><title>Agent based simulation architecture for evaluating operational policies in transshipping containers      </title><content>An agent based simulator for evaluating operational policies in the transshipment of containers in a container terminal is         described. The simulation tool, called SimPort, is a decentralized approach to simulating managers and entities in a container         terminal. Real data from two container terminals are used as input for evaluating eight transshipment policies. The policies         concern the sequencing of ships, berth allocation, and stacking rule. They are evaluated with respect to a number of aspects,         such as, turn-around time for ships and traveled distance of straddle carriers. The simulation results indicate that a good         choice in yard stacking and berthing position policies can lead to faster ship turn-around times. For instance, in the terminal         studied the Overall-Time-Shortening policy offers fast turn-around times when combined with a Shortest-Job-First sequencing         of arriving ships.      </content></document><document><year>2008</year><authors>Elizabeth Black1  | Anthony Hunter2</authors><title>An inquiry dialogue system      </title><content>The majority of existing work on agent dialogues considers negotiation, persuasion or deliberation dialogues; we focus on         inquiry dialogues, which allow agents to collaborate in order to find new knowledge. We present a general framework for representing         dialogues and give the details necessary to generate two subtypes of inquiry dialogue that we define: argument inquiry dialogues         allow two agents to share knowledge to jointly construct arguments; warrant inquiry dialogues allow two agents to share knowledge         to jointly construct dialectical trees (essentially a tree with an argument at each node in which a child node is a counter         argument to its parent). Existing inquiry dialogue systems only model dialogues, meaning they provide a protocol which dictates         what the possible legal next moves are but not which of these moves to make. Our system not only includes a dialogue-game         style protocol for each subtype of inquiry dialogue that we present, but also a strategy that selects exactly one of the legal         moves to make. We propose a benchmark against which we compare our dialogues, being the arguments that can be constructed         from the union of the agents&amp;#8217; beliefs, and use this to define soundness and completeness properties that we show hold for         all inquiry dialogues generated by our system.      </content></document><document><year>2008</year><authors>Adrian K. Agogino1  | Kagan Tumer2 </authors><title>Analyzing and visualizing multiagent rewards in dynamic and stochastic domains      </title><content>The ability to analyze the effectiveness of agent reward structures is critical to the successful design of multiagent learning         algorithms. Though final system performance is the best indicator of the suitability of a given reward structure, it is often         preferable to analyze the reward properties that lead to good system behavior (i.e., properties promoting coordination among         the agents and providing agents with strong signal to noise ratios). This step is particularly helpful in continuous, dynamic,         stochastic domains ill-suited to simple table backup schemes commonly used in TD(&amp;#955;)/Q-learning where the effectiveness of         the reward structure is difficult to distinguish from the effectiveness of the chosen learning algorithm. In this paper, we         present a new reward evaluation method that provides a visualization of the tradeoff between the level of coordination among         the agents and the difficulty of the learning problem each agent faces. This method is independent of the learning algorithm         and is only a function of the problem domain and the agents&amp;#8217; reward structure. We use this reward property visualization method         to determine an effective reward without performing extensive simulations. We then test this method in both a static and a         dynamic multi-rover learning domain where the agents have continuous state spaces and take noisy actions (e.g., the agents&amp;#8217;         movement decisions are not always carried out properly). Our results show that in the more difficult dynamic domain, the reward         efficiency visualization method provides a two order of magnitude speedup in selecting good rewards, compared to running a         full simulation. In addition, this method facilitates the design and analysis of new rewards tailored to the observational         limitations of the domain, providing rewards that combine the best properties of traditional rewards.      </content></document><document><year>2008</year><authors>A. Doniec1 | R. M|iau2 | S. Piechowiak2  | S. EspiГ©3 </authors><title>Anticipation based on constraint processing in a multi-agent context      </title><content>Anticipation is a general concept used and applied in various domains. Many studies in the field of artificial intelligence         have investigated the capacity for anticipation. In this article, we focus on the use of anticipation in multi-agent coordination,         particularly preventive anticipation which consists of anticipating undesirable future situations in order to avoid them.         We propose to use constraint processing to formalize preventive anticipation in the context of multi-agent coordination. The         resulting algorithm allows any action that may induce an undesirable future state to be detected upstream of any multi-agent         coordination process. Our proposed method is instantiated in a road traffic simulation tool. For the specific question of         simulating traffic at road junctions, our results show that taking anticipation into account allows globally realistic behaviors         to be reproduced without provoking gridlock between the simulated vehicles.      </content></document><document><year>2008</year><authors>Andrea Omicini1 | Aless|ro Ricci1  | Mirko Viroli1 </authors><title>Artifacts in the A&amp;amp;A meta-model for multi-agent systems      </title><content>In this article we focus on the notion of artifact for agents in multi-agent systems (MAS) as a basis for a new meta-model promoting the modelling and engineering of agent         societies and MAS environment as first-class entities. Its conceptual foundations lay upon theories and results coming from         computational sciences as well as from organisational and cognitive sciences, psychology, computer supported cooperative work         (CSCW), anthropology and ethology. In the resulting agents &amp;amp; artifacts (A&amp;amp;A) meta-model, agents are the (pro-)active entities         in charge of the goals/tasks that altogether build up the whole MAS behaviour, whereas artifacts are the reactive entities         providing the services and functions that make individual agents work together in a MAS, and that shape agent environment         according to the MAS needs. After presenting the scientific background, we define the notions of artifact in the A&amp;amp;A meta-model,         discuss how it affects the notion of intelligence in MAS, and show its application to a number of agent-related research fields.      </content></document><document><year>2008</year><authors>Raffaele Quitadamo1  | Franco Zambonelli2 </authors><title>Autonomic communication services: a new challenge for software agents      </title><content>The continuous growth in ubiquitous and mobile network connectivity, together with the increasing number of networked devices         populating our everyday environments, call for a deep rethinking of traditional communication and service architectures. The         emerging area of autonomic communication addresses such challenging issues by trying to identify novel flexible network architectures,         and by conceiving novel conceptual and practical tools for the design, development, and execution of &amp;#8220;autonomic&amp;#8221; (i.e., self-organizing,         self-adaptive and context-aware) communication services. In this paper, after having introduced the general concepts behind         autonomic communication and autonomic communication services, we analyze the key issue of defining suitable &amp;#8220;component&amp;#8221; models         for autonomic communication services, and discuss the strict relation between such models and agent models. On this basis,         we survey and compare different approaches, and eventually try to synthesize the key desirable characteristics that one should         expect from a general-purpose component model for autonomic communication services. The key message we will try to deliver         is that current research in software agents and multi-agent systems have the potential for playing a major role in inspiring         and driving the identification of such a model, and more in general for influencing and advancing the whole area of autonomic         communication.      </content></document><document><year>2008</year><authors>Guido Governatori1 | Antonino Rotolo2 </authors><title>BIO logical agents: Norms, beliefs, intentions in defeasible logic      </title><content>In this paper we follow the BOID (Belief, Obligation, Intention, Desire) architecture to describe agents and agent types in         Defeasible Logic. We argue, in particular, that the introduction of obligations can provide a new reading of the concepts         of intention and intentionality. Then we examine the notion of social agent (i.e., an agent where obligations prevail over         intentions) and discuss some computational and philosophical issues related to it. We show that the notion of social agent         either requires more complex computations or has some philosophical drawbacks.      </content></document><document><year>2008</year><authors>Jason M. O&amp;#8217 Kane1 </authors><title>Book Review: Maja J. Matari&amp;#263;: The Robotics Primer         MIT Press, Cambridge, 2007, 300pp, $30.00, ISBN 0-262-63354-X</title><content>Without Abstract</content></document><document><year>2008</year><authors>Elise Bonzon1 | Marie-Christine Lagasquie-Schiex1 | JГ©rГґme Lang1  | Bruno Zanuttini2 </authors><title>Compact preference representation and Boolean games      </title><content>Game theory is a widely used formal model for studying strategical interactions between agents. Boolean games (Harrenstein, Logic in conflict, PhD thesis, 2004; Harrenstein et al., Theoretical Aspects of Rationality and Knowledge, pp. 287&amp;#8211;298, San Francisco Morgan Kaufmann, 2001) yield a compact representation of 2-player zero-sum static games with         binary preferences: an agent&amp;#8217;s strategy consists of a truth assignment of the propositional variables she controls, and a         player&amp;#8217;s preferences are expressed by a plain propositional formula. These restrictions (2-player, zero-sum, binary preferences)         strongly limit the expressivity of the framework. We first generalize the framework to n-player games which are not necessarily zero-sum. We give simple characterizations of Nash equilibria and dominated strategies,         and investigate the computational complexity of the associated problems. Then, we relax the last restriction by coupling Boolean         games with a representation, namely, CP-nets.      </content></document><document><year>2008</year><authors>Sven Koenig1  | Xiaoxun Sun1 </authors><title>Comparing real-time and incremental heuristic search for real-time situated agents      </title><content>Real-time situated agents, such as characters in real-time computer games, often do not know the terrain in advance but automatically         observe it within a certain range around themselves. They have to interleave searches with action executions to make the searches         tractable when moving autonomously to user-specified coordinates. The searches face real-time requirements since it is important         that the agents be responsive to the commands of the users and move smoothly. In this article, we compare two classes of fast         heuristic search methods for these navigation tasks that speed up A* searches in different ways, namely real-time heuristic         search and incremental heuristic search, to understand their advantages and disadvantages and make recommendations about when         each one should be used. We first develop a competitive real-time heuristic search method. LSS-LRTA* is a version of Learning         Real-Time A* that uses A* to determine its local search spaces and learns quickly. We analyze the properties of LSS-LRTA*         and then compare it experimentally against the state-of-the-art incremental heuristic search method D* Lite on our navigation         tasks, for which D* Lite was specifically developed, resulting in the first comparison of real-time and incremental heuristic         search in the literature. We characterize when to choose each one of the two heuristic search methods, depending on the search         objective and the kind of terrain. Our experimental results show that LSS-LRTA* can outperform D* Lite under the right conditions,         namely when there is time pressure or the user-supplied h-values are generally not misleading.      </content></document><document><year>2008</year><authors>Francesca Toni1  | Jamal Bentahar2 </authors><title>Computational logic-based agents      </title><content>Without Abstract</content></document><document><year>2008</year><authors>AndrГ©s GarcГ­a-Camino1 | Juan A. RodrГ­guez-Aguilar1 | Carles Sierra1  | Wamberto Vasconcelos2 </authors><title>Constraint rule-based programming of norms for electronic institutions      </title><content>Norms constitute a powerful coordination mechanism among heterogeneous agents. In this paper, we propose a rule language to         specify and explicitly manage the normative positions of agents (permissions, prohibitions and obligations), with which distinct         deontic notions and their relationships can be captured. Our rule-based formalism includes constraints for more expressiveness         and precision and allows to supplement (and implement) electronic institutions with norms. We also show how some normative         aspects are given computational interpretation.      </content></document><document><year>2008</year><authors>Jiefei Ma1 | Aless|ra Russo1 | Krysia Broda1  | Keith Clark1 </authors><title>DARE: a system for distributed abductive reasoning      </title><content>Abductive reasoning is a well established field of Artificial Intelligence widely applied to different problem domains not         least cognitive robotics and planning. It has been used to abduce high-level descriptions of the world from robot sense data,         using rules that tell us what sense data would be generated by certain objects and events of the robots world, subject to         certain constraints on their co-occurrence. It has also been used to abduce actions that might result in a desired goal state         of the world, using descriptions of the normal effects of these actions, subject to constraints on the action combinations.         We can generalise these applications to a multi-agent context. Several robots can collaboratively try to abduce an agreed         higher-level description of the state of the world from their separate sense data consistent with their collective constraints         on the abduced description. Similarly, multi-agent planning can be accomplished by the abduction of the actions of a collective         plan where each agent uses its own description of the effect of its actions within the plan, such that the constraints on         the actions of all the participating agents are satisfied. To address this class of problems, we need to generalise the single         agent abductive reasoning algorithm to a distributed abductive inference algortihm. In addition, if we want to investigate         applications in which the set of collaborating robots/agents is open, we need an algorithm that allows agents to join or leave         the collaborating group whilst a particular inference is under way, but which still produces sound abductive inferences. This         paper describes such a distributed abductive reasoning system, which we call DARE, and its implementation in the multi-threaded         Qu-Prolog variant of Prolog. We prove the soundness of the algorithm it uses and we discuss its completeness in relation to         non-distributed abductive reasoning. We illustrate the use of the algorithm with a multi-agent meeting scheduling example.         The task is open in that the actual agents who need to attend is not determined in advance. Each individual agent has its         own constraints on the possible meeting time and concerning which other agents must or must attend the meeting, if it attends.         The algorithm selects the agents to attend and ensures that the constraints of each of the attending agents are satisfied.      </content></document><document><year>2008</year><authors>Gal A. Kaminka1 </authors><title>Detecting disagreements in large-scale multi-agent teams      </title><content>Intermittent sensory, actuation and communication failures may cause agents to fail in maintaining their commitments to others.         Thus to collaborate robustly, agents must monitor others to detect coordination failures. Previous work on monitoring has         focused mainly on small-scale systems, with only a limited number of agents. However, as the number of monitored agents is         scaled up, two issues are raised that challenge previous work. First, agents become physically and logically disconnected         from their peers, and thus their ability to monitor each other is reduced. Second, the number of possible coordination failures         grows exponentially, with all potential interactions. Thus previous techniques that sift through all possible failure hypotheses         cannot be used in large-scale teams. This paper tackles these challenges in the context of detecting disagreements among team-members,         a monitoring task that is of particular importance to robust teamwork. First, we present new bounds on the number of agents         that must be monitored in a team to guarantee disagreement detection. These bounds significantly reduce the connectivity requirements         of the monitoring task in the distributed case. Second, we present YOYO, a highly scalable disagreement-detection algorithm         which guarantees sound detection. YOYO&amp;#8217;s run-time scales linearly in the number of monitored agents, despite the exponential         number of hypotheses. It compactly represents all valid hypotheses in single structure, while allowing for a complex hierarchical         organizational structure to be considered in the monitoring. Both YOYO and the new bounds are explored analytically and empirically         in monitoring problems involving thousands of agents.      </content></document><document><year>2008</year><authors>Luke Hunsberger1  | Charles L. Ortiz Jr.2 </authors><title>Dynamic intention structures I: a theory of intention representation      </title><content>This article introduces a new theory of intention representation which is based on a structure called a Dynamic Intention         Structure (DIS). The theory of DISs was motivated by the problem of how to properly represent incompletely specified intentions         and their evolution. Since the plans and intentions of collaborating agents are most often elaborated incrementally and jointly,         elaboration processes naturally involve agreements among agents on the identity of appropriate agents, objects and properties         that figure into their joint plans. The paper builds on ideas from dynamic logic to present a solution to the representation         and evolution of agent intentions involving reference to incompletely specified and, possibly, mutually dependent intentions,         as well as the objects referenced within those intentions. It provides a first order semantics for the resulting logic. A         companion paper extends further the logical form of DISs and explores the problem of logical consequence and intention revision.      </content></document><document><year>2008</year><authors>FranГ§ois Guerrin1| 2 </authors><title>Dynamic simulation of action at operations level      </title><content>The attempt of using lumped or agent-based simulation models to support operations management in production systems puts action         modelling to the fore. To fill the gap of classical decision-support systems ignoring human agents&amp;#8217; practices, a modelling         framework of action at operations level is proposed. This framework aims at answering two questions: How to represent action?         How to represent the management of action? Every action (i.e., what is actually done by an agent) is represented by a binary         function of time governed by events detected upon processes of various kinds: artefacts (clocks or schedules), external processes         occurring in the environment, other actions. In turn, every action exerts its effect on target processes. This modelling framework         allows one to simulate the interpretation of ongoing actions by using temporal or propositional logics and operations management         behaviors through plan specification and execution, action composition, and resource allocation to concurrent actions. It         enables complex activity systems to be represented and management options to be tested by simulation. These capacities are         illustrated on the example of a farming system. The main benefits and issues raised by this dynamical system approach close         to the &amp;#8216;situated&amp;#8217; (vs. &amp;#8216;planned&amp;#8217;) action paradigm are discussed in the light of related works in Artificial intelligence.         Future directions of research are drawn, namely that of how to scale up this lower-level representation of action to the higher-level         representation of agents endowed with skills relevant at the level of the individual (e.g., anticipation).      </content></document><document><year>2008</year><authors>Peter McBurney1  | Andrea Omicini2 </authors><title>Editorial: Special issue on foundations, advanced topics and industrial perspectives of multi-agent systems      </title><content>This paper introduces the Special Issue of the Journal of Autonomous Agents and Multi-Agent Systems on Foundations, Advanced Topics and Industrial Perspectives of Multi-Agent Systems. This special issue collects four articles         dealing with some of the main issues that arose during the three Technical Forum Group meetings held in 2004 and 2005, which         were organised and sponsored by the European FP6 Coordination Action AgentLink III.      </content></document><document><year>2008</year><authors>Axel BГјrkle1 | Alice Hertel1 | Wilmuth MГјller1  | Martin Wieser1 </authors><title>Evaluating the security of mobile agent platforms      </title><content>Mobility of software agents requires additional security measures. While the theoretical aspects of mobile agent security         have been widely studied, there are few studies about the security levels of current agent platforms. In this paper, test         cases are proposed to assess agent platform security. These tests focus on malicious agents trying to attack other agents         or the agency. Currently, they have been carried out for two agent platforms: JADE and SeMoA. These tests show which of the         known theoretical security problems are relevant in practice. Furthermore, they reveal how these problems are addressed by         the respective platform and what security flaws are present.      </content></document><document><year>2008</year><authors>Murat &amp;#350 ensoy1  | P&amp;#305 nar Yolum1 </authors><title>Evolving service semantics cooperatively: a consumer-driven approach      </title><content>Commerce relies on dynamic creation and modification of services. New service offerings or service demands come into play         frequently. Whereas traditional commerce supports creation of new service demands from consumers, e-commerce has so far expected         service providers to come up with desirable new service offerings and assigned service consumers a passive role in the process.         That is, current e-commerce architecture lacks a consumer-driven approach for the generation of new service descriptions.         This paper bridges this gap by proposing a multiagent system of consumers that represent their service needs semantically         using ontologies. Using our proposed approach, agents can create new service descriptions, share them with interested others,         and use service descriptions that are created by other agents. Hence, more accurate concepts describing consumers&amp;#8217; service         needs are cooperatively and iteratively created. This leads to a society of consumers with different but overlapping ontologies         where mutually accepted service concepts emerge based on consumers&amp;#8217; exchange of service descriptions. Our simulations of consumer         societies show that allowing cooperative evolution of service ontologies facilitates better representation of consumers&amp;#8217; service         needs. Further, through cooperation, not only more useful service concepts emerge over time, but also ontologies of consumers         having similar service needs become aligned gradually.      </content></document><document><year>2008</year><authors>Rineke Verbrugge1  | Barbara Dunin-Ke&amp;#807 plicz1</authors><title>Formal approaches to multi-agent sysems      </title><content>Without Abstract</content></document><document><year>2008</year><authors>Sven Seuken1  | Shlomo Zilberstein2 </authors><title>Formal models and algorithms for decentralized decision making under uncertainty      </title><content>Over the last 5;years, the AI community has shown considerable interest in decentralized control of multiple decision makers         or &amp;#8220;agents&amp;#8221; under uncertainty. This problem arises in many application domains, such as multi-robot coordination, manufacturing,         information gathering, and load balancing. Such problems must be treated as decentralized decision problems because each agent         may have different partial information about the other agents and about the state of the world. It has been shown that these         problems are significantly harder than their centralized counterparts, requiring new formal models and algorithms to be developed.         Rapid progress in recent years has produced a number of different frameworks, complexity results, and planning algorithms.         The objectives of this paper are to provide a comprehensive overview of these results, to compare and contrast the existing         frameworks, and to provide a deeper understanding of their relationships with one another, their strengths, and their weaknesses.         While we focus on cooperative systems, we do point out important connections with game-theoretic approaches. We analyze five         different formal frameworks, three different optimal algorithms, as well as a series of approximation techniques. The paper         provides interesting insights into the structure of decentralized problems, the expressiveness of the various models, and         the relative advantages and limitations of the different solution techniques. A better understanding of these issues will         facilitate further progress in the field and help resolve several open problems that we identify.      </content></document><document><year>2008</year><authors>Viviane Torres da Silva1 </authors><title>From the specification to the implementation of norms: an automatic approach to generate rules from norms to govern the behavior         of agents      </title><content>Open multi-agent systems composed of heterogeneous, autonomous and independently designed agents are usually governed by a         set of norms. The established norms regulate the behavior of the agents by pointing out their permissions, prohibitions and         obligations. This paper presents a normative language to specify norms and proposes the implementation of such norms by using         a rule-based system. The implementation is achieved by automatically transforming the specification of each norm of the system         into a set of rules used to govern the behavior of the agents according to the norm. The governance system is able to activate         and deactivate norms, to point out the norms violations and fulfillments and to inform about punishments and rewards.      </content></document><document><year>2008</year><authors>Thomas Schmickl1 | Ronald Thenius1| Christoph Moeslinger2| Gerald Radspieler1| Serge Kernbach3| Marc Szymanski4 | Karl Crailsheim1</authors><title>Get in touch: cooperative decision making based on robot-to-robot collisions      </title><content>We demonstrate the ability of a swarm of autonomous micro-robots to perform collective decision making in a dynamic environment.         This decision making is an emergent property of decentralized self-organization, which results from executing a very simple         bio-inspired algorithm. This algorithm allows the robotic swarm to choose from several distinct light sources in the environment         and to aggregate in the area with the highest illuminance. Interestingly, these decisions are formed by the collective, although         no information is exchanged by the robots. The only communicative act is the detection of robot-to-robot encounters. We studied         the performance of the robotic swarm under four environmental conditions and investigated the dynamics of the aggregation         behaviour as well as the flexibility and the robustness of the solutions. In summary, we can report that the tested robotic         swarm showed two main characteristic features of swarm systems: it behaved flexible and the achieved solutions were very robust.         This was achieved with limited individual sensor abilities and with low computational effort on each single robot in the swarm.      </content></document><document><year>2008</year><authors>M. Birna van Riemsdijk1 | Mehdi Dastani2  | John-Jules Ch. Meyer2 </authors><title>Goals in conflict: semantic foundations of goals in agent programming      </title><content>This paper addresses the notion of (declarative) goals as used in agent programming. Goals describe desirable states, and         semantics of these goals in an agent programming context can be defined in various ways. We focus in this paper on the representation         of conflicting goals. In particular, we define two semantics for goals, one for unconditional goals and one for conditional         goals. The first is based on propositional logic, and the latter is based on default logic. We establish relations between         and properties of these semantics.      </content></document><document><year>2008</year><authors>Yoram Bachrach1 | Ariel Parnes1 | Ariel D. Procaccia2  | Jeffrey S. Rosenschein1 </authors><title>Gossip-based aggregation of trust in decentralized reputation systems      </title><content>Decentralized Reputation Systems have recently emerged as a prominent method of establishing trust among self-interested agents         in online environments. A key issue is the efficient aggregation of data in the system; several approaches have been proposed,         but they are plagued by major shortcomings. We put forward a novel, decentralized data management scheme grounded in gossip-based         algorithms. Rumor mongering is known to possess algorithmic advantages, and indeed, our framework inherits many of their salient         features: scalability, robustness, a global perspective, and simplicity. We demonstrate that our scheme motivates agents to         maintain a very high reputation, by showing that the higher an agent&amp;#8217;s reputation is above the threshold set by its peers,         the more transactions it would be able to complete within a certain time unit. We analyze the relation between the amount         by which an agent&amp;#8217;s average reputation exceeds the threshold and the time required to close a deal. This analysis is carried         out both theoretically, and empirically through a simulation system called GossipTrustSim. Finally, we show that our approach is inherently impervious to certain kinds of attacks.      </content></document><document><year>2008</year><authors>Prashant Doshi1 | Yifeng Zeng2  | Qiongyu Chen3</authors><title>Graphical models for interactive POMDPs: representations and solutions      </title><content>We develop new graphical representations for the problem of sequential decision making in partially observable multiagent environments, as formalized by interactive partially observable Markov decision processes (I-POMDPs). The graphical models         called interactive influence diagrams (I-IDs) and their dynamic counterparts, interactive dynamic influence diagrams (I-DIDs), seek to explicitly model the structure that is often present in real-world problems by decomposing the situation into chance         and decision variables, and the dependencies between the variables. I-DIDs generalize DIDs, which may be viewed as graphical         representations of POMDPs, to multiagent settings in the same way that I-POMDPs generalize POMDPs. I-DIDs may be used to compute         the policy of an agent given its belief as the agent acts and observes in a setting that is populated by other interacting         agents. Using several examples, we show how I-IDs and I-DIDs may be applied and demonstrate their usefulness. We also show         how the models may be solved using the standard algorithms that are applicable to DIDs. Solving I-DIDs exactly involves knowing         the solutions of possible models of the other agents. The space of models grows exponentially with the number of time steps.         We present a method of solving I-DIDs approximately by limiting the number of other agents&amp;#8217; candidate models at each time         step to a constant. We do this by clustering models that are likely to be behaviorally equivalent and selecting a representative         set from the clusters. We discuss the error bound of the approximation technique and demonstrate its empirical performance.      </content></document><document><year>2008</year><authors>Michal P&amp;#283 chou&amp;#269 ek1  | VladimГ­r Ma&amp;#345 Г­k1| 2</authors><title>Industrial deployment of multi-agent technologies: review and selected case studies      </title><content>This paper reports on industrial deployment of multi-agent systems and agent technology. It provides an overview of several         application domains and an in-depth presentation of four specific case studies. The presented applications and deployment         domains have been analyzed. The analysis indicates that despite strong industrial involvement in this field, the full potential         of the agent technology has not been fully utilized yet and that not all of the developed agent concepts and agent techniques         have been completely exploited in industrial practice. In the paper, the key obstacles for wider deployments are listed and         potential future challenges are discussed.      </content></document><document><year>2008</year><authors>Budhitama Subagdja1 | Liz Sonenberg2  | Iyad Rahwan3| 4 </authors><title>Intentional learning agent architecture      </title><content>Dealing with changing situations is a major issue in building agent systems. When the time is limited, knowledge is unreliable,         and resources are scarce, the issue becomes more challenging. The BDI (Belief-Desire-Intention) agent architecture provides         a model for building agents that addresses that issue. The model can be used to build intentional agents that are able to         reason based on explicit mental attitudes, while behaving reactively in changing circumstances. However, despite the reactive         and deliberative features, a classical BDI agent is not capable of learning. Plans as recipes that guide the activities of the agent are assumed to be static. In this paper, an architecture for an intentional learning         agent is presented. The architecture is an extension of the BDI architecture in which the learning process is explicitly described         as plans. Learning plans are meta-level plans which allow the agent to introspectively monitor its mental states and update         other plans at run time. In order to acquire the intricate structure of a plan, a process pattern called manipulative abduction         is encoded as a learning plan. This work advances the state of the art by combining the strengths of learning and BDI agent         frameworks in a rich language for describing deliberation processes and reactive execution. It enables domain experts to specify         learning processes and strategies explicitly, while allowing the agent to benefit from procedural domain knowledge expressed         in plans.      </content></document><document><year>2008</year><authors>Guido Boella1 | Leendert van der Torre2  | Harko Verhagen3 </authors><title>Introduction to the special issue on normative multiagent systems      </title><content>This special issue contains four selected and revised papers from the second international workshop on normative multiagent         systems, for short NorMAS07 (Boella et;al. (eds) Normative multiagent systems. Dagstuhl seminar proceedings 07122, 2007),         held at Schloss Dagstuhl, Germany, in March 2007. At the workshop a shift was identified in the research community from a         legal to an interactionist view on normative multiagent systems. In this editorial we discuss the shift, examples, and 10         new challenges in this more dynamic setting, which we use to introduce the papers of this special issue.      </content></document><document><year>2008</year><authors>Klaus Fischer1 | Ingo Timm2 | Elisabeth AndrГ©3</authors><title>Introduction to the special issue on the Fourth German Conference on Multiagent System Technologies (MATES)      </title><content>Without Abstract</content></document><document><year>2008</year><authors>Thomas J. Walsh1 | Ali Nouri1 | Lihong Li1  | Michael L. Littman1 </authors><title>Learning and planning in environments with delayed feedback      </title><content>This work considers the problems of learning and planning in Markovian environments with constant observation and reward delays.         We provide a hardness result for the general planning problem and positive results for several special cases with deterministic         or otherwise constrained dynamics. We present an algorithm, Model Based Simulation, for planning in such environments and         use model-based reinforcement learning to extend this approach to the learning setting in both finite and continuous environments.         Empirical comparisons show this algorithm holds significant advantages over others for decision making in delayed-observation         environments.      </content></document><document><year>2008</year><authors>Michael J. Smith1  | Marie desJardins1 </authors><title>Learning to trust in the competence and commitment of agents      </title><content>For agents to collaborate in open multi-agent systems, each agent must trust in the other agents&amp;#8217; ability to complete tasks         and willingness to cooperate. Agents need to decide between cooperative and opportunistic behavior based on their assessment         of another agents&amp;#8217; trustworthiness. In particular, an agent can have two beliefs about a potential partner that tend to indicate         trustworthiness: that the partner is competent and that the partner expects to engage in future interactions. This paper explores an approach that models competence as an agent&amp;#8217;s probability of successfully performing an action, and         models belief in future interactions as a discount factor. We evaluate the underlying decision framework&amp;#8217;s performance given         accurate knowledge of the model&amp;#8217;s parameters in an evolutionary game setting. We then introduce a game-theoretic framework         in which an agent can learn a model of another agent online, using the Harsanyi transformation. The learning agents evaluate         a set of competing hypotheses about another agent during the simulated play of an indefinitely repeated game. The Harsanyi         strategy is shown to demonstrate robust and successful online play against a variety of static, classic, and learning strategies         in a variable-payoff Iterated Prisoner&amp;#8217;s Dilemma setting.      </content></document><document><year>2008</year><authors>Azzurra Ragone1 | Tommaso Di Noia1 | Eugenio Di Sciascio1  | Francesco M. Donini2 </authors><title>Logic-based automated multi-issue bilateral negotiation in peer-to-peer e-marketplaces      </title><content>We present a novel logic-based framework to automate multi-issue bilateral negotiation in e-commerce settings. The approach         exploits logic as communication language among agents, and optimization techniques in order to find Pareto-efficient agreements.         We introduce , a propositional logic extended with concrete domains, which allows one to model relations among issues (both numerical and         non-numerical ones) via logical entailment, differently from well-known approaches that describe issues as uncorrelated. Through          it is possible to represent buyer&amp;#8217;s request, seller&amp;#8217;s supply and their respective preferences as formulas endowed with a         formal semantics, e.g., &amp;#8220;if I spend more than 30000 &amp;#8364; for a sedan then I want more than a two-years warranty and a GPS system included&amp;#8221;. We mix logic and utility theory in order to express preferences in a qualitative and quantitative way. We illustrate the         theoretical framework, the logical language, the one-shot negotiation protocol we adopt, and show we are able to compute Pareto-efficient         outcomes, using a mediator to solve an optimization problem. We prove the computational adequacy of our method by studying         the complexity of the problem of finding Pareto-efficient solutions in our setting.      </content></document><document><year>2008</year><authors>Mehmet A. Orgun1| Guido Governatori2  | Chuchang Liu3</authors><title>Modal tableaux for verifying stream authentication protocols      </title><content>To develop theories to specify and reason about various aspects of multi-agent systems, many researchers have proposed the         use of modal logics such as belief logics, logics of knowledge, and logics of norms. As multi-agent systems operate in dynamic         environments, there is also a need to model the evolution of multi-agent systems through time. In order to introduce a temporal         dimension to a belief logic, we combine it with a linear-time temporal logic using a powerful technique called fibring for         combining logics. We describe a labelled modal tableaux system for the resulting fibred belief logic (FL) which can be used         to automatically verify correctness of inter-agent stream authentication protocols. With the resulting fibred belief logic         and its associated modal tableaux, one is able to build theories of trust for the description of, and reasoning about, multi-agent         systems operating in dynamic environments.      </content></document><document><year>2008</year><authors>Meriem Ennigrou1  | Khaled GhГ©dira2 </authors><title>New local diversification techniques for flexible job shop scheduling problem with a multi-agent approach      </title><content>The Flexible Job Shop problem is among the hardest scheduling problems. It is a generalization of the classical Job Shop problem         in that each operation can be processed by a set of resources and has a processing time depending on the resource used. The         objective is to assign and to sequence the operations on the resources so that they are processed in the smallest time. In         our previous work, we have proposed two Multi-Agent approaches based on the Tabu Search (TS) meta-heuristic. Depending on         the location of the optimisation core in the system, we have distinguished between the global optimisation approach where         the TS has a global view on the system and the local optimisation approach (FJS MATSLO) where the optimisation is distributed         among a collection of agents, each of them has its own local view. In this paper, firstly, we propose new diversification         techniques for the second approach in order to get better results and secondly, we propose a new promising approach combining         the two latter ones. Experimental results are also presented in this paper in order to evaluate these new techniques.      </content></document><document><year>2008</year><authors>Wamberto W. Vasconcelos1 | Martin J. Kollingbaum2  | Timothy J. Norman1 </authors><title>Normative conflict resolution in multi-agent systems      </title><content>Norms (permissions, obligations and prohibitions) offer a useful and powerful abstraction with which to capture social constraints         in multi-agent systems. Norms should exclude disruptive or antisocial behaviour without prescribing the design of individual         agents or restricting their autonomy. An important challenge, however, in the design and management of systems governed by         norms is that norms may, at times, conflict with one another; e.g, an action may be simultaneously prohibited and obliged         for a particular agent. In such circumstances, agents no longer have the option of complying with these norms; whatever they         do or refrain from doing will lead to a social constraint being broken. In this paper, we present mechanisms for the detection and resolution of normative conflicts. These mechanisms, based on first-order unification and constraint solving techniques, are the building         blocks of more sophisticated algorithms we present for the management of normative positions, that is, the adoption and removal         of permissions, obligations and prohibitions in societies of agents. We capture both direct and indirect conflicts between         norms, formalise a practical concept of authority, and model conflicts that may arise as a result of delegation. We are able         to formally define classic ways for resolving conflicts such as lex superior and lex posterior.      </content></document><document><year>2008</year><authors>Aldo Gangemi1 </authors><title>Norms and plans as unification criteria for social collectives      </title><content>Based on the paradigm of Constructive Descriptions and Situations, we introduce NIC, an ontology of social collectives that includes social agents, plans, norms, and the conceptual relations between them.         Norms are distinguished from plans, and their relations are formalized. A typology of social collectives is also proposed,         including collection of agents, knowledge community, intentional collective, and normative intentional collective. NIC, represented as a first-order theory as well as a description logic for applications requiring automated reasoning, provides         the expressivity to talk about the contexts (social, informational, circumstantial, and conceptual), in which collectives         make and produce sense within the interplay of plans and norms.      </content></document><document><year>2008</year><authors>Wouter Teepe1 </authors><title>On BAN logic and hash functions or: how an unjustified inference rule causes problems      </title><content>BAN logic, an epistemic logic for analyzing security protocols, contains an unjustifiable inference rule. The inference rule         assumes that possession of H(X) (i.e., the cryptographic hash value of X) counts as a proof of possession of X, which is not the case. As a result, BAN logic exhibits a problematic property, which is similar to unsoundness, but not         strictly equivalent to it. We will call this property &amp;#8216;unsoundness&amp;#8217; (with quotes). The property is demonstrated using a specially         crafted protocol, the two parrots protocol. The &amp;#8216;unsoundness&amp;#8217; is proven using the partial semantics which is given for BAN logic. Because of the questionable character         of the semantics of BAN logic, we also provide an alternative proof of &amp;#8216;unsoundness&amp;#8217; which we consider more important.      </content></document><document><year>2008</year><authors>Ana L. C. Bazzan1 </authors><title>Opportunities for multiagent systems and multiagent reinforcement learning in traffic control      </title><content>The increasing demand for mobility in our society poses various challenges to traffic engineering, computer science in general,         and artificial intelligence and multiagent systems in particular. As it is often the case, it is not possible to provide additional         capacity, so that a more efficient use of the available transportation infrastructure is necessary. This relates closely to         multiagent systems as many problems in traffic management and control are inherently distributed. Also, many actors in a transportation         system fit very well the concept of autonomous agents: the driver, the pedestrian, the traffic expert; in some cases, also         the intersection and the traffic signal controller can be regarded as an autonomous agent. However, the &amp;#8220;agentification&amp;#8221; of         a transportation system is associated with some challenging issues: the number of agents is high, typically agents are highly         adaptive, they react to changes in the environment at individual level but cause an unpredictable collective pattern, and         act in a highly coupled environment. Therefore, this domain poses many challenges for standard techniques from multiagent         systems such as coordination and learning. This paper has two main objectives: (i) to present problems, methods, approaches         and practices in traffic engineering (especially regarding traffic signal control); and (ii) to highlight open problems and         challenges so that future research in multiagent systems can address them.      </content></document><document><year>2008</year><authors>Mairi McCallum1 | Wamberto W. Vasconcelos1  | Timothy J. Norman1 </authors><title>Organisational change through influence      </title><content>         Influence is a phenomenon underpinning many types of interactions in both human and artificial organisations, and has a significant         impact on the operation of the organisation. If influence can be examined at the organisational level, instead of at the level         of the agents involved, engineers can better understand an organisation&amp;#8217;s robustness to structural, behavioural and population         changes. In this paper we present the Model of Organisational Change using Agents (MOChA) as a means to formally specify,         check and simulate organisations using agents, particularly with a view to determining the impact of influence on the operation         of an organisation. This formalisation of influence is not specific to our model, and is relevant and adaptable to any organisational         model in which explicit relationships among roles of agents are formed.      </content></document><document><year>2008</year><authors>Yoram Bachrach1  | Jeffrey S. Rosenschein1 </authors><title>Power in threshold network flow games      </title><content>Preference aggregation is used in a variety of multiagent applications, and as a result, voting theory has become an important         topic in multiagent system research. However, power indices (which reflect how much &amp;#8220;real power&amp;#8221; a voter has in a weighted         voting system) have received relatively little attention, although they have long been studied in political science and economics.         We consider a particular multiagent domain, a threshold network flow game. Agents control the edges of a graph; a coalition         wins if it can send a flow that exceeds a given threshold from a source vertex to a target vertex. The relative power of each         edge/agent reflects its significance in enabling such a flow, and in real-world networks could be used, for example, to allocate         resources for maintaining parts of the network. We examine the computational complexity of calculating two prominent power         indices, the Banzhaf index and the Shapley-Shubik index, in this network flow domain. We also consider the complexity of calculating         the core in this domain. The core can be used to allocate, in a stable manner, the gains of the coalition that is established.         We show that calculating the Shapley-Shubik index in this network flow domain is NP-hard, and that calculating the Banzhaf         index is #P-complete. Despite these negative results, we show that for some restricted network flow domains there exists a         polynomial algorithm for calculating agents&amp;#8217; Banzhaf power indices. We also show that computing the core in this game can         be performed in polynomial time.      </content></document><document><year>2008</year><authors>Femke de Jonge1 | Nico Roos1  | Cees Witteveen2 </authors><title>Primary and secondary diagnosis of multi-agent plan execution      </title><content>Diagnosis of plan failures is an important subject in both single- and multi-agent planning. Plan diagnosis can be used to         deal with plan failures in three ways: (i) to provide information necessary for the adjustment of the current plan or for         the development of a new plan, (ii) to point out which equipment and/or agents should be repaired or adjusted to avoid further         violation of the plan execution, and (iii) to identify the agents responsible for plan-execution failures. We introduce two         general types of plan diagnosis: primary plan diagnosis identifying the incorrect or failed execution of actions, and secondary plan diagnosis that identifies the underlying causes of the faulty actions. Furthermore, three special cases of secondary plan diagnosis         are distinguished, namely agent diagnosis, equipment diagnosis and environment diagnosis.      </content></document><document><year>2008</year><authors>Ettore Ferranti1 | Niki Trigoni1 | Mark Levene2</authors><title>Rapid exploration of unknown areas through dynamic deployment of mobile and stationary sensor nodes      </title><content>When an emergency occurs within a building, it may be initially safer to send autonomous mobile nodes, instead of human responders,         to explore the area and identify hazards and victims. Exploring all the area in the minimum amount of time and reporting back         interesting findings to the human personnel outside the building is an essential part of rescue operations. Our assumptions         are that the area map is unknown, there is no existing network infrastructure, long-range wireless communication is unreliable         and nodes are not location-aware. We take into account these limitations, and propose an architecture consisting of both mobile         nodes (robots, called agents) and stationary nodes (inexpensive smart devices, called tags). As agents enter the emergency         area, they sprinkle tags within the space to label the environment with states. By reading and updating the state of the local         tags, agents are able to coordinate indirectly with each other, without relying on direct agent-to-agent communication. In         addition, tags wirelessly exchange local information with nearby tags to further assist agents in their exploration task.         Our simulation results show that the proposed algorithm, which exploits both tag-to-tag and agent-to-tag communication, outperforms         previous algorithms that rely only on agent-to-tag communication.      </content></document><document><year>2008</year><authors>Jez McKean1 | Hayden Shorter2 | Michael Luck3 | Peter McBurney4  | Steven Willmott5 </authors><title>Technology diffusion: analysing the diffusion of agent technologies      </title><content>Despite several examples of deployed agent systems, there remain barriers to the large-scale adoption of agent technologies.         In order to understand these barriers, this paper considers aspects of marketing theory which deal with diffusion of innovations         and their relevance to the agents domain and the current state of diffusion of agent technologies. In particular, the paper         examines the role of standards in the adoption of new technologies, describes the agent standards landscape, and compares         the development and diffusion of agent technologies with that of object-oriented programming. The paper also reports on a         simulation model developed in order to consider different trajectories for the adoption of agent technologies, with trajectories         based on various assumptions regarding industry structure and the existence of competing technology standards. We present         details of the simulation model and its assumptions, along with the results of the simulation exercises.      </content></document><document><year>2008</year><authors>K. V. Hindriks1  | J.-J. Ch. Meyer2 </authors><title>Toward a programming theory for rational agents      </title><content>An important problem in agent verification is a lack of proper understanding of the relation between agent programs on the         one hand and agent logics on the other. Understanding this relation would help to establish that an agent programming language         is both conceptually well-founded and well-behaved, as well as yield a way to reason about agent programs by means of agent         logics. As a step toward bridging this gap, we study several issues that need to be resolved in order to establish a precise         mathematical relation between a modal agent logic and an agent programming language specified by means of an operational semantics. In this paper, we present an agent programming theory that provides both an agent programming language as well as a corresponding agent verification logic to verify agent programs.         The theory is developed in stages to show, first, how a modal semantics can be grounded in a state-based semantics, and, second, how denotational semantics can be used to define the mathematical relation connecting the logic and agent programming language. Additionally, it is         shown how to integrate declarative goals and add precompiled plans to the programming theory. In particular, we discuss the         use of the concept of higher-order goals in our theory. Other issues such as a complete axiomatization and the complexity         of decision procedures for the verification logic are not the focus of this paper and remain for future investigation.      </content></document><document><year>2008</year><authors>Yan Zheng Wei1 | Nicholas R. Jennings2 | Luc Moreau2  | Wendy Hall2 </authors><title>User evaluation of a market-based recommender system      </title><content>Recommender systems have been developed for a wide variety of applications (ranging from books, to holidays, to web pages).         These systems have used a number of different approaches, since no one technique is best for all users in all situations.         Given this, we believe that to be effective, systems should incorporate a wide variety of such techniques and then some form         of overarching framework should be put in place to coordinate them so that only the best recommendations (from whatever source)         are presented to the user. To this end, in our previous work, we detailed a market-based approach in which various recommender         agents competed with one another to present their recommendations to the user. We showed through theoretical analysis and         empirical evaluation with simulated users that an appropriately designed marketplace should be able to provide effective coordination.         Building on this, we now report on the development of this multi-agent system and its evaluation with real users. Specifically, we show that our system is capable of consistently giving high quality recommendations, that the best recommendations         that could be put forward are actually put forward, and that the combination of recommenders performs better than any constituent         recommender.      </content></document><document><year>2006</year><authors>Walter Binder1 | Ion Constantinescu1 | Boi Faltings1 | Klaus Haller | Can TГјrker2 </authors><title>A Multiagent System for the Reliable Execution of Automatically Composed Ad-hoc Processes      </title><content>This article presents an architecture to automatically create ad-hoc processes for complex value-added services and to execute         them in a reliable way. The uniqueness of ad-hoc processes is to support users not only in standardized situations like traditional         workflows do, but also in unique non-recurring situations. Based on user requirements, a service composition engine generates         such ad-hoc processes, which integrate individual services in order to provide the desired functionality. Our infrastructure         executes ad-hoc processes by transactional agents in a peer-to-peer style. The process execution is thereby performed under         transactional guarantees. Moreover, the service composition engine is used to re-plan in the case of execution failures.      </content></document><document><year>2006</year><authors>Raquel Ros1  | Carles Sierra1 </authors><title>A Negotiation Meta Strategy Combining Trade-off and Concession Moves      </title><content>In this paper we present a meta strategy that combines two negotiation tactics. The first one based on concessions, and the         second one, a trade-off tactic. The goal of this work is to demonstrate by experimental analysis that the combination of different         negotiation tactics allows agents to improve the negotiation process and as a result, to obtain more satisfactory agreements.         The scenario proposed is based on two agents, a buyer and a seller, which negotiate over four issues. The paper presents the         results and analysis of the meta strategy&amp;#8217;s behaviour.      </content></document><document><year>2006</year><authors>Cheryl Martin1  | K. Suzanne Barber2 </authors><title>Adaptive decision-making frameworks for dynamic multi-agent organizational change      </title><content>This article presents a capability called Adaptive Decision-Making Frameworks (ADMF) and shows that it can result in significantly         improved system performance across run-time situation changes in a multi-agent system. Specifically, ADMF can result in improved         and more robust performance compared to the use of a single static decision-making framework (DMF). The ADMF capability allows         agents to dynamically adapt the DMF in which they participate to fit their run-time situation as it changes. A DMF identifies         a set of agents and specifies the distribution of decision-making control and the authority to assign subtasks among these         agents as they determine how a goal or set of goals should be achieved. The ADMF capability is a form of organizational adaptation         and differs from previous approaches to organizational adaptation and dynamic coordination in that it is the first to allow         dynamic and explicit manipulation of these DMF characteristics at run-time as variables controlling agent behavior. The approach         proposed for selecting DMFs at run-time parameterizes all domain-specific knowledge as characteristics of the agents&amp;#8217; situation,         so the approach is application-independent. The presented evaluation empirically shows that, for at least one multi-agent         system, there is no one best DMF for multiple agents across run-time situational changes. Next, it motivates the further exploration         of ADMF by showing that adapting DMFs to run-time variations in situation can result in improved overall system performance         compared to static or random DMFs.      </content></document><document><year>2006</year><authors>Nicoletta Fornara1 | Francesco ViganГІ1  | Marco Colombetti1| 2 </authors><title>Agent communication and artificial institutions      </title><content>In this paper we propose an application-independent model for the definition of artificial institutions that can be used to         define open multi-agent systems. Such a model of institutional reality makes us able also to define an objective and external         semantics of a commitment-based Agent Communication Language (ACL). In particular we propose to regard an ACL as a set of         conventions to act on a fragment of institutional reality, defined in the context of an artificial institution. Another contribution         of the work presented in this paper is an operational definition of norms, a crucial component of artificial institutions.         In fact in open systems interacting agents might not conform to the specifications. We regard norms as event-driven rules         that when are fired by events happening in the system create or cancel a set of commitments. An interesting aspect of our         proposal is that both the definition of the ACL and the definition of norms are based on the same notion of commitment. Therefore         an agent capable of reasoning on commitments can reason on the semantics of communicative acts and on the system of norms.      </content></document><document><year>2006</year><authors>Frank Dignum1 | Rogier M. van Eijk1 </authors><title>Agent communication and social concepts      </title><content>Without Abstract</content></document><document><year>2006</year><authors>Ashok U. Mallya1  | Munindar P. Singh1 </authors><title>An algebra for commitment protocols      </title><content>Protocols enable unambiguous, smooth interactions among agents. Commitments among agents are a powerful means of developing         protocols. Commitments enable flexible execution of protocols and help agents reason about protocols and plan their actions         accordingly, while at the same time providing a basis for compliance checking. Multiagent systems based on commitments can         conveniently and effectively model business interactions because the autonomy and heterogeneity of agents mirrors real-world         businesses. Such modeling, however, requires multiagent systems to host a rich variety of protocols that can capture the needs         of different applications. We show how a commitment-based semantics provides a basis for refining and aggregating protocols.         We propose an approach for designing commitment protocols wherein traditional software engineering notions such as refinement         and aggregation are extended to apply to protocols. We present an algebra of protocols that can be used to compose protocols         by refining and merging existing ones, and does this at a level of abstraction high enough to be useful for real-world applications.      </content></document><document><year>2006</year><authors>Elisabeth Crawford1  | Manuela Veloso1 </authors><title>An experts approach to strategy selection in multiagent meeting scheduling      </title><content>In the multiagent meeting scheduling problem, agents negotiate with each other on behalf of their users to schedule meetings.         While a number of negotiation approaches have been proposed for scheduling meetings, it is not well understood how agents         can negotiate strategically in order to maximize their users&amp;#8217; utility. To negotiate strategically, agents need to learn to         pick good strategies for negotiating with other agents. In this paper, we show how agents can learn online to negotiate strategically         in order to better satisfy their users&amp;#8217; preferences. We outline the applicability of experts algorithms to the problem of         learning to select negotiation strategies. In particular, we show how two different experts approaches, plays [3] and Exploration&amp;#8211;Exploitation         Experts (EEE) [10] can be adapted to the task. We show experimentally the effectiveness of our approach for learning to negotiate         strategically.      </content></document><document><year>2006</year><authors>Trung Dong Huynh1 | Nicholas R. Jennings1  | Nigel R. Shadbolt1 </authors><title>An integrated trust and reputation model for open multi-agent systems      </title><content>Trust and reputation are central to effective interactions in open multi-agent systems (MAS) in which agents, that are owned         by a variety of stakeholders, continuously enter and leave the system. This openness means existing trust and reputation models         cannot readily be used since their performance suffers when there are various (unforseen) changes in the environment. To this         end, this paper presents FIRE, a trust and reputation model that integrates a number of information sources to produce a comprehensive         assessment of an agent&amp;#8217;s likely performance in open systems. Specifically, FIRE incorporates interaction trust, role-based         trust, witness reputation, and certified reputation to provide trust metrics in most circumstances. FIRE is empirically evaluated         and is shown to help agents gain better utility (by effectively selecting appropriate interaction partners) than our benchmarks         in a variety of agent populations. It is also shown that FIRE is able to effectively respond to changes that occur in an agent&amp;#8217;s         environment.      </content></document><document><year>2006</year><authors>Paul Valckenaers1 | John Sauter2 | Carles Sierra3  | Juan Antonio Rodriguez-Aguilar3 </authors><title>Applications and environments for multi-agent systems</title><content>This paper addresses multi agent system (MAS) environments from an application perspective. It presents a structured view on environment-centric MAS applications. This comprises three base configurations, which MAS applications may apply directly or combine into a composite configuration. For each configuration, the paper presents key issues, requirements and opportunities (e.g. time management issues, real-world augmentation opportunities and state snapshot requirements). Thus, the paper delineates what environment technology may implement to serve MAS applications. Sample applications illustrate the configurations. Next, electronic institutions provide an example of an environment technology, addressing norms and laws in an agent society, already achieving some maturity. In comparison, application-domain specific environment technologies still are in embryonic stages.</content></document><document><year>2006</year><authors>Frank Guerin1 </authors><title>Applying game theory mechanisms in open agent systems with complete information      </title><content>Game theory is a popular tool for designing interaction protocols for agent systems. It is currently not clear how to extend         this to open agent systems. By &amp;#8220;open&amp;#8221; we mean that foreign agents will be free to enter and leave different systems at will.         This means that agents will need to be able to work with previously unseen protocols. There does not yet exist any agreement         on a standard way in which such protocols can be specified and published. Furthermore, it is not clear how an agent could         be given the ability to use an arbitrary published protocol; the agent would need to be able to work out a strategy for participation.         To address this we propose a machine readable language in which a game theory mechanism can be written in the form of an agent         interaction protocol. This language allows the workings of the protocol to be made public so that agents can inspect it to         determine its properties and hence their best strategy. Enabling agents to automatically determine the game theoretic properties         of an arbitrary interaction protocol is difficult. Rather than requiring agents to find the equilibrium of a game, we propose         that a recommended equilibrium will be published along with the protocol; agents can then check the recommendation to decide         if it is indeed an equilibrium. We present an algorithm for this decision problem. We also develop an equilibrium which simplifies         the complexity of the checking problem, while still being robust to unilateral deviations.      </content></document><document><year>2006</year><authors>Vangelis Kourakos Mavromichalis1  | George Vouros1 </authors><title>Building intelligent collaborative interface agents with the ICAGENT development framework      </title><content>This paper describes the implementation of intelligent collaborative interface agents using the intelligent collaborative         agent (ICagent) development framework. In particular, the paper presents the implementation of a collaborative interface agent that acts         as a tutor in the context of an educational software application. The agent deliberates socially with users following the         SharedPlans model of collaborative activity. Social deliberation requires interface agents to make their desires and intentions clear         to the application users, being in constant communication with them, to understand the context of their activity and to reconcile         their own and users&amp;#8217; desires in the overall context of action. Reconciliation of users&amp;#8217; desires allows agents to recognize         the situations where users need help. The paper briefly presents the ICagent development framework, describes the implementation of the interface agent, and discusses an example of the behavior of the         agent during a collaboration session.      </content></document><document><year>2006</year><authors>Patrick F. Riley1  | Manuela M. Veloso1 </authors><title>Coach planning with opponent models for distributed execution      </title><content>In multi-agent domains, the generation and coordinated execution of plans in the presence of adversaries is a significant         challenge. In our research, a special &amp;#8220;coach&amp;#8221; agent works with a team of distributed agents. The coach has a global view of         the world, but has no actions other than occasionally communicating with the team over a limited bandwidth channel. Our coach         is given a set of predefined opponent models which predict future states of the world caused by the opponents&amp;#8217; actions. The         coach observes the world state changes resulting from the execution of its team and opponents and selects the best matched         opponent model based on its observations. The coach uses the recognized opponent model to predict the behavior of the opponent.         Upon opportunities to communicate, the coach generates a plan for the team, using the predictions of the opponent model. The         centralized coach generates a plan for distributed execution. We introduce (i) the probabilistic representation and recognition         algorithm for the opponent models; (ii) a multi-agent plan representation, Multi-Agent Simple Temporal Networks; and (iii)         a plan execution algorithm that allows the robust distributed execution in the presence of noisy perception and actions. The         complete approach is implemented in a complex simulated robot soccer environment. We present the contributions as developed         in this domain, carefully highlighting their generality along with a series of experiments validating the effectiveness of         our coach approach.      </content></document><document><year>2006</year><authors>Charles Lee Isbell Jr.1 | Michael Kearns2 | Satinder Singh3 | Christian R. Shelton4 | Peter Stone5  | Dave Kormann6 </authors><title>Cobot in LambdaMOO: An Adaptive Social Statistics Agent      </title><content>We describe our development of Cobot, a novel software agent who lives in LambdaMOO, a popular virtual world frequented by         hundreds of users. Cobot&amp;#8217;s goal was to become an actual part of that community. Here, we present a detailed discussion of         the functionality that made him one of the objects most frequently interacted with in LambdaMOO, human or artificial. Cobot&amp;#8217;s         fundamental power is that he has the ability to collect social statistics summarizing the quantity and quality of interpersonal         interactions. Initially, Cobot acted as little more than a reporter of this information; however, as he collected more and         more data, he was able to use these statistics as models that allowed him to modify his own behavior. In particular, cobot         is able to use this data to &amp;#8220;self-program,&amp;#8221; learning the proper way to respond to the actions of individual users, by observing         how others interact with one another. Further, Cobot uses reinforcement learning to proactively take action in this complex         social environment, and adapts his behavior based on multiple sources of human reward. Cobot represents a unique experiment         in building adaptive agents who must live in and navigate social spaces.      </content></document><document><year>2006</year><authors>Roberto A. Flores1 | Philippe Pasquier2  | Brahim Chaib-draa2 </authors><title>Conversational semantics sustained by commitments      </title><content>We propose an operational model that combines message meaning and conversational structure in one comprehensive approach.         Our long-term research goal is to lay down principles uniting message meaning and conversational structure while providing         an operational foundation that could be implemented in open computer systems. In this paper we explore our advances in one         aspect of meaning that in theories of language use is known as &amp;#8220;signal meaning&amp;#8221;, and propose a layered model in which the         meaning of messages can be defined according to their fitness to advance the state of joint activities. Messages in our model         are defined in terms of social commitments, which have been shown to entice conversational structure.      </content></document><document><year>2006</year><authors>Tad Hogg1 </authors><title>Coordinating microscopic robots in viscous fluids      </title><content>Multiagent control provides strategies for aggregating microscopic robots (&amp;#8220;nanorobots&amp;#8221;) in fluid environments relevant for         medical applications. Unlike larger robots, viscous forces and Brownian motion dominate the behavior. Examples range from         modified microorganisms (programmable bacteria) to future robots using ongoing developments in molecular computation, sensors         and motors. We evaluate controls for locating a cell-sized area emitting a chemical into a moving fluid with parameters corresponding         to chemicals released in response to injury or infection in small blood vessels. These control methods are passive Brownian         motion, following the chemical concentration gradient, and cooperative behaviors in which some robots use acoustic signals         to guide others to the chemical source. Control performance is evaluated using diffusion equations to describe the robot motions         and control state transitions. The quantitative results show these control techniques are feasible approaches to the task         with trade-offs among fabrication difficulty, response speed, false positive detection rate and energy use. Controlled aggregation         at chemically distinctive locations could be useful for sensitive diagnosis, selective changes to biological tissues and forming         structures using previous proposals for multiagent control of modular robots.      </content></document><document><year>2006</year><authors>Pieter Buzing1 | Adriaan ter Mors1 | Jeroen Valk1  | Cees Witteveen1| 2 </authors><title>Coordinating Self-interested Planning Agents      </title><content>We consider planning problems where a number of non-cooperative agents have to work on a joint problem. Such problems consist         in completing a set of interdependent, hierarchically ordered tasks. Each agent is assigned a subset of tasks to perform for         which it has to construct a plan. Since the agents are non-cooperative, they insist on planning independently and do not want         to revise their individual plans when the joint plan has to be assembled from the individual plans. We present a general formal         framework to study some computational aspects of this non-cooperative coordination problem and we establish some complexity results to identify some of the factors that contribute to the complexity of this         problem. Finally, we illustrate our approach with an application to coordination in multi-modal logistic planning.      </content></document><document><year>2006</year><authors>Nicola Dragoni1  | Mauro Gaspari1 </authors><title>Crash failure detection in asynchronous agent communication languages      </title><content>Agent Communication Languages (ACLs) have been developed to provide a way for agents to communicate with each other supporting         cooperation in Multi-Agent Systems (MAS). In the past few years many ACLs have been proposed for MAS and new standards are         emerging such as the ACL developed by the Foundation for Intelligent Physical Agents (FIPA). Despite these efforts, an important         issue in the research on ACLs is still open and concerns how these languages should deal with failures of agents in asynchronous MAS. The Fault Tolerant Agent Communication Language (                  -                  ) presented in this paper addresses this issue dealing with crash failures of agents.                   -                   provides high-level communication primitives which support a fault-tolerant anonymous interaction protocol designed for open         MAS. We present a formal semantics for                   -                   and a formal specification of the underlying agent architecture. This formal framework allows us to prove that the ACL satisfies         a set of well defined knowledge-level programming requirements. To illustrate the language features we show how                   -                   can be effectively used to write high-level executable specifications of fault tolerant protocols, such as the Contract Net         one.      </content></document><document><year>2006</year><authors>Brahim Chaib-draa1 | Marc-AndrГ© Labrie1 | Mathieu Bergeron1  | Philippe Pasquier1 </authors><title>DIAGAL: An Agent Communication Language Based on Dialogue Games and Sustained by Social Commitments      </title><content>In recent years, social commitment based approaches have been proposed to solve problems issuing from previous mentalistic         based semantics for agent communication languages. This paper follows the same line of thought since it presents the latest         version of our dialogue game based agent communication language &amp;#8211; DIAlogue-Game based Agent Language (DIAGAL) &amp;#8211; which allows         agents to manipulate the public layer of social commitments through dialogue, by creating, canceling and updating their social         commitments. To make apparent such commitments, we consider here Agent Communication Language (ACL) from the dialectic point         of view, where agents &amp;#8220;play a game&amp;#8221; based on commitments. Such games based on commitments are incorporated in the DIAGAL language,         which has been developed having in mind the following questions: (a) What kind of structure does the game have? How are rules         specified within the game? (b) What kind of games compositions are allowed? (c) How do participants in conversations reach         agreement on the current game? How are games opened or closed? Using such games we show how we can study the commitments dynamic         to model agent dialogue and we present metrics that can be used to evaluate the quality of a dialogue between agents. Next,         we use an example (summer festival organization) to show how DIAGAL can be used in analyzing and modeling automated conversations         in offices. Finally, we present the results and analysis of the summer festival simulations that we realized through our dialogue         game simulator (DGS).      </content></document><document><year>2006</year><authors>Danny Weyns1 | Andrea Omicini2  | James Odell3 </authors><title>Environment as a first class abstraction in multiagent systems</title><content>The current practice in multiagent systems typically associates the environment with resources that are external to agents and their communication infrastructure. Advanced uses of the environment include infrastructures for indirect coordination, such as digital pheromones, or support for governed interaction in electronic institutions. Yet, in general, the notion of environment is not well defined. Functionalities of the environment are often dealt with implicitly or in an ad hoc manner. This is not only poor engineering practice, it also hinders engineers to exploit the full potential of the environment in multiagent systems. In this paper, we put forward the environment as an explicit part of multiagent systems.We give a definition stating that the environment in a multiagent system is a first-class abstraction with dual roles: (1) the environment provides the surrounding conditions for agents to exist, which implies that the environment is an essential part of every multiagent system, and (2) the environment provides an exploitable design abstraction for building multiagent system applications. We discuss the responsibilities of such an environment in multiagent systems and we present a reference model for the environment that can serve as a basis for environment engineering. To illustrate the power of the environment as a design abstraction, we show how the environment is successfully exploited in a real world application. Considering the environment as a first-class abstraction in multiagent systems opens up new horizons for research and development in multiagent systems.</content></document><document><year>2006</year><authors>Katja Verbeeck1 | Ann NowГ©1 | Johan Parent1  | Karl Tuyls2 </authors><title>Exploring selfish reinforcement learning in repeated games with stochastic rewards      </title><content>In this paper we introduce a new multi-agent reinforcement learning algorithm, called exploring selfish reinforcement learning         (ESRL). ESRL allows agents to reach optimal solutions in repeated non-zero sum games with stochastic rewards, by using coordinated         exploration. First, two ESRL algorithms for respectively common interest and conflicting interest games are presented. Both         ESRL algorithms are based on the same idea, i.e. an agent explores by temporarily excluding some of the local actions from         its private action space, to give the team of agents the opportunity to look for better solutions in a reduced joint action         space. In a latter stage these two algorithms are transformed into one generic algorithm which does not assume that the type         of the game is known in advance. ESRL is able to find the Pareto optimal solution in common interest games without communication.         In conflicting interest games ESRL only needs limited communication to learn a fair periodical policy, resulting in a good         overall policy. Important to know is that ESRL agents are independent in the sense that they only use their own action choices         and rewards to base their decisions on, that ESRL agents are flexible in learning different solution concepts and they can         handle both stochastic, possible delayed rewards and asynchronous action selection. A real-life experiment, i.e. adaptive         load-balancing of parallel applications is added.      </content></document><document><year>2006</year><authors>H. Van Dyke Parunak1  | Danny Weyns2</authors><title>Guest editors&amp;#8217; introduction, special issue on environments for multi-agent systems</title><content>Without Abstract</content></document><document><year>2006</year><authors>Adrian K. Agogino1  | Kagan Tumer2 </authors><title>Handling Communication Restrictions and Team Formation in Congestion Games      </title><content>There are many domains in which a multi-agent system needs to maximize a &amp;#8220;system utility&amp;#8221; function which rates the performance         of the entire system, while subject to communication restrictions among the agents. Such communication restrictions make it         difficult for agents that take actions to optimize their own &amp;#8220;private&amp;#8221; utilities to also help optimize the system utility.         In this article we show how previously introduced utilities that promote coordination among agents can be modified to be effective         in domains with communication restrictions. The modified utilities provide performance improvements of up to 75 over previously         used utilities in congestion games (i.e., games where the system utility depends solely on the number of agents choosing a         particular action). In addition, we show that in the presence of severe communication restrictions, team formation for the         purpose of information sharing among agents leads to an additional 25 improvement in system utility. Finally, we show that         agents&amp;#8217; private utilities and team sizes can be manipulated to form the best compromise between how &amp;#8220;aligned&amp;#8221; an agent&amp;#8217;s utility         is with the system utility and how easily an agent can learn that utility.      </content></document><document><year>2006</year><authors>Mohammad Ghavamzadeh1 | Sridhar Mahadevan2  | Rajbala Makar3 </authors><title>Hierarchical multi-agent reinforcement learning      </title><content>In this paper, we investigate the use of hierarchical reinforcement learning (HRL) to speed up the acquisition of cooperative         multi-agent tasks. We introduce a hierarchical multi-agent reinforcement learning (RL) framework, and propose a hierarchical         multi-agent RL algorithm called Cooperative HRL. In this framework, agents are cooperative and homogeneous (use the same task decomposition). Learning is decentralized,         with each agent learning three interrelated skills: how to perform each individual subtask, the order in which to carry them         out, and how to coordinate with other agents. We define cooperative subtasks to be those subtasks in which coordination among agents significantly improves the performance of the overall task. Those         levels of the hierarchy which include cooperative subtasks are called cooperation levels. A fundamental property of the proposed approach is that it allows agents to learn coordination faster by sharing information         at the level of cooperative subtasks, rather than attempting to learn coordination at the level of primitive actions. We study the empirical performance of the         Cooperative HRL algorithm using two testbeds: a simulated two-robot trash collection task, and a larger four-agent automated guided vehicle         (AGV) scheduling problem. We compare the performance and speed of Cooperative HRL with other learning algorithms, as well as several well-known industrial AGV heuristics. We also address the issue of rational         communication behavior among autonomous agents in this paper. The goal is for agents to learn both action and communication         policies that together optimize the task given a communication cost. We extend the multi-agent HRL framework to include communication         decisions and propose a cooperative multi-agent HRL algorithm called COM-Cooperative HRL. In this algorithm, we add a communication level to the hierarchical decomposition of the problem below each cooperation level. Before an agent makes a decision at a cooperative subtask, it decides if it is worthwhile to perform a communication action. A communication action has a certain cost and provides         the agent with the actions selected by the other agents at a cooperation level. We demonstrate the efficiency of the COM-Cooperative HRL algorithm as well as the relation between the communication cost and the learned communication policy using a multi-agent         taxi problem.      </content></document><document><year>2006</year><authors>Mirko Viroli1 | Tom Holvoet3 | Aless|ro Ricci1 | Kurt Schelfthout3  | Franco Zambonelli2 </authors><title>Infrastructures for the environment of multiagent systems</title><content>The notion of environment is receiving an increasing attention in the development of multiagent applications. This is witnessed by the emergence of a number of infrastructures providing agent designers with useful means to develop the agent environment, and thus to structure an effective multiagent application. In this paper we analyse the role and features of such infrastructures, and survey some relevant examples. We endorse a general viewpoint where the environment of a multiagent system is seen as a set of basic bricks we call environment abstractions, which (i) provide agents with services useful for achieving individual and social goals, and (ii) are supported by some underlying software infrastructure managing their creation and exploitation. Accordingly, we focus the survey on the opportunities that environment infrastructures provide to system designers when developing multiagent applications.</content></document><document><year>2006</year><authors>Enric Plaza1  | Santiago OntaГ±Гіn1| 2 </authors><title>Learning collaboration strategies for committees of learning agents      </title><content>A main issue in cooperation in multi-agent systems is how an agent decides in which situations is better to cooperate with         other agents, and with which agents does the agent cooperate. Specifically in this paper we focus on multi-agent systems composed         of learning agents, where the goal of the agents is to achieve a high accuracy on predicting the correct solution of the problems         they encounter. For that purpose, when encountering a new problem each agent has to decide whether to solve it individually         or to ask other agents for collaboration. We will see that learning agents can collaborate forming committees in order to improve performance. Moreover, in this paper we will present a proactive learning approach that will allow the         agents to learn when to convene a committee and with which agents to invite to join the committee. Our experiments show that         learning results in smaller committees while maintaining (and sometimes improving) the problem solving accuracy than forming         committees composed of all agents.      </content></document><document><year>2006</year><authors>Claudia V. Goldman1 | Martin Allen2  | Shlomo Zilberstein2 </authors><title>Learning to communicate in a decentralized environment      </title><content>Learning to communicate is an emerging challenge in AI research. It is known that agents interacting in decentralized, stochastic         environments can benefit from exchanging information. Multi-agent planning generally assumes that agents share a common means         of communication; however, in building robust distributed systems it is important to address potential miscoordination resulting         from misinterpretation of messages exchanged. This paper lays foundations for studying this problem, examining its properties         analytically and empirically in a decision-theoretic context. We establish a formal framework for the problem, and identify         a collection of necessary and sufficient properties for decision problems that allow agents to employ probabilistic updating         schemes in order to learn how to interpret what others are communicating. Solving the problem optimally is often intractable,         but our approach enables agents using different languages to converge upon coordination over time. Our experimental work establishes         how these methods perform when applied to problems of varying complexity.      </content></document><document><year>2006</year><authors>Blazej Bulka1 | Matthew Gaston1  | Marie desJardins1 </authors><title>Local strategy learning in networked multi-agent team formation      </title><content>Networked multi-agent systems are comprised of many autonomous yet interdependent agents situated in a virtual social network.         Two examples of such systems are supply chain networks and sensor networks. A common challenge in many networked multi-agent         systems is decentralized team formation among the spatially and logically extended agents. Even in cooperative multi-agent         systems, efficient team formation is made difficult by the limited local information available to the individual agents. We         present a model of distributed multi-agent team formation in networked multi-agent systems, describe a policy learning framework         for joining teams based on local information, and give empirical results on improving team formation performance. In particular,         we show that local policy learning from limited information leads to a significant increase in organizational team formation         performance compared to a random policy.      </content></document><document><year>2006</year><authors>Eric Platon1 | Marco Mamei2 | Nicolas Sabouret3 | Shinichi Honiden4  | H. Van Dyke Parunak5 </authors><title>Mechanisms for environments in multi-agent systems: Survey and opportunities</title><content>The environment has been recognized as an explicit and exploitable element to design multi-agent systems (MAS). It can be assigned a number of responsibilities that would be more difficult to design with the sole notion of agents. To support the engineering of these responsibilities, we identify a set of mechanisms that offer solutions to software designers. We describe the mechanisms, their usage in representative projects, and potential opportunities for further research and applications. The purpose of this article is to clarify the notion of environment in terms of mechanisms, from their abstract description to their practical exploitation. Mechanisms are expected to provide agent-based software designers with a set of design elements to build MAS that take advantage of the environment.</content></document><document><year>2006</year><authors>Lalana Kagal1  | Tim Finin2 </authors><title>Modeling conversation policies using permissions and obligations      </title><content>Both conversation specifications and policies are required to facilitate effective agent communication. Specifications provide         the order in which speech acts can occur in a meaningful conversation, whereas policies restrict the specifications that can         be used in a certain conversation based on the sender, receiver, messages exchanged thus far, content, and other context.         We propose that positive/negative permissions and obligations be used to model conversation specifications and policies. We         also propose the use of ontologies to categorize speech acts such that high level policies can be defined without going into         specifics of the speech acts. This approach is independent of the syntax and semantics of the communication language and can         be used for different agent communication languages. Our policy based framework can help in agent communication in three ways:         (i) to filter inappropriate messages, (ii) to help an agent to decide which speech act to use next, and (iii) to prevent an         agent from sending inappropriate messages. Our work differs from most existing research on communication policies because         it is not tightly coupled to any domain information such as the mental states of agents or specific communicative acts. Contributions         of this work include: (i) an extensible framework that is applicable to varied domain knowledge and different agent communication         languages, and (ii) the declarative representation of conversation specifications and policies in terms of permitted and obligated         speech acts.      </content></document><document><year>2006</year><authors>Alex|er Helleboogh1 | Giuseppe Vizzari2 | Adelinde Uhrmacher3  | Fabien Michel4 </authors><title>Modeling dynamic environments in multi-agent simulation</title><content>Real environments in which agents operate are inherently dynamic&amp;#8212;the environment changes beyond the agents&amp;#8217; control. We advocate that, for multi-agent simulation, this dynamism must be modeled explicitly as part of the simulated environment, preferably using concepts and constructs that relate to the real world. In this paper, we describe such concepts and constructs, and we provide a formal framework to unambiguously specify their relations and meaning. We apply the formal framework to model a dynamic RoboCup Soccer environment and elaborate on how the framework poses new challenges for exploring the modeling of environments in multi-agent simulation.</content></document><document><year>2006</year><authors>Thomas A. Wagner1 | Anita Raja2  | Victor R. Lesser3 </authors><title>Modeling Uncertainty and its Implications to Sophisticated Control in TГ¦ms Agents      </title><content>Open environments are characterized by their uncertainty and non-determinism. Agents need to adapt their task processing to         available resources, deadlines, the goal criteria specified by the clients as well their current problem solving context in         order to survive in these environments. If there were no resource constraints, then an optimal Markov Decision Process based         policy would obviously be the best way for complex problem solving agents to make scheduling decisions. However in many agent         systems, these scheduling decisions have to be made on-line or in soft real-time, making the off-line policy computationally         infeasible in open environments. The hybrid planner/scheduler used to control Task Analysis, Environment Modeling, and Simulation         (TГ†MS) agents is the Design-to-Criteria (DTC) agent scheduler. Design-to-Criteria scheduling is the soft real-time process         of custom building a plan/schedule to meet an agent&amp;#8217;s current objectives which are expressed as dynamic goal criteria (including         real-time deadlines), using task models that describe alternate ways to achieve tasks and subtasks. Recent advances in Design-to-Criteria         control include the addition of uncertainty to the TГ†MS computational task models analyzed by the scheduler and the incorporation         of uncertainty in the scheduling process. As we show, the use of uncertainty in TГ†MS and Design-to-Criteria enables agents         to make better control decisions in uncertain environments. Design-to-Criteria uses a heuristic approach for on-line scheduling         of medium granularity tasks.It approximates the analysis used to generate an optimal policy by heuristically reasoning about         the implications of uncertainty in task execution. The addition of uncertainty has also spawned a post-scheduling contingency         analysis step for situations in which an agent must produce a result by a given deadline (deadline critical situations) and         where the added computational cost is worth the expense. We describe the uncertainty representation in TГ†MS and how it improves         task models and the scheduling process, and provide empirical examples of reasoning about uncertainty in action. We also evaluate         the performance of our heuristic-based approach to agent control using the performance of the policy generated by an optimal         controller as the benchmark.      </content></document><document><year>2006</year><authors>Thomas A. Wagner 1 |  Anita Raja2  | Victor R. Lesser3 </authors><title>Modeling uncertainty and its implications to sophisticated control TГ¦ms agents      </title><content>Without Abstract</content></document><document><year>2006</year><authors>Manuel Kolp1 | Paolo Giorgini2  | John Mylopoulos3 </authors><title>Multi-Agent Architectures as Organizational Structures      </title><content>A Multi-Agent System (hereafter MAS) is an organization of coordinated autonomous agents that interact in order to achieve         common goals. Considering real world organizations as an metaphor, this paper proposes architectural styles for MAS which         adopt concepts from organizational theories. The styles are modeled in i*/Tropos, using the notions of actor, goal and actor         dependency and are intended to capture needs/wants, delegations and obligations. The proposed architectural styles are evaluated         with respect to a set of software quality attributes, such as predictability and adaptability. In addition, we report on a         comparative study of organizational and conventional software architectures using a mobile robot control example from the         Software Engineering literature. The research reported here was conducted within the scope of the Tropos project, whose objective         is to develop a comprehensive agent-oriented software development methodology.      </content></document><document><year>2006</year><authors>Chiara Ghidini1 | Paolo Giorgini2  | Wiebe van der Hoek3 </authors><title>Preface      </title><content>Without Abstract</content></document><document><year>2006</year><authors>Rajiv T. Maheswaran1 | Jonathan P. Pearce1| Emma Bowring1| Pradeep Varakantham1 | Milind Tambe1</authors><title>Privacy Loss in Distributed Constraint Reasoning: A Quantitative Framework for Analysis and its Applications      </title><content>It is critical that agents deployed in real-world settings, such as businesses, offices, universities and research laboratories,         protect their individual users&amp;#8217; privacy when interacting with other entities. Indeed, privacy is recognized as a key motivating         factor in the design of several multiagent algorithms, such as in distributed constraint reasoning (including both algorithms         for distributed constraint optimization (DCOP) and distributed constraint satisfaction (DisCSPs)), and researchers have begun         to propose metrics for analysis of privacy loss in such multiagent algorithms. Unfortunately, a general quantitative framework         to compare these existing metrics for privacy loss or to identify dimensions along which to construct new metrics is currently         lacking. This paper presents three key contributions to address this shortcoming. First, the paper presents VPS (Valuations         of Possible States), a general quantitative framework to express, analyze and compare existing metrics of privacy loss. Based         on a state-space model, VPS is shown to capture various existing measures of privacy created for specific domains of DisCSPs.         The utility of VPS is further illustrated through analysis of privacy loss in DCOP algorithms, when such algorithms are used         by personal assistant agents to schedule meetings among users. In addition, VPS helps identify dimensions along which to classify         and construct new privacy metrics and it also supports their quantitative comparison. Second, the article presents key inference         rules that may be used in analysis of privacy loss in DCOP algorithms under different assumptions. Third, detailed experiments         based on the VPS-driven analysis lead to the following key results: (i) decentralization by itself does not provide superior         protection of privacy in DisCSP/DCOP algorithms when compared with centralization; instead, privacy protection also requires         the presence of uncertainty about agents&amp;#8217; knowledge of the constraint graph. (ii) one needs to carefully examine the metrics         chosen to measure privacy loss; the qualitative properties of privacy loss and hence the conclusions that can be drawn about         an algorithm can vary widely based on the metric chosen. This paper should thus serve as a call to arms for further privacy         research, particularly within the DisCSP/DCOP arena.      </content></document><document><year>2006</year><authors>Ariel Felner1 | Roni Stern1 | Jeffrey S. Rosenschein2  | Alex Pomeransky3</authors><title>Searching for close alternative plans      </title><content>Consider the situation where an intelligent agent accepts as input a complete plan, i.e., a sequence of states (or operators)         that should be followed in order to achieve a goal. For some reason, the given plan cannot be implemented by the agent, who         then goes about trying to find an alternative plan that is as close as possible to the original. To achieve this, a search         algorithm that will find similar alternative plans is required, as well as some sort of comparison function that will determine         which alternative plan is closest to the original. In this paper, we define a number of distance metrics between plans, and characterize these functions and their respective attributes and advantages. We then develop a general         algorithm based on best-first search that helps an agent efficiently find the most suitable alternative plan. We also propose         a number of heuristics for the cost function of this best-first search algorithm. To explore the generality of our idea, we         provide three different problem domains where our approach is applicable: physical roadmap path finding, the blocks world,         and task scheduling. Experimental results on these various domains support the efficiency of our algorithm for finding close         alternative plans.      </content></document><document><year>2006</year><authors>W. T. Luke Teacy1 | Jigar Patel1 | Nicholas R. Jennings1  | Michael Luck1 </authors><title>TRAVOS: Trust and Reputation in the Context of Inaccurate Information Sources      </title><content>In many dynamic open systems, agents have to interact with one another to achieve their goals. Here, agents may be self-interested,         and when trusted to perform an action for another, may betray that trust by not performing the action as required. In addition,         due to the size of such systems, agents will often interact with other agents with which they have little or no past experience.         There is therefore a need to develop a model of trust and reputation that will ensure good interactions among software agents         in large scale open systems. Against this background, we have developed TRAVOS (Trust and Reputation model for Agent-based Virtual OrganisationS) which models an agent&amp;#8217;s trust in an interaction partner.         Specifically, trust is calculated using probability theory taking account of past interactions between agents, and when there         is a lack of personal experience between agents, the model draws upon reputation information gathered from third parties.         In this latter case, we pay particular attention to handling the possibility that reputation information may be inaccurate.      </content></document><document><year>2006</year><authors>Rafael H. Bordini1 | Michael Fisher2 | Willem Visser3  | Michael Wooldridge2 </authors><title>Verifying Multi-agent Programs by Model Checking      </title><content>This paper gives an overview of our recent work on an approach to verifying multi-agent programs. We automatically translate         multi-agent systems programmed in the logic-based agent-oriented programming language AgentSpeak into either Promela or Java,         and then use the associated Spin and JPF model checkers to verify the resulting systems. We also describe the simplified BDI         logical language that is used to write the properties we want the systems to satisfy. The approach is illustrated by means         of a simple case study.      </content></document><document><year>2007</year><authors>Scott A. DeLoach1 | Walamitien H. Oyenan1 | Eric T. Matson2</authors><title>A capabilities-based model for adaptive organizations      </title><content>Multiagent systems have become popular over the last few years for building complex, adaptive systems in a distributed, heterogeneous         setting. Multiagent systems tend to be more robust and, in many cases, more efficient than single monolithic applications.         However, unpredictable application environments make multiagent systems susceptible to individual failures that can significantly         reduce its ability to accomplish its overall goal. The problem is that multiagent systems are typically designed to work within         a limited set of configurations. Even when the system possesses the resources and computational power to accomplish its goal,         it may be constrained by its own structure and knowledge of its member&amp;#8217;s capabilities. To overcome these problems, we are         developing a framework that allows the system to design its own organization at runtime. This paper presents a key component of that framework, a metamodel for multiagent organizations named the Organization Model         for Adaptive Computational Systems. This model defines the requisite knowledge of a system&amp;#8217;s organizational structure and         capabilities that will allow it to reorganize at runtime and enable it to achieve its goals effectively in the face of a changing         environment and its agent&amp;#8217;s capabilities.      </content></document><document><year>2007</year><authors>Ayodele Oluyomi1 | Shanika Karunasekera1  | Leon Sterling1 </authors><title>A comprehensive view of agent-oriented patterns      </title><content>This paper presents a comprehensive framework for classifying, analyzing and describing agent-oriented software patterns.         We present a two dimensional scheme for classifying agent-oriented patterns. We define agent-oriented pattern attributes and         use these attributes in a process for analyzing and placing agent-oriented patterns within the classification scheme. Using         the proposed classification scheme, we classify 28 patterns written by a variety of agent researchers, chosen from almost         100 patterns which we have studied.      </content></document><document><year>2007</year><authors>Francesco Amigoni1  | Nicola Gatti1 </authors><title>A formal framework for connective stability of highly decentralized cooperative negotiations      </title><content>Multiagent cooperative negotiation is a promising technique for modeling and controlling complex systems. Effective and flexible         cooperative negotiations are especially useful for open complex systems characterized by high decentralization (which implies         a low amount of exchanged information) and by dynamic connection and disconnection of agents. Applications include ad hoc         network management, vehicle formation, and physiological model combination. To obtain an effective control action, the stability of the negotiation, namely the guarantee that an agreement will be eventually reached, is of paramount importance. However,         the techniques usually employed for assessing the stability of a negotiation can be hardly applied in open scenarios. In this         paper, whose nature is mainly theoretical, we make a first attempt towards engineering stable cooperative negotiations proposing         a framework for their analysis and design. Specifically, we present a formal protocol for cooperative negotiations between a number of agents and we propose a criterion for negotiation stability based on the concept of connective stability. This is a form of stability that accounts for the effects of structural changes on the composition of a system and that         appears very suitable for multiagent cooperative negotiations. To show its possible uses, we apply our framework for connective         stability to some negotiations taken from literature.      </content></document><document><year>2007</year><authors>Anita Raja1  | Victor Lesser2 </authors><title>A framework for meta-level control in multi-agent systems      </title><content>Sophisticated agents operating in open environments must make decisions that efficiently trade off the use of their limited         resources between dynamic deliberative actions and domain actions. This is the meta-level control problem for agents operating         in resource-bounded multi-agent environments. Control activities involve decisions on when to invoke and the amount to effort         to put into scheduling and coordination of domain activities. The focus of this paper is how to make effective meta-level         control decisions. We show that meta-level control with bounded computational overhead allows complex agents to solve problems         more efficiently than current approaches in dynamic open multi-agent environments. The meta-level control approach that we         present is based on the decision-theoretic use of an abstract representation of the agent state. This abstraction concisely         captures critical information necessary for decision making while bounding the cost of meta-level control and is appropriate         for use in automatically learning the meta-level control policies.      </content></document><document><year>2007</year><authors>Frank Edward Walter1 | Stefano Battiston1  | Frank Schweitzer1 </authors><title>A model of a trust-based recommendation system on a social network      </title><content>In this paper, we present a model of a trust-based recommendation system on a social network. The idea of the model is that         agents use their social network to reach information and their trust relationships to filter it. We investigate how the dynamics         of trust among agents affect the performance of the system by comparing it to a frequency-based recommendation system. Furthermore,         we identify the impact of network density, preference heterogeneity among agents, and knowledge sparseness to be crucial factors         for the performance of the system. The system self-organises in a state with performance near to the optimum; the performance         on the global level is an emergent property of the system, achieved without explicit coordination from the local interactions         of agents.      </content></document><document><year>2007</year><authors>Leila Amgoud1  | Mathieu Serrurier1 </authors><title>Agents that argue and explain classifications      </title><content>Argumentation is a promising approach used by autonomous agents for reasoning about inconsistent/incomplete/uncertain knowledge,         based on the construction and the comparison of arguments. In this paper, we apply this approach to the classification problem,         whose purpose is to construct from a set of training examples a model that assigns a class to any new example. We propose         a formal argumentation-based model that constructs arguments in favor of each possible classification of an example, evaluates         them, and determines among the conflicting arguments the acceptable ones. Finally, a &amp;#8220;valid&amp;#8221; classification of the example         is suggested. Thus, not only the class of the example is given, but also the reasons behind that classification are provided         to the user as well in a form that is easy to grasp. We show that such an argumentation-based approach for classification         offers other advantages, like for instance classifying examples even when the set of training examples is inconsistent, and         considering more general preference relations between hypotheses. In the particular case of concept learning, the results         of version space theory developed by Mitchell are retrieved in an elegant way in our argumentation framework. Finally, we         show that the model satisfies the rationality postulates identified in argumentation literature. This ensures that the model         delivers sound results.      </content></document><document><year>2007</year><authors>Catholijn M. Jonker1 | Valentin Robu2  | Jan Treur3 </authors><title>An agent architecture for multi-attribute negotiation using incomplete preference information      </title><content>A component-based generic agent architecture for multi-attribute (integrative) negotiation is introduced and its application         is described in a prototype system for negotiation about cars, developed in cooperation with, among others, Dutch Telecom         KPN. The approach can be characterized as cooperative one-to-one multi-criteria negotiation in which the privacy of both parties         is protected as much as desired. We model a mechanism in which agents are able to use any amount of incomplete preference         information revealed by the negotiation partner in order to improve the efficiency of the reached agreements. Moreover, we         show that the outcome of such a negotiation can be further improved by incorporating a &amp;#8220;guessing&amp;#8221; heuristic, by which an agent         uses the history of the opponent&amp;#8217;s bids to predict his preferences. Experimental evaluation shows that the combination of         these two strategies leads to agreement points close to or on the Pareto-efficient frontier. The main original contribution         of this paper is that it shows that it is possible for parties in a cooperative negotiation to reveal only a limited amount         of preference information to each other, but still obtain significant joint gains in the outcome.      </content></document><document><year>2007</year><authors>Mark Sims1 | Daniel Corkill1  | Victor Lesser1 </authors><title>Automated organization design for multi-agent systems      </title><content>The ability to create effective multi-agent organizations is key to the development of larger, more diverse multi-agent systems.         In this article we present KB-ORG: a fully automated, knowledge-based organization designer for multi-agent systems. Organization         design is the process that accepts organizational goals, environmental expectations, performance requirements, role characterizations,         and agent descriptions and assigns roles to each agent. These long-term roles serve as organizational-control guidelines that         are used by each agent in making moment-to-moment operational control decisions. An important aspect of KB-ORG is its efficient,         knowledge-informed search process for designing multi-agent organizations. KB-ORG uses both application-level and coordination-level         organization design knowledge to explore the combinatorial search space of candidate organizations selectively. KB-ORG also         delays making coordination-level organizational decisions until it has explored and elaborated candidate application-level         agent roles. This approach significantly reduces the exploration effort required to produce effective designs as compared         to modeling and evaluation-based approaches that do not incorporate design expertise. KB-ORG designs are not restricted to         a single organization form such as a hierarchy, and the organization designs described here contain both hierarchical and         peer-to-peer elements. We use examples from the distributed sensor network (DSN) domain to show how KB-ORG uses situational         parameters as well as application-level and coordination-level knowledge to generate organization designs. We also show that         KB-ORG designs effective, yet substantially different, organizations when given different organizational requirements and         environmental expectations.      </content></document><document><year>2007</year><authors>Bikramjit Banerjee1  | Jing Peng1 </authors><title>Generalized multiagent learning with performance bound      </title><content>We present new Multiagent learning (MAL) algorithms with the general philosophy of policy convergence against some classes         of opponents but otherwise ensuring high payoffs. We consider a 3-class breakdown of opponent types: (eventually) stationary,         self-play and &amp;#8220;other&amp;#8221; (see Definition 4) agents. We start with ReDVaLeR that can satisfy policy convergence against the first         two types and no-regret against the third, but it needs to know the type of the opponents. This serves as a baseline to delineate         the difficulty of achieving these goals. We show that a simple modification on ReDVaLeR yields a new algorithm, RV         &amp;#963;(t), that achieves no-regret payoffs in all games, and convergence to Nash equilibria in self-play (and to best response against         eventually stationary opponents&amp;#8212;a corollary of no-regret) simultaneously, without knowing the opponent types, but in a smaller class of games than ReDVaLeR . RV         &amp;#963;(t) effectively ensures the performance of a learner during the process of learning, as opposed to the performance of a learned behavior. We show that the expression for regret of RV         &amp;#963;(t) can have a slightly better form than those of other comparable algorithms like GIGA and GIGA-WoLF though, contrastingly,         our analysis is in continuous time. Moreover, experiments show that RV         &amp;#963;(t) can converge to an equilibrium in some cases where GIGA, GIGA-WoLF would fail, and to better equilibria where GIGA, GIGA-WoLF         converge to undesirable equilibria (coordination games). This important class of coordination games also highlights the key         desirability of policy convergence as a criterion for MAL in self-play instead of high average payoffs. To our knowledge,         this is also the first successful (guaranteed) attempt at policy convergence of a no-regret;algorithm in the Shapley game.      </content></document><document><year>2007</year><authors>Mario GГіmez1 | Javier CarbГі1  | Clara Benac Earle1 </authors><title>Honesty and trust revisited: the advantages of being neutral about other&amp;#8217;s cognitive models      </title><content>Open distributed systems pose a challenge to trust modelling due to the dynamic nature of these systems (e.g., electronic         auctions) and the unreliability of self-interested agents. The majority of trust models implicitly assume a shared cognitive         model for all the agents participating in a society, and thus they treat the discrepancy between information and experience         as a source of distrust: if an agent states a given quality of service, and another agent experiences a different quality         for that service, such discrepancy is typically assumed to indicate dishonesty, and thus trust is reduced. Herein, we propose         a trust model, which does not assume a concrete cognitive model for other agents, but instead uses the discrepancy between         the information about other agents and its own experience to better predict the behavior of the others. This neutrality about         other agents&amp;#8217; cognitive models allows an agent to obtain utility from lyres or agents having a different model of the world.         The experiments performed suggest that this model improves the performance of an agent in dynamic scenarios under certain         conditions such as those found in market-like evolving environments.      </content></document><document><year>2007</year><authors>Nico Roos1  | Cees Witteveen2 </authors><title>Models and methods for plan diagnosis      </title><content>We consider a model-based diagnosis approach to the diagnosis of plans. Here, a plan performed by some agent(s) is considered         as a system to be diagnosed. We introduce a simple formal model of plans and plan execution where it is assumed that the execution         of a plan can be monitored by making partial observations of plan states. These observed states are used to compare them with         states predicted based on (normal) plan execution. Deviations between observed and predicted states can be explained by qualifying         some plan steps in the plan as behaving abnormally. A diagnosis is a subset of plan steps qualified as abnormal that can be         used to restore the compatibility between the predicted and the observed partial state. Besides minimum and subset minimal         diagnoses, we argue that in plan-based diagnosis maximum informative diagnoses should be considered as preferred diagnoses,         too. The latter ones are diagnoses that make the strongest predictions with respect to partial states to be observed in the         future. We show that in contrast to minimum diagnoses, finding a (subset minimal) maximum informative diagnosis can be achieved         in polynomial time. Finally, we show how these diagnoses can be found efficiently if the plan is distributed over a number         of agents.      </content></document><document><year>2007</year><authors>Eduardo Alonso1 </authors><title>Multi-agent learning      </title><content>Without Abstract</content></document><document><year>2007</year><authors>JГ¶rg Hansen1 </authors><title>Prioritized conditional imperatives: problems and a new proposal      </title><content>The sentences of deontic logic may be understood as describing what an agent ought to do when faced with a given set of norms.         If these norms come into conflict, the best the agent can be expected to do is to follow a maximal subset of the norms. Intuitively,         a priority ordering of the norms can be helpful in determining the relevant sets and resolve conflicts, but a formal resolution         mechanism has been difficult to provide. In particular, reasoning about prioritized conditional imperatives is overshadowed         by problems such as the &amp;#8216;order puzzle&amp;#8217; that are not satisfactorily resolved by existing approaches. The paper provides a new         proposal as to how these problems may be overcome.      </content></document><document><year>2007</year><authors>Dipyaman Banerjee1  | S|ip Sen1 </authors><title>Reaching pareto-optimality in prisoner&amp;#8217;s dilemma using conditional joint action learning      </title><content>We consider the learning problem faced by two self-interested agents repeatedly playing a general-sum stage game. We assume         that the players can observe each other&amp;#8217;s actions but not the payoffs received by the other player. The concept of Nash Equilibrium         in repeated games provides an individually rational solution for playing such games and can be achieved by playing the Nash         Equilibrium strategy for the single-shot game in every iteration. Such a strategy, however can sometimes lead to a Pareto-Dominated         outcome for games like Prisoner&amp;#8217;s Dilemma. So we prefer learning strategies that converge to a Pareto-Optimal outcome that         also produces a Nash Equilibrium payoff for repeated two-player, n-action general-sum games. The Folk Theorem enable us to         identify such outcomes. In this paper, we introduce the Conditional Joint Action Learner (CJAL) which learns the conditional         probability of an action taken by the opponent given its own actions and uses it to decide its next course of action. We empirically         show that under self-play and if the payoff structure of the Prisoner&amp;#8217;s Dilemma game satisfies certain conditions, a CJAL         learner, using a random exploration strategy followed by a completely greedy exploitation technique, will learn to converge         to a Pareto-Optimal solution. We also show that such learning will generate Pareto-Optimal payoffs in a large majority of         other two-player general sum games. We compare the performance of CJAL with that of existing algorithms such as WOLF-PHC and         JAL on all structurally distinct two-player conflict games with ordinal payoffs.      </content></document><document><year>2007</year><authors>Ariel Felner1 | Roni Stern1 | Jeffrey S. Rosenschein2  | Alex Pomeransky3</authors><title>Searching for close alternative plans      </title><content>Without Abstract</content></document><document><year>2007</year><authors>U. Topaloglu1  | C. Bayrak2 </authors><title>Secure mobile agent execution in virtual environment      </title><content>Creating a secure framework for mobile agents that leverage such an efficient tool&amp;#8217;s usage is yet to be found [Farmer WM,         Guttman JD, Swarup V (1996) Proceedings of the 19th national information systems security conference, Tardo J, Valente L (1996)         Mobile agent security and telescript, IEEE CompCon]. There are some available approaches to prevent agent-to-agent and agent-to-host         type attacks; however, host-to-agent type attacks prevention is still at large [Jansen W, Karygiannis T NIST special publication         800-19&amp;#8212;Mobile agent security, National Institute of Standards and Technology]. In this paper, we have implemented a framework         in which both agents and hosts are protected. The three virtualization techniques (vserver, vmware, and xen) are utilized         as host environments to create a secure, scalable, and efficient framework. Three agent platforms (ajanta, aglets, and sage)         are installed on these virtual environments and tested for attacks. Along with a trusted server, our framework claims to be         a solution to prevent host-to-agent type attacks during execution as well as most of the other types of attacks. As a result,         we believe that the convergence of two promising technologies (virtualization and mobile agents) can create cost-effective,         robust, reliable, and easy-to-manage frameworks.      </content></document><document><year>2007</year><authors>Olivier Buffet1 | Alain Dutech2  | FranГ§ois Charpillet2 </authors><title>Shaping multi-agent systems with gradient reinforcement learning      </title><content>An original reinforcement learning (RL) methodology is proposed for the design of multi-agent systems. In the realistic setting         of situated agents with local perception, the task of automatically building a coordinated system is of crucial importance.         To that end, we design simple reactive agents in a decentralized way as independent learners. But to cope with the difficulties         inherent to RL used in that framework, we have developed an incremental learning algorithm where agents face a sequence of         progressively more complex tasks. We illustrate this general framework by computer experiments where agents have to coordinate to reach a global goal.      </content></document><document><year>2007</year><authors>Kees Zoethout1 | W|er Jager2  | Eric Molleman1 </authors><title>Task dynamics in self-organising task groups: expertise, motivational, and performance differences of specialists and generalists      </title><content>Multi-agent simulation is applied to explore how different types of task variety cause workgroups to change their task allocation         accordingly. We studied two groups, generalists and specialists. We hypothesised that the performance of the specialists would         decrease when task variety increases. The generalists, on the other hand, would perform better in a high task variety condition.         The results show that these hypotheses were only partly supported because both learning and motivational effects changed the         task allocation process in a much more complex way. We conclude that although no task variety leads to specialisation and         high task variety leads to generalisation, in general, performance is better when task variety is low. Further, in case of         no task variety, specialists outperform generalists. In case of moderate variety the opposite is true. With high task variety,         since there is no space for any expertise and motivational development, the behaviour of specialists and generalists becomes         more similar, and, consequently also their performance.      </content></document><document><year>2007</year><authors>Bryan Horling1| 2  | Victor Lesser1 </authors><title>Using quantitative models to search for appropriate organizational designs      </title><content>As the scale and scope of distributed and multi-agent systems grow, it becomes increasingly important to design and manage         the participants&amp;#8217; interactions. The potential for bottlenecks, intractably large sets of coordination partners, and shared         bounded resources can make individual and high-level goals difficult to achieve. To address these problems, many large systems         employ an additional layer of structuring, known as an organizational design, that assigns agents different roles, responsibilities         and peers. These additional constraints can allow agents to operate more efficiently within the system by limiting the options         they must consider. Different designs applied to the same problem will have different performance characteristics, therefore         it is important to understand the behavior of competing candidate designs. In this article, we describe a new representation         for capturing such designs, and in particular we show how quantitative information can form the basis of a flexible, predictive         organizational model. The representation is capable of capturing a wide range of multi-agent characteristics in a single,         succinct model. We demonstrate the language&amp;#8217;s capabilities and efficacy by comparing a range of metrics predicted by detailed         models of a distributed sensor network and information retrieval system to empirical results. These same models also describe         the space of possible organizations in those domains and several search techniques are described that can be used to explore         this space, using those quantitative predictions and context-specific definitions of utility to evaluate alternatives. The         results of such a search process can be used to select the organizational design most appropriate for a given situation.      </content></document><document><year>2005</year><authors>Katie Atkinson1 | Trevor Bench-Capon1  | Peter Mcburney1 </authors><title>A Dialogue Game Protocol for Multi-Agent Argument over Proposals for Action</title><content>We present the syntax and semantics for a multi-agent dialogue game protocol which permits argument over proposals for action. The protocol, called the Persuasive Argument for Multiple Agents (PARMA) Protocol, embodies an earlier theory by the authors of persuasion over action which enables participants to rationally propose, attack, and defend, an action or course of actions (or inaction). We present an outline of both an axiomatic and a denotational semantics, and discuss implementation of the protocol, in the context of both human and artificial agents.</content></document><document><year>2005</year><authors>Ana L. C. Bazzan1</authors><title>A Distributed Approach for Coordination of Traffic Signal Agents</title><content>Innovative control strategies are needed to cope with the increasing urban traffic chaos. In most cases, the currently used strategies are based on a central traffic-responsive control system which can be demanding to implement and maintain. Therefore, a functional and spatial decentralization is desired. For this purpose, distributed artificial intelligence and multi-agent systems have come out with a series of techniques which allow coordination and cooperation. However, in many cases these are reached by means of communication and centrally controlled coordination processes, giving little room for decentralized management. Consequently, there is a lack of decision-support tools at managerial level (traffic control centers) capable of dealing with decentralized policies of control and actually profiting from them. In the present work a coordination concept is used, which overcomes some disadvantages of the existing methods. This concept makes use of techniques of evolutionary game theory: intersections in an arterial are modeled as individually-motivated agents or players taking part in a dynamic process in which not only their own local goals but also a global one has to be taken into account. The role of the traffic manager is facilitated since s/he has to deal only with tactical ones, leaving the operational issues to the agents. Thus the system ultimately provides support for the traffic manager to decide on traffic control policies. Some application in traffic scenarios are discussed in order to evaluate the feasibility of transferring the responsibility of traffic signal coordination to agents. The results show different performances of the decentralized coordination process in different scenarios (e.g. the flow of vehicles is nearly equal in both opposing directions, one direction has a clearly higher flow, etc.). Therefore, the task of the manager is facilitate once s/he recognizes the scenario and acts accordingly.</content></document><document><year>2005</year><authors>Ana L. C. Bazzan1</authors><title>A Distributed Approach for Coordination of Traffic Signal Agents</title><content>Innovative control strategies are needed to cope with the increasing urban traffic chaos. In most cases, the currently used strategies are based on a central traffic-responsive control system which can be demanding to implement and maintain. Therefore, a functional and spatial decentralization is desired. For this purpose, distributed artificial intelligence and multi-agent systems have come out with a series of techniques which allow coordination and cooperation. However, in many cases these are reached by means of communication and centrally controlled coordination processes, giving little room for decentralized management. Consequently, there is a lack of decision-support tools at managerial level (traffic control centers) capable of dealing with decentralized policies of control and actually profiting from them. In the present work a coordination concept is used, which overcomes some disadvantages of the existing methods. This concept makes use of techniques of evolutionary game theory: intersections in an arterial are modeled as individually-motivated agents or players taking part in a dynamic process in which not only their own local goals but also a global one has to be taken into account. The role of the traffic manager is facilitated since s/he has to deal only with tactical ones, leaving the operational issues to the agents. Thus the system ultimately provides support for the traffic manager to decide on traffic control policies. Some application in traffic scenarios are discussed in order to evaluate the feasibility of transferring the responsibility of traffic signal coordination to agents. The results show different performances of the decentralized coordination process in different scenarios (e.g. the flow of vehicles is nearly equal in both opposing directions, one direction has a clearly higher flow, etc.). Therefore, the task of the manager is facilitate once s/he recognizes the scenario and acts accordingly.</content></document><document><year>2005</year><authors>Carles Sierra | Liz Sonenberg</authors><title>A Real-Time Negotiation Model and A Multi-Agent Sensor Network Implementation</title><content>Without Abstract</content></document><document><year>2005</year><authors>Leen-Kiat Soh1  | Costas Tsatsoulis2</authors><title>A Real-Time Negotiation Model and A Multi-Agent Sensor Network Implementation      </title><content>This paper describes a negotiation model that incorporates real-time issues for autonomous agents. This model consists of         two important ideas: a real-time logical negotiation protocol and a case-based negotiation model. The protocol integrates         a real-time Belief-Desire-Intention (BDI) model, a temporal logic model, and communicative acts for negotiation. This protocol         explicitly defines the logical and temporal relationships of different knowledge states, facilitating real-time designs such         as multi-threaded processing, state profiling and updating, and a set of real-time enabling functional predicates in our implementation.         To further support the protocol, we use a case-based reasoning model for negotiation strategy selection. An agent learns from         its past experience by deriving a negotiation strategy from the most similar and useful case to its current situation. Guided         by the strategy, the agent negotiates with its partners using an argumentation-based negotiation protocol. The model is time         and situation aware such that each agent changes its negotiation behavior according to the progress and status of the ongoing         negotiation and its current agent profile. We apply the negotiation model to a resource allocation problem and obtain promising         results.      </content></document><document><year>2005</year><authors>Ka-Man Lam1  | Ho-Fung Leung1 </authors><title>A Trust/Honesty Model with Adaptive Strategy for Multiagent Semi-Competitive Environments      </title><content>In multiagent semi-competitive environments, competitions and cooperations can both exist. As agents compete with each other,         they have incentives to lie. Sometimes, agents can increase their utilities by cooperating with each other, then they have         incentives to tell the truth. Therefore, being a receiver, an agent needs to decide whether or not to trust the received message(s).         To help agents make this decision, some of the existing models make use of trust or reputation only, which means agents choose         to believe (or cooperate with) the trustworthy senders or senders with high reputation. However, a trustworthy agent may only         bring little benefit. Another way to make the decision is to use expected utility. However, agents who only believe messages         with high expected utilities can be cheated easily. To solve the problems, this paper introduces the Trust Model, which makes         use of trust, expected utility, and also agents&amp;#8217; attitudes towards risk to make decisions. On the other hand, being a sender,         an agent needs to decide whether or not to be honest. To help agents make this decision, this paper introduces the Honesty         Model, which is symmetric to the Trust Model. In addition, we introduce an adaptive strategy to the Trust/Honesty Model, which         enables agents to learn from and adapt to the environment. Simulations show that agents with the Adaptive Trust/Honesty Model         perform much better than agents which only use trust or expected utility to make the decision      </content></document><document><year>2005</year><authors>Karl Tuyls1 | Pieter Jan &amp;#8217 T Hoen2  | Bram Vanschoenwinkel3 </authors><title>An Evolutionary Dynamical Analysis of Multi-Agent Learning in Iterated Games      </title><content>In this paper, we investigate Reinforcement learning (RL) in multi-agent systems (MAS) from an evolutionary dynamical perspective.         Typical for a MAS is that the environment is not stationary and the Markov property is not valid. This requires agents to         be adaptive. RL is a natural approach to model the learning of individual agents. These Learning algorithms are however known         to be sensitive to the correct choice of parameter settings for single agent systems. This issue is more prevalent in the         MAS case due to the changing interactions amongst the agents. It is largely an open question for a developer of MAS of how         to design the individual agents such that, through learning, the agents as a collective arrive at good solutions. We will         show that modeling RL in MAS, by taking an evolutionary game theoretic point of view, is a new and potentially successful         way to guide learning agents to the most suitable solution for their task at hand. We show how evolutionary dynamics (ED)         from Evolutionary Game Theory can help the developer of a MAS in good choices of parameter settings of the used RL algorithms.         The ED essentially predict the equilibriums outcomes of the MAS where the agents use individual RL algorithms. More specifically,         we show how the ED predict the learning trajectories of Q-Learners for iterated games. Moreover, we apply our results to (an         extension of) the COllective INtelligence framework (COIN). COIN is a proved engineering approach for learning of cooperative         tasks in MASs. The utilities of the agents are re-engineered to contribute to the global utility. We show how the improved         results for MAS RL in COIN, and a developed extension, are predicted by the ED.      </content></document><document><year>2005</year><authors>Marcela Capobianco1 | Carlos I. Ches&amp;ntilde evar1| 2  | Guillermo R. Simari1 </authors><title>Argumentation and the Dynamics of Warranted Beliefs in Changing Environments</title><content>One of the most difficult problems in Multi-Agent Systems (MAS) involves representing the knowledge and beliefs of an agent which performs its tasks in a dynamic environment. New perceptions modify this agent&amp;#x2019;s current knowledge about the world, and consequently its beliefs about it also change. Such a revision and update process should be performed efficiently by the agent, particularly in the context of real-time constraints. In the last decade argumentation has evolved as a successful approach to formalize defeasible, commonsense reasoning, gaining wide acceptance in the MAS community by providing tools for designing and implementing features, which characterize reasoning capabilities in rational agents. In this paper we present a new argument-based formalism specifically designed for representing knowledge and beliefs of agents in dynamic environments, called Observation-based Defeasible Logic Programming (ODeLP). A simple but effective perception mechanism allows an ODeLP-based agent to model new incoming perceptions, and modify the agent&amp;#x2019;s knowledge about the world accordingly. In addition, in order to improve the reactive capabilities of ODeLP-based agents, the process of computing beliefs in a changing environment is made computationally attractive by integrating a &amp;#x201c;dialectical database&amp;#x201d; with the agent&amp;#x2019;s program, providing pre-compiled information about previous inferences. We present algorithms for managing dialectical databases as well as examples of their use in the context of real-world problems.</content></document><document><year>2005</year><authors>Anthony Bagnall1  | Iain Toft1 </authors><title>Autonomous Adaptive Agents for Single Seller Sealed Bid Auctions      </title><content>In developing open, heterogeneous and distributed multi-agent systems researchers often face a problem of facilitating negotiation         and bargaining amongst agents. It is increasingly common to use auction mechanisms for negotiation in multi-agent systems.         The choice of auction mechanism and the bidding strategy of an agent are of central importance to the success of the agent         model. Our aim is to determine the best agent learning algorithm for bidding in a variety of single seller auction structures         in both static environments where a known optimal strategy exists and in complex environments where the optimal strategy may         be constantly changing. In this paper we present a model of single seller auctions and describe three adaptive agent algorithms         to learn strategies through repeated competition. We experiment in a range of auction environments of increasing complexity         to determine how well each agent performs, in relation to an optimal strategy in cases where one can be deduced, or in relation         to each other in other cases. We find that, with a uniform value distribution, a purely reactive agent based on Cliff&amp;#8217;s ZIP         algorithm for continuous double auctions (CDA) performs well, although is outperformed in some cases by a memory based agent         based on the Gjerstad Dickhaut agent for CDA.      </content></document><document><year>2005</year><authors>Adam J. Rocke1  | Ronald F. Demara1 </authors><title>CONFIDANT: Collaborative Object Notification Framework for Insider Defense using Autonomous Network Transactions      </title><content>File Integrity Analyzers serve as a component of an Intrusion Detection environment by performing filesystem inspections to verify the content of security-critical files in order to detect suspicious         modification. Existing file integrity frameworks exhibit single point-of-failure exposures. The Collaborative Object Notification Framework for Insider Defense using Autonomous Network Transactions (CONFIDANT) framework aims at fail-safe and trusted detection of unauthorized modifications to executable, data, and configuration         files. In this paper, an IDS architecture taxonomy is proposed to classify and compare CONFIDANT with existing frameworks.         The CONFIDANT file integrity verification framework is then defined and evaluated. CONFIDANT utilizes three echelons of agent interaction and four autonomous behaviors. Sensor agents in the lowest echelon comprise the sensor level to generate an assured report to companion agents of computed MD5 file digests. At the control level, beacon agents verify file integrity based on the digests from sensor-level agents assembled over time. Upper echelon transactions         occur at the response level. Here watchdog behavior agents dispatch probe agents to implement the alarm signaling protocol. CONFIDANT has been implemented in the Concordia agent environment to evaluate         and refine its agent behaviors. Evaluation shows that CONFIDANT mitigates single point-of-failure exposures that are present         in existing frameworks.      </content></document><document><year>2005</year><authors>Liviu Panait1  | Sean Luke1 </authors><title>Cooperative Multi-Agent Learning: The State of the Art      </title><content>Cooperative multi-agent systems (MAS) are ones in which several agents attempt, through their interaction, to jointly solve         tasks or to maximize utility. Due to the interactions among the agents, multi-agent problem complexity can rise rapidly with         the number of agents or their behavioral sophistication. The challenge this presents to the task of programming solutions         to MAS problems has spawned increasing interest in machine learning techniques to automate the search and optimization process.         We provide a broad survey of the cooperative multi-agent learning literature. Previous surveys of this area have largely focused         on issues common to specific subareas (for example, reinforcement learning, RL or robotics). In this survey we attempt to         draw from multi-agent learning work in a spectrum of areas, including RL, evolutionary computation, game theory, complex systems,         agent modeling, and robotics. We find that this broad view leads to a division of the work into two categories, each with         its own special issues: applying a single learner to discover joint solutions to multi-agent problems (team learning), or using multiple simultaneous learners, often one per agent (concurrent learning). Additionally, we discuss direct and indirect communication in connection with learning, plus open issues in task decomposition,         scalability, and adaptive dynamics. We conclude with a presentation of multi-agent learning problem domains, and a list of         multi-agent learning resources.      </content></document><document><year>2005</year><authors>Gang Chen1 | Zhonghua Yang1 | Hao He2  | Kiah Mok Goh2 </authors><title>Coordinating Multiple Agents via Reinforcement Learning</title><content>In this paper, we attempt to use reinforcement learning techniques to solve agent coordination problems in task-oriented environments. The Fuzzy Subjective Task Structure model (FSTS) is presented to model the general agent coordination. We show that an agent coordination problem modeled in FSTS is a Decision-Theoretic Planning (DTP) problem, to which reinforcement learning can be applied. Two learning algorithms, coarse-grained and fine-grained, are proposed to address agents coordination behavior at two different levels. The coarse-grained algorithm operates at one level and tackle hard system constraints, and the fine-grained at another level and for soft constraints. We argue that it is important to explicitly model and explore coordination-specific (particularly system constraints) information, which underpins the two algorithms and attributes to the effectiveness of the algorithms. The algorithms are formally proved to converge and experimentally shown to be effective.</content></document><document><year>2005</year><authors>Xiaoqin Zhang1 | Victor Lesser2  | Sherief Abdallah2 </authors><title>Efficient Management of Multi-Linked Negotiation Based on a Formalized Model</title><content>A Multi-linked negotiation problem occurs when an agent needs to negotiate with multiple other agents about different subjects (tasks, conflicts, or resource requirements), and the negotiation over one subject has influence on negotiations over other subjects. The solution of the multi-linked negotiations problem will become increasingly important for the next generation of advanced multi-agent systems. However, most current negotiation research looks only at a single negotiation and thus does not present techniques to manage and reason about multi-linked negotiations. In this paper, we first present a technique based on the use of a partial-order schedule and a measure of the schedule, called flexibility, which enables an agent to reason explicitly about the interactions among multiple negotiations. Next, we introduce a formalized model of the multi-linked negotiation problem. Based on this model, a heuristic search algorithm is developed for finding a near-optimal ordering of negotiation issues and their parameters. Using this algorithm, an agent can evaluate and compare different negotiation approaches and choose the best one. We show how an agent uses this technology to effectively manage interacting negotiation issues. Experimental work is presented which shows the efficiency of this approach.</content></document><document><year>2005</year><authors>Fabr&amp;iacute cio Enembreck1  | Jean-Paul Brath&amp;egrave s1 </authors><title>ELA&amp;#x2014;A new Approach for Learning Agents</title><content>In this paper we discuss a new incremental learning approach used to implement adaptive behavior in autonomous agents. Adaptive agents must increase their performance based on experience using some learning approach. Often, incremental learning techniques like memory-based reasoning (MBR) are used. However, traditional MBR algorithms require an adequate (generally complex) measure of similarity, need much data and spend much time for computing similarities between examples. Such problems are unacceptable for autonomous agents that live in very dynamic environments, because they have little time to make decisions. Our approach does not use similarity measures between examples, classifies examples very fast and can compact data. We represent data as a concept graph (CG), each node representing a partition of the data. We propose an algorithm that uses the partitions to classify new examples. We compare our results with other techniques and conclude that the method performs quite well. Finally, we apply the approach to an application of adaptive agents for personalizing web search.</content></document><document><year>2005</year><authors>Jonathan Gratch1  | Stacy Marsella2 </authors><title>Evaluating a Computational Model of Emotion</title><content>Spurred by a range of potential applications, there has been a growing body of research in computational models of human emotion. To advance the development of these models, it is critical that we evaluate them against the phenomena they purport to model. In this paper, we present one method to evaluate an emotion model that compares the behavior of the model against human behavior using a standard clinical instrument for assessing human emotion and coping. We use this method to evaluate the Emotion and Adaptation (EMA) model of emotion Gratch and Marsella. The evaluation highlights strengths of the approach and identifies where the model needs further development.</content></document><document><year>2005</year><authors>Lin Padgham1  | Patrick Lambrix2 </authors><title>Formalisations of Capabilities for BDI-Agents</title><content>Intentional agent systems are increasingly being used in a wide range of complex applications. Capabilities has recently been introduced into some of these systems as a software engineering mechanism to support modularity and reusability while still allowing meta-level reasoning. This paper presents possible formalisations of capabilities within the framework of beliefs, goals and intentions and indicates how capabilities can affect agent reasoning about its intentions. We define a style of agent commitment which we refer to as a self-aware agent which allows an agent to modify its goals and intentions as its capabilities change. We also indicate which aspects of the specification of a BDI interpreter are affected by the introduction of capabilities and give some indications of additional reasoning which could be incorporated into an agent system on the basis of both the theoretical analysis and the existing implementation.</content></document><document><year>2005</year><authors>Magdalena Kacprzak1  | Wojciech Penczek2| 3 </authors><title>Fully Symbolic Unbounded Model Checking for Alternating-time Temporal Logic1</title><content>Alternating-time Temporal Logic (ATL) is typically applied for specifying properties of multi-agent systems modelled by game-like structures. This paper deals with verification of ATL by means of a fully symbolic model checking. Unbounded model checking (a SAT-based technique) is applied for the first time to verification of AT. Several examples are given in order to present an application of the technique.</content></document><document><year>2005</year><authors>Iyad Rahwan1| 2 </authors><title>Guest Editorial: Argumentation in Multi-Agent Systems</title><content>Without Abstract</content></document><document><year>2005</year><authors>Shaul Markovitch1  | Ronit Reger1 </authors><title>Learning and Exploiting Relative Weaknesses of Opponent Agents</title><content>Agents in a competitive interaction can greatly benefit from adapting to a particular adversary, rather than using the same general strategy against all opponents. One method of such adaptation isOpponent Modeling, in which a model of an opponent is acquired and utilized as part of the agents decision procedure in future interactions with this opponent. However, acquiring an accurate model of a complex opponent strategy may be computationally infeasible. In addition, if the learned model is not accurate, then using it to predict the opponents actions may potentially harm the agents strategy rather than improving it. We thus define the concept ofopponent weakness, and present a method for learning a model of this simpler concept. We analyze examples of past behavior of an opponent in a particular domain, judging its actions using a trusted judge. We then infer aweakness model based on the opponents actions relative to the domain state, and incorporate this model into our agents decision procedure. We also make use of a similar self-weakness model, allowing the agent to prefer states in which the opponent is weak and our agent strong; where we have arelative advantage over the opponent. Experimental results spanning two different test domains demonstrate the agents improved performance when making use of the weakness models.</content></document><document><year>2005</year><authors>Pilar Herrero1 | Chris Greenhalgh2 | AngГ©lica de Antonio3</authors><title>Modelling the Sensory Abilities of Intelligent Virtual Agents      </title><content>An important property of Intelligent Virtual Agents (IVAs) is their capability to acquire/perceive information from their         environment. Bearing in mind some studies on situational awareness &amp;#8211; where sensitive perception can be understood as the first level of awareness &amp;#8211; and taking into account one of the most         successful awareness models in Computer Supported Cooperative Work (CSCW) &amp;#8211; the Spatial Model of Interaction (SMI), we have         developed a human-like perceptual model for IVAs. This perceptual model extends and reinterprets the key concepts of the SMI         and also introduces some factors typical from human being perception with the aim of making perception, in this kind of systems,         more human-like.      </content></document><document><year>2005</year><authors>Antonis Kakas1 | Nicolas Maudet2  | Pavlos Moraitis1 </authors><title>Modular Representation of Agent Interaction Rules through Argumentation</title><content>Communication between agents needs to be flexible enough to encompass together a variety of different aspects such as, conformance to society protocols, private tactics of the individual agents, strategies that reflect different classes of agent types (or personal attitudes) and adaptability to the particular external circumstances at the time when the communication takes place. In this paper, we propose an argument-based framework for representing communication theories of agents that can take into account in a uniform way these different aspects. We show how this approach can be used to realize existing types of dialogue strategies and society protocols in a way that facilitates their modular development and extension to make them more flexible in handling different or special circumstances.</content></document><document><year>2005</year><authors>Ariel Felner1 | Yaron Shoshani2 | Yaniv Altshuler3  | Alfred M. Bruckstein3 </authors><title>Multi-agent Physical A* with Large Pheromones      </title><content>Physical A* (PHA*) and its multi-agent version MAPHA* are algorithms that find the shortest path between two points in an         unknown real physical environment with one or many mobile agents [A. Felner et al. Journal of Artificial Intelligence Research, 21:631&amp;#8211;679, 2004; A. Felner et al. Proceedings of the First International Joint Conference on Autonomous Agents and Multi-Agent Systems, Bologna, Italy, 2002:240&amp;#8211;247]. Previous work assumed a complete sharing of knowledge between agents. Here we apply this         algorithm to a more restricted model of communication which we call large pheromones, where agents communicate by writing and reading data at nodes of the graph that constitutes their environment. Previous         works on pheromones usually assumed that only a limited amount of data can be written at each node. The large pheromones model assumes no limitation on the size of the pheromones and thus each agent can write its entire knowledge at a node. We         show that with this model of communication the behavior of a multi-agent system is almost as good as with complete knowledge         sharing. Under this model we also introduce a new type of agent, a communication agent, that is responsible for spreading the knowledge among other agents by moving around the graph and copying pheromones. Experimental         results show that the contribution of communication agents is rather limited as data is already spread to other agents very         well with large pheromones      </content></document><document><year>2005</year><authors>Xiaoqin Zhang1| Victor Lesser2 | Rodion Podorozhny3</authors><title>Multi-Dimensional, MultiStep Negotiation</title><content>We present a multi-dimensional, multi-step negotiation mechanism for task allocation among cooperative agents based on distributed search. This mechanism uses marginal utility gain and marginal utility cost to structure this search process, so as to find a solution that maximizes the agents&amp;#x2019; combined utility. These two utility values together with temporal constraints summarize the agents&amp;#x2019; local information and reduce the communication load. This mechanism is anytime in character: by investing more time, the agents increase the likelihood of getting a better solution. We also introduce a multiple attribute utility function into negotiations. This allows agents to negotiate over the multiple attributes of the commitment, which produces more options, making it more likely for agents to find a solution that increases the global utility. A set of protocols are constructed and the experimental result shows a phase transition phenomenon as the complexity of negotiation situation changes. A measure of negotiation complexity is developed that can be used by an agent to choose an appropriate protocol, allowing the agents to explicitly balance the gain from the negotiation and the resource usage of the negotiation.</content></document><document><year>2005</year><authors>Pinata Winoto1 | Gordon I. McCalla1  | Julita Vassileva1 </authors><title>Non-Monotonic-Offers Bargaining Protocol</title><content>This paper concerns the strengths and weaknesses of non-monotonic-offers in alternating-offer bargaining protocols. It is commonly assumed that bargainers submit monotonic offers over time corresponding to their belief revisions. However, through formal analysis and simulations, we are able to show that a non-monotonic-offers protocol can generate higher average surplus and a lower breakdown rate compared to a monotonic-offers protocol.</content></document><document><year>2005</year><authors>RenГ©e Elio1 | Anita Petrinjak1</authors><title>Normative Communication Models for Agent      </title><content>An agent message is an attempted action upon the information state of the receiver that, if successful, would cause the receiver         to move to a new information state. A model of normative communication can define when messages are not merely unsuccessful         but instead are illegal or impossible actions upon the receiver&amp;#8217;s internal state. The model uses the preconditions of the         other core message types, coupled with a model of task interdependencies, agent roles, and belief-desire-intention elements,         to define the preconditions for sending a canonical not-understood error message. By defining the space of messages that are legal actions on an agent&amp;#8217;s internal state, a normative communication         model also defines a set of &amp;#8216;reasons&amp;#8217; that can accompany the error message. A not-understood error message signals a mismatch between agent interaction models and the accompanying reason opens the possibility for agents         to realign their respective models. The paper discusses the matters arising from this possibility. This approach assumes that         normative communication behavior reflects normative domain behavior. It also assumes that each agent accesses the normative         model, in contrast with more centralized frameworks for defining normative interaction among agents and identifying interaction         errors.      </content></document><document><year>2005</year><authors>Ulle Endriss1  | Nicolas Maudet2 </authors><title>On the Communication Complexity of Multilateral Trading: Extended Report</title><content>We study the complexity of a multilateral negotiation framework, where autonomous agents agree on a sequence of deals to exchange sets of discrete resources in order to both further their own goals and to achieve a distribution of resources that is socially optimal. When analysing such a framework, we can distinguish different aspects of complexity: How many deals are required to reach an optimal allocation of resources? How many communicative exchanges are required to agree on one such deal? How complex a communication language do we require? And finally, how complex is the reasoning task faced by each agent?</content></document><document><year>2005</year><authors>Javier VГЎzquez-Salceda1 | Virginia Dignum1  | Frank Dignum1 </authors><title>Organizing Multiagent Systems      </title><content>Despite all the research done in the last years on the development of methodologies for designing MAS, there is no methodology         suitable for the specification and design of MAS in complex domains where both the agent view and the organizational view         can be modeled. Current multiagent approaches either take a centralist, static approach to organizational design or take an         emergent view in which agent interactions are not pre-determined, thus making it impossible to make any predictions on the         behavior of the whole systems. Most of them also lack a model of the norms in the environment that should rule the (emergent)         behavior of the agent society as a whole and/or the actions of individuals. In this paper, we propose a framework for modeling         agent organizations, Organizational Model for Normative Institutions (OMNI), that allows the balance of global organizational         requirements with the autonomy of individual agents. It specifies global goals of the system independently from those of the         specific agents that populate the system. Both the norms that regulate interaction between agents, as well as the contextual         meaning of those interactions are important aspects when specifying the organizational structure.      </content></document><document><year>2005</year><authors>Michael Wooldridge</authors><title>Sarit Kraus, Strategic Negotiation in Multiagent Environments, MIT Press, 2001; ISBN: 0-262-11264-7</title><content>Without Abstract</content></document><document><year>2005</year><authors>Takayuki Suyama1  | Makoto Yokoo2 </authors><title>Strategy/False-name Proof Protocols for Combinatorial Multi-Attribute Procurement Auction</title><content>In this paper, we investigate a model of a combinatorial, procurement multi-attribute auction, in which each sales item is defined by several attributes called quality, the buyer is the auctioneer (e.g., a government), and the sellers are the bidders. Furthermore, there exist multiple items and both buyer and sellers can have arbitrary (e.g., substitutable/complementary) preferences on a bundle of items. Our goal is to develop a protocol that is strategy-proof for sellers. We first present a VickreyClarkeGroves (VCG)-type protocol. As in a standard combinatorial auction, a VCG-type protocol is not false-name-proof, i.e., it is vulnerable against manipulations using multiple identifiers. Next, we show that any strategy-proof protocol in this model can be represented as a framework called Price-Oriented Rationing-Free (PORF) protocol, in which for each bidder, for each bundle of items, and for each quality, the payment for the bidder is determined independently of his own declaration, and the bidder can obtain a bundle that maximizes his utility independently of the allocations of other bidders. We develop a false-name-proof protocol in this model.</content></document><document><year>2005</year><authors>Michael Fisher1</authors><title>Temporal Development Methods for Agent-Based</title><content>In this paper we overview one specific approach to the formal development of multi-agent systems. This approach is based on the use of temporal logics to represent both the behaviour of individual agents, and the macro-level behaviour of multi-agent systems. We describe how formal specification, verification and refinement can all be developed using this temporal basis, and how implementation can be achieved by directly executing these formal representations. We also show how the basic framework can be extended in various ways to handle the representation and implementation of agents capable of more complex deliberation and reasoning.</content></document><document><year>2005</year><authors>Bryan Horling1 | Victor Lesser1 | RГ©gis Vincent2  | Thomas Wagner3 </authors><title>The Soft Real-Time Agent Control Architecture      </title><content>Real-time control has become increasingly important as technologies are moved from the lab into real world situations. The         complexity associated with these systems increases as control and autonomy are distributed, due to such issues as temporal         and ordering constraints, shared resources, and the lack of a complete and consistent world view. In this paper we describe         a soft real-time architecture designed to address these requirements, motivated by challenges encountered in a real-time distributed         sensor allocation environment. The system features the ability to generate schedules respecting temporal, structural and resource         constraints, to merge new goals with existing ones, and to detect and handle unexpected results from activities. We will cover         a suite of technologies being employed, including quantitative task representation, alternative plan selection, partial-order         scheduling, schedule consolidation and execution and conflict resolution in an uncertain environment. Technologies which facilitate         on-line real-time control, including meta-level accounting, schedule caching and variable time granularities are also discussed.      </content></document><document><year>2005</year><authors>Chris Reed1  | Doug Walton2 </authors><title>Towards a Formal and Implemented Model of Argumentation Schemes in Agent Communication</title><content>Argumentation schemes are patterns of non-deductive reasoning that have been the focus of extended study in argumentation theory. They have also been identified in computational domains including multi-agent systems as holding the potential for significant improvements in reasoning and communication abilities. By focusing on models of natural language argumentation schemes, and then building formal systems from them, direct implementation in multi-agent environments becomes a possibility. The formal, representational and implementational details are presented here, along with results that demonstrate not only advantages of flexibility, scope, and knowledge sharing, but also of computational efficiency.</content></document></documents>