<?xml version="1.0" encoding="UTF-8" standalone="no"?><documents><document><year>2004</year><authors>Adam Meyerson | Liadan O'Callaghan  | Serge Plotkin </authors><title>A k-Median Algorithm with Running Time Independent of Data Size</title><content>We give a sampling-based algorithm for the k-Median problem, with running time O(k log), where k is the desired number of clusters and  is a confidence parameter. This is the first k-Median algorithm with fully polynomial running time that is independent of n, the size of the data set. It gives a solution that is, with high probability, an O(1)-approximation, if each cluster in some optimal solution has  points. We also give weakly-polynomial-time algorithms for this problem and a relaxed version of k-Median in which a small fraction of outliers can be excluded. We give near-matching lower bounds showing that this assumption about cluster size is necessary. We also present a related algorithm for finding a clustering that excludes a small number of outliers.</content></document><document><year>2004</year><authors>Gregory F. Cooper1 | Edward Herskovits2</authors><title>A Bayesian Method for the Induction of Probabilistic Networks from Data</title><content>This paper presents a Bayesian method for constructing probabilistic networks from databases. In particular, we focus on constructing Bayesian belief networks. Potential applications include computer-assisted hypothesis testing, automated scientific discovery, and automated construction of probabilistic expert systems. We extend the basic method to handle missing data and hidden (latent) variables. We show how to perform probabilistic inference by averaging over the inferences of multiple belief networks. Results are presented of a preliminary evaluation of an algorithm for constructing a belief network from a database of cases. Finally, we relate the methods in this paper to previous work, and we discuss open problems.</content></document><document><year>2004</year><authors>Jonathan Baxter1| 2 </authors><title>A Bayesian/Information Theoretic Model of Learning to Learn via Multiple Task Sampling</title><content>A Bayesian model of learning to learn by sampling from multiple tasks is presented. The multiple tasks are themselves generated by sampling from a distribution over an environment of related tasks. Such an environment is shown to be naturally modelled within a Bayesian context by the concept of an objective prior distribution. It is argued that for many common machine learning problems, although in general we do not know the true (objective) prior for the problem, we do have some idea of a set of possible priors to which the true prior belongs. It is shown that under these circumstances a learner can use Bayesian inference to learn the true prior by learning sufficiently many tasks from the environment. In addition, bounds are given on the amount of information required to learn a task when it is simultaneously learnt with several other tasks. The bounds show that if the learner has little knowledge of the true prior, but the dimensionality of the true prior is small, then sampling multiple tasks is highly advantageous. The theory is applied to the problem of learning a common feature set or equivalently a low-dimensional-representation (LDR) for an environment of related tasks.</content></document><document><year>2004</year><authors>Peter van der Putten1  | Maarten van Someren2 </authors><title>A Bias-Variance Analysis of a Real World Learning Problem: The CoIL Challenge 2000</title><content>The CoIL Challenge 2000 data mining competition attracted a wide variety of solutions, both in terms of approaches and performance. The goal of the competition was to predict who would be interested in buying a specific insurance product and to explain why people would buy. Unlike in most other competitions, the majority of participants provided a report describing the path to their solution. In this article we use the framework of bias-variance decomposition of error to analyze what caused the wide range of prediction performance. We characterize the challenge problem to make it comparable to other problems and evaluate why certain methods work or not. We also include an evaluation of the submitted explanations by a marketing expert. We find that variance is the key component of error for this problem. Participants use various strategies in data preparation and model development that reduce variance error, such as feature selection and the use of simple, robust and low variance learners like Naive Bayes. Adding constructed features, modeling with complex, weak bias learners and extensive fine tuning by the participants often increase the variance error.</content></document><document><year>2004</year><authors>Arthur J. Nevins1</authors><title>A Branch and Bound Incremental Conceptual Clusterer</title><content>A computer program is described that is capable of learning multiple concepts and their structural descriptions from observations of examples. It decomposes this conceptual clustering problem into two modules. The first module is concerned with forming a generalization from a pair of examples by extracting their common structure and calculating an information measure for each structural description. The second module, which is the subject of this paper, incrementally incorporates these generalizations into a hierarchy of concepts. This second module operates without reference to any underlying representation language and utilizes only the information measure provided by the first module, while employing a branch and bound procedure to search the hierarchy for concepts from which to form new clusters. This ability to search the hierarchy is used as the basis of a hill climbing strategy which has as its goal the avoidance of local peaks so as to reduce the sensitivity of the program to the order in which the observations are encountered.</content></document><document><year>2004</year><authors>Claire Cardie1 </authors><title>A Cognitive Bias Approach to Feature Selection and Weighting for Case-Based Learners</title><content>Research in psychology, psycholinguistics, and cognitive science has discovered and examined numerous psychological constraints on human information processing. Short term memory limitations, a focus of attention bias, and a preference for the use of temporally recent information are three examples. This paper shows that psychological constraints such as these can be used effectively as domain-independent sources of bias to guide feature set selection and weighting for case-based learning algorithms.We first show that cognitive biases can be automatically and explicitly encoded into the baseline instance representation: each bias modifies the representation by changing features, deleting features, or modifying feature weights. Next, we investigate the related problems of cognitive bias selection and cognitive bias interaction for the feature weighting approach. In particular, we compare two cross-validation algorithms for bias selection that make different assumptions about the independence of individual component biases. In evaluations on four natural language learning tasks, we show that the bias selection algorithms can determine which cognitive bias or biases are relevant for each learning task and that the accuracy of the case-based learning algorithm improves significantly when the selected bias(es) are incorporated into the baseline instance representation.</content></document><document><year>2004</year><authors>Thomas G. Dietterich1| Hermann Hild2 | Ghulum Bakiri3</authors><title>A Comparison of ID3 and Backpropagation for English Text-To-Speech Mapping</title><content>The performance of the error backpropagation (BP) and ID3 learning algorithms was compared on the task of mapping English text to phonemes and stresses. Under the distributed output code developed by Sejnowski and Rosenberg, it is shown that BP consistently out-performs ID3 on this task by several percentage points. Three hypotheses explaining this difference were explored: (a) ID3 is overfitting the training data, (b) BP is able to share hidden units across several output units and hence can learn the output units better, and (c) BP captures statistical information that ID3 does not. We conclude that only hypothesis (c) is correct. By augmenting ID3 with a simple statistical learning procedure, the performance of BP can be closely matched. More complex statistical procedures can improve the performance of both BP and ID3 substantially in this domain.</content></document><document><year>2004</year><authors>David P. Helmbold1 | Robert E. Schapire2 | Yoram Singer3  | Manfred K. Warmuth1 </authors><title>A Comparison of New and Old Algorithms for a Mixture Estimation Problem</title><content>We investigate the problem of estimating the proportion vector which maximizes the likelihood of a given sample for a mixture of given densities. We adapt a framework developed for supervised learning and give simple derivations for many of the standard iterative algorithms like gradient projection and EM. In this framework, the distance between the new and old proportion vectors is used as a penalty term. The square distance leads to the gradient projection update, and the relative entropy to a new update which we call the exponentiated gradient update (EG). Curiously, when a second order Taylor expansion of the relative entropy is used, we arrive at an update EM which, for =1, gives the usual EM update. Experimentally, both the EM-update and the EG-update for  &gt; 1 outperform the EM algorithm and its variants. We also prove a polynomial bound on the rate of convergence of the EG algorithm.</content></document><document><year>2004</year><authors>Tjen-Sien Lim1| Wei-Yin Loh2  | Yu-Shan Shih3 </authors><title>A Comparison of Prediction Accuracy, Complexity, and Training Time of Thirty-Three Old and New Classification Algorithms</title><content>Twenty-two decision tree, nine statistical, and two neural network algorithms are compared on thirty-two datasets in terms of classification accuracy, training time, and (in the case of trees) number of leaves. Classification accuracy is measured by mean error rate and mean rank of error rate. Both criteria place a statistical, spline-based, algorithm called POLYCLSSS at the top, although it is not statistically significantly different from twenty other algorithms. Another statistical algorithm, logistic regression, is second with respect to the two accuracy criteria. The most accurate decision tree algorithm is QUEST with linear splits, which ranks fourth and fifth, respectively. Although spline-based statistical algorithms tend to have good accuracy, they also require relatively long training times. POLYCLASS, for example, is third last in terms of median training time. It often requires hours of training compared to seconds for other algorithms. The QUEST and logistic regression algorithms are substantially faster. Among decision tree algorithms with univariate splits, C4.5, IND-CART, and QUEST have the best combinations of error rate and speed. But C4.5 tends to produce trees with twice as many leaves as those from IND-CART and QUEST.</content></document><document><year>2004</year><authors>Alberto Segre1 | Charles Elkan2  | Alex|er Russell3 </authors><title>A critical look at experimental evaluations of EBL</title><content>A number of experimental evaluations ofexplanation-based learning (EBL) have been reported in the literature on machine learning. A close examination of the design of these experiments revelas certain methodological problems that could affect the conclusions drawn from the experiments. This article analyzes some of the more common methodological difficulties, and illustrates them using selected previous studies.</content></document><document><year>2004</year><authors>William C. Schmidt1  | Charles X. Ling2 </authors><title>A decision-tree model of balance scale development</title><content>We present an alternative model of human cognitive development on the balance scale task. Study of this task has inspired a wide range of human and computational work. The task requires that children predict the outcome of placing a discrete number of weights at various distances on either side of a fulcrum. Our model, which features the symbolic learning algorithm C4.5 as a transition mechanism, exhibits regularities found in the human data including orderly stage progression. U-shaped development, and the torque difference effect. Unlike previous successful models of the task, the current model uses a single free parameter, is not restricted in the size of the balance scale that it can accommodate, and does not require the assumption of a highly structured output representation or a training environment biased towards weight or distance information. The model makes a number of predictions differing from those of previous computational efforts.</content></document><document><year>2004</year><authors>V&amp;iacute ictor Dalmau1 </authors><title>A Dichotomy Theorem for Learning Quantified Boolean Formulas</title><content>We consider the following classes of quantified boolean formulas. Fix a finite set of basic boolean functions. Take conjunctions of these basic functions applied to variables and constants in arbitrary ways. Finally quantify existentially or universally some of the variables. We prove the following dichotomy theorem: For any set of basic boolean functions, the resulting set of formulas is either polynomially learnable from equivalence queries alone or else it is not PAC-predictable even with membership queries under cryptographic assumptions. Furthermore, we identify precisely which sets of basic functions are in which of the two cases.</content></document><document><year>2004</year><authors>R. L&amp;oacute pez De M&amp;aacute ntaras1 </authors><title>A distance-based attribute selection measure for decision tree induction</title><content>This note introduces a new attribute selection measure for ID3-like inductive algorithms. This measure is based on a distance between partitions such that the selected attribute in a node induces the partition which is closest to the correct partition of the subset of training examples corresponding to this node. The relationship of this measure with Quinlan's information gain is also established. It is also formally proved that our distance is not biased towards attributes with large numbers of values. Experimental studies with this distance confirm previously reported results showing that the predictive accuracy of induced decision trees is not sensitive to the goodness of the attribute selection measure. However, this distance produces smaller trees than the gain ratio measure of Quinlan, especially in the case of data whose attributes have significantly different numbers of values.</content></document><document><year>2004</year><authors>David A. Bell1  | Hui Wang2 </authors><title>A Formalism for Relevance and Its Application in Feature Subset Selection</title><content>The notion of relevance is used in many technical fields. In the areas of machine learning and data mining, for example, relevance is frequently used as a measure in feature subset selection (FSS). In previous studies, the interpretation of relevance has varied and its connection to FSS has been loose. In this paper a rigorous mathematical formalism is proposed for relevance, which is quantitative and normalized. To apply the formalism in FSS, a characterization is proposed for FSS: preservation of learning information and minimization of joint entropy. Based on the characterization, a tight connection between relevance and FSS is established: maximizing the relevance of features to the decision attribute, and the relevance of the decision attribute to the features. This connection is then used to design an algorithm for FSS. The algorithm is linear in the number of instances and quadratic in the number of features. The algorithm is evaluated using 23 public datasets, resulting in an improvement in prediction accuracy on 16 datasets, and a loss in accuracy on only 1 dataset. This provides evidence that both the formalism and its connection to FSS are sound.</content></document><document><year>2004</year><authors>Michael J. Pazzani1 | Wendy Sarrett1</authors><title>A Framework for Average Case Analysis of Conjunctive Learning Algorithms</title><content>We present an approach to modeling the average case behavior of learning algorithms. Our motivation is to predict the expected accuracy of learning algorithms as a function of the number of training examples. We apply this framework to a purely empirical learning algorithm, (the one-sided algorithm for pure conjunctive concepts), and to an algorithm that combines empirical and explanation-based learning. The model is used to gain insight into the behavior of these algorithms on a series of problems. Finally, we evaluate how well the average case model performs when the training examples violate the assumptions of the model.</content></document><document><year>2004</year><authors>Wray Buntine1| 2 | Tim Niblett</authors><title>A Further Comparison of Splitting Rules for Decision-Tree Induction</title><content>One approach to learning classification rules from examples is to build decision trees. A review and comparison paper by Mingers (Mingers, 1989) looked at the first stage of tree building, which uses a splitting rule to grow trees with a greedy recursive partitioning algorithm. That paper considered a number of different measures and experimentally examined their behavior on four domains. The main conclusion was that a random splitting rule does not significantly decrease classificational accuracy. This note suggests an alternative experimental method and presents additional results on further domains. Our results indicate that random splitting leads to increased error. These results are at variance with those presented by Mingers.</content></document><document><year>2004</year><authors>Larry Rendell1 </authors><title>A general framework for induction and a study of selective induction</title><content>This paper has two major parts. The first is an extensive analysis of the problem of induction, and the second part is a detailed study of selective induction. Throughout the paper we integrate a number of notions, mainly from artificial intelligence, but also from pattern recognition and cognitive psychology. The result is a synthetic view which exploits uncertainty, task-guidance, and biases such as language restriction. Some of the main themes and contributions are as follows. (1) Practical induction is really a problem of efficacy and efficiency (power). (2) Search in a space of hypothetical concepts is governed by acredibility function which combines various knowledge sources in a single subjective probability or belief measure . (3) The amount of knowledge supplied by various sources can often be quantified; these sources include various biases and the learning system itself. (4) Induction is equivalent to discovery of autility function u, which captures the purpose or goal of induction. (5) The difficulty of induction may be characterized by the form of u. Smooth or coherent functions mean selective induction, which has had the most attention in machine learning. (6) Systems for selective induction are more similar than commonly understood. By juxtaposing them we can discover similarities and improvements. (7) Our analysis suggests a number of incipient principles for powerful induction.</content></document><document><year>2004</year><authors>Glenn A. Iba1 </authors><title>A heuristic approach to the discovery of macro-operators</title><content>This paper describes a heuristic approach to the discovery of useful macro-operators (macros) in problem solving. The approach has been implemented in a program,Maclearn, that has three parts: macro-proposer, static filter, and dynamic filter. Learning occurs during problem solving, so that performance unproves in the course of a single problem trial. Primitive operators and macros are both represented within a uniform representational framework that is closed under composition. This means that new macros can be defined in terms of others, which leads to a definitional hierarchy. The representation also supports the transfer of macros to related problems.Maclearn is embedded in a supporting system that carries out best-first search. Experiments in macro learning were conducted for two classes of problems: peg solitaire (generalized Hi-Q puzzle), and tile sliding (generalized Fiteen puzzle). The results indicate thatMaclearn's filtering heuristics all improve search performance, sometimes dramatically. When the system was given practice on simpler training problems, it learned a set of macros that led to successful solutions of several much harder problems.</content></document><document><year>2004</year><authors>Cezary Z. Janikow1</authors><title>A Knowledge-Intensive Genetic Algorithm for Supervised Learning</title><content>Supervised learning in attribute-based spaces is one of the most popular machine learning problems studied and, consequently, has attracted considerable attention of the genetic algorithm community. The full-memory approach developed here uses the same high-level descriptive language that is used in rule-based systems. This allows for an easy utilization of inference rules of the well-known inductive learning methodology, which replace the traditional domain-independent operators and make the search task-specific. Moreover, a closer relationship between the underlying task and the processing mechanisms provides a setting for an application of more powerful task-specific heuristics. Initial results obtained with a prototype implementation for the simplest case of single concepts indicate that genetic algorithms can be effectively used to process high-level concepts and incorporate task-specific knowledge. The method of abstracting the genetic algorithm to the problem level, described here for the supervised inductive learning, can be also extended to other domains and tasks, since it provides a framework for combining recently popular genetic algorithm methods with traditional problem-solving methodologies. Moreover, in this particular case, it provides a very powerful tool enabling study of the widely accepted but not so well understood inductive learning methodology.</content></document><document><year>2004</year><authors>Claudio Carpineto1  | Giovanni Romano1 </authors><title>A lattice conceptual clustering system and its application to browsing retrieval</title><content>The theory of concept (or Galois) lattices provides a simple and formal approach to conceptual clustering. In this paper we present GALOIS, a system that automates and applies this theory. The algorithm utilized by GALOIS to build a concept lattice is incremental and efficient, each update being done in time at most quadratic in the number of objects in the lattice. Also, the algorithm may incorporate background information into the lattice, and through clustering, extend the scope of the theory. The application we present is concerned with information retrieval via browsing, for which we argue that concept lattices may represent major support structures. We describe a prototype user interface for browsing through the concept lattice of a document-term relation, possibly enriched with a thesaurus of terms. An experimental evaluation of the system performed on a medium-sized bibliographic database shows good retrieval performance and a significant improvement after the introduction of background knowledge.</content></document><document><year>2004</year><authors>Kenji Yamanishi1</authors><title>A Learning Criterion for Stochastic Rules</title><content>This paper proposes a learning criterion for stochastic rules. This criterion is developed by extending Valiant's PAC (Probably Approximately Correct) learning model, which is a learning criterion for deterministic rules. Stochastic rules here refer to those which probabilistically asign a number of classes, {Y}, to each attribute vector X. The proposed criterion is based on the idea that learning stochastic rules may be regarded as probably approximately correct identification of conditional probability distributions over classes for given input attribute vectors. An algorithm (an MDL algorithm) based on the MDL (Minimum Description Length) principle is used for learning stochastic rules. Specifically, for stochastic rules with finite partitioning (each of which is specified by a finite number of disjoint cells of the domain and a probability parameter vector associated with them), this paper derives target-dependent upper bounds and worst-case upper bounds on the sample size required by the MDL algorithm to learn stochastic rules with given accuracy and confidence. Based on these sample size bounds, this paper proves polynomial-sample-size learnability of stochastic decision lists (which are newly proposed in this paper as a stochastic analogue of Rivest's decision lists) with at most k literals (k is fixed) in each decision, and polynomial-sample-size learnability of stochastic decision trees (a stochastic analogue of decision trees) with at most k depth. Sufficient conditions for polynomial-sample-size learnability and polynomial-time learnability of any classes of stochastic rules with finite partitioning are also derived.</content></document><document><year>2004</year><authors>Yoram Gat1</authors><title>A Learning Generalization Bound with an Application to Sparse-Representation Classifiers</title><content>A classifier is said to have good generalization ability if it performs on test data almost as well as it does on the training data. The main result of this paper provides a sufficient condition for a learning algorithm to have good finite sample generalization ability. This criterion applies in some cases where the set of all possible classifiers has infinite VC dimension. The result is applied to prove the good generalization ability of support vector machines by a exploiting a sparse-representation property.</content></document><document><year>2004</year><authors>Llu&amp;iacute s M&amp;agrave rquez1 | Llu&amp;iacute s Padr&amp;oacute 2  | Horacio Rodr&amp;iacute guez3 </authors><title>A Machine Learning Approach to POS Tagging</title><content>We have applied the inductive learning of statistical decision trees and relaxation labeling to the Natural Language Processing (NLP) task of morphosyntactic disambiguation (Part Of Speech Tagging). The learning process is supervised and obtains a language model oriented to resolve POS ambiguities, consisting of a set of statistical decision trees expressing distribution of tags and words in some relevant contexts. The acquired decision trees have been directly used in a tagger that is both relatively simple and fast, and which has been tested and evaluated on the Wall Street Journal (WSJ) corpus with competitive accuracy. However, better results can be obtained by translating the trees into rules to feed a flexible relaxation labeling based tagger. In this direction we describe a tagger which is able to use information of any kind (n-grams, automatically acquired constraints, linguistically motivated manually written constraints, etc.), and in particular to incorporate the machine-learned decision trees. Simultaneously, we address the problem of tagging when only limited training material is available, which is crucial in any process of constructing, from scratch, an annotated corpus. We show that high levels of accuracy can be achieved with our system in this situation, and report some results obtained when using it to develop a 5.5 million words Spanish corpus from scratch.</content></document><document><year>2004</year><authors>Carlos Soares1 | Pavel B. Brazdil1  | Petr Kuba2 </authors><title>A Meta-Learning Method to Select the Kernel Width in Support Vector Regression</title><content>The Support Vector Machine algorithm is sensitive to the choice of parameter settings. If these are not set correctly, the algorithm may have a substandard performance. Suggesting a good setting is thus an important problem. We propose a meta-learning methodology for this purpose and exploit information about the past performance of different settings. The methodology is applied to set the width of the Gaussian kernel. We carry out an extensive empirical evaluation, including comparisons with other methods (fixed default ranking; selection based on cross-validation and a heuristic method commonly used to set the width of the SVM kernel). We show that our methodology can select settings with low error while providing significant savings in time. Further work should be carried out to see how the methodology could be adapted to different parameter setting tasks.</content></document><document><year>2004</year><authors>Yoram Gat1 </authors><title>A Microchoice Bound for Continuous-Space Classification Algorithms</title><content>Classifiers are often constructed iteratively by introducing changes sequentially to an initial classifier. Langford and Blum (COLT'99: Proceedings of the 12th Annual Conference on Computational Learning Theory, 1999, San Mateo, CA: Morgan Kaufmann, pp. 209&amp;#x2013;214) take advantage of this structure (the microchoice structure), to obtain bounds for the generalization ability of such algorithms. These bounds can be sharper than more general bounds. This paper extends the applicability of the microchoice approach to the more realistic case where the classifier space is continuous and the sequence of changes is not restricted to a pre-fixed finite set.Proving the microchoice bound in the continuous case relies on a conditioning technique that is often used in proving VC results. It is shown how this technique can be used to convert any learning algorithm over a continuous space into a family of algorithms over discrete spaces.</content></document><document><year>2004</year><authors>William H. Hsu1 | Sylvian R. Ray2  | David C. Wilkins3 </authors><title>A Multistrategy Approach to Classifier Learning from Time Series</title><content>We present an approach to inductive concept learning using multiple models for time series. Our objective is to improve the efficiency and accuracy of concept learning by decomposing learning tasks that admit multiple types of learning architectures and mixture estimation methods. The decomposition method adapts attribute subset selection and constructive induction (cluster definition) to define new subproblems. To these problem definitions, we can apply metric-based model selection to select from a database of learning components, thereby producing a specification for supervised learning using a mixture model. We report positive learning results using temporal artificial neural networks (ANNs), on a synthetic, multiattribute learning problem and on a real-world time series monitoring application.</content></document><document><year>2004</year><authors>Katharina Morik1  | Peter Brockhausen1 </authors><title>A Multistrategy Approach to Relational Knowledge Discovery in Databases</title><content>When learning from very large databases, the reduction of complexity is extremely important. Two extremes of making knowledge discovery in databases (KDD) feasible have been put forward. One extreme is to choose a very simple hypothesis language, thereby being capable of very fast learning on real-world databases. The opposite extreme is to select a small data set, thereby being able to learn very expressive (first-order logic) hypotheses. A multistrategy approach allows one to include most of these advantages and exclude most of the disadvantages. Simpler learning algorithms detect hierarchies which are used to structure the hypothesis space for a more complex learning algorithm. The better structured the hypothesis space is, the better learning can prune away uninteresting or losing hypotheses and the faster it becomes.We have combined inductive logic programming (ILP) directly with a relational database management system. The ILP algorithm is controlled in a model-driven way by the user and in a data-driven way by structures that are induced by three simple learning algorithms.</content></document><document><year>2004</year><authors>Steven Salzberg1 </authors><title>A nearest hyperrectangle learning method</title><content>This paper presents a theory of learning called nested generalized exemplar (NGE) theory, in which learning is accomplished by storing objects in Euclidean n-space, En, as hyperrectangles. The hyperrectangles may be nested inside one another to arbitrary depth. In contrast to generalization processes that replace symbolic formulae by more general formulae, the NGE algorithm modifies hyperrectangles by growing and reshaping them in a well-defined fashion. The axes of these hyperrectangles are defined by the variables measured for each example. Each variable can have any range on the real line; thus the theory is not restricted to symbolic or binary values.This paper describes some advantages and disadvantages of NGE theory, positions it as a form of exemplarbased learning, and compares it to other inductive learning theories. An implementation has been tested in three different domains, for which results are presented below: prediction of breast cancer, classification of iris flowers, and prediction of survival times for heart attack patients. The results in these domains support the claim that NGE theory can be used to create compact representations with excellent predictive accuracy.</content></document><document><year>2004</year><authors>Haim Shvaytser1 </authors><title>A necessary condition for learning from positive examples</title><content>We present a simple combinatorial criterion for determining concept classes that cannot be learned in the sense of Valiant from a polynomial number of positive-only examples. The criterion is applied to several types of Boolean formulae in conjunctive and disjunctive normal form, to the majority function, to graphs with large connected components, and to a neural network with a single threshold unit. All are shown to be nonlearnable from positive-only examples.</content></document><document><year>2004</year><authors>Nina Mishra1| 2 | Dana Ron2  | Ram Swaminathan3 </authors><title>A New Conceptual Clustering Framework</title><content>We propose a new formulation of the conceptual clustering problem where the goal is to explicitly output a collection of simple and meaningful conjunctions of attributes that define the clusters. The formulation differs from previous approaches since the clusters discovered may overlap and also may not cover all the points. In addition, a point may be assigned to a cluster description even if it only satisfies most, and not necessarily all, of the attributes in the conjunction. Connections between this conceptual clustering problem and the maximum edge biclique problem are made. Simple, randomized algorithms are given that discover a collection of approximate conjunctive cluster descriptions in sublinear time.</content></document><document><year>2004</year><authors>Shlomo Dubnov1 | Ran El-Yaniv2 | Yoram Gdalyahu3 | Elad Schneidman4 | Naftali Tishby3  | Golan Yona5 </authors><title>A New Nonparametric Pairwise Clustering Algorithm Based on Iterative Estimation of Distance Profiles</title><content>We present a novel pairwise clustering method. Given a proximity matrix of pairwise relations (i.e. pairwise similarity or dissimilarity estimates) between data points, our algorithm extracts the two most prominent clusters in the data set. The algorithm, which is completely nonparametric, iteratively employs a two-step transformation on the proximity matrix. The first step of the transformation represents each point by its relation to all other data points, and the second step re-estimates the pairwise distances using a statistically motivated proximity measure on these representations. Using this transformation, the algorithm iteratively partitions the data points, until it finally converges to two clusters. Although the algorithm is simple and intuitive, it generates a complex dynamics of the proximity matrices. Based on this bipartition procedure we devise a hierarchical clustering algorithm, which employs the basic bipartition algorithm in a straightforward divisive manner. The hierarchical clustering algorithm copes with the model validation problem using a general cross-validation approach, which may be combined with various hierarchical clustering methods.We further present an experimental study of this algorithm. We examine some of the algorithm's properties and performance on some synthetic and standard data sets. The experiments demonstrate the robustness of the algorithm and indicate that it generates a good clustering partition even when the data is noisy or corrupted.</content></document><document><year>2004</year><authors>Herbert K.H. Lee1 </authors><title>A Noninformative Prior for Neural Networks</title><content>While many implementations of Bayesian neural networks use large, complex hierarchical priors, in much of modern Bayesian statistics, noninformative (flat) priors are very common. This paper introduces a noninformative prior for feed-forward neural networks, describing several theoretical and practical advantages of this approach. In particular, a simpler prior allows for a simpler Markov chain Monte Carlo algorithm. Details of MCMC implementation are included.</content></document><document><year>2004</year><authors>Avrim Blum1| 1  | Adam Kalai1| 1 </authors><title>A Note on Learning from Multiple-Instance Examples</title><content>We describe a simple reduction from the problem of PAC-learning from multiple-instance examples to that of PAC-learning with one-sided random classification noise. Thus, all concept classes learnable with one-sided noise, which includes all concepts learnable in the usual 2-sided random noise model plus others such as the parity function, are learnable from multiple-instance examples. We also describe a more efficient (and somewhat technically more involved) reduction to the Statistical-Query model that results in a polynomial-time algorithm for learning axis-parallel rectangles with sample complexity &amp;Otilde;(d2r/2) , saving roughly a factor of r over the results of Auer et al. (1997).</content></document><document><year>2004</year><authors>Christopher J. Merz1  | Michael J. Pazzani1 </authors><title>A Principal Components Approach to Combining Regression Estimates</title><content>The goal of combining the predictions of multiple learned models is to form an improved estimator. A combining strategy must be able to robustly handle the inherent correlation, or multicollinearity, of the learned models while identifying the unique contributions of each. A progression of existing approaches and their limitations with respect to these two issues are discussed. A new approach, PCR*, based on principal components regression is proposed to address these limitations. An evaluation of the new approach on a collection of domains reveals that (1) PCR* was the most robust combining method, (2) correlation could be handled without eliminating any of the learned models, and (3) the principal components of the learned models provided a continuum of regularized weights from which PCR* could choose.</content></document><document><year>2004</year><authors>Sebastian Thrun| Wolfram Burgard | Dieter Fox</authors><title>A Probabilistic Approach to Concurrent Mapping and Localization for Mobile Robots</title><content>This paper addresses the problem of building large-scale geometric maps of indoor environments with mobile robots. It poses the map building problem as a constrained, probabilistic maximum-likelihood estimation problem. It then devises a practical algorithm for generating the most likely map from data, along with the most likely path taken by the robot. Experimental results in cyclic environments of size up to 80 by 25 meter illustrate the appropriateness of the approach.</content></document><document><year>2004</year><authors>J.B. Gao1 | S.R. Gunn1 | C.J. Harris1  | M. Brown2 </authors><title>A Probabilistic Framework for SVM Regression and Error Bar Estimation</title><content>In this paper, we elaborate on the well-known relationship between Gaussian Processes (GP) and Support Vector Machines (SVM) under some convex assumptions for the loss functions. This paper concentrates on the derivation of the evidence and error bar approximation for regression problems. An error bar formula is derived based on the -insensitive loss function.</content></document><document><year>2004</year><authors>Jos&amp;eacute  Del R. Mill&amp;aacute n1 | Carme Torras2</authors><title>A Reinforcement Connectionist Approach to Robot Path Finding in Non-Maze-Like Environments</title><content>This paper presents a reinforcement connectionist system which finds and learns the suitable situation-action rules so as to generate feasible paths for a point robot in a 2D environment with circular obstacles. The basic reinforcement algorithm is extended with a strategy for discovering stable solution paths. Equipped with this strategy and a powerful codification scheme, the path-finder (i) learns quickly, (ii) deals with continuous-valued inputs and outputs, (iii) exhibits good noise-tolerance and generalization capabilities, (iv) copes with dynamic environments, and (v) solves an instance of the path finding problem with strong performance demands.</content></document><document><year>2004</year><authors>Abhijit Gosavi1 </authors><title>A Reinforcement Learning Algorithm Based on Policy Iteration for Average Reward: Empirical Results with Yield Management and Convergence Analysis</title><content>We present a Reinforcement Learning (RL) algorithm based on policy iteration for solving average reward Markov and semi-Markov decision problems. In the literature on discounted reward RL, algorithms based on policy iteration and actor-critic algorithms have appeared. Our algorithm is an asynchronous, model-free algorithm (which can be used on large-scale problems) that hinges on the idea of computing the value function of a given policy and searching over policy space. In the applied operations research community, RL has been used to derive good solutions to problems previously considered intractable. Hence in this paper, we have tested the proposed algorithm on a commercially significant case study related to a real-world problem from the airline industry. It focuses on yield management, which has been hailed as the key factor for generating profits in the airline industry. In the experiments conducted, we use our algorithm with a nearest-neighbor approach to tackle a large state space. We also present a convergence analysis of the algorithm via an ordinary differential equation method.</content></document><document><year>2004</year><authors>Michael Pazzani1</authors><title>A Reply to Cohen's Book Review of Creating a Memory of Causal Relationships</title><content>Without Abstract</content></document><document><year>2004</year><authors>B.K. Natarajan1</authors><title>A Reply to Hellerstein's Book Review of Machine Learning: A Theoretical Approach</title><content>Without Abstract</content></document><document><year>2004</year><authors>J. Stephen Judd1</authors><title>A Reply to Honavar's Book Review of Neural Network Design and the Complexity of Learning</title><content>Without Abstract</content></document><document><year>2004</year><authors>Nada Lavra1  | Sao Deroski1 </authors><title>A reply to Pazzani's book review of Inductive Logic Programming: Techniques and Applications</title><content>Without Abstract</content></document><document><year>2004</year><authors>Ray Bareiss1 </authors><title>A reply to Reich's book review of Exemplar-based knowledge acquisition</title><content>Without Abstract</content></document><document><year>2004</year><authors>Dean A. Pomerleau1</authors><title>A Reply to Towell's Book Review of Neural Network Perception for Mobile Robot Guidance</title><content>Without Abstract</content></document><document><year>2009</year><authors>Alex|er Liu1 | Goo Jun1  | Joydeep Ghosh1 </authors><title>A self-training approach to cost sensitive uncertainty sampling      </title><content>Uncertainty sampling is an effective method for performing active learning that is computationally efficient compared to other         active learning methods such as loss-reduction methods. However, unlike loss-reduction methods, uncertainty sampling cannot         minimize total misclassification costs when errors incur different costs. This paper introduces a method for performing cost-sensitive         uncertainty sampling that makes use of self-training. We show that, even when misclassification costs are equal, this self-training         approach results in faster reduction of loss as a function of number of points labeled and more reliable posterior probability         estimates as compared to standard uncertainty sampling. We also show why other more naive methods of modifying uncertainty         sampling to minimize total misclassification costs will not always work well.      </content></document><document><year>2009</year><authors>Francesco Dinuzzo1  | Giuseppe De Nicolao2 </authors><title>An algebraic characterization of the optimum of;regularized kernel methods      </title><content>The representer theorem for kernel methods states that the solution of the associated variational problem can be expressed         as the linear combination of a finite number of kernel functions. However, for non-smooth loss functions, the analytic characterization         of the coefficients poses nontrivial problems. Standard approaches resort to constrained optimization reformulations which,         in general, lack a closed-form solution. Herein, by a proper change of variable, it is shown that, for any convex loss function,         the coefficients satisfy a system of algebraic equations in a fixed-point form, which may be directly obtained from the primal         formulation. The algebraic characterization is specialized to regression and classification methods and the fixed-point equations         are explicitly characterized for many loss functions of practical interest. The consequences of the main result are then investigated         along two directions. First, the existence of an unconstrained smooth reformulation of the original non-smooth problem is         proven. Second, in the context of SURE (Stein&amp;#8217;s Unbiased Risk Estimation), a general formula for the degrees of freedom of         kernel regression methods is derived.      </content></document><document><year>2009</year><authors>Tapio Pahikkala1 | Evgeni Tsivtsivadze1 | Antti Airola1 | Jouni JГ¤rvinen1  | Jorma Boberg1 </authors><title>An efficient algorithm for learning to rank from;preference graphs      </title><content>In this paper, we introduce a framework for regularized least-squares (RLS) type of ranking cost functions and we propose         three such cost functions. Further, we propose a kernel-based preference learning algorithm, which we call RankRLS, for minimizing         these functions. It is shown that RankRLS has many computational advantages compared to the ranking algorithms that are based         on minimizing other types of costs, such as the hinge cost. In particular, we present efficient algorithms for training, parameter         selection, multiple output learning, cross-validation, and large-scale learning. Circumstances under which these computational         benefits make RankRLS preferable to RankSVM are considered. We evaluate RankRLS on four different types of ranking tasks using         RankSVM and the standard RLS regression as the baselines. RankRLS outperforms the standard RLS regression and its performance         is very similar to that of RankSVM, while RankRLS has several computational benefits over RankSVM.      </content></document><document><year>2009</year><authors>Lucia Specia1 | Ashwin Srinivasan2 | Sachindra Joshi2 | Ganesh Ramakrishnan3  | Maria das GraГ§as Volpe Nunes4 </authors><title>An investigation into feature construction to assist word sense disambiguation      </title><content>Identifying the correct sense of a word in context is crucial for many tasks in natural language processing (machine translation         is an example). State-of-the art methods for Word Sense Disambiguation (WSD) build models using hand-crafted features that         usually capturing shallow linguistic information. Complex background knowledge, such as semantic relationships, are typically         either not used, or used in specialised manner, due to the limitations of the feature-based modelling techniques used. On         the other hand, empirical results from the use of Inductive Logic Programming (ILP) systems have repeatedly shown that they         can use diverse sources of background knowledge when constructing models. In this paper, we investigate whether this ability         of ILP systems could be used to improve the predictive accuracy of models for WSD. Specifically, we examine the use of a general-purpose         ILP system as a method to construct a set of features using semantic, syntactic and lexical information. This feature-set         is then used by a common modelling technique in the field (a;support vector machine) to construct a classifier for predicting         the sense of a word. In our investigation we examine one-shot and incremental approaches to feature-set construction applied         to monolingual and bilingual WSD tasks. The monolingual tasks use 32 verbs and 85 verbs and nouns (in English) from the SENSEVAL-3         and SemEval-2007 benchmarks; while the bilingual WSD task consists of 7 highly ambiguous verbs in translating from English         to Portuguese. The results are encouraging: the ILP-assisted models show substantial improvements over those that simply use         shallow features. In addition, incremental feature-set construction appears to identify smaller and better sets of features.         Taken together, the results suggest that the use of ILP with diverse sources of background knowledge provide a way for making         substantial progress in the field of WSD.      </content></document><document><year>2009</year><authors>Bei Hui1 | Ying Yang2  | Geoffrey I. Webb3 </authors><title>Anytime classification for a pool of instances      </title><content>In many real-world applications of classification learning, such as credit card transaction vetting or classification embedded         in sensor nodes, multiple instances simultaneously require classification under computational resource constraints such as         limited time or limited battery capacity. In such a situation, available computational resources should be allocated across         the instances in order to optimize the overall classification efficacy and efficiency. We propose a novel anytime classification         framework, Scheduling Anytime Averaged Probabilistic Estimators (SAAPE), which is capable of classifying a pool of instances,         delivering accurate results whenever interrupted and optimizing the collective classification performance. Following the practice         of our previous anytime classification system AAPE, SAAPE runs a sequence of very efficient Bayesian probabilistic classifiers         to classify each single instance. Furthermore, SAAPE implements seven alternative scheduling schemes to decide which instance         gets available computational resources next such that a new classifier can be applied to refine its classification. We formally         present each scheduling scheme&amp;#8217;s definition, rationale and time complexity. We conduct large-scale experiments using 60 benchmark         data sets and diversified statistical tests to evaluate SAAPE&amp;#8217;s performance on zero-one loss classification as well as on         probability estimation. We analyze each scheduling scheme&amp;#8217;s advantages and disadvantages according to both theoretical understandings         and empirical observations. Consequently we identify effective scheduling schemes that enable SAAPE to accomplish accurate         anytime classification for a pool of instances.      </content></document><document><year>2009</year><authors>Manfred K. Warmuth1  | Dima Kuzmin1 </authors><title>Bayesian generalized probability calculus for density matrices      </title><content>One of the main concepts in quantum physics is a density matrix, which is a symmetric positive definite matrix of trace one.         Finite probability distributions can be seen as a special case when the density matrix is restricted to be diagonal.                     We develop a probability calculus based on these more general distributions that includes definitions of joints, conditionals               and formulas that relate these, including analogs of the Theorem of Total Probability and various Bayes rules for the calculation               of posterior density matrices. The resulting calculus parallels the familiar &amp;#8220;conventional&amp;#8221; probability calculus and always               retains the latter as a special case when all matrices are diagonal. We motivate both the conventional and the generalized               Bayes rule with a minimum relative entropy principle, where the Kullbach-Leibler version gives the conventional Bayes rule               and Umegaki&amp;#8217;s quantum relative entropy the new Bayes rule for density matrices.            </content></document><document><year>2009</year><authors>Pekka Marttinen1  | Jukka Cor|er2</authors><title>Bayesian learning of graphical vector autoregressions with unequal lag-lengths      </title><content>Graphical modelling strategies have been recently discovered as a versatile tool for analyzing multivariate stochastic processes.         Vector autoregressive processes can be structurally represented by mixed graphs having both directed and undirected edges         between the variables representing process components. To allow for more expressive vector autoregressive structures, we consider         models with separate time dynamics for each directed edge and non-decomposable graph topologies for the undirected part of         the mixed graph.                     Contrary to static graphical models, the number of possible mixed graphs is extremely large even for small systems, and consequently,               standard Bayesian computation based on Markov chain Monte Carlo is not in practice a feasible alternative for model learning.               To obtain a numerically efficient approach we utilize a recent Bayesian information theoretic criterion for model learning,               which has attractive properties when the potential model complexity is large relative to the size of the observed data set.               The performance of our method is illustrated by analyzing both simulated and real data sets. Our simulation experiments demonstrate               the gains in predictive accuracy which can obtained by considering structural learning of vector autoregressive processes               instead of unstructured models. The analysis of the real data also shows that the understanding of the dynamics of a multivariate               process can be improved significantly by considering more flexible model classes.            </content></document><document><year>2009</year><authors>Chiaki Sakama1  | Katsumi Inoue2 </authors><title>Brave induction: a logical framework for learning from;incomplete information      </title><content>This paper introduces a novel logical framework for concept-learning called brave induction. Brave induction uses brave inference for induction and is useful for learning from incomplete information. Brave induction         is weaker than explanatory induction which is normally used in inductive logic programming, and is stronger than learning from satisfiability, a general setting of concept-learning in clausal logic. We first investigate formal properties of brave induction, then         develop an algorithm for computing hypotheses in full clausal theories. Next we extend the framework to induction in nonmonotonic logic programs. We analyze computational complexity of decision problems for induction on propositional theories. Further, we provide examples         of problem solving by brave induction in systems biology, requirement engineering, and multiagent negotiation.      </content></document><document><year>2009</year><authors>Albrecht Zimmermann1  | Luc De Raedt1 </authors><title>Cluster-grouping: from subgroup discovery to clustering      </title><content>We introduce the problem of cluster-grouping and show that it can be considered a subtask in several important data mining tasks, such as subgroup discovery, mining correlated patterns, clustering and classification. The algorithm CG for solving cluster-grouping problems is then introduced, and it is incorporated as a component in several existing and novel algorithms for tackling         subgroup discovery, clustering and classification. The resulting systems are empirically compared to state-of-the-art systems such as CN2, CBA, Ripper, Autoclass and CobWeb.         The results indicate that the CG algorithm can be useful as a generic local pattern mining component in a wide variety of data mining and machine learning         algorithms.      </content></document><document><year>2009</year><authors>Weiwei Cheng1  | Eyke HГјllermeier1 </authors><title>Combining instance-based learning and logistic regression for multilabel classification      </title><content>Multilabel classification is an extension of conventional classification in which a single instance can be associated with         multiple labels. Recent research has shown that, just like for conventional classification, instance-based learning algorithms         relying on the nearest neighbor estimation principle can be used quite successfully in this context. However, since hitherto         existing algorithms do not take correlations and interdependencies between labels into account, their potential has not yet         been fully exploited. In this paper, we propose a new approach to multilabel classification, which is based on a framework         that unifies instance-based learning and logistic regression, comprising both methods as special cases. This approach allows         one to capture interdependencies between labels and, moreover, to combine model-based and similarity-based inference for multilabel         classification. As will be shown by experimental studies, our approach is able to improve predictive accuracy in terms of         several evaluation criteria for multilabel prediction.      </content></document><document><year>2009</year><authors>RaГєl Santos-RodrГ­guez1 | Alicia Guerrero-Curieses2 | RocГ­o Alaiz-RodrГ­guez3  | JesГєs Cid-Sueiro1 </authors><title>Cost-sensitive learning based on Bregman divergences      </title><content>This paper analyzes the application of a particular class of Bregman divergences to design cost-sensitive classifiers for         multiclass problems. We show that these divergence measures can be used to estimate posterior probabilities with maximal accuracy         for the probability values that are close to the decision boundaries. Asymptotically, the proposed divergence measures provide         classifiers minimizing the sum of decision costs in non-separable problems, and maximizing a margin in separable MAP problems.      </content></document><document><year>2009</year><authors>Thorsten Joachims1 | Thomas Finley1  | Chun-Nam John Yu1 </authors><title>Cutting-plane training of structural SVMs      </title><content>Discriminative training approaches like structural SVMs have shown much promise for building highly complex and accurate models         in areas like natural language processing, protein structure prediction, and information retrieval. However, current training         algorithms are computationally expensive or intractable on large datasets. To overcome this bottleneck, this paper explores         how cutting-plane methods can provide fast training not only for classification SVMs, but also for structural SVMs. We show         that for an equivalent &amp;#8220;1-slack&amp;#8221; reformulation of the linear SVM training problem, our cutting-plane method has time complexity         linear in the number of training examples. In particular, the number of iterations does not depend on the number of training         examples, and it is linear in the desired precision and the regularization parameter. Furthermore, we present an extensive         empirical evaluation of the method applied to binary classification, multi-class classification, HMM sequence tagging, and         CFG parsing. The experiments show that the cutting-plane algorithm is broadly applicable and fast in practice. On large datasets,         it is typically several orders of magnitude faster than conventional training methods derived from decomposition methods like         SVM-light, or conventional cutting-plane methods. Implementations of our methods are available at www.joachims.org.      </content></document><document><year>2009</year><authors>Thorsten Suttorp1 | Nikolaus Hansen2  | Christian Igel1 </authors><title>Efficient covariance matrix update for variable metric evolution strategies      </title><content>Randomized direct search algorithms for continuous domains, such as evolution strategies, are basic tools in machine learning.         They are especially needed when the gradient of an objective function (e.g., loss, energy, or reward function) cannot be computed         or estimated efficiently. Application areas include supervised and reinforcement learning as well as model selection. These         randomized search strategies often rely on normally distributed additive variations of candidate solutions. In order to efficiently         search in non-separable and ill-conditioned landscapes the covariance matrix of the normal distribution must be adapted, amounting         to a variable metric method. Consequently, covariance matrix adaptation (CMA) is considered state-of-the-art in evolution         strategies. In order to sample the normal distribution, the adapted covariance matrix needs to be decomposed, requiring in         general &amp;#920;(n         3) operations, where n is the search space dimension. We propose a new update mechanism which can replace a rank-one covariance matrix update and         the computationally expensive decomposition of the covariance matrix. The newly developed update rule reduces the computational         complexity of the rank-one covariance matrix adaptation to &amp;#920;(n         2) without resorting to outdated distributions. We derive new versions of the elitist covariance matrix adaptation evolution         strategy (CMA-ES) and the multi-objective CMA-ES. These algorithms are equivalent to the original procedures except that the         update step for the variable metric distribution scales better in the problem dimension. We also introduce a simplified variant         of the non-elitist CMA-ES with the incremental covariance matrix update and investigate its performance. Apart from the reduced         time-complexity of the distribution update, the algebraic computations involved in all new algorithms are simpler compared         to the original versions. The new update rule improves the performance of the CMA-ES for large scale machine learning problems         in which the objective function can be evaluated fast.      </content></document><document><year>2009</year><authors>Daniel Nikovski1  | Ankur Jain1</authors><title>Fast adaptive algorithms for abrupt change detection      </title><content>We propose two fast algorithms for abrupt change detection in streaming data that can operate on arbitrary unknown data distributions         before and after the change. The first algorithm,                   , computes efficiently the average Euclidean distance between all pairs of data points before and after the hypothesized change.         The second algorithm,                   , computes the log-likelihood ratio statistic for the data distributions before and after the change, similarly to the classical         CUSUM algorithm, but unlike that algorithm,                    does not need to know the exact distributions, and uses kernel density estimates instead. Although a straightforward computation         of the two change statistics would have computational complexity of O(N         4) with respect to the size N of the streaming data buffer, the proposed algorithms are able to use the computational structure of these statistics to         achieve a computational complexity of only O(N         2) and memory requirement of O(N). Furthermore, the algorithms perform surprisingly well on dependent observations generated by underlying dynamical systems,         unlike traditional change detection algorithms.      </content></document><document><year>2009</year><authors>Filip &amp;#381 eleznГЅ1  | Nada Lavra&amp;#269 2 </authors><title>Guest editors&amp;#8217; introduction: Special issue on;Inductive Logic Programming (ILP-2008)      </title><content>Without Abstract</content></document><document><year>2009</year><authors>Thomas GГ¤rtner1  | Gemma C. Garriga2 </authors><title>Guest editors&amp;#8217; introduction: special issue on;mining and;learning with;graphs      </title><content>Without Abstract</content></document><document><year>2009</year><authors>Aleks|er Ko&amp;#322 cz1 | Dunja Mladeni&amp;#263 2 | Wray Buntine3| 5 | Marko Grobelnik2  | John Shawe-Taylor4 </authors><title>Guest editors&amp;#8217; introduction: Special;Issue;from;ECML;PKDD;2009      </title><content>Without Abstract</content></document><document><year>2009</year><authors>Jeff Johns1 | Marek Petrik1  | Sridhar Mahadevan1 </authors><title>Hybrid least-squares algorithms for approximate policy evaluation      </title><content>The goal of approximate policy evaluation is to &amp;#8220;best&amp;#8221; represent a target value function according to a specific criterion.         Different algorithms offer different choices of the optimization criterion. Two popular least-squares algorithms for performing         this task are the Bellman residual method, which minimizes the Bellman residual, and the fixed point method, which minimizes the projection of the Bellman residual. When used within policy iteration, the fixed point algorithm tends to ultimately find better performing         policies whereas the Bellman residual algorithm exhibits more stable behavior between rounds of policy iteration. We propose         two hybrid least-squares algorithms to try to combine the advantages of these algorithms. We provide an analytical and geometric interpretation of hybrid algorithms         and demonstrate their utility on a simple problem. Experimental results on both small and large domains suggest hybrid algorithms         may find solutions that lead to better policies when performing policy iteration.      </content></document><document><year>2009</year><authors>Hitoshi Yamasaki1 | Yosuke Sasaki1 | Takayoshi Shoudai1 | Tomoyuki Uchida2  | Yusuke Suzuki2 </authors><title>Learning block-preserving graph patterns and its application to data mining      </title><content>Recently, due to the rapid growth of electronic data having graph structures such as HTML and XML texts and chemical compounds,         many researchers have been interested in data mining and machine learning techniques for finding useful patterns from graph-structured         data (graph data). Since graph data contain a huge number of substructures and it tends to be computationally expensive to         decide whether or not such data have given structural features, graph mining problems face computational difficulties. Let                            be a graph class which satisfies a connected hereditary property and contains infinitely many different biconnected graphs,         and for which a special kind of the graph isomorphism problem can be computed in polynomial time. In this paper, we consider         learning and mining problems for;                  . Firstly, we define a new graph pattern, which is called a block preserving graph pattern (bp-graph pattern) for;                  . Secondly, we present a polynomial time algorithm for deciding whether or not a given bp-graph pattern matches a given graph         in;                  . Thirdly, by giving refinement operators over bp-graph patterns, we present a polynomial time algorithm for finding a minimally         generalized bp-graph pattern for;                  . Outerplanar graphs are planar graphs which can be embedded in the plane in such a way that all of vertices lie on the outer         boundary. Many pharmacologic chemical compounds are known to be represented by outerplanar graphs. The class of connected         outerplanar graphs                    satisfies the above conditions for;                  . Next, we propose two incremental polynomial time algorithms for enumerating all frequent bp-graph patterns with respect         to a given finite set of graphs in;                  . Finally, by reporting experimental results obtained by applying the two graph mining algorithms to a subset of the NCI dataset,         we evaluate the performance of the two graph mining algorithms.      </content></document><document><year>2009</year><authors>Dan Roth1  | Rajhans Samdani1 </authors><title>Learning multi-linear representations of distributions for;efficient inference      </title><content>We examine the class of multi-linear representations (MLR) for expressing probability distributions over discrete variables.         Recently, MLR have been considered as intermediate representations that facilitate inference in distributions represented         as graphical models.                     We show that MLR is an expressive representation of discrete distributions and can be used to concisely represent classes               of distributions which have exponential size in other commonly used representations, while supporting probabilistic inference               in time linear in the size of the representation. Our key contribution is presenting techniques for learning bounded-size               distributions represented using MLR, which support efficient probabilistic inference. We demonstrate experimentally that the               MLR representations we learn support accurate and very efficient inference.            </content></document><document><year>2009</year><authors>FranГ§ois Laviolette1 | Mario March|1 | Mohak Shah2  | Sara Shanian1 </authors><title>Learning the set covering machine by bound minimization and margin-sparsity trade-off      </title><content>We investigate classifiers in the sample compression framework that can be specified by two distinct sources of information:         a compression set and a message string of additional information. In the compression setting, a reconstruction function specifies a classifier when given this information.         We examine how an efficient redistribution of this reconstruction information can lead to more general classifiers. In particular,         we derive risk bounds that can provide an explicit control over the sparsity of the classifier and the magnitude of its separating margin and a capability to perform a margin-sparsity trade-off in favor of better classifiers. We show how an application to the         set covering machine algorithm results in novel learning strategies. We also show that these risk bounds are tighter than         their traditional counterparts such as VC-dimension and Rademacher complexity-based bounds that explicitly take into account         the hypothesis class complexity. Finally, we show how these bounds are able to guide the model selection for the set covering         machine algorithm enabling it to learn by bound minimization.      </content></document><document><year>2009</year><authors>Ofer Dekel1 | Ohad Shamir2  | Lin Xiao1 </authors><title>Learning to classify with missing and corrupted features      </title><content>A common assumption in supervised machine learning is that the training examples provided to the learning algorithm are statistically         identical to the instances encountered later on, during the classification phase. This assumption is unrealistic in many real-world         situations where machine learning techniques are used. We focus on the case where features of a binary classification problem,         which were available during the training phase, are either deleted or become corrupted during the classification phase. We         prepare for the worst by assuming that the subset of deleted and corrupted features is controlled by an adversary, and may         vary from instance to instance. We design and analyze two novel learning algorithms that anticipate the actions of the adversary         and account for them when training a classifier. Our first technique formulates the learning problem as a linear program.         We discuss how the particular structure of this program can be exploited for computational efficiency and we prove statistical         bounds on the risk of the resulting classifier. Our second technique addresses the robust learning problem by combining a         modified version of the Perceptron algorithm with an online-to-batch conversion technique, and also comes with statistical         generalization guarantees. We demonstrate the effectiveness of our approach with a set of experiments.      </content></document><document><year>2009</year><authors>Yair Goldberg1  | Ya&amp;#8217 acov Ritov1 </authors><title>Local procrustes for manifold embedding: a measure of;embedding quality and embedding algorithms      </title><content>We present the Procrustes measure, a novel measure based on Procrustes rotation that enables quantitative comparison of the         output of manifold-based embedding algorithms such as LLE (Roweis and Saul, Science 290(5500), 2323&amp;#8211;2326, 2000) and Isomap (Tenenbaum et;al., Science 290(5500), 2319&amp;#8211;2323, 2000). The measure also serves as a natural tool when choosing dimension-reduction parameters. We also present two novel dimension-reduction         techniques that attempt to minimize the suggested measure, and compare the results of these techniques to the results of existing         algorithms. Finally, we suggest a simple iterative method that can be used to improve the output of existing algorithms.      </content></document><document><year>2009</year><authors>David J. H|1| 2 </authors><title>Measuring classifier performance: a;coherent alternative to the area under the ROC curve      </title><content>The area under the ROC curve (AUC) is a very widely used measure of performance for classification and diagnostic rules. It has the appealing property of being         objective, requiring no subjective input from the user. On the other hand, the AUC has disadvantages, some of which are well known. For example, the AUC can give potentially misleading results if ROC curves cross. However, the AUC also has a much more serious deficiency, and one which appears not to have been previously recognised. This is that it is         fundamentally incoherent in terms of misclassification costs: the AUC uses different misclassification cost distributions for different classifiers. This means that using the AUC is equivalent to using different metrics to evaluate different classification rules. It is equivalent to saying that, using         one classifier, misclassifying a class 1;point is p;times as serious as misclassifying a class 0;point, but, using another classifier, misclassifying a class 1;point is P;times as serious, where p&amp;#8800;P. This is nonsensical because the relative severities of different kinds of misclassifications of individual points is a property         of the problem, not the classifiers which happen to have been chosen. This property is explored in detail, and a simple valid         alternative to the AUC is proposed.      </content></document><document><year>2009</year><authors>JosГ© L. BalcГЎzar1 | Albert Bifet1  | Antoni Lozano1 </authors><title>Mining frequent closed rooted trees      </title><content>Many knowledge representation mechanisms are based on tree-like structures, thus symbolizing the fact that certain pieces         of information are related in one sense or another. There exists a well-studied process of closure-based data mining in the         itemset framework: we consider the extension of this process into trees. We focus mostly on the case where labels on the nodes         are nonexistent or unreliable, and discuss algorithms for closure-based mining that only rely on the root of the tree and         the link structure. We provide a notion of intersection that leads to a deeper understanding of the notion of support-based         closure, in terms of an actual closure operator. We describe combinatorial characterizations and some properties of ordered         trees, discuss their applicability to unordered trees, and rely on them to design efficient algorithms for mining frequent         closed subtrees both in the ordered and the unordered settings. Empirical validations and comparisons with alternative algorithms         are provided.      </content></document><document><year>2009</year><authors>StГ©phanie Jacquemont1 | FranГ§ois Jacquenet1  | Marc Sebban1 </authors><title>Mining probabilistic automata: a statistical view of;sequential pattern mining      </title><content>During the past decade, sequential pattern mining has been the core of numerous research efforts. It is now possible to efficiently         extract knowledge of users&amp;#8217; behavior from a huge set of sequences collected over time. This has applications in various domains         such as purchases in supermarkets, Web site visits, etc. However, sequence mining algorithms do little to control the risks         of extracting false discoveries or overlooking true knowledge. In this paper, the theoretical conditions to achieve a relevant sequence mining process are examined. Then, the article         offers a statistical view of sequence mining which has the following advantages: First, it uses a compact and generalized         representation of the original sequences in the form of a probabilistic automaton. Second, it integrates statistical constraints         to guarantee the extraction of significant patterns. Finally, it provides an interesting solution in a privacy preserving         context in order to respect individuals&amp;#8217; information. An application in car flow modeling is presented, showing the ability         of our algorithm (acsm) to discover frequent routes without any private information. Comparisons with a classical sequence mining algorithm (spam) are made, showing the effectiveness of our approach.      </content></document><document><year>2009</year><authors>Daniel Aloise1 | Amit Deshp|e2 | Pierre Hansen3  | Preyas Popat4 </authors><title>NP-hardness of Euclidean sum-of-squares clustering      </title><content>A recent proof of NP-hardness of Euclidean sum-of-squares clustering, due to Drineas et al. (Mach. Learn. 56:9&amp;#8211;33, 2004), is not valid. An alternate short proof is provided.      </content></document><document><year>2009</year><authors>Thomas GГ¤rtner1  | Shankar Vembu1 </authors><title>On structured output training: hard cases and;an;efficient alternative      </title><content>We consider a class of structured prediction problems for which the assumptions made by state-of-the-art algorithms fail.         To deal with exponentially sized output sets, these algorithms assume, for instance, that the best output for a given input         can be found efficiently. While this holds for many important real world problems, there are also many relevant and seemingly         simple problems where these assumptions do not hold. In this paper, we consider route prediction, which is the problem of         finding a cyclic permutation of some points of interest, as an example and show that state-of-the-art approaches cannot guarantee         polynomial runtime for this output set. We then present a novel formulation of the learning problem that can be trained efficiently         whenever a particular &amp;#8216;super-structure counting&amp;#8217; problem can be solved efficiently for the output set. We also list several         output sets for which this assumption holds and report experimental results.      </content></document><document><year>2009</year><authors>Charles Sutton1| 2  | Andrew McCallum1 </authors><title>Piecewise training for structured prediction      </title><content>A drawback of structured prediction methods is that parameter estimation requires repeated inference, which is intractable         for general structures. In this paper, we present an approximate training algorithm called piecewise training (PW) that divides the factors into tractable subgraphs, which we call pieces, that are trained independently. Piecewise training can be interpreted as approximating the exact likelihood using belief         propagation, and different ways of making this interpretation yield different insights into the method. We also present an         extension to piecewise training, called piecewise pseudolikelihood (PWPL), designed for when variables have large cardinality. On several real-world natural language processing tasks, piecewise training         performs superior to Besag&amp;#8217;s pseudolikelihood and sometimes comparably to exact maximum likelihood. In addition, PWPL performs         similarly to PW and superior to standard pseudolikelihood, but is five to ten times more computationally efficient than batch         maximum likelihood training.      </content></document><document><year>2009</year><authors>Charles Dugas1  | David Gadoury1 </authors><title>Pointwise exact bootstrap distributions of ROC curves      </title><content>We derive pointwise exact bootstrap distributions of ROC curves and the difference between ROC curves for threshold and vertical         averaging. From these distributions, pointwise confidence intervals are derived and their performance is measured in terms         of coverage accuracy. Improvements over techniques currently in use are obtained, in particular in the extremes of ROC curves         where we show that typical drastic falls in coverage accuracy can be avoided.      </content></document><document><year>2009</year><authors>Masashi Sugiyama1  | Shinichi Nakajima2 </authors><title>Pool-based active learning in approximate linear regression      </title><content>The goal of pool-based active learning is to choose the best input points to gather output values from a &amp;#8216;pool&amp;#8217; of input samples.         We develop two pool-based active learning criteria for linear regression. The first criterion allows us to obtain a closed-form         solution so it is computationally very efficient. However, this solution is not necessarily optimal in the single-trial generalization         error analysis. The second criterion can give a better solution, but it does not have a closed-form solution and therefore         some additional search strategy is needed. To cope with this problem, we propose a practical procedure which enables us to         efficiently search for a better solution around the optimal solution of the first method. Simulations with toy and benchmark         datasets show that the proposed active learning method compares favorably with other active learning methods as well as the         baseline passive learning scheme. Furthermore, the usefulness of the proposed active learning method is also demonstrated         in wafer alignment in semiconductor exposure apparatus.      </content></document><document><year>2009</year><authors>Hal DaumГ© III1 | John Langford2 | Daniel Marcu3</authors><title>Search-based structured prediction      </title><content>We present Searn, an algorithm for integrating search and learning to solve complex structured prediction problems such as those that occur in natural language, speech, computational biology,         and vision. Searn is a meta-algorithm that transforms these complex problems into simple classification problems to which any binary classifier         may be applied. Unlike current algorithms for structured learning that require decomposition of both the loss function and the feature functions over the predicted structure, Searn is able to learn prediction functions for any loss function and any class of features. Moreover, Searn comes with a strong, natural theoretical guarantee: good performance on the derived classification problems implies good         performance on the structured prediction problem.      </content></document><document><year>2009</year><authors>Masashi Sugiyama1 | Tsuyoshi IdГ©2 | Shinichi Nakajima3  | Jun Sese4 </authors><title>Semi-supervised local Fisher discriminant analysis for;dimensionality reduction      </title><content>When only a small number of labeled samples are available, supervised dimensionality reduction methods tend to perform poorly         because of overfitting. In such cases, unlabeled samples could be useful in improving the performance. In this paper, we propose         a semi-supervised dimensionality reduction method which preserves the global structure of unlabeled samples in addition to         separating labeled samples in different classes from each other. The proposed method, which we call SEmi-supervised Local Fisher discriminant analysis (SELF), has an analytic form of the globally optimal solution and it can be computed based on eigen-decomposition. We show         the usefulness of SELF through experiments with benchmark and real-world document classification datasets.      </content></document><document><year>2009</year><authors>Thorsten Joachims1  | Chun-Nam John Yu1 </authors><title>Sparse kernel SVMs via cutting-plane training      </title><content>We explore an algorithm for training SVMs with Kernels that can represent the learned rule using arbitrary basis vectors,         not just the support vectors (SVs) from the training set. This results in two benefits. First, the added flexibility makes         it possible to find sparser solutions of good quality, substantially speeding-up prediction. Second, the improved sparsity         can also make training of Kernel SVMs more efficient, especially for high-dimensional and sparse data (e.g. text classification).         This has the potential to make training of Kernel SVMs tractable for large training sets, where conventional methods scale         quadratically due to the linear growth of the number of SVs. In addition to a theoretical analysis of the algorithm, we also         present an empirical evaluation.      </content></document><document><year>2009</year><authors>Christoph H. Lampert1  | Matthew B. Blaschko1| 2</authors><title>Structured prediction by joint kernel support estimation      </title><content>Discriminative techniques, such as conditional random fields (CRFs) or structure aware maximum-margin techniques (maximum         margin Markov networks (M3N), structured output support vector machines (S-SVM)), are state-of-the-art in the prediction of structured data. However,         to achieve good results these techniques require complete and reliable ground truth, which is not always available in realistic         problems. Furthermore, training either CRFs or margin-based techniques is computationally costly, because the runtime of current         training methods depends not only on the size of the training set but also on properties of the output space to which the         training samples are assigned.                     We propose an alternative model for structured output prediction, Joint Kernel Support Estimation (JKSE), which is rather generative in nature as it relies on estimating the joint probability density of samples and labels in the               training set. This makes it tolerant against incomplete or incorrect labels and also opens the possibility of learning in               situations where more than one output label can be considered correct.            </content></document><document><year>2009</year><authors>Bin Zou1| 2 | Luoqing Li2  | Zongben Xu1 </authors><title>The generalization performance of ERM algorithm with;strongly mixing observations      </title><content>The generalization performance is the main concern of machine learning theoretical research. The previous main bounds describing         the generalization ability of the Empirical Risk Minimization (ERM) algorithm are based on independent and identically distributed         (i.i.d.) samples. In order to study the generalization performance of the ERM algorithm with dependent observations, we first         establish the exponential bound on the rate of relative uniform convergence of the ERM algorithm with exponentially strongly         mixing observations, and then we obtain the generalization bounds and prove that the ERM algorithm with exponentially strongly         mixing observations is consistent. The main results obtained in this paper not only extend the previously known results for         i.i.d. observations to the case of exponentially strongly mixing observations, but also improve the previous results for strongly         mixing samples. Because the ERM algorithm is usually very time-consuming and overfitting may happen when the complexity of         the hypothesis space is high, as an application of our main results we also explore a new strategy to implement the ERM algorithm         in high complexity hypothesis space.      </content></document><document><year>2009</year><authors>Alireza Tamaddoni-Nezhad1  | Stephen Muggleton1 </authors><title>The lattice structure and refinement operators for;the;hypothesis space bounded by a bottom clause      </title><content>Searching the hypothesis space bounded below by a bottom clause is the basis of several state-of-the-art ILP systems (e.g.         Progol, Aleph). These systems use refinement operators together with search heuristics to explore a bounded hypothesis space.         It is known that the search space of these systems is limited to a sub-graph of the general subsumption lattice. However,         the structure and properties of this sub-graph have not been properly characterised. In this paper firstly, we characterise         the hypothesis space considered by the ILP systems which use a bottom clause to constrain the search. In particular, we discuss         refinement in Progol as a representative of these ILP systems. Secondly, we study the lattice structure of this bounded hypothesis         space. Thirdly, we give a new analysis of refinement operators, least generalisation and greatest specialisation in the subsumption         order relative to a bottom clause. The results of this study are important for better understanding of the constrained refinement         space of ILP systems such as Progol and Aleph, which proved to be successful for solving real-world problems (despite being         incomplete with respect to the general subsumption order). Moreover, characterising this refinement sub-lattice can lead to         more efficient ILP algorithms and operators for searching this particular sub-lattice. For example, it is shown that, unlike         for the general subsumption order, efficient least generalisation operators can be designed for the subsumption order relative         to a bottom clause.      </content></document><document><year>2009</year><authors>Gergely Neu1| 2  | Csaba SzepesvГЎri2| 3</authors><title>Training parsers by inverse reinforcement learning      </title><content>One major idea in structured prediction is to assume that the predictor computes its output by finding the maximum of a score         function. The training of such a predictor can then be cast as the problem of finding weights of the score function so that         the output of the predictor on the inputs matches the corresponding structured labels on the training set. A;similar problem         is studied in inverse reinforcement learning (IRL) where one is given an environment and a set of trajectories and the problem         is to find a reward function such that an agent acting optimally with respect to the reward function would follow trajectories         that match those in the training set. In this paper we show how IRL algorithms can be applied to structured prediction, in         particular to parser training. We present a number of recent incremental IRL algorithms in a unified framework and map them         to parser training algorithms. This allows us to recover some existing parser training algorithms, as well as to obtain a         new one. The resulting algorithms are compared in terms of their sensitivity to the choice of various parameters and generalization         ability on the Penn Treebank WSJ corpus.      </content></document><document><year>2009</year><authors>Andreas Maurer1 </authors><title>Transfer bounds for linear feature learning      </title><content>If regression tasks are sampled from a distribution, then the expected error for a future task can be estimated by the average         empirical errors on the data of a finite sample of tasks, uniformly over a class of regularizing or pre-processing transformations.         The bound is dimension free, justifies optimization of the pre-processing feature-map and explains the circumstances under         which learning-to-learn is preferable to single task learning.      </content></document><document><year>2009</year><authors>Kazuho Watanabe1 | Motoki Shiga2  | Sumio Watanabe3 </authors><title>Upper bound for variational free energy of Bayesian networks      </title><content>In recent years, variational Bayesian learning has been used as an approximation of Bayesian learning. In spite of the computational         tractability and good generalization in many applications, its statistical properties have yet to be clarified. In this paper,         we focus on variational Bayesian learning of Bayesian networks which are widely used in information processing and uncertain         artificial intelligence. We derive upper bounds for asymptotic variational free energy or stochastic complexities of bipartite         Bayesian networks with discrete hidden variables. Our result theoretically supports the effectiveness of variational Bayesian         learning as an approximation of Bayesian learning.      </content></document><document><year>2009</year><authors>Ana LuГ­sa Duboc1 | Aline Paes1  | Gerson Zaverucha1 </authors><title>Using the bottom clause and mode declarations in FOL theory revision from examples      </title><content>Theory revision systems are designed to improve the accuracy of an initial theory, producing more accurate and comprehensible         theories than purely inductive methods. Such systems search for points where examples are misclassified and modify them using         revision operators. This includes trying to add antecedents to clauses usually following a top-down approach, considering         all the literals of the knowledge base. Such an approach leads to a huge search space which dominates the cost of the revision         process. ILP Mode Directed Inverse Entailment systems restrict the search for antecedents to the literals of the bottom clause.         In this work the bottom clause and mode declarations are introduced in a first-order logic theory revision system aiming to         improve the efficiency of the antecedent addition operation and, consequently, also of the whole revision process. Experimental         results compared to revision system FORTE show that the revision process is on average 55 times faster, generating more comprehensible         theories and still not significantly decreasing the accuracies obtained by the original revision process. Moreover, the results         show that when the initial theory is approximately correct, it is more efficient to revise it than learn from scratch, obtaining         significantly better accuracies. They also show that using the proposed theory revision system to induce theories from scratch         is faster and generates more compact theories than when the theory is induced using a traditional ILP system, obtaining competitive         accuracies.      </content></document><document><year>2008</year><authors>Mingyu Zhong1 | Michael Georgiopoulos1  | Georgios C. Anagnostopoulos2 </authors><title>A k-norm pruning algorithm for decision tree classifiers based on error rate estimation      </title><content>         Decision trees are well-known and established models for classification and regression. In this paper, we focus on the estimation         and the minimization of the misclassification rate of decision tree classifiers. We apply Lidstone&amp;#8217;s Law of Succession for         the estimation of the class probabilities and error rates. In our work, we take into account not only the expected values         of the error rate, which has been the norm in existing research, but also the corresponding reliability (measured by standard         deviations) of the error rate. Based on this estimation, we propose an efficient pruning algorithm, called k-norm pruning, that has a clear theoretical interpretation, is easily implemented, and does not require a validation set.         Our experiments show that our proposed pruning algorithm produces accurate trees quickly, and compares very favorably with         two other well-known pruning algorithms, CCP of CART and EBP of C4.5.               </content></document><document><year>2008</year><authors>Jennifer Neville1  | David Jensen2</authors><title>A bias/variance decomposition for models using collective inference      </title><content>Bias/variance analysis is a useful tool for investigating the performance of machine learning algorithms. Conventional analysis         decomposes loss into errors due to aspects of the learning process, but in relational domains, the inference process used         for prediction introduces an additional source of error. Collective inference techniques introduce additional error, both through the use of approximate inference algorithms and through variation in         the availability of test-set information. To date, the impact of inference error on model performance has not been investigated. We propose a new bias/variance framework that decomposes loss into         errors due to both the learning and inference processes. We evaluate the performance of three relational models on both synthetic and real-world datasets and show that         (1) inference can be a significant source of error, and (2) the models exhibit different types of errors as data characteristics         are varied.      </content></document><document><year>2008</year><authors>Heng Luo1 | Changyong Niu1 | Ruimin Shen1  | Carsten Ullrich1 </authors><title>A collaborative filtering framework based on both local user similarity and global user similarity      </title><content>Collaborative filtering as a classical method of information retrieval has been widely used in helping people to deal with         information overload. In this paper, we introduce the concept of local user similarity and global user similarity, based on         surprisal-based vector similarity and the application of the concept of maximin distance in graph theory. Surprisal-based         vector similarity expresses the relationship between any two users based on the quantities of information (called surprisal) contained in their ratings. Global user similarity defines two users being similar if they can be connected through their         locally similar neighbors. Based on both of Local User Similarity and Global User Similarity, we develop a collaborative filtering         framework called LS&amp;amp;GS. An empirical study using the MovieLens dataset shows that our proposed framework outperforms other         state-of-the-art collaborative filtering algorithms.      </content></document><document><year>2008</year><authors>Stijn V|erlooy1  | Eyke HГјllermeier2 </authors><title>A critical analysis of variants of the AUC      </title><content>The area under the ROC curve, or AUC, has been widely used to assess the ranking performance of binary scoring classifiers.         Given a sample, the metric considers the ordering of positive and negative instances, i.e., the sign of the corresponding         score differences. From a model evaluation and selection point of view, it may appear unreasonable to ignore the absolute         value of these differences. For this reason, several variants of the AUC metric that take score differences into account have         recently been proposed. In this paper, we present a unified framework for these metrics and provide a formal analysis. We         conjecture that, despite their intuitive appeal, actually none of the variants is effective, at least with regard to model         evaluation and selection. An extensive empirical analysis corroborates this conjecture. Our findings also shed light on recent         research dealing with the construction of AUC-optimizing classifiers.      </content></document><document><year>2008</year><authors>Shai Ben-David1  | Reba Schuller Borbely1 </authors><title>A notion of task relatedness yielding provable multiple-task learning guarantees      </title><content>         The approach of learning multiple &amp;#8220;related&amp;#8221; tasks simultaneously has proven quite successful in practice; however, theoretical         justification for this success has remained elusive. The starting point for previous work on multiple task learning has been         that the tasks to be learned jointly are somehow &amp;#8220;algorithmically related&amp;#8221;, in the sense that the results of applying a specific learning algorithm to these tasks are assumed to be similar. We offer an alternative approach, defining         relatedness of tasks on the basis of similarity between the example generating distributions that underlie these tasks.                                             We provide a formal framework for this notion of task relatedness, which captures a sub-domain of the wide scope of issues               in which one may apply a multiple task learning approach. Our notion of task similarity is relevant to a variety of real life               multitask learning scenarios and allows the formal derivation of generalization bounds that are strictly stronger than the               previously known bounds for both the learning-to-learn and the multitask learning scenarios. We give precise conditions under               which our bounds guarantee generalization on the basis of smaller sample sizes than the standard single-task approach.                           </content></document><document><year>2008</year><authors>Maria-Florina Balcan1 | Avrim Blum1  | Nathan Srebro2 </authors><title>A theory of learning with similarity functions      </title><content>Kernel functions have become an extremely popular tool in machine learning, with an attractive theory as well. This theory         views a kernel as implicitly mapping data points into a possibly very high dimensional space, and describes a kernel function         as being good for a given learning problem if data is separable by a large margin in that implicit space. However, while quite         elegant, this theory does not necessarily correspond to the intuition of a good kernel as a good measure of similarity, and         the underlying margin in the implicit space usually is not apparent in &amp;#8220;natural&amp;#8221; representations of the data. Therefore, it         may be difficult for a domain expert to use the theory to help design an appropriate kernel for the learning task at hand.         Moreover, the requirement of positive semi-definiteness may rule out the most natural pairwise similarity functions for the         given problem domain.                     In this work we develop an alternative, more general theory of learning with similarity functions (i.e., sufficient conditions               for a similarity function to allow one to learn well) that does not require reference to implicit spaces, and does not require               the function to be positive semi-definite (or even symmetric). Instead, our theory talks in terms of more direct properties               of how the function behaves as a similarity measure. Our results also generalize the standard theory in the sense that any               good kernel function under the usual definition can be shown to also be a good similarity function under our definition (though               with some loss in the parameters). In this way, we provide the first steps towards a theory of kernels and more general similarity               functions that describes the effectiveness of a given function in terms of natural similarity-based properties.            </content></document><document><year>2008</year><authors>A. Dalalyan1  | A. B. Tsybakov1| 2</authors><title>Aggregation by exponential weighting, sharp PAC-Bayesian bounds and sparsity      </title><content>We study the problem of aggregation under the squared loss in the model of regression with deterministic design. We obtain         sharp PAC-Bayesian risk bounds for aggregates defined via exponential weights, under general assumptions on the distribution         of errors and on the functions to aggregate. We then apply these results to derive sparsity oracle inequalities.      </content></document><document><year>2008</year><authors>Yushi Jing1 | Vladimir Pavlovi&amp;#263 2  | James M. Rehg1 </authors><title>Boosted Bayesian network classifiers      </title><content>The use of Bayesian networks for classification problems has received a significant amount of recent attention. Although computationally         efficient, the standard maximum likelihood learning method tends to be suboptimal due to the mismatch between its optimization         criteria (data likelihood) and the actual goal of classification (label prediction accuracy). Recent approaches to optimizing         classification performance during parameter or structure learning show promise, but lack the favorable computational properties         of maximum likelihood learning. In this paper we present boosted Bayesian network classifiers, a framework to combine discriminative         data-weighting with generative training of intermediate models. We show that boosted Bayesian network classifiers encompass         the basic generative models in isolation, but improve their classification performance when the model structure is suboptimal.         We also demonstrate that structure learning is beneficial in the construction of boosted Bayesian network classifiers. On         a large suite of benchmark data-sets, this approach outperforms generative graphical models such as naive Bayes and TAN in         classification accuracy. Boosted Bayesian network classifiers have comparable or better performance in comparison to other         discriminatively trained graphical models including ELR and BNC. Furthermore, boosted Bayesian networks require significantly         less training time than the ELR and BNC algorithms.      </content></document><document><year>2008</year><authors>David R. Hardoon1  | John Shawe-Taylor1 </authors><title>Convergence analysis of kernel Canonical Correlation Analysis: theory and practice      </title><content>Canonical Correlation Analysis is a technique for finding pairs of basis vectors that maximise the correlation of a set of         paired variables, these pairs can be considered as two views of the same object. This paper provides a convergence analysis         of Canonical Correlation Analysis by defining a pattern function that captures the degree to which the features from the two         views are similar. We analyse the convergence using Rademacher complexity, hence deriving the error bound for new data. The         analysis provides further justification for the regularisation of kernel Canonical Correlation Analysis and is corroborated         by experiments on real world data.      </content></document><document><year>2008</year><authors>Andreas Argyriou1 | Theodoros Evgeniou2  | Massimiliano Pontil1 </authors><title>Convex multi-task feature learning      </title><content>         We present a method for learning sparse representations shared across multiple tasks. This method is a generalization of the         well-known single-task 1-norm regularization. It is based on a novel non-convex regularizer which controls the number of learned         features common across the tasks. We prove that the method is equivalent to solving a convex optimization problem for which         there is an iterative algorithm which converges to an optimal solution. The algorithm has a simple interpretation: it alternately         performs a supervised and an unsupervised step, where in the former step it learns task-specific functions and in the latter         step it learns common-across-tasks sparse representations for these functions. We also provide an extension of the algorithm         which learns sparse nonlinear representations using kernels. We report experiments on simulated and real data sets which demonstrate         that the proposed method can both improve the performance relative to learning each task independently and lead to a few learned         features common across related tasks. Our algorithm can also be used, as a special case, to simply select&amp;#8212;not learn&amp;#8212;a few         common variables across the tasks.               </content></document><document><year>2008</year><authors>Celine Vens1 | Jan Struyf1 | Le|er Schietgat1 | Sa&amp;#353 o D&amp;#382 eroski2  | Hendrik Blockeel1 </authors><title>Decision trees for hierarchical multi-label classification      </title><content>Hierarchical multi-label classification (HMC) is a variant of classification where instances may belong to multiple classes         at the same time and these classes are organized in a hierarchy. This article presents several approaches to the induction         of decision trees for HMC, as well as an empirical study of their use in functional genomics. We compare learning a single         HMC tree (which makes predictions for all classes together) to two approaches that learn a set of regular classification trees         (one for each class). The first approach defines an independent single-label classification task for each class (SC). Obviously,         the hierarchy introduces dependencies between the classes. While they are ignored by the first approach, they are exploited         by the second approach, named hierarchical single-label classification (HSC). Depending on the application at hand, the hierarchy         of classes can be such that each class has at most one parent (tree structure) or such that classes may have multiple parents         (DAG structure). The latter case has not been considered before and we show how the HMC and HSC approaches can be modified         to support this setting. We compare the three approaches on 24 yeast data sets using as classification schemes MIPS&amp;#8217;s FunCat         (tree structure) and the Gene Ontology (DAG structure). We show that HMC trees outperform HSC and SC trees along three dimensions:         predictive accuracy, model size, and induction time. We conclude that HMC trees should definitely be considered in HMC tasks         where interpretable models are desired.      </content></document><document><year>2008</year><authors>Geoffrey I. Webb1 </authors><title>Discovering significant patterns      </title><content>Without Abstract</content></document><document><year>2008</year><authors>Ying Yang1  | Geoffrey I. Webb2 </authors><title>Discretization for naive-Bayes learning: managing;discretization bias and variance      </title><content>Quantitative attributes are usually discretized in Naive-Bayes learning. We establish simple conditions under which discretization         is equivalent to use of the true probability density function during naive-Bayes learning. The use of different discretization         techniques can be expected to affect the classification bias and variance of generated naive-Bayes classifiers, effects we         name discretization bias and variance. We argue that by properly managing discretization bias and variance, we can effectively reduce naive-Bayes classification         error. In particular, we supply insights into managing discretization bias and variance by adjusting the number of intervals         and the number of training instances contained in each interval. We accordingly propose proportional discretization and fixed frequency discretization, two efficient unsupervised discretization methods that are able to effectively manage discretization bias and variance.         We evaluate our new techniques against four key discretization methods for naive-Bayes classifiers. The experimental results         support our theoretical analyses by showing that with statistically significant frequency, naive-Bayes classifiers trained         on data discretized by our new methods are able to achieve lower classification error than those trained on data discretized         by current established discretization methods.      </content></document><document><year>2008</year><authors>Finnegan Southey1 | Bret Hoehn2 | Robert C. Holte2</authors><title>Effective short-term opponent exploitation in simplified poker      </title><content>Uncertainty in poker stems from two key sources, the shuffled deck and an adversary whose strategy is unknown. One approach         to playing poker is to find a pessimistic game-theoretic solution (i.e., a Nash equilibrium), but human players have idiosyncratic         weaknesses that can be exploited if some model or counter-strategy can be learned by observing their play. However, games         against humans last for at most a few hundred hands, so learning must be very fast to be useful. We explore two approaches         to opponent modelling in the context of Kuhn poker, a small game for which game-theoretic solutions are known. Parameter estimation         and expert algorithms are both studied. Experiments demonstrate that, even in this small game, convergence to maximally exploitive         solutions in a small number of hands is impractical, but that good (e.g., better than Nash) performance can be achieved in         as few as 50 hands. Finally, we show that amongst a set of strategies with equal game-theoretic value, in particular the set         of Nash equilibrium strategies, some are preferable because they speed learning of the opponent&amp;#8217;s strategy by exploring it         more effectively.      </content></document><document><year>2008</year><authors>Gavin C. Cawley1  | Nicola L. C. Talbot1</authors><title>Efficient approximate leave-one-out cross-validation for;kernel logistic regression      </title><content>Kernel logistic regression (KLR) is the kernel learning method best suited to binary pattern recognition problems where estimates         of a-posteriori probability of class membership are required. Such problems occur frequently in practical applications, for instance because         the operational prior class probabilities or equivalently the relative misclassification costs are variable or unknown at         the time of training the model. The model parameters are given by the solution of a convex optimization problem, which may         be found via an efficient iteratively re-weighted least squares (IRWLS) procedure. The generalization properties of a kernel         logistic regression machine are however governed by a small number of hyper-parameters, the values of which must be determined         during the process of model selection. In this paper, we propose a novel model selection strategy for KLR, based on a computationally         efficient closed-form approximation of the leave-one-out cross-validation procedure. Results obtained on a variety of synthetic         and real-world benchmark datasets are given, demonstrating that the proposed model selection procedure is competitive with         a more conventional k-fold cross-validation based approach and also with Gaussian process (GP) classifiers implemented using the Laplace approximation         and via the Expectation Propagation (EP) algorithm.      </content></document><document><year>2008</year><authors>Brian M. Steele1 </authors><title>Exact bootstrap k-nearest neighbor learners      </title><content>Bootstrap aggregation, or bagging, is a method of reducing the prediction error of a statistical learner. The goal of bagging         is to construct a new learner which is the expectation of the original learner with respect to the empirical distribution         function. In nearly all cases, the expectation cannot be computed analytically, and bootstrap sampling is used to produce         an approximation. The k-nearest neighbor learners are exceptions to this generalization, and exact bagging of many k-nearest neighbor learners is straightforward. This article presents computationally simple and fast formulae for exact bagging         of k-nearest neighbor learners and extends exact bagging methods from the conventional bootstrap sampling (sampling n observations with replacement from a set of n observations) to bootstrap sub-sampling schemes (with and without replacement). In addition, a partially exact k-nearest neighbor regression learner is developed. The article also compares the prediction error associated with elementary         and exact bagging k-nearest neighbor learners, and several other ensemble methods using a suite of publicly available data sets.      </content></document><document><year>2008</year><authors>Umaa Rebbapragada1 | Pavlos Protopapas2| 3 | Carla E. Brodley1  | Charles Alcock2 </authors><title>Finding anomalous periodic time series         An application to catalogs of periodic variable stars</title><content>Catalogs of periodic variable stars contain large numbers of periodic light-curves (photometric time series data from the         astrophysics domain). Separating anomalous objects from well-known classes is an important step towards the discovery of new         classes of astronomical objects. Most anomaly detection methods for time series data assume either a single continuous time         series or a set of time series whose periods are aligned. Light-curve data precludes the use of these methods as the periods         of any given pair of light-curves may be out of sync. One may use an existing anomaly detection method if, prior to similarity         calculation, one performs the costly act of aligning two light-curves, an operation that scales poorly to massive data sets.         This paper presents PCAD, an unsupervised anomaly detection method for large sets of unsynchronized periodic time-series data,         that outputs a ranked list of both global and local anomalies. It calculates its anomaly score for each light-curve in relation         to a set of centroids produced by a modified k-means clustering algorithm. Our method is able to scale to large data sets         through the use of sampling. We validate our method on both light-curve data and other time series data sets. We demonstrate         its effectiveness at finding known anomalies, and discuss the effect of sample size and number of centroids on our results.         We compare our method to naive solutions and existing time series anomaly detection methods for unphased data, and show that         PCAD&amp;#8217;s reported anomalies are comparable to or better than all other methods. Finally, astrophysicists on our team have verified         that PCAD finds true anomalies that might be indicative of novel astrophysical phenomena.      </content></document><document><year>2008</year><authors>Jian Zhang1 | Zoubin Ghahramani2| 3  | Yiming Yang3 </authors><title>Flexible latent variable models for multi-task learning      </title><content>Given multiple prediction problems such as regression or classification, we are interested in a joint inference framework         that can effectively share information between tasks to improve the prediction accuracy, especially when the number of training         examples per problem is small. In this paper we propose a probabilistic framework which can support a set of latent variable         models for different multi-task learning scenarios. We show that the framework is a generalization of standard learning methods         for single prediction problems and it can effectively model the shared structure among different prediction tasks. Furthermore,         we present efficient algorithms for the empirical Bayes method as well as point estimation. Our experiments on both simulated         datasets and real world classification datasets show the effectiveness of the proposed models in two evaluation settings:         a standard multi-task learning setting and a transfer learning setting.      </content></document><document><year>2008</year><authors>Hiroto Saigo1| 2 | Sebastian Nowozin1| Tadashi Kadowaki3| 4| Taku Kudo5 | Koji Tsuda1</authors><title>gBoost: a mathematical programming approach to graph classification and regression      </title><content>Graph mining methods enumerate frequently appearing subgraph patterns, which can be used as features for subsequent classification         or regression. However, frequent patterns are not necessarily informative for the given learning problem. We propose a mathematical         programming boosting method (gBoost) that progressively collects informative patterns. Compared to AdaBoost, gBoost can build         the prediction rule with fewer iterations. To apply the boosting method to graph data, a branch-and-bound pattern search algorithm         is developed based on the DFS code tree. The constructed search space is reused in later iterations to minimize the computation         time. Our method can learn more efficiently than the simpler method based on frequent substructure mining, because the output         labels are used as an extra information source for pruning the search space. Furthermore, by engineering the mathematical         program, a wide range of machine learning problems can be solved without modifying the pattern search algorithm.      </content></document><document><year>2008</year><authors>Pierre MahГ©1  | Jean-Philippe Vert1| 2| 3 </authors><title>Graph kernels based on tree patterns for molecules      </title><content>Motivated by chemical applications, we revisit and extend a family of positive definite kernels for graphs based on the detection         of common subtrees, initially proposed by Ramon and GГ¤rtner (Proceedings of the first international workshop on mining graphs,         trees and sequences, pp.;65&amp;#8211;74, 2003). We propose new kernels with a parameter to control the complexity of the subtrees used as features to represent the graphs.         This parameter allows to smoothly interpolate between classical graph kernels based on the count of common walks, on the one         hand, and kernels that emphasize the detection of large common subtrees, on the other hand. We also propose two modular extensions         to this formulation. The first extension increases the number of subtrees that define the feature space, and the second one         removes noisy features from the graph representations. We validate experimentally these new kernels on problems of toxicity         and anti-cancer activity prediction for small molecules with support vector machines.      </content></document><document><year>2008</year><authors>Walter Daelemans1 | Bart Goethals1  | Katharina Morik2 </authors><title>Guest Editors&amp;#8217; introduction: special issue of selected papers from ECML PKDD 2008      </title><content>Without Abstract</content></document><document><year>2008</year><authors>Hendrik Blockeel1 | Jude Shavlik2  | Prasad Tadepalli3 </authors><title>Guest editors&amp;#8217; introduction: special issue on inductive logic programming (ILP-2007)      </title><content>Without Abstract</content></document><document><year>2008</year><authors>Nader H. Bshouty1  | Claudio Gentile2 </authors><title>Guest Editors&amp;#8217; Introduction: Special issue on Learning Theory (COLT-2007)      </title><content>Without Abstract</content></document><document><year>2008</year><authors>Daniel L. Silver1  | Kristin P. Bennett2 </authors><title>Guest editor&amp;#8217;s introduction: special issue on inductive transfer learning      </title><content>Without Abstract</content></document><document><year>2008</year><authors>Qingping Tao1  | Stephen D. Scott2 </authors><title>Improved MCMC sampling methods for estimating weighted sums in Winnow with application to DNF learning      </title><content>A Markov chain Monte Carlo method has previously been introduced to estimate weighted sums in multiplicative weight update         algorithms when the number of inputs is exponential. However, the original algorithm still required extensive simulation of         the Markov chain in order to get accurate estimates of the weighted sums. We propose an optimized version of the original         algorithm that produces exactly the same classifications while often using fewer Markov chain simulations. We also apply three         other sampling techniques and empirically compare them with the original Metropolis sampler to determine how effective each         is in drawing good samples in the least amount of time, in terms of accuracy of weighted sum estimates and in terms of Winnow&amp;#8217;s         prediction accuracy. We found that two other samplers (Gibbs and Metropolized Gibbs) were slightly better than Metropolis         in their estimates of the weighted sums. For prediction errors, there is little difference between any pair of MCMC techniques         we tested. Also, on the data sets we tested, we discovered that all approximations of Winnow have no disadvantage when compared         to brute force Winnow (where weighted sums are exactly computed), so generalization accuracy is not compromised by our approximation.         This is true even when very small sample sizes and mixing times are used.      </content></document><document><year>2008</year><authors>Markus Weimer1 | Alex|ros Karatzoglou2  | Alex Smola3 </authors><title>Improving maximum margin matrix factorization      </title><content>Collaborative filtering is a popular method for personalizing product recommendations. Maximum Margin Matrix Factorization         (MMMF) has been proposed as one successful learning approach to this task and has been recently extended to structured ranking         losses. In this paper we discuss a number of extensions to MMMF by introducing offset terms, item dependent regularization         and a graph kernel on the recommender graph. We show equivalence between graph kernels and the recent MMMF extensions by Mnih         and Salakhutdinov (Advances in Neural Information Processing Systems;20, 2008). Experimental evaluation of the introduced extensions show improved performance over the original MMMF formulation.      </content></document><document><year>2008</year><authors>Marco Grzegorczyk1| 2  | Dirk Husmeier1| 2 </authors><title>Improving the structure MCMC sampler for Bayesian networks by introducing a new edge reversal move      </title><content>Applications of Bayesian networks in systems biology are computationally demanding due to the large number of model parameters.         Conventional MCMC schemes based on proposal moves in structure space tend to be too slow in mixing and convergence, and have         recently been superseded by proposal moves in the space of node orders. A disadvantage of the latter approach is the intrinsic         inability to specify the prior probability on network structures explicitly. The relative paucity of different experimental         conditions in contemporary systems biology implies a strong influence of the prior probability on the posterior probability         and, hence, the outcome of inference. Consequently, the paradigm of performing MCMC proposal moves in order rather than structure         space is not entirely satisfactory. In the present article, we propose a new and more extensive edge reversal move in the         original structure space, and we show that this significantly improves the convergence of the classical structure MCMC scheme.      </content></document><document><year>2008</year><authors>R|a Kassab1  | FrГ©dГ©ric Alex|re1 </authors><title>Incremental data-driven learning of a novelty detection model for one-class classification with application to;high-dimensional         noisy data      </title><content>Most conventional learning algorithms require both positive and negative training data for achieving accurate classification         results. However, the problem of learning classifiers from only positive data arises in many applications where negative data         are too costly, difficult to obtain, or not available at all. This paper describes a new machine learning approach, called         ILoNDF (Incremental data-driven Learning of Novelty Detector Filter). The approach is inspired by novelty detection theory         and its learning method, which typically requires only examples from one class to learn a model. One advantage of ILoNDF is         the ability of its generative learning to capture the intrinsic characteristics of the training data by continuously integrating         the information relating to the relative frequencies of the features of training data and their co-occurrence dependencies.         This makes ILoNDF rather stable and less sensitive to noisy features which may be present in the representation of the positive         data. In addition, ILoNDF does not require extensive computational resources since it operates on-line without repeated training,         and no parameters need to be tuned. In this study we mainly focus on the robustness of ILoNDF in dealing with high-dimensional         noisy data and we investigate the variation of its performance depending on the amount of data available for training. To         make our study comparable to previous studies, we investigate four common methods: PCA residuals, Hotelling&amp;#8217;s T         2 test, an auto-associative neural network, and a one-class version of the SVM classifier (lately a favored method for one-class         classification). Experiments are conducted on two real-world text corpora: Reuters and WebKB. Results show that ILoNDF tends         to be more robust, is less affected by initial settings, and consistently outperforms the other methods.      </content></document><document><year>2008</year><authors>Ankur Jain1  | Daniel Nikovski1 </authors><title>Incremental exemplar learning schemes for classification on embedded devices      </title><content>Although memory-based classifiers offer robust classification performance, their widespread usage on embedded devices is hindered         due to the device&amp;#8217;s limited memory resources. Moreover, embedded devices often operate in an environment where data exhibits         evolutionary changes which entails frequent update of the in-memory training data. A viable option for dealing with the memory         constraint is to use Exemplar Learning (EL) schemes that learn a small memory set (called the exemplar set) of high functional information that fits in memory. However, traditional EL schemes have several drawbacks that make them         inapplicable for embedded devices; (1) they have high memory overheads and are unable to handle incremental updates to the         exemplar set, (2) they cannot be customized to obtain exemplar sets of any user-defined size that fits in the memory and (3)         they learn exemplar sets based on local neighborhood structures that do not offer robust classification performance. In this         paper, we propose two novel EL schemes,                    (Entropy-Based Exemplar Learning) and                    (AUC-Based Exemplar Learning) that overcome the aforementioned short-comings of traditional EL algorithms. We show that our         schemes efficiently incorporate new training datasets while maintaining high quality exemplar sets of any user-defined size.         We present a comprehensive experimental analysis showing excellent classification-accuracy versus memory-usage tradeoffs using         our proposed methods.      </content></document><document><year>2008</year><authors>Daniel L. Silver1 | Ryan Poirier1 | Duane Currie1</authors><title>Inductive transfer with context-sensitive neural networks      </title><content>         Context-sensitive Multiple Task Learning, or csMTL, is presented as a method of inductive transfer which uses a single output neural network and additional contextual inputs         for learning multiple tasks. Motivated by problems with the application of MTL networks to machine lifelong learning systems,         csMTL encoding of multiple task examples was developed and found to improve predictive performance. As evidence, the csMTL method is tested on seven task domains and shown to produce hypotheses for primary tasks that are often better than standard         MTL hypotheses when learning in the presence of related and unrelated tasks. We argue that the reason for this performance         improvement is a reduction in the number of effective free parameters in the csMTL network brought about by the shared output node and weight update constraints due to the context inputs. An examination         of IDT and SVM models developed from csMTL encoded data provides initial evidence that this improvement is not shared across all machine learning models.      </content></document><document><year>2008</year><authors>Ran El-Yaniv1 | Dmitry Pechyony1  | Vladimir Vapnik2 </authors><title>Large margin vs. large volume in transductive learning      </title><content>We consider a large volume principle for transductive learning that prioritizes the transductive equivalence classes according         to the volume they occupy in hypothesis space. We approximate volume maximization using a geometric interpretation of the         hypothesis space. The resulting algorithm is defined via a non-convex optimization problem that can still be solved exactly         and efficiently. We provide a bound on the test error of the algorithm and compare it to transductive SVM (TSVM) using 31         datasets.      </content></document><document><year>2008</year><authors>Eerika Savia1| 2 | Kai PuolamГ¤ki2  | Samuel Kaski1| 2 </authors><title>Latent grouping models for user preference prediction      </title><content>We tackle the problem of new users or documents in collaborative filtering. Generalization over users by grouping them into         user groups is beneficial when a rating is to be predicted for a relatively new document having only few observed ratings.         Analogously, generalization over documents improves predictions in the case of new users. We show that if either users and         documents or both are new, two-way generalization becomes necessary. We demonstrate the benefits of grouping of users, grouping         of documents, and two-way grouping, with artificial data and in two case studies with real data. We have introduced a probabilistic         latent grouping model for predicting the relevance of a document to a user. The model assumes a latent group structure for         both users and items. We compare the model against a state-of-the-art method, the User Rating Profile model, where only the         users have a latent group structure. We compute the posterior of both models by Gibbs sampling. The Two-Way Model predicts         relevance more accurately when the target consists of both new documents and new users. The reason is that generalization         over documents becomes beneficial for new documents and at the same time generalization over users is needed for new users.      </content></document><document><year>2008</year><authors>Geoffrey I. Webb1 </authors><title>Layered critical values: a powerful direct-adjustment approach to discovering significant patterns      </title><content>Standard pattern discovery techniques, such as association rules, suffer an extreme risk of finding very large numbers of         spurious patterns for many knowledge discovery tasks. The direct-adjustment approach to controlling this risk applies a statistical         test during the discovery process, using a critical value adjusted to take account of the size of the search space. However,         a problem with the direct-adjustment strategy is that it may discard numerous true patterns. This paper investigates the assignment         of different critical values to different areas of the search space as an approach to alleviating this problem, using a variant         of a technique originally developed for other purposes. This approach is shown to be effective at increasing the number of         discoveries while still maintaining strict control over the risk of false discoveries.      </content></document><document><year>2008</year><authors>Stefan Raeymaekers1 | Maurice Bruynooghe1  | Jan Van den Bussche2 </authors><title>Learning (k,l)-contextual tree languages for information extraction from web pages      </title><content>This paper introduces a novel method for learning a wrapper for extraction of information from web pages, based upon (k,l)-contextual tree languages. It also introduces a method to learn good values of k and l based on a few positive and negative examples. Finally, it describes how the algorithm can be integrated in a tool for information         extraction.      </content></document><document><year>2008</year><authors>Dana Angluin1 | James Aspnes1 | Jiang Chen2  | Lev Reyzin1 </authors><title>Learning large-alphabet and analog circuits with value injection queries      </title><content>We consider the problem of learning an acyclic discrete circuit with n wires, fan-in bounded by k and alphabet size s using value injection queries. For the class of transitively reduced circuits, we develop the Distinguishing Paths Algorithm,         that learns such a circuit using (ns)            O(k) value injection queries and time polynomial in the number of queries. We describe a generalization of the algorithm to the         class of circuits with shortcut width bounded by b that uses (ns)            O(k+b) value injection queries. Both algorithms use value injection queries that fix only O(kd) wires, where d is the depth of the target circuit. We give a reduction showing that without such restrictions on the topology of the circuit,         the learning problem may be computationally intractable when s=n                     &amp;#920;(1), even for circuits of depth O(log&amp;#8201;n). We then apply our large-alphabet learning algorithms to the problem of approximate learning of analog circuits whose gate         functions satisfy a Lipschitz condition. Finally, we consider models in which behavioral equivalence queries are also available,         and extend and improve the learning algorithms of;(Angluin in Proceedings of the Thirty-Eighth Annual ACM Symposium on Theory         of Computing, pp.;584&amp;#8211;593, 2006) to handle general classes of gate functions that are polynomial time learnable from counterexamples.      </content></document><document><year>2008</year><authors>Jianzhong Chen1 | Stephen Muggleton1  | JosГ© Santos1 </authors><title>Learning probabilistic logic models from probabilistic examples      </title><content>We revisit an application developed originally using abductive Inductive Logic Programming (ILP) for modeling inhibition in         metabolic networks. The example data was derived from studies of the effects of toxins on rats using Nuclear Magnetic Resonance         (NMR) time-trace analysis of their biofluids together with background knowledge representing a subset of the Kyoto Encyclopedia         of Genes and Genomes (KEGG). We now apply two Probabilistic ILP (PILP) approaches&amp;#8212;abductive Stochastic Logic Programs (SLPs)         and PRogramming In Statistical modeling (PRISM) to the application. Both approaches support abductive learning and probability         predictions. Abductive SLPs are a PILP framework that provides possible worlds semantics to SLPs through abduction. Instead         of learning logic models from non-probabilistic examples as done in ILP, the PILP approach applied in this paper is based         on a general technique for introducing probability labels within a standard scientific experimental setting involving control         and treated data. Our results demonstrate that the PILP approach provides a way of learning probabilistic logic models from         probabilistic examples, and the PILP models learned from probabilistic examples lead to a significant decrease in error accompanied         by improved insight from the learned results compared with the PILP models learned from non-probabilistic examples.      </content></document><document><year>2008</year><authors>Rasa Jurgelenaite1  | Tom Heskes1 </authors><title>Learning symmetric causal independence models      </title><content>Causal independence modelling is a well-known method for reducing the size of probability tables, simplifying the probabilistic         inference and explaining the underlying mechanisms in Bayesian networks. Recently, a generalization of the widely-used noisy         OR and noisy AND models, causal independence models based on symmetric Boolean functions, was proposed. In this paper, we         study the problem of learning the parameters in these models, further referred to as symmetric causal independence models.         We present a computationally efficient EM algorithm to learn parameters in symmetric causal independence models, where the         computational scheme of the Poisson binomial distribution is used to compute the conditional probabilities in the E-step.         We study computational complexity and convergence of the developed algorithm. The presented EM algorithm allows us to assess         the practical usefulness of symmetric causal independence models. In the assessment, the models are applied to a classification         task; they perform competitively with state-of-the-art classifiers.      </content></document><document><year>2008</year><authors>Harri LГ¤hdesmГ¤ki1| 2  | Ilya Shmulevich1 </authors><title>Learning the structure of dynamic Bayesian networks from;time series and;steady state measurements      </title><content>Dynamic Bayesian networks (DBN) are a class of graphical models that has become a standard tool for modeling various stochastic         time-varying phenomena. In many applications, the primary goal is to infer the network structure from measurement data. Several         efficient learning methods have been introduced for the inference of DBNs from time series measurements. Sometimes, however,         it is either impossible or impractical to collect time series data, in which case, a common practice is to model the non-time         series observations using static Bayesian networks (BN). Such an approach is obviously sub-optimal if the goal is to gain         insight into the underlying dynamical model. Here, we introduce Bayesian methods for the inference of DBNs from steady state         measurements. We also consider learning the structure of DBNs from a combination of time series and steady state measurements.         We introduce two different methods: one that is based on an approximation and another one that provides exact computation.         Simulation results demonstrate that dynamic network structures can be learned to an extent from steady state measurements         alone and that inference from a combination of steady state and time series data has the potential to improve learning performance         relative to the inference from time series data alone.      </content></document><document><year>2008</year><authors>FrГ©dГ©ric Koriche1 </authors><title>Learning to assign degrees of belief in relational domains      </title><content>A recurrent problem in the development of reasoning agents is how to assign degrees of beliefs to uncertain events in a complex         environment. The standard knowledge representation framework imposes a sharp separation between learning and reasoning; the         agent starts by acquiring a &amp;#8220;model&amp;#8221; of its environment, represented into an expressive language, and then uses this model         to quantify the likelihood of various queries. Yet, even for simple queries, the problem of evaluating probabilities from         a general purpose representation is computationally prohibitive. In contrast, this study embarks on the learning to reason         (L2R) framework that aims at eliciting degrees of belief in an inductive manner. The agent is viewed as an anytime reasoner         that iteratively improves its performance in light of the knowledge induced from its mistakes. Indeed, by coupling exponentiated         gradient strategies in learning and weighted model counting techniques in reasoning, the L2R framework is shown to provide         efficient solutions to relational probabilistic reasoning problems that are provably intractable in the classical paradigm.      </content></document><document><year>2008</year><authors>Tapio Pahikkala1 | Sampo Pyysalo1 | Jorma Boberg1 | Jouni JГ¤rvinen1  | Tapio Salakoski1 </authors><title>Matrix representations, linear transformations, and;kernels for disambiguation in natural language      </title><content>In the application of machine learning methods with natural language inputs, the words and their positions in the input text         are some of the most important features. In this article, we introduce a framework based on a word-position matrix representation         of text, linear feature transformations of the word-position matrices, and kernel functions constructed from the transformations.         We consider two categories of transformations, one based on word similarities and the second on their positions, which can         be applied simultaneously in the framework in an elegant way. We show how word and positional similarities obtained by applying         previously proposed techniques, such as latent semantic analysis, can be incorporated as transformations in the framework.         We also introduce novel ways to determine word and positional similarities. We further present efficient algorithms for computing         kernel functions incorporating the transformations on the word-position matrices, and, more importantly, introduce a highly         efficient method for prediction. The framework is particularly suitable to natural language disambiguation tasks where the         aim is to select for a single word a particular property from a set of candidates based on the context of the word. We demonstrate         the applicability of the framework to this type of tasks using context-sensitive spelling error correction on the Reuters         News corpus as a model problem.      </content></document><document><year>2008</year><authors>Johannes FГјrnkranz1 | Eyke HГјllermeier2 | Eneldo Loza MencГ­a1  | Klaus Brinker2 </authors><title>Multilabel classification via calibrated label ranking      </title><content>Label ranking studies the problem of learning a mapping from instances to rankings over a predefined set of labels. Hitherto         existing approaches to label ranking implicitly operate on an underlying (utility) scale which is not calibrated in the sense         that it lacks a natural zero point. We propose a suitable extension of label ranking that incorporates the calibrated scenario         and substantially extends the expressive power of these approaches. In particular, our extension suggests a conceptually novel         technique for extending the common learning by pairwise comparison approach to the multilabel scenario, a setting previously         not being amenable to the pairwise decomposition technique. The key idea of the approach is to introduce an artificial calibration         label that, in each example, separates the relevant from the irrelevant labels. We show that this technique can be viewed         as a combination of pairwise preference learning and the conventional relevance classification technique, where a separate         classifier is trained to predict whether a label is relevant or not. Empirical results in the area of text categorization,         image classification and gene analysis underscore the merits of the calibrated model in comparison to state-of-the-art multilabel         learning methods.      </content></document><document><year>2008</year><authors>Dvijotham Krishnamurthy1 | Soumen Chakrabarti1 | Subhasis Chaudhuri1</authors><title>New closed-form bounds on the partition function      </title><content>Estimating the partition function is a key but difficult computation in graphical models. One approach is to estimate tractable         upper and lower bounds. The piecewise upper bound of Sutton et al. is computed by breaking the graphical model into pieces         and approximating the partition function as a product of local normalizing factors for these pieces. The tree reweighted belief         propagation algorithm (TRW-BP) by Wainwright et al. gives tighter upper bounds. It optimizes an upper bound expressed in terms         of convex combinations of spanning trees of the graph. Recently, Globerson et al. gave a different, convergent iterative dual         optimization algorithm TRW-GP for the TRW objective. However, in many practical applications, particularly those that train         CRFs with many nodes, TRW-BP and TRW-GP are too slow to be practical. Without changing the algorithm, we prove that TRW-BP         converges in a single iteration for associative potentials, and give a closed form for the solution it finds. The closed-form         solution obviates the need for complex optimization. We use this result to develop new closed-form upper bounds for MRFs with         arbitrary pairwise potentials. Being closed-form, they are much faster to compute than TRW-based bounds. We also prove similar         convergence results for loopy belief propagation (LBP) and use it to obtain closed-form solutions to the LBP pseudomarginals         and approximation to the partition function for associative potentials. We then use recent results proved by Wainwright et         al for binary MRFs to obtain closed-form lower bounds on the partition function. We then develop novel lower bounds for arbitrary         associative networks. We report on experiments with synthetic and real-world graphs. Our new upper bounds are considerably         tighter than the piecewise bounds in practice. Moreover, we can compute our bounds on several graphs where TRW-BP does not         converge. Our novel lower bound, in spite of being closed-form and much faster to compute, outperforms more complicated popular         algorithms for computing lower bounds like mean-field on densely connected graphs by wide margins although it does worse on         sparsely connected graphs like chains.      </content></document><document><year>2008</year><authors>Chris Bourke1 | Kun Deng1 | Stephen D. Scott1 | Robert E. Schapire2  | N. V. Vinodch|ran1 </authors><title>On reoptimizing multi-class classifiers      </title><content>Significant changes in the instance distribution or associated cost function of a learning problem require one to reoptimize         a previously-learned classifier to work under new conditions. We study the problem of reoptimizing a multi-class classifier         based on its ROC hypersurface and a matrix describing the costs of each type of prediction error. For a binary classifier,         it is straightforward to find an optimal operating point based on its ROC curve and the relative cost of true positive to         false positive error. However, the corresponding multi-class problem (finding an optimal operating point based on a ROC hypersurface         and cost matrix) is more challenging and until now, it was unknown whether an efficient algorithm existed that found an optimal         solution. We answer this question by first proving that the decision version of this problem is                   -complete. As a complementary positive result, we give an algorithm that finds an optimal solution in polynomial time if the         number of classes n is a constant. We also present several heuristics for this problem, including linear, nonlinear, and quadratic programming         formulations, genetic algorithms, and a customized algorithm. Empirical results suggest that under both uniform and non-uniform         cost models, simple greedy methods outperform more sophisticated methods.      </content></document><document><year>2008</year><authors>Masashi Shimbo1 | Takahiko Ito1| 2 | Daichi Mochihashi3  | Yuji Matsumoto1 </authors><title>On the properties of von;Neumann kernels for link analysis      </title><content>We study the effectiveness of Kandola et;al.&amp;#8217;s von;Neumann kernels as a link analysis measure. We show that von;Neumann kernels         subsume Kleinberg&amp;#8217;s HITS importance at the limit of their parameter range. Because they reduce to co-citation relatedness         at the other end of the parameter, von;Neumann kernels give us a spectrum of link analysis measures between the two established         measures of importance and relatedness. Hence the relative merit of a vertex can be evaluated in terms of varying trade-offs         between the global importance and the local relatedness within a single parametric framework. As a generalization of HITS,         von;Neumann kernels inherit the problem of topic drift. When a graph consists of multiple communities each representing a different topic, HITS is known to rank vertices in the         most dominant community higher regardless of the query term. This problem persists in von;Neumann kernels; when the parameter         is biased towards the direction of global importance, they tend to rank vertices in the dominant community uniformly higher         irrespective of the community of the seed vertex relative to which the ranking is computed. To alleviate topic drift, we propose         to use of a PLSI-based technique in combination with von;Neumann kernels. Experimental results on a citation network of scientific         papers demonstrate the characteristics and effectiveness of von;Neumann kernels.      </content></document><document><year>2008</year><authors>Nuno A. Fonseca1 | Ashwin Srinivasan2| 3 | Fern|o Silva4  | Rui Camacho5 </authors><title>Parallel ILP for distributed-memory architectures      </title><content>The growth of machine-generated relational databases, both in the sciences and in industry, is rapidly outpacing our ability         to extract useful information from them by manual means. This has brought into focus machine learning techniques like Inductive         Logic Programming (ILP) that are able to extract human-comprehensible models for complex relational data. The price to pay         is that ILP techniques are not efficient: they can be seen as performing a form of discrete optimisation, which is known to         be computationally hard; and the complexity is usually some super-linear function of the number of examples. While little         can be done to alter the theoretical bounds on the worst-case complexity of ILP systems, some practical gains may follow from         the use of multiple processors. In this paper we survey the state-of-the-art on parallel ILP. We implement several parallel         algorithms and study their performance using some standard benchmarks. The principal findings of interest are these: (1) of         the techniques investigated, one that simply constructs models in parallel on each processor using a subset of data and then         combines the models into a single one, yields the best results; and (2) sequential (approximate) ILP algorithms based on randomized         searches have lower execution times than (exact) parallel algorithms, without sacrificing the quality of the solutions found.      </content></document><document><year>2008</year><authors>Eyal Even-Dar1| Michael Kearns2| Yishay Mansour1| 3 | Jennifer Wortman2 </authors><title>Regret to the best vs. regret to the average      </title><content>We study online regret minimization algorithms in an experts setting. In this setting, the algorithm chooses a distribution         over experts at each time step and receives a gain that is a weighted average of the experts&amp;#8217; instantaneous gains. We consider         a bicriteria setting, examining not only the standard notion of regret to the best expert, but also the regret to the average         of all experts, the regret to any given fixed mixture of experts, or the regret to the worst expert. This study leads both         to new understanding of the limitations of existing no-regret algorithms, and to new algorithms with novel performance guarantees.         More specifically, we show that any algorithm that achieves only                    cumulative regret to the best expert on a sequence of T trials must, in the worst case, suffer regret                    to the average, and that for a wide class of update rules that includes many existing no-regret algorithms (such as Exponential         Weights and Follow the Perturbed Leader), the product of the regret to the best and the regret to the average is, in the worst         case, &amp;#937;(T). We then describe and analyze two alternate new algorithms that both achieve cumulative regret only                    to the best expert and have only constant regret to any given fixed distribution over experts (that is, with no dependence on either T or the number of experts N). The key to the first algorithm is the gradual increase in the &amp;#8220;aggressiveness&amp;#8221; of updates in response to observed divergences         in expert performances. The second algorithm is a simple twist on standard exponential-update algorithms.      </content></document><document><year>2008</year><authors>Maria-Florina Balcan1 | Nikhil Bansal2 | Alina Beygelzimer3 | Don Coppersmith4 | John Langford5  | Gregory B. Sorkin2 </authors><title>Robust reductions from ranking to classification      </title><content>We reduce ranking, as measured by the Area Under the Receiver Operating Characteristic Curve (AUC), to binary classification.         The core theorem shows that a;binary classification regret of r on the induced binary problem implies an;AUC regret of at most 2r. This is a;large improvement over approaches such as ordering according to regressed scores, which have a;regret transform         of r         &amp;#8614;         nr where n is the number of elements.      </content></document><document><year>2008</year><authors>Christos Dimitrakakis1  | Michail G. Lagoudakis2 </authors><title>Rollout sampling approximate policy iteration      </title><content>Several researchers have recently investigated the connection between reinforcement learning and classification. We are motivated         by proposals of approximate policy iteration schemes without value functions, which focus on policy representation using classifiers         and address policy learning as a supervised learning problem. This paper proposes variants of an improved policy iteration         scheme which addresses the core sampling problem in evaluating a policy through simulation as a multi-armed bandit machine.         The resulting algorithm offers comparable performance to the previous algorithm achieved, however, with significantly less         computational effort. An order of magnitude improvement is demonstrated experimentally in two standard reinforcement learning         domains: inverted pendulum and mountain-car.      </content></document><document><year>2008</year><authors>Brian Kulis1 | Sugato Basu2| Inderjit Dhillon1 | Raymond Mooney1</authors><title>Semi-supervised graph clustering: a kernel approach      </title><content>Semi-supervised clustering algorithms aim to improve clustering results using limited supervision. The supervision is generally         given as pairwise constraints; such constraints are natural for graphs, yet most semi-supervised clustering algorithms are         designed for data represented as vectors. In this paper, we unify vector-based and graph-based approaches. We first show that         a recently-proposed objective function for semi-supervised clustering based on Hidden Markov Random Fields, with squared Euclidean         distance and a certain class of constraint penalty functions, can be expressed as a special case of the weighted kernel k-means objective;(Dhillon et al., in Proceedings of the 10th International Conference on Knowledge Discovery and Data Mining,         2004a). A recent theoretical connection between weighted kernel k-means and several graph clustering objectives enables us to perform semi-supervised clustering of data given either as vectors         or as a graph. For graph data, this result leads to algorithms for optimizing several new semi-supervised graph clustering         objectives. For vector data, the kernel approach also enables us to find clusters with non-linear boundaries in the input         data space. Furthermore, we show that recent work on spectral learning;(Kamvar et al., in Proceedings of the 17th International         Joint Conference on Artificial Intelligence, 2003) may be viewed as a special case of our formulation. We empirically show that our algorithm is able to outperform current         state-of-the-art semi-supervised algorithms on both vector-based and graph-based data sets.      </content></document><document><year>2008</year><authors>Sudipto Guha1 | Piotr Indyk2  | Andrew McGregor3 </authors><title>Sketching information divergences      </title><content>When comparing discrete probability distributions, natural measures of similarity are not &amp;#8467;                     p             distances but rather are information divergences such as Kullback-Leibler and Hellinger. This paper considers some of the         issues related to constructing small-space sketches of distributions in the data-stream model, a concept related to dimensionality reduction, such that these measures can be         approximated from the sketches. Related problems for &amp;#8467;                     p             distances are reasonably well understood via a series of results by Johnson and Lindenstrauss (Contemp. Math. 26:189&amp;#8211;206,         1984), Alon et al. (J. Comput. Syst. Sci. 58(1):137&amp;#8211;147, 1999), Indyk (IEEE Symposium on Foundations of Computer Science, pp.;202&amp;#8211;208, 2000), and Brinkman and Charikar (IEEE Symposium on Foundations of Computer Science, pp.;514&amp;#8211;523, 2003). In contrast, almost no analogous results are known to date about constructing sketches for the information divergences         used in statistics and learning theory.                     Our main result is an impossibility result that shows that no small-space sketches exist for the multiplicative approximation               of any commonly used f-divergences and Bregman divergences with the notable exceptions of &amp;#8467;               1 and &amp;#8467;               2 where small-space sketches exist. We then present data-stream algorithms for the additive approximation of a wide range of               information divergences. Throughout, our emphasis is on providing general characterizations.            </content></document><document><year>2008</year><authors>Thomas G. Dietterich1 | Pedro Domingos2 | Lise Getoor3 | Stephen Muggleton4  | Prasad Tadepalli1 </authors><title>Structured machine learning: the next ten years      </title><content>The field of inductive logic programming (ILP) has made steady progress, since the first ILP workshop in 1991, based on a         balance of developments in theory, implementations and applications. More recently there has been an increased emphasis on         Probabilistic ILP and the related fields of Statistical Relational Learning (SRL) and Structured Prediction. The goal of the         current paper is to consider these emerging trends and chart out the strategic directions and open problems for the broader         area of structured machine learning for the next 10 years.      </content></document><document><year>2008</year><authors>Neville Mehta1 | Sriraam Natarajan1 | Prasad Tadepalli1  | Alan Fern1 </authors><title>Transfer in variable-reward hierarchical reinforcement learning      </title><content>Transfer learning seeks to leverage previously learned tasks to achieve faster learning in a new task. In this paper, we consider         transfer learning in the context of related but distinct Reinforcement Learning (RL) problems. In particular, our RL problems are derived from Semi-Markov Decision Processes (SMDPs) that share the same         transition dynamics but have different reward functions that are linear in a set of reward features. We formally define the         transfer learning problem in the context of RL as learning an efficient algorithm to solve any SMDP drawn from a fixed distribution         after experiencing a finite number of them. Furthermore, we introduce an online algorithm to solve this problem, Variable-Reward         Reinforcement Learning (VRRL), that compactly stores the optimal value functions for several SMDPs, and uses them to optimally         initialize the value function for a new SMDP. We generalize our method to a hierarchical RL setting where the different SMDPs         share the same task hierarchy. Our experimental results in a simplified real-time strategy domain show that significant transfer         learning occurs in both flat and hierarchical settings. Transfer is especially effective in the hierarchical setting where         the overall value functions are decomposed into subtask value functions which are more widely amenable to transfer across         different SMDPs.      </content></document><document><year>2008</year><authors>Xiaogang Su1 | Chih-Ling Tsai2  | Morgan C. Wang1 </authors><title>Tree-structured model diagnostics for linear regression      </title><content>This paper studies model diagnostics for linear regression models. We propose two tree-based procedures to check the adequacy         of linear functional form and the appropriateness of homoscedasticity, respectively. The proposed tree methods not only facilitate         a natural assessment of the linear model, but also automatically provide clues for amending deficiencies. We explore and illustrate         their uses via both Monte Carlo studies and real data examples.      </content></document><document><year>2008</year><authors>John Case1 | Samuel E. Moelius III1 </authors><title>U-shaped, iterative, and iterative-with-counter learning      </title><content>This paper solves an important problem left open in the literature by showing that U-shapes are unnecessary in iterative learning from positive data. A U-shape occurs when a learner first learns, then unlearns, and, finally, relearns, some target concept. Iterative learning is a Gold-style learning model in which each of a learner&amp;#8217;s output conjectures depends only upon the learner&amp;#8217;s most recent conjecture and input element. Previous results had shown, for example, that U-shapes are unnecessary for explanatory learning, but are necessary for behaviorally correct learning.                     Work on the aforementioned problem led to the consideration of an iterative-like learning model, in which each of a learner&amp;#8217;s               conjectures may, in addition, depend upon the number of elements so far presented to the learner. Learners in this new model are strictly more powerful               than traditional iterative learners, yet not as powerful as full explanatory learners. Can any class of languages learnable               in this new model be learned without U-shapes? For now, this problem is left open.            </content></document><document><year>2006</year><authors>Maarten Grachten1 | Josep-LluГ­s Arcos1 | Ramon LГіpez de MГЎntaras1</authors><title>A case based approach to expressivity-aware tempo transformation      </title><content>The research presented in this paper focuses on global tempo transformations of monophonic audio recordings of saxophone jazz         performances. We are investigating the problem of how a performance played at a particular tempo can be rendered automatically         at another tempo, while preserving naturally sounding expressivity. Or, differently stated, how does expressiveness change         with global tempo. Changing the tempo of a given melody is a problem that cannot be reduced to just applying a uniform transformation         to all the notes of a musical piece. The expressive resources for emphasizing the musical structure of the melody and the         affective content differ depending on the performance tempo. We present a case-based reasoning system called TempoExpress for addressing this problem, and describe the experimental results obtained with our approach.      </content></document><document><year>2006</year><authors>Shai Ben-David1 </authors><title>A framework for statistical clustering with constant time approximation algorithms for K-median and K-means clustering      </title><content>We consider a framework of sample-based clustering. In this setting, the input to a clustering algorithm is a sample generated i.i.d by some unknown arbitrary distribution.         Based on such a sample, the algorithm has to output a clustering of the full domain set, that is evaluated with respect to         the underlying distribution. We provide general conditions on clustering problems that imply the existence of sampling based         clustering algorithms that approximate the optimal clustering. We show that the K-median clustering, as well as K-means and the Vector Quantization problems, satisfy these conditions. Our results apply to the combinatorial optimization         setting where, assuming that sampling uniformly over an input set can be done in constant time, we get a sampling-based algorithm         for the K-median and K-means clustering problems that finds an almost optimal set of centers in time depending only on the confidence and accuracy         parameters of the approximation, but independent of the input size. Furthermore, in the Euclidean input case, the dependence         of the running time of our algorithm on the Euclidean dimension is only linear. Our main technical tool is a uniform convergence         result for center based clustering that can be viewed as showing that the effective VC-dimension of k-center clustering equals k.      </content></document><document><year>2006</year><authors>Rob Powers1 | Yoav Shoham1  | Thuc Vu1 </authors><title>A general criterion and an algorithmic framework for learning in multi-agent systems      </title><content>We offer a new formal criterion for agent-centric learning in multi-agent systems, that is, learning that maximizes one&amp;#8217;s         rewards in the presence of other agents who might also be learning (using the same or other learning algorithms). This new         criterion takes in as a parameter the class of opponents. We then provide a modular approach for achieving effective agent-centric         learning; the approach consists of a number of basic algorithmic building blocks, which can be instantiated and composed differently         depending on the environment setting (for example, 2- versus n-player games) as well as the target class of opponents. We then provide several specific instances of the approach: an algorithm         for stationary opponents, and two algorithms for adaptive opponents with bounded memory, one algorithm for the n-player case and another optimized for the 2-player case. We prove our algorithms correct with respect to the formal criterion,         and furthermore show the algorithms to be experimentally effective via comprehensive computer testing.      </content></document><document><year>2006</year><authors>Peter Auer1  | Ronald Ortner1 </authors><title>A new PAC bound for intersection-closed concept classes      </title><content>For hyper-rectangles in                    Auer (1997) proved a PAC bound of                   , where                    and                    are the accuracy and confidence parameters. It is still an open question whether one can obtain the same bound for intersection-closed         concept classes of VC-dimension                    in general. We present a step towards a solution of this problem showing on one hand a new PAC bound of                    for arbitrary intersection-closed concept classes, complementing the well-known bounds                    and                    of Blumer et al. and (1989) and Haussler, Littlestone and Warmuth (1994). Our bound is established using the closure algorithm, that generates as its hypothesis the intersection of all concepts that are consistent with the positive training examples.         On the other hand, we show that many intersection-closed concept classes including e.g.  maximum intersection-closed classes         satisfy an additional combinatorial property that allows a proof of the optimal bound of                   . For such improved bounds the choice of the learning algorithm is crucial, as there are consistent learning algorithms that         need                    examples to learn some particular maximum intersection-closed concept classes.      </content></document><document><year>2006</year><authors>Rajesh Pampapathi1 | Boris Mirkin1  | Mark Levene1 </authors><title>A suffix tree approach to anti-spam email filtering      </title><content>We present an approach to email filtering based on the suffix tree data structure. A method for the scoring of emails using         the suffix tree is developed and a number of scoring and score normalisation functions are tested. Our results show that the         character level representation of emails and classes facilitated by the suffix tree can significantly improve classification         accuracy when compared with the currently popular methods, such as naive Bayes. We believe the method can be extended to the         classification of documents in other domains.      </content></document><document><year>2006</year><authors>Tao Li1 </authors><title>A Unified View on Clustering Binary Data      </title><content>Clustering is the problem of identifying the distribution of patterns and intrinsic correlations in large data sets by partitioning         the data points into similarity classes. This paper studies the problem of clustering binary data. Binary data have been occupying         a special place in the domain of data analysis. A unified view of binary data clustering is presented by examining the connections         among various clustering criteria. Experimental studies are conducted to empirically verify the relationships.      </content></document><document><year>2006</year><authors>Pieter Spronck1 | Marc Ponsen1 | Ida Sprinkhuizen-Kuyper1  | Eric Postma1 </authors><title>Adaptive game AI with dynamic scripting      </title><content>Online learning in commercial computer games allows computer-controlled opponents to adapt to the way the game is being played.         As such it provides a mechanism to deal with weaknesses in the game AI, and to respond to changes in human player tactics.         We argue that online learning of game AI should meet four computational and four functional requirements. The computational         requirements are speed, effectiveness, robustness and efficiency. The functional requirements are clarity, variety, consistency         and scalability. This paper investigates a novel online learning technique for game AI called &amp;#8216;dynamic scripting&amp;#8217;, that uses         an adaptive rulebase for the generation of game AI on the fly. The performance of dynamic scripting is evaluated in experiments         in which adaptive agents are pitted against a collection of manually-designed tactics in a simulated computer roleplaying         game. Experimental results indicate that dynamic scripting succeeds in endowing computer-controlled opponents with adaptive         performance. To further improve the dynamic-scripting technique, an enhancement is investigated that allows scaling of the         difficulty level of the game AI to the human player&amp;#8217;s skill level. With the enhancement, dynamic scripting meets all computational         and functional requirements. The applicability of dynamic scripting in state-of-the-art commercial games is demonstrated by         implementing the technique in the game Neverwinter Nights. We conclude that dynamic scripting can be successfully applied to the online adaptation of game AI in commercial computer         games.      </content></document><document><year>2006</year><authors>Abraham P. George1  | Warren B. Powell1 </authors><title>Adaptive stepsizes for recursive estimation with applications in approximate dynamic programming      </title><content>We address the problem of determining optimal stepsizes for estimating parameters in the context of approximate dynamic programming.         The sufficient conditions for convergence of the stepsize rules have been known for 50 years, but practical computational         work tends to use formulas with parameters that have to be tuned for specific applications. The problem is that in most applications         in dynamic programming, observations for estimating a value function typically come from a data series that can be initially         highly transient. The degree of transience affects the choice of stepsize parameters that produce the fastest convergence.         In addition, the degree of initial transience can vary widely among the value function parameters for the same dynamic program.         This paper reviews the literature on deterministic and stochastic stepsize rules, and derives formulas for optimal stepsizes         for minimizing estimation error. This formula assumes certain parameters are known, and an approximation is proposed for the         case where the parameters are unknown. Experimental work shows that the approximation provides faster convergence than other         popular formulas.      </content></document><document><year>2006</year><authors>K. Pelckmans1 | J. A. K. Suykens1  | B. De Moor1</authors><title>Additive Regularization Trade-Off: Fusion of Training and Validation Levels in Kernel Methods      </title><content>This paper presents a convex optimization perspective towards the task of tuning the regularization trade-off with validation         and cross-validation criteria in the context of kernel machines. We focus on the problem of tuning the regularization trade-off         in the context of Least Squares Support Vector Machines (LS-SVMs) for function approximation and classification. By adopting         an additive regularization trade-off scheme, the task of tuning the regularization trade-off with respect to a validation         and cross-validation criterion can be written as a convex optimization problem. The solution of this problem then contains         both the optimal regularization constants with respect to the model selection criterion at hand, and the corresponding training         solution. We refer to such formulations as the fusion of training with model selection. The major tool to accomplish this         task is found in the primal-dual derivations as occuring in convex optimization theory. The paper advances the discussion         by relating the additive regularization trade-off scheme with the classical Tikhonov scheme. Motivations are given for the         usefulness of the former scheme. Furthermore, it is illustrated how to restrict the additive trade-off scheme towards the         solution path corresponding with a Tikhonov scheme while retaining convexity of the overall problem of fusion of model selection         and training. We relate such a scheme with an ensemble learning problem and with stability of learning machines. The approach         is illustrated on a number of artificial and benchmark datasets relating the proposed method with the classical practice of         tuning the Tikhonov scheme with a cross-validation measure.      </content></document><document><year>2006</year><authors>James Bergstra1 | Norman Casagr|e1 | Dumitru Erhan1 | Douglas Eck1  | BalГЎzs KГ©gl1 </authors><title>Aggregate features and ADABOOST for music classification      </title><content>We present an algorithm that predicts musical genre and artist from an audio waveform. Our method uses the ensemble learner         ADABOOST to select from a set of audio features that have been extracted from segmented audio and then aggregated. Our classifier         proved to be the most effective method for genre classification at the recent MIREX 2005 international contests in music information         extraction, and the second-best method for recognizing artists. This paper describes our method in detail, from feature extraction         to song classification, and presents an evaluation of our method on three genre databases and two artist-recognition databases.         Furthermore, we present evidence collected from a variety of popular features and classifiers that the technique of classifying         features aggregated over segments of audio is better than classifying either entire songs or individual short-timescale features.      </content></document><document><year>2006</year><authors>Christopher Raphael1 </authors><title>Aligning music audio with symbolic scores using a hybrid graphical model      </title><content>We present a new method for establishing an alignment between a polyphonic musical score and a corresponding sampled audio         performance. The method uses a graphical model containing both latent discrete variables, corresponding to score position,         as well as a latent continuous tempo process. We use a simple data model based only on the pitch content of the audio signal.         The data interpretation is defined to be the most likely configuration of the hidden variables, given the data, and we develop         computational methodology to identify or approximate this configuration using a variant of dynamic programming involving parametrically         represented continuous variables. Experiments are presented on a 55-minute hand-marked orchestral test set.      </content></document><document><year>2006</year><authors>Rosa I. Arriaga1  | Santosh Vempala2 </authors><title>An algorithmic theory of learning: Robust concepts and random projection      </title><content>We study the phenomenon of cognitive learning from an algorithmic standpoint. How does the brain effectively learn concepts         from a small number of examples despite the fact that each example contains a huge amount of information? We provide a novel         algorithmic analysis via a model of robust concept learning (closely related to &amp;#8220;margin classifiers&amp;#8221;), and show that a relatively small number of examples are sufficient         to learn rich concept classes. The new algorithms have several advantages&amp;#8212;they are faster, conceptually simpler, and resistant         to low levels of noise. For example, a robust half-space can be learned in linear time using only a constant number of training         examples, regardless of the number of attributes. A general (algorithmic) consequence of the model, that &amp;#8220;more robust concepts         are easier to learn&amp;#8221;, is supported by a multitude of psychological studies.      </content></document><document><year>2006</year><authors>E. K. Tang1 | P. N. Suganthan1  | X. Yao2 </authors><title>An analysis of diversity measures      </title><content>Diversity among the base classifiers is deemed to be important when constructing a classifier ensemble. Numerous algorithms         have been proposed to construct a good classifier ensemble by seeking both the accuracy of the base classifiers and the diversity         among them. However, there is no generally accepted definition of diversity, and measuring the diversity explicitly is very         difficult. Although researchers have designed several experimental studies to compare different diversity measures, usually         confusing results were observed. In this paper, we present a theoretical analysis on six existing diversity measures (namely         disagreement measure, double fault measure, KW variance, inter-rater agreement, generalized diversity and measure of difficulty),         show underlying relationships between them, and relate them to the concept of margin, which is more explicitly related to         the success of ensemble learning algorithms. We illustrate why confusing experimental results were observed and show that         the discussed diversity measures are naturally ineffective. Our analysis provides a deeper understanding of the concept of         diversity, and hence can help design better ensemble learning algorithms.      </content></document><document><year>2006</year><authors>Dougu Nam1 | Seunghyun Seo2  | Sangsoo Kim1| 3 </authors><title>An efficient top-down search algorithm for learning Boolean networks of gene expression      </title><content>Boolean networks provide a simple and intuitive model for gene regulatory networks, but a critical defect is the time required         to learn the networks. In recent years, efficient network search algorithms have been developed for a noise-free case and         for a limited function class. In general, the conventional algorithm has the high time complexity of O(22k                                 mn            k+1) where m is the number of measurements, n is the number of nodes (genes), and k is the number of input parents. Here, we suggest a simple and new approach to Boolean networks, and provide a randomized         network search algorithm with average time complexity O         (mn            k+1/ (log m)(k&amp;#8722;1)). We show the efficiency of our algorithm via computational experiments, and present optimal parameters. Additionally, we         provide tests for yeast expression data.      </content></document><document><year>2006</year><authors>Alireza Tamaddoni-Nezhad1 | Raphael Chaleil2 | Antonis Kakas3  | Stephen Muggleton1 </authors><title>Application of abductive ILP to learning metabolic network inhibition from temporal data      </title><content>In this paper we use a logic-based representation and a combination of Abduction and Induction to model inhibition in metabolic         networks. In general, the integration of abduction and induction is required when the following two conditions hold. Firstly,         the given background knowledge is incomplete. Secondly, the problem must require the learning of general rules in the circumstance         in which the hypothesis language is disjoint from the observation language. Both these conditions hold in the application         considered in this paper. Inhibition is very important from the therapeutic point of view since many substances designed to         be used as drugs can have an inhibitory effect on other enzymes. Any system able to predict the inhibitory effect of substances         on the metabolic network would therefore be very useful in assessing the potential harmful side-effects of drugs. In modelling         the phenomenon of inhibition in metabolic networks, background knowledge is used which describes the network topology and         functional classes of inhibitors and enzymes. This background knowledge, which represents the present state of understanding,         is incomplete. In order to overcome this incompleteness hypotheses are considered which consist of a mixture of specific inhibitions         of enzymes (ground facts) together with general (non-ground) rules which predict classes of enzymes likely to be inhibited         by the toxin. The foreground examples are derived from in vivo experiments involving NMR analysis of time-varying metabolite         concentrations in rat urine following injections of toxins. The model&amp;#8217;s performance is evaluated on training and test sets         randomly generated from a real metabolic network. It is shown that even in the case where the hypotheses are restricted to         be ground, the predictive accuracy increases with the number of training examples and in all cases exceeds the default (majority         class). Experimental results also suggest that when sufficient training data is provided, non-ground hypotheses show a better         predictive accuracy than ground hypotheses. The model is also evaluated in terms of the biological insight that it provides.      </content></document><document><year>2006</year><authors>Vladislav B. Tadi&amp;#263 1 </authors><title>Asymptotic analysis of temporal-difference learning algorithms with constant step-sizes      </title><content>The mean-square asymptotic behavior of temporal-difference learning algorithms with constant step-sizes and linear function         approximation is analyzed in this paper. The analysis is carried out for the case of discounted cost function associated with         a Markov chain with a finite dimensional state-space. Under mild conditions, an upper bound for the asymptotic mean-square         error of these algorithms is determined as a function of the step-size. Moreover, under the same assumptions, it is also shown         that this bound is linear in the step size. The main results of the paper are illustrated with examples related to M/G/1 queues and nonlinear AR models with Markov switching.      </content></document><document><year>2006</year><authors>Vincent Conitzer1  | Tuomas S|holm1 </authors><title>AWESOME: A general multiagent learning algorithm that converges in self-play and learns a best response against stationary         opponents      </title><content>Two minimal requirements for a satisfactory multiagent learning algorithm are that it 1. learns to play optimally against stationary         opponents and 2. converges to a Nash equilibrium in self-play. The previous algorithm that has come closest, WoLF-IGA, has         been proven to have these two properties in 2-player 2-action (repeated) games&amp;#8212;assuming that the opponent&amp;#8217;s mixed strategy         is observable. Another algorithm, ReDVaLeR (which was introduced after the algorithm described in this paper), achieves the         two properties in games with arbitrary numbers of actions and players, but still requires that the opponents' mixed strategies         are observable. In this paper we present AWESOME, the first algorithm that is guaranteed to have the two properties in games         with arbitrary numbers of actions and players. It is still the only algorithm that does so while only relying on observing         the other players' actual actions (not their mixed strategies). It also learns to play optimally against opponents that eventually become stationary. The basic idea behind AWESOME (Adapt When Everybody is Stationary, Otherwise Move to Equilibrium) is to try to adapt to the others' strategies when they appear stationary, but otherwise to retreat to a precomputed equilibrium         strategy. We provide experimental results that suggest that AWESOME converges fast in practice. The techniques used to prove         the properties of AWESOME are fundamentally different from those used for previous algorithms, and may help in analyzing future         multiagent learning algorithms as well.      </content></document><document><year>2006</year><authors>Albert Xin Jiang1  | Kevin Leyton-Brown1 </authors><title>Bidding agents for online auctions with hidden bids      </title><content>There is much active research into the design of automated bidding agents, particularly for environments that involve multiple         decoupled auctions. These settings are complex partly because an agent&amp;#8217;s strategy depends on information about other bidders&amp;#8217;interests.         When bidders&amp;#8217; valuation distributions are not known ex ante, machine learning techniques can be used to approximate them from historical data. It is a characteristic feature of auctions,         however, that information about some bidders&amp;#8217;valuations is systematically concealed. This occurs in the sense that some bidders         may fail to bid at all because the asking price exceeds their valuations, and also in the sense that a high bidder may not         be compelled to reveal her valuation. Ignoring these &amp;#8220;hidden bids&amp;#8221; can introduce bias into the estimation of valuation distributions.         To overcome this problem, we propose an EM-based algorithm. We validate the algorithm experimentally using agents that react         to their environments both decision-theoretically and game-theoretically, using both synthetic and real-world (eBay) datasets.         We show that our approach estimates bidders&amp;#8217; valuation distributions and the distribution over the true number of bidders         significantly more accurately than more straightforward density estimation techniques.      </content></document><document><year>2006</year><authors>Ning Hu1  | Roger B. Dannenberg2 </authors><title>Bootstrap learning for accurate onset detection      </title><content>Supervised learning models have been applied to create good onset detection systems for musical audio signals. However, this         always requires a large set of labeled training examples, and hand-labeling is quite tedious and time consuming. In this paper,         we present a bootstrap learning approach to train an accurate note onset detection model. Audio alignment techniques are first         used to find the correspondence between a symbolic music representation (such as MIDI data) and an acoustic recording. This         alignment provides an initial estimate of note boundaries which can be used to train an onset detector. Once trained, the         detector can be used to refine the initial set of note boundaries and training can be repeated. This iterative training process         eliminates the need for hand-labeled audio. Tests show that this training method can improve an onset detector initially trained         on synthetic data.      </content></document><document><year>2006</year><authors>Helge Langseth1| 2  | Thomas D. Nielsen3 </authors><title>Classification using Hierarchical NaГЇve Bayes models      </title><content>Classification problems have a long history in the machine learning literature. One of the simplest, and yet most consistently         well-performing set of classifiers is the NaГЇve Bayes models. However, an inherent problem with these classifiers is the assumption         that all attributes used to describe an instance are conditionally independent given the class of that instance. When this         assumption is violated (which is often the case in practice) it can reduce classification accuracy due to &amp;#8220;information double-counting&amp;#8221;         and interaction omission.                     In this paper we focus on a relatively new set of models, termed Hierarchical NaГЇve Bayes models. Hierarchical NaГЇve Bayes               models extend the modeling flexibility of NaГЇve Bayes models by introducing latent variables to relax some of the independence               statements in these models. We propose a simple algorithm for learning Hierarchical NaГЇve Bayes models in the context of classification.               Experimental results show that the learned models can significantly improve classification accuracy as compared to other frameworks.            </content></document><document><year>2006</year><authors>Daniel P. W. Ellis1  | Graham E. Poliner1 </authors><title>Classification-based melody transcription      </title><content>The melody of a musical piece&amp;#8212;informally, the part you would hum along with&amp;#8212;is a useful and compact summary of a full audio         recording. The extraction of melodic content has practical applications ranging from content-based audio retrieval to the         analysis of musical structure. Whereas previous systems generate transcriptions based on a model of the harmonic (or periodic)         structure of musical pitches, we present a classification-based system for performing automatic melody transcription that         makes no assumptions beyond what is learned from its training data. We evaluate the success of our algorithm by predicting         the melody of the ADC 2004 Melody Competition evaluation set, and we show that a simple frame-level note classifier, temporally         smoothed by post processing with a hidden Markov model, produces results comparable to state of the art model-based transcription         systems.      </content></document><document><year>2006</year><authors>Michael Rimer1  | Tony Martinez1 </authors><title>Classification-based objective functions      </title><content>Backpropagation, similar to most learning algorithms that can form complex decision surfaces, is prone to overfitting. This         work presents classification-based objective functions, an approach to training artificial neural networks on classification         problems. Classification-based learning attempts to guide the network directly to correct pattern classification rather than         using common error minimization heuristics, such as sum-squared error (SSE) and cross-entropy (CE), that do not explicitly         minimize classification error. CB1 is presented here as a novel objective function for learning classification problems. It         seeks to directly minimize classification error by backpropagating error only on misclassified patterns from culprit output         nodes. CB1 discourages weight saturation and overfitting and achieves higher accuracy on classification problems than optimizing         SSE or CE. Experiments on a large OCR data set have shown CB1 to significantly increase generalization accuracy over SSE or         CE optimization, from 97.86% and 98.10%, respectively, to 99.11%. Comparable results are achieved over several data sets from         the UC Irvine Machine Learning Database Repository, with an average increase in accuracy from 90.7% and 91.3% using optimized         SSE and CE networks, respectively, to 92.1% for CB1. Analysis indicates that CB1 performs a fundamentally different search         of the feature space than optimizing SSE or CE and produces significantly different solutions.      </content></document><document><year>2006</year><authors>Marta Arias1  | Roni Khardon2 </authors><title>Complexity parameters for first order classes      </title><content>We study several complexity parameters for first order formulas and their suitability for first order learning models. We         show that the standard notion of size is not captured by sets of parameters that are used in the literature and thus they         cannot give a complete characterization in terms of learnability with polynomial resources. We then identify an alternative         notion of size and a simple set of parameters that are useful for first order Horn Expressions. These parameters are the number         of clauses in the expression, the maximum number of distinct terms in a clause, and the maximum number of literals in a clause.         Matching lower bounds derived using the Vapnik Chervonenkis dimension complete the picture showing that these parameters are         indeed crucial.      </content></document><document><year>2006</year><authors>Chris Drummond1  | Robert C. Holte2 </authors><title>Cost curves: An improved method for visualizing classifier performance      </title><content>This paper introduces cost curves, a graphical technique for visualizing the performance (error rate or expected cost) of         2-class classifiers over the full range of possible class distributions and misclassification costs. Cost curves are shown         to be superior to ROC curves for visualizing classifier performance for most purposes. This is because they visually support         several crucial types of performance assessment that cannot be done easily with ROC curves, such as showing confidence intervals         on a classifier's performance, and visualizing the statistical significance of the difference in performance of two classifiers.         A software tool supporting all the cost curve analysis described in this paper is available from the authors.      </content></document><document><year>2006</year><authors>Mingyang Xu1| 2  | Michael W. Golay1| 2 </authors><title>Data-guided model combination by decomposition and aggregation      </title><content>Model selection and model combination is a general problem in many areas. Especially, when we have several different candidate         models and also have gathered a new data set, we want to construct a more accurate and precise model in order to help predict         future events. In this paper, we propose a new data-guided model combination method by decomposition and aggregation. With         the aid of influence diagrams, we analyze the dependence among candidate models and apply latent factors to characterize such         dependence. After analyzing model structures in this framework, we derive an optimal composite model. Two widely used data         analysis tools, namely, Principal Component Analysis (PCA) and Independent Component Analysis (ICA) are applied for the purpose         of factor extraction from the class of candidate models. Once factors are ready, they are sorted and aggregated in order to         produce composite models. During the course of factor aggregation, another important issue, namely factor selection, is also         touched on. Finally, a numerical study shows how this method works and an application using physical data is also presented.      </content></document><document><year>2006</year><authors>Jussi KlemelГ¤1 </authors><title>Density estimation with stagewise optimization of the empirical risk      </title><content>We consider multivariate density estimation with identically distributed observations. We study a density estimator which         is a convex combination of functions in a dictionary and the convex combination is chosen by minimizing the L         2 empirical risk in a stagewise manner. We derive the convergence rates of the estimator when the estimated density belongs         to the L         2 closure of the convex hull of a class of functions which satisfies entropy conditions. The L         2 closure of a convex hull is a large non-parametric class but under suitable entropy conditions the convergence rates of the         estimator do not depend on the dimension, and density estimation is feasible also in high dimensional cases. The variance         of the estimator does not increase when the number of components of the estimator increases. Instead, we control the bias-variance         trade-off by the choice of the dictionary from which the components are chosen.      </content></document><document><year>2006</year><authors>Claudia Perlich1  | Foster Provost2 </authors><title>Distribution-based aggregation for relational learning with identifier attributes      </title><content>Identifier attributes&amp;#8212;very high-dimensional categorical attributes such as particular product ids or people's names&amp;#8212;rarely         are incorporated in statistical modeling. However, they can play an important role in relational modeling: it may be informative         to have communicated with a particular set of people or to have purchased a particular set of products. A key limitation of         existing relational modeling techniques is how they aggregate bags (multisets) of values from related entities. The aggregations         used by existing methods are simple summaries of the distributions of features of related entities: e.g., MEAN, MODE, SUM,         or COUNT. This paper's main contribution is the introduction of aggregation operators that capture more information about         the value distributions, by storing meta-data about value distributions and referencing this meta-data when aggregating&amp;#8212;for         example by computing class-conditional distributional distances. Such aggregations are particularly important for aggregating         values from high-dimensional categorical attributes, for which the simple aggregates provide little information. In the first         half of the paper we provide general guidelines for designing aggregation operators, introduce the new aggregators in the         context of the relational learning system ACORA (Automated Construction of Relational Attributes), and provide theoretical         justification. We also conjecture special properties of identifier attributes, e.g., they proxy for unobserved attributes         and for information deeper in the relationship network. In the second half of the paper we provide extensive empirical evidence         that the distribution-based aggregators indeed do facilitate modeling with high-dimensional categorical attributes, and in         support of the aforementioned conjectures.      </content></document><document><year>2006</year><authors>Springer</authors><title>Erratum      </title><content>Without Abstract</content></document><document><year>2006</year><authors>Pierre Geurts1 | Damien Ernst1  | Louis Wehenkel1 </authors><title>Extremely randomized trees      </title><content>This paper proposes a new tree-based ensemble method for supervised classification and regression problems. It essentially         consists of randomizing strongly both attribute and cut-point choice while splitting a tree node. In the extreme case, it         builds totally randomized trees whose structures are independent of the output values of the learning sample. The strength         of the randomization can be tuned to problem specifics by the appropriate choice of a parameter. We evaluate the robustness         of the default choice of this parameter, and we also provide insight on how to adjust it in particular situations. Besides         accuracy, the main strength of the resulting algorithm is computational efficiency. A bias/variance analysis of the Extra-Trees         algorithm is also provided as well as a geometrical and a kernel characterization of the models induced.      </content></document><document><year>2006</year><authors>Anneleen Van Assche1 | Celine Vens1 | Hendrik Blockeel1  | Sa&amp;#353 o D&amp;#382 eroski2 </authors><title>First order random forests: Learning relational classifiers with complex aggregates      </title><content>In relational learning, predictions for an individual are based not only on its own properties but also on the properties         of a set of related individuals. Relational classifiers differ with respect to how they handle these sets: some use properties         of the set as a whole (using aggregation), some refer to properties of specific individuals of the set, however, most classifiers         do not combine both. This imposes an undesirable bias on these learners. This article describes a learning approach that avoids         this bias, using first order random forests. Essentially, an ensemble of decision trees is constructed in which tests are         first order logic queries. These queries may contain aggregate functions, the argument of which may again be a first order         logic query. The introduction of aggregate functions in first order logic, as well as upgrading the forest&amp;#8217;s uniform feature         sampling procedure to the space of first order logic, generates a number of complications. We address these and propose a         solution for them. The resulting first order random forest induction algorithm has been implemented and integrated in the         ACE-ilProlog system, and experimentally evaluated on a variety of datasets. The results indicate that first order random forests         with complex aggregates are an efficient and effective approach towards learning relational classifiers that involve aggregates         over complex selections.      </content></document><document><year>2006</year><authors>TamГЎs HorvГЎth1  | Akihiro Yamamoto2 </authors><title>Foreword      </title><content>Without Abstract</content></document><document><year>2006</year><authors>Mark Goadrich1 | Louis Oliphant1 | Jude Shavlik1</authors><title>Gleaner: Creating ensembles of first-order clauses to improve recall-precision curves      </title><content>Many domains in the field of Inductive Logic Programming (ILP) involve highly unbalanced data. A common way to measure performance         in these domains is to use precision and recall instead of simply using accuracy. The goal of our research is to find new approaches within ILP particularly suited for large,         highly-skewed domains. We propose Gleaner, a randomized search method that collects good clauses from a broad spectrum of         points along the recall dimension in recall-precision curves and employs an &amp;#8220;at least L of these K clauses&amp;#8221; thresholding method to combine sets of selected clauses. Our research focuses on Multi-Slot Information Extraction         (IE), a task that typically involves many more negative examples than positive examples. We formulate this problem into a         relational domain, using two large testbeds involving the extraction of important relations from the abstracts of biomedical         journal articles. We compare Gleaner to ensembles of standard theories learned by Aleph, finding that Gleaner produces comparable         testset results in a fraction of the training time.      </content></document><document><year>2006</year><authors>Kurt Driessens1 | Jan Ramon2  | Thomas GГ¤rtner3 </authors><title>Graph kernels and Gaussian processes for relational reinforcement learning      </title><content>RRL is a relational reinforcement learning system based on Q-learning in relational state-action spaces. It aims to enable         agents to learn how to act in an environment that has no natural representation as a tuple of constants. For relational reinforcement         learning, the learning algorithm used to approximate the mapping between state-action pairs and their so called Q(uality)-value         has to be very reliable, and it has to be able to handle the relational representation of state-action pairs. In this paper         we investigate the use of Gaussian processes to approximate the Q-values of state-action pairs. In order to employ Gaussian         processes in a relational setting we propose graph kernels as a covariance function between state-action pairs. The standard         prediction mechanism for Gaussian processes requires a matrix inversion which can become unstable when the kernel matrix has         low rank. These instabilities can be avoided by employing QR-factorization. This leads to better and more stable performance         of the algorithm and a more efficient incremental update mechanism. Experiments conducted in the blocks world and with the         Tetris game show that Gaussian processes with graph kernels can compete with, and often improve on, regression trees and instance         based regression as a generalization algorithm for RRL.      </content></document><document><year>2006</year><authors>Rui Camacho1 | Ross King2  | Ashwin Srinivasan3 </authors><title>Guest editorial      </title><content>Without Abstract</content></document><document><year>2006</year><authors>G. Widmer1| 2 </authors><title>Guest Editorial: Machine learning in and for music      </title><content>Without Abstract</content></document><document><year>2006</year><authors>Gerhard Widmer1| 2 </authors><title>Guest editorial: Machine learning in and for music      </title><content>Without Abstract</content></document><document><year>2006</year><authors>Georgios Paliouras1  | Yasubumi Sakakibara2 </authors><title>Guest editorial to the special issue on grammatical inference      </title><content>Without Abstract</content></document><document><year>2006</year><authors>NicolГІ Cesa-Bianchi1 | Yishay Mansour2  | Gilles Stoltz3 </authors><title>Improved second-order bounds for prediction with expert advice      </title><content>This work studies external regret in sequential prediction games with both positive and negative payoffs. External regret         measures the difference between the payoff obtained by the forecasting strategy and the payoff of the best action. In this         setting, we derive new and sharper regret bounds for the well-known exponentially weighted average forecaster and for a second         forecaster with a different multiplicative update rule. Our analysis has two main advantages: first, no preliminary knowledge         about the payoff sequence is needed, not even its range; second, our bounds are expressed in terms of sums of squared payoffs,         replacing larger first-order quantities appearing in previous bounds. In addition, our most refined bounds have the natural         and desirable property of being stable under rescalings and general translations of the payoff sequence.      </content></document><document><year>2006</year><authors>Julien Carme1| RГ©mi Gilleron1| AurГ©lien Lemay1  | Joachim Niehren1</authors><title>Interactive learning of node selecting tree transducer      </title><content>We develop new algorithms for learning monadic node selection queries in unranked trees from annotated examples, and apply         them to visually interactive Web information extraction.                     We propose to represent monadic queries by bottom-up deterministic Node Selecting Tree Transducers (NSTTs), a particular class               of tree automata that we introduce. We prove that deterministic NSTTs capture the class of queries definable in monadic second               order logic (MSO) in trees, which Gottlob and Koch (2002) argue to have the right expressiveness for Web information extraction,               and prove that monadic queries defined by NSTTs can be answered efficiently. We present a new polynomial time algorithm in               RPNI-style that learns monadic queries defined by deterministic NSTTs from completely annotated examples, where all selected nodes               are distinguished.            </content></document><document><year>2006</year><authors>Hendrik Blockeel| David Jensen | Stefan Kramer</authors><title>Introduction to the special issue on multi-relational data mining and statistical relational learning      </title><content>Without Abstract</content></document><document><year>2006</year><authors>Maria-Florina Balcan1 | Avrim Blum1  | Santosh Vempala2 </authors><title>Kernels as features: On kernels, margins, and low-dimensional mappings      </title><content>Kernel functions are typically viewed as providing an implicit mapping of points into a high-dimensional space, with the ability         to gain much of the power of that space without incurring a high cost if the result is linearly-separable by a large margin         &amp;#947;. However, the Johnson-Lindenstrauss lemma suggests that in the presence of a large margin, a kernel function can also be         viewed as a mapping to a low-dimensional space, one of dimension only                   . In this paper, we explore the question of whether one can efficiently produce such low-dimensional mappings, using only         black-box access to a kernel function. That is, given just a program that computes K(x,y) on inputs x,y of our choosing, can we efficiently construct an explicit (small) set of features that effectively capture the power of the         implicit high-dimensional space? We answer this question in the affirmative if our method is also allowed black-box access         to the underlying data distribution (i.e., unlabeled examples). We also give a lower bound, showing that if we do not have         access to the distribution, then this is not possible for an arbitrary black-box kernel function; we leave as an open problem, however, whether this can be done for standard kernel functions such         as the polynomial kernel. Our positive result can be viewed as saying that designing a good kernel function is much like designing         a good feature space. Given a kernel, by running it in a black-box manner on random unlabeled examples, we can efficiently generate an explicit set of                    features, such that if the data was linearly separable with margin &amp;#947; under the kernel, then it is approximately separable         in this new feature space.      </content></document><document><year>2006</year><authors>RГ©mi Eyraud1 | Colin de la Higuera1  | Jean-Christophe Janodet1 </authors><title>LARS: A learning algorithm for rewriting systems      </title><content>Whereas there is a number of methods and algorithms to learn regular languages, moving up the Chomsky hierarchy is proving         to be a challenging task. Indeed, several theoretical barriers make the class of context-free languages hard to learn. To         tackle these barriers, we choose to change the way we represent these languages. Among the formalisms that allow the definition         of classes of languages, the one of string-rewriting systems (SRS) has outstanding properties. We introduce a new type of         SRS&amp;#8217;s, called Delimited SRS (DSRS), that are expressive enough to define, in a uniform way, a noteworthy and non trivial class         of languages that contains all the regular languages,                   ,                   , the parenthesis languages of Dyck, the language of Lukasiewicz, and many others. Moreover, DSRS&amp;#8217;s constitute an efficient         (often linear) parsing device for strings, and are thus promising candidates in forthcoming applications of grammatical inference.         In this paper, we pioneer the problem of their learnability. We propose a novel and sound algorithm (called LARS) which identifies a large subclass of them in polynomial time (but not data). We illustrate the execution of our algorithm         through several examples, discuss the position of the class in the Chomsky hierarchy and finally raise some open questions         and research directions.      </content></document><document><year>2006</year><authors>Y. Xiang1  | J. Lee1</authors><title>Learning decomposable markov networks in pseudo-independent domains with local evaluation      </title><content>We consider learning probabilistic graphical models in a problem domain of unknown dependence structure. Common learning algorithms         rely on single-link lookahead search, which assumes the underlying domain is not pseudo-independent. Since the dependence structure of the domain is unknown, such assumption is fallible. We study learning algorithms that         make no such assumption and return an approximate dependence structure no matter whether the domain is pseudo-independent         or not. The focus of this paper is on learning decomposable Markov networks, which can directly be used for model-based inference         or as the intermediate step for further learning of directed graphical models. We identify a small subset of domain variables,         termed crux, in the graphical models currently being examined during search. We prove that crux is sufficient for computing the incremental         change of both model description length as well as data description length given the model. Based on crux, we propose algorithms         that reduce evaluation of alternative graphical models to local computation, improve efficiency significantly, and introduce         no error to the selection of alternative models.      </content></document><document><year>2006</year><authors>Alex|er Clark1 </authors><title>Learning deterministic context free grammars: The Omphalos competition      </title><content>This paper describes the winning entry to the Omphalos context free grammar learning competition. We describe a context-free         grammatical inference algorithm operating on positive data only, which integrates an information theoretic constituent likelihood         measure together with more traditional heuristics based on substitutability and frequency. The competition is discussed from         the perspective of a competitor. We discuss a class of deterministic grammars, the Non-terminally Separated (NTS) grammars,         that have a property relied on by our algorithm, and consider the possibilities of extending the algorithm to larger classes         of languages.      </content></document><document><year>2006</year><authors>Francisco Casacuberta1  | Enrique Vidal1</authors><title>Learning finite-state models for machine translation      </title><content>In formal language theory, finite-state transducers are well-know models for simple &amp;#8220;input-output&amp;#8221; mappings between two languages.         Even if more powerful, recursive models can be used to account for more complex mappings, it has been argued that the input-output         relations underlying most usual natural language pairs can essentially be modeled by finite-state devices. Moreover, the relative         simplicity of these mappings has recently led to the development of techniques for learning finite-state transducers from         a training set of input-output sentence pairs of the languages considered. In the last years, these techniques have lead to         the development of a number of machine translation systems. Under the statistical statement of machine translation, we overview         here how modeling, learning and search problems can be solved by using stochastic finite-state transducers. We also review         the results achieved by the systems we have developed under this paradigm. As a main conclusion of this review we argue that,         as task complexity and training data scarcity increase, those systems which rely more on statistical techniques tend produce         the best results.      </content></document><document><year>2006</year><authors>Tolga KГ¶nik1  | John E. Laird2 </authors><title>Learning goal hierarchies from structured observations and expert annotations      </title><content>We describe a relational learning by observation framework that automatically creates cognitive agent programs that model expert task performance in complex dynamic domains.         Our framework uses observed behavior and goal annotations of an expert as the primary input, interprets them in the context         of background knowledge, and returns an agent program that behaves similar to the expert. We map the problem of creating an         agent program on to multiple learning problems that can be represented in a &amp;#8220;supervised concept learning&amp;#8217;&amp;#8217; setting. The acquired         procedural knowledge is partitioned into a hierarchy of goals and represented with first order rules. Using an inductive logic         programming (ILP) learning component allows our framework to naturally combine structured behavior observations, parametric         and hierarchical goal annotations, and complex background knowledge. To deal with the large domains we consider, we have developed         an efficient mechanism for storing and retrieving structured behavior data. We have tested our approach using artificially         created examples and behavior observation traces generated by AI agents. We evaluate the learned rules by comparing them to         hand-coded rules.      </content></document><document><year>2006</year><authors>Aleks|er Sadikov1  | Ivan Bratko1 </authors><title>Learning long-term chess strategies from databases      </title><content>We propose an approach to the learning of long-term plans for playing chess endgames. We assume that a computer-generated         database for an endgame is available, such as the king and rook vs. king, or king and queen vs. king and rook endgame. For         each position in the endgame, the database gives the &amp;#8220;value&amp;#8221; of the position in terms of the minimum number of moves needed         by the stronger side to win given that both sides play optimally. We propose a method for automatically dividing the endgame         into stages characterised by different objectives of play. For each stage of such a game plan, a stage-specific evaluation         function is induced, to be used by minimax search when playing the endgame. We aim at learning playing strategies that give         good insight into the principles of playing specific endgames. Games played by these strategies should resemble human expert&amp;#8217;s         play in achieving goals and subgoals reliably, but not necessarily as quickly as possible.      </content></document><document><year>2006</year><authors>Asaf Amit1  | Shaul Markovitch1 </authors><title>Learning to bid in bridge      </title><content>Bridge bidding is considered to be one of the most difficult problems for game-playing programs. It involves four agents rather         than two, including a cooperative agent. In addition, the partial observability of the game makes it impossible to predict         the outcome of each action. In this paper we present a new decision-making algorithm that is capable of overcoming these problems.         The algorithm allows models to be used for both opponent agents and partners, while utilizing a novel model-based Monte Carlo         sampling method to overcome the problem of hidden information. The paper also presents a learning framework that uses the         above decision-making algorithm for co-training of partners. The agents refine their selection strategies during training         and continuously exchange their refined strategies. The refinement is based on inductive learning applied to examples accumulated         for classes of states with conflicting actions. The algorithm was empirically evaluated on a set of bridge deals. The pair         of agents that co-trained significantly improved their bidding performance to a level surpassing that of the current state-of-the-art         bidding algorithm.      </content></document><document><year>2006</year><authors>Michael Bowling | Johannes FГјrnkranz | Thore Graepel  | Ron Musick </authors><title>Machine learning and games      </title><content>Without Abstract</content></document><document><year>2006</year><authors>Matthew Richardson1  | Pedro Domingos1 </authors><title>Markov logic networks      </title><content>We propose a simple approach to combining first-order logic and probabilistic graphical models in a single representation.         A Markov logic network (MLN) is a first-order knowledge base with a weight attached to each formula (or clause). Together         with a set of constants representing objects in the domain, it specifies a ground Markov network containing one feature for         each possible grounding of a first-order formula in the KB, with the corresponding weight. Inference in MLNs is performed         by MCMC over the minimal subset of the ground network required for answering the query. Weights are efficiently learned from         relational databases by iteratively optimizing a pseudo-likelihood measure. Optionally, additional clauses are learned using         inductive logic programming techniques. Experiments with a real-world database and knowledge base in a university domain illustrate         the promise of this approach.      </content></document><document><year>2006</year><authors>Simon Colton1  | Stephen Muggleton1</authors><title>Mathematical applications of inductive logic programming      </title><content>The application of Inductive Logic Programming to scientific datasets has been highly successful. Such applications have led         to breakthroughs in the domain of interest and have driven the development of ILP systems. The application of AI techniques         to mathematical discovery tasks, however, has largely involved computer algebra systems and theorem provers rather than machine         learning systems. We discuss here the application of the HR and Progol machine learning programs to discovery tasks in mathematics.         While Progol is an established ILP system, HR has historically not been described as an ILP system. However, many applications         of HR have required the production of first order hypotheses given data expressed in a Prolog-style manner, and the core functionality         of HR can be expressed in ILP terminology. In Colton (2003), we presented the first partial description of HR as an ILP system,         and we build on this work to provide a full description here. HR performs a novel ILP routine called Automated Theory Formation,         which combines inductive and deductive reasoning to form clausal theories consisting of classification rules and association         rules. HR generates definitions using a set of production rules, interprets the definitions as classification rules, then         uses the success sets of the definitions to induce hypotheses from which it extracts association rules. It uses third party         theorem provers and model generators to check whether the association rules are entailed by a set of user supplied axioms.                     HR has been applied successfully to a number of predictive, descriptive and subgroup discovery tasks in domains of pure mathematics.               We survey various applications of HR which have led to it producing number theory results worthy of journal publication, graph               theory results rivalling those of the highly successful Graffiti program and algebraic results leading to novel classification               theorems. To further promote mathematics as a challenge domain for ILP systems, we present the first application of Progol               to an algebraic domain&amp;#8212;we use Progol to find algebraic properties of quasigroups, semigroups and magmas (groupoids) of varying               sizes which differentiate pairs of non-isomorphic objects. This development is particularly interesting because algebraic               domains have been an important proving ground for both deduction systems and constraint solvers. We believe that AI programs               written for discovery tasks will need to simultaneously employ a variety of reasoning techniques such as induction, abduction,               deduction, calculation and invention. We argue that mathematics is not only a challenging domain for the application of ILP               systems, but that mathematics could be a good domain in which to develop a new generation of systems which integrate various               reasoning techniques.            </content></document><document><year>2006</year><authors>Darrell Conklin1 </authors><title>Melodic analysis with segment classes      </title><content>This paper presents a representation for melodic segment classes and applies it to music data mining. Melody is modeled as         a sequence of segments, each segment being a sequence of notes. These segments are assigned to classes through a knowledge         representation scheme which allows the flexible construction of abstract views of the music surface. The representation is         applied to sequential pattern discovery and to the statistical modeling of musical style.      </content></document><document><year>2006</year><authors>Magalie Fromont1 </authors><title>Model selection by bootstrap penalization for classification      </title><content>We consider the binary classification problem. Given an i.i.d. sample drawn from the distribution of an &amp;#967;Г—{0,1}&amp;#8722;valued random         pair, we propose to estimate the so-called Bayes classifier by minimizing the sum of the empirical classification error and a penalty term based on Efron&amp;#8217;s or i.i.d. weighted bootstrap         samples of the data. We obtain exponential inequalities for such bootstrap type penalties, which allow us to derive non-asymptotic         properties for the corresponding estimators. In particular, we prove that these estimators achieve the global minimax risk         over sets of functions built from Vapnik-Chervonenkis classes. The obtained results generalize Koltchinskii (2001) and Bartlett         et al.&amp;#8217;s (2002) ones for Rademacher penalties that can thus be seen as special examples of bootstrap type penalties. To illustrate         this, we carry out an experimental study in which we compare the different methods for an intervals model selection problem.      </content></document><document><year>2006</year><authors>Zhihua Zhang1 | James T. Kwok1  | Dit-Yan Yeung1 </authors><title>Model-based transductive learning of the kernel matrix      </title><content>This paper addresses the problem of transductive learning of the kernel matrix from a probabilistic perspective. We define         the kernel matrix as a Wishart process prior and construct a hierarchical generative model for kernel matrix learning. Specifically,         we consider the target kernel matrix as a random matrix following the Wishart distribution with a positive definite parameter         matrix and a degree of freedom. This parameter matrix, in turn, has the inverted Wishart distribution (with a positive definite         hyperparameter matrix) as its conjugate prior and the degree of freedom is equal to the dimensionality of the feature space         induced by the target kernel. Resorting to a missing data problem, we devise an expectation-maximization (EM) algorithm to infer the missing data, parameter matrix and feature dimensionality in a maximum a posteriori (MAP) manner. Using different settings for the target kernel and hyperparameter matrices, our model can be applied to different         types of learning problems. In particular, we consider its application in a semi-supervised learning setting and present two         classification methods. Classification experiments are reported on some benchmark data sets with encouraging results. In addition,         we also devise the EM algorithm for kernel matrix completion.      </content></document><document><year>2006</year><authors>Graham Grindlay1  | David Helmbold2</authors><title>Modeling, analyzing, and synthesizing expressive piano performance with graphical models      </title><content>Trained musicians intuitively produce expressive variations that add to their audience&amp;#8217;s enjoyment. However, there is little         quantitative information about the kinds of strategies used in different musical contexts. Since the literal synthesis of         notes from a score is bland and unappealing, there is an opportunity for learning systems that can automatically produce compelling         expressive variations. The ESP (Expressive Synthetic Performance) system generates expressive renditions using hierarchical         hidden Markov models trained on the stylistic variations employed by human performers. Furthermore, the generative models         learned by the ESP system provide insight into a number of musicological issues related to expressive performance.      </content></document><document><year>2006</year><authors>Marc BoullГ©1 </authors><title>MODL: A Bayes optimal discretization method for continuous attributes      </title><content>While real data often comes in mixed format, discrete and continuous, many supervised induction algorithms require discrete         data. Efficient discretization of continuous attributes is an important problem that has effects on speed, accuracy and understandability         of the induction models. In this paper, we propose a new discretization method MODL1, founded on a Bayesian approach. We introduce a space of discretization models and a prior distribution defined on this model         space. This results in the definition of a Bayes optimal evaluation criterion of discretizations. We then propose a new super-linear         optimization algorithm that manages to find near-optimal discretizations. Extensive comparative experiments both on real and         synthetic data demonstrate the high inductive performances obtained by the new discretization method.      </content></document><document><year>2006</year><authors>Naim Zbidi1 | Sami Faiz2  | Mohamed Limam1 </authors><title>On Mining Summaries by Objective Measures of Interestingness      </title><content>Knowledge discovery in databases is used to discover useful and understandable knowledge from large databases. A process of         knowledge discovery consists of two steps, the data mining step and the evaluation step. In this paper, evaluating and ranking         the interestingness of summaries generated from databases, which is a part of the second step, is studied using diversity         measures. Sixteen previously analyzed diversity measures of interestingness are used along with three not previously considered         ones, brought from different well-known areas. The latter three measures are evaluated theoretically according to five principles         that a measure must satisfy to be qualified acceptable for ranking summaries. A theoretical correlation study between the         eight measures that satisfy all five principles is presented based on mathematical proofs. An empirical evaluation is conducted         using three real databases. Then, a classification of the eight measures is deduced. The resulting classification is used         to reduce the number of measures to only two, which are the best over all criteria, and that produce non-similar results.         This helps the user interpret the most important discovered knowledge in his decision making process.      </content></document><document><year>2006</year><authors>Shie Mannor1 | Jeff S. Shamma2  | GГјrdal Arslan3 </authors><title>Online calibrated forecasts: Memory efficiency versus universality for learning in games      </title><content>We provide a simple learning process that enables an agent to forecast a sequence of outcomes. Our forecasting scheme, termed         tracking forecast, is based on tracking the past observations while emphasizing recent outcomes. As opposed to other forecasting         schemes, we sacrifice universality in favor of a significantly reduced memory requirements. We show that if the sequence of         outcomes has certain properties&amp;#8212;it has some internal (hidden) state that does not change too rapidly&amp;#8212;then the tracking forecast         is weakly calibrated so that the forecast appears to be correct most of the time. For binary outcomes, this result holds without         any internal state assumptions. We consider learning in a repeated strategic game where each player attempts to compute some         forecast of the opponent actions and play a best response to it. We show that if one of the players uses a tracking forecast,         while the other player uses a standard learning algorithm (such as exponential regret matching or smooth fictitious play),         then the player using the tracking forecast obtains the best response to the actual play of the other players. We further show that if both players use tracking forecast, then under certain conditions on the game         matrix, convergence to a Nash equilibrium is possible with positive probability for a larger class of games than the class         of games for which smooth fictitious play converges to a Nash equilibrium.      </content></document><document><year>2006</year><authors>Lise Getoor1  | John Grant2 </authors><title>PRL: A probabilistic relational language      </title><content>In this paper, we describe the syntax and semantics for a probabilistic relational language (PRL). PRL is a recasting of recent         work in Probabilistic Relational Models (PRMs) into a logic programming framework. We show how to represent varying degrees         of complexity in the semantics including attribute uncertainty, structural uncertainty and identity uncertainty. Our approach         is similar in spirit to the work in Bayesian Logic Programs (BLPs), and Logical Bayesian Networks (LBNs). However, surprisingly,         there are still some important differences in the resulting formalism; for example, we introduce a general notion of aggregates         based on the PRM approaches. One of our contributions is that we show how to support richer forms of structural uncertainty         in a probabilistic logical language than have been previously described. Our goal in this work is to present a unifying framework         that supports all of the types of relational uncertainty yet is based on logic programming formalisms. We also believe that         it facilitates understanding the relationship between the frame-based approaches and alternate logic programming approaches,         and allows greater transfer of ideas between them.      </content></document><document><year>2006</year><authors>Filip &amp;#381 eleznГЅ1  | Nada Lavra&amp;#269 2 </authors><title>Propositionalization-based relational subgroup discovery with RSD      </title><content>Relational rule learning algorithms are typically designed to construct classification and prediction rules. However, relational         rule learning can be adapted also to subgroup discovery. This paper proposes a propositionalization approach to relational         subgroup discovery, achieved through appropriately adapting rule learning and first-order feature construction. The proposed         approach was successfully applied to standard ILP problems (East-West trains, King-Rook-King chess endgame and mutagenicity         prediction) and two real-life problems (analysis of telephone calls and traffic accident analysis).      </content></document><document><year>2006</year><authors>Ashwin Srinivasan1 | David Page2 | Rui Camacho3  | Ross King4 </authors><title>Quantitative pharmacophore models with inductive logic programming      </title><content> and (b) Models that predict the actual         medicinal activity of a ligand. Quantitative predictions are obtained by the utilising the following statistical procedures         as background knowledge: logistic regression and naive Bayes, for probability prediction; linear and kernel regression, for         activity prediction. The multi-conformation issue and, more generally, the relational representation used by ILP results in         some special difficulties in the use of any statistical procedure. We present the principal issues and some solutions. Specifically,         using data on the inhibition of the protease Thermolysin, we demonstrate that it is possible for an ILP program to construct         good quantitative structure-activity models. We also comment on the relationship of this work to other recent developments         in statistical relational learning.      </content></document><document><year>2006</year><authors>Filip &amp;#381 eleznГЅ1 | Ashwin Srinivasan2  | C. David Page Jr.3 </authors><title>Randomised restarted search in ILP      </title><content>Recent statistical performance studies of search algorithms in difficult combinatorial problems have demonstrated the benefits         of randomising and restarting the search procedure. Specifically, it has been found that if the search cost distribution of         the non-restarted randomised search exhibits a slower-than-exponential decay (that is, a &amp;#8220;heavy tail&amp;#8221;), restarts can reduce         the search cost expectation. We report on an empirical study of randomised restarted search in ILP. Our experiments conducted         on a high-performance distributed computing platform provide an extensive statistical performance sample of five search algorithms         operating on two principally different classes of ILP problems, one represented by an artificially generated graph problem         and the other by three traditional classification benchmarks (mutagenicity, carcinogenicity, finite element mesh design).         The sample allows us to (1) estimate the conditional expected value of the search cost (measured by the total number of clauses         explored) given the minimum clause score required and a &amp;#8220;cutoff&amp;#8221; value (the number of clauses examined before the search is         restarted), (2) estimate the conditional expected clause score given the cutoff value and the invested search cost, and (3)         compare the performance of randomised restarted search strategies to a deterministic non-restarted search. Our findings indicate         striking similarities across the five search algorithms and the four domains, in terms of the basic trends of both the statistics         (1) and (2). Also, we observe that the cutoff value is critical for the performance of the search algorithm, and using its         optimal value in a randomised restarted search may decrease the mean search cost (by several orders of magnitude) or increase         the mean achieved score significantly with respect to that obtained with a deterministic non-restarted search.      </content></document><document><year>2006</year><authors>Asmir Tobudic1 | Gerhard Widmer2 </authors><title>Relational IBL in classical music      </title><content>It is well known that many hard tasks considered in machine learning and data mining can be solved in a rather simple and         robust way with an instance- and distance-based approach. In this work we present another difficult task: learning, from large         numbers of complex performances by concert pianists, to play music expressively. We model the problem as a multi-level decomposition         and prediction task. We show that this is a fundamentally relational learning problem and propose a new similarity measure         for structured objects, which is built into a relational instance-based learning algorithm named DISTALL. Experiments with         data derived from a substantial number of Mozart piano sonata recordings by a skilled concert pianist demonstrate that the         approach is viable. We show that the instance-based learner operating on structured, relational data outperforms a propositional         k-NN algorithm. In qualitative terms, some of the piano performances produced by DISTALL after learning from the human artist         are of substantial musical quality; one even won a prize in an international &amp;#8216;computer music performance&amp;#8217; contest. The experiments         thus provide evidence of the capabilities of ILP in a highly complex domain such as music.      </content></document><document><year>2006</year><authors>Shi Zhong1 </authors><title>Semi-supervised model-based document clustering: A comparative study      </title><content>Semi-supervised learning has become an attractive methodology for improving classification models and is often viewed as using         unlabeled data to aid supervised learning. However, it can also be viewed as using labeled data to help clustering, namely,         semi-supervised clustering. Viewing semi-supervised learning from a clustering angle is useful in practical situations when         the set of labels available in labeled data are not complete, i.e., unlabeled data contain new classes that are not present         in labeled data. This paper analyzes several multinomial model-based semi-supervised document clustering methods under a principled         model-based clustering framework. The framework naturally leads to a deterministic annealing extension of existing semi-supervised         clustering approaches. We compare three (slightly) different semi-supervised approaches for clustering documents: Seeded damnl, Constrained damnl, and Feedback-based damnl, where damnl stands for multinomial model-based deterministic annealing algorithm. The first two are extensions of the seeded k-means and constrained k-means algorithms studied by Basu et al. (2002); the last one is motivated by Cohn et al. (2003). Through empirical experiments         on text datasets, we show that: (a) deterministic annealing can often significantly improve the performance of semi-supervised         clustering; (b) the constrained approach is the best when available labels are complete whereas the feedback-based approach         excels when available labels are incomplete.      </content></document><document><year>2006</year><authors>Elchanan Mossel1  | SГ©bastien Roch1 </authors><title>Slow emergence of cooperation for win-stay lose-shift on trees      </title><content>We consider a group of agents on a graph who repeatedly play the prisoner&amp;#8217;s dilemma game against their neighbors. The players         adapt their actions to the past behavior of their opponents by applying the win-stay lose-shift strategy. On a finite connected         graph, it is easy to see that the system learns to cooperate by converging to the all-cooperate state in a finite time. We         analyze the rate of convergence in terms of the size and structure of the graph. Dyer et al. (2002) showed that the system         converges rapidly on the cycle, but that it takes a time exponential in the size of the graph to converge to cooperation on         the complete graph. We show that the emergence of cooperation is exponentially slow in some expander graphs. More surprisingly,         we show that it is also exponentially slow in bounded-degree trees, where many other dynamics are known to converge rapidly.      </content></document><document><year>2006</year><authors>Laurent Zwald1 </authors><title>Statistical properties of kernel principal component analysis      </title><content>Without Abstract</content></document><document><year>2006</year><authors>Gilles Blanchard1 | Olivier Bousquet2  | Laurent Zwald3 </authors><title>Statistical properties of kernel principal component analysis      </title><content>The main goal of this paper is to prove inequalities on the reconstruction error for kernel principal component analysis.         With respect to previous work on this topic, our contribution is twofold: (1) we give bounds that explicitly take into account         the empirical centering step in this algorithm, and (2) we show that a &amp;#8220;localized&amp;#8221; approach allows to obtain more accurate         bounds. In particular, we show faster rates of convergence towards the minimum reconstruction error; more precisely, we prove         that the convergence rate can typically be faster than n         &amp;#8722;1/2. We also obtain a new relative bound on the error.                     A secondary goal, for which we present similar contributions, is to obtain convergence bounds for the partial sums of the               biggest or smallest eigenvalues of the kernel Gram matrix towards eigenvalues of the corresponding kernel operator. These               quantities are naturally linked to the KPCA procedure; furthermore these results can have applications to the study of various               other kernel algorithms.            </content></document><document><year>2006</year><authors>Ioannis Tsamardinos1 | Laura E. Brown1  | Constantin F. Aliferis1 </authors><title>The max-min hill-climbing Bayesian network structure learning algorithm      </title><content>We present a new algorithm for Bayesian network structure learning, called Max-Min Hill-Climbing (MMHC). The algorithm combines ideas from local learning, constraint-based, and search-and-score techniques in a principled and         effective way. It first reconstructs the skeleton of a Bayesian network and then performs a Bayesian-scoring greedy hill-climbing         search to orient the edges. In our extensive empirical evaluation MMHC outperforms on average and in terms of various metrics several prototypical and state-of-the-art algorithms, namely the PC, Sparse Candidate, Three Phase Dependency Analysis, Optimal Reinsertion, Greedy Equivalence Search, and Greedy Search. These         are the first empirical results simultaneously comparing most of the major Bayesian network algorithms against each other.         MMHC offers certain theoretical advantages, specifically over the Sparse Candidate algorithm, corroborated by our experiments.         MMHC and detailed results of our study are publicly available at http://www.dsl-lab.org/supplements/mmhc_paper/mmhc_index.html.      </content></document><document><year>2006</year><authors>Kar-Ann Toh1 </authors><title>Training a reciprocal-sigmoid classifier by feature scaling-space      </title><content>This paper presents a reciprocal-sigmoid model for pattern classification. This proposed classifier can be considered as a         &amp;#934;-machine since it preserves the theoretical advantage of linear machines where the weight parameters can be estimated in         a single step. The model can also be considered as an approximation to logistic regression under the framework of Generalized         Linear Models. While inheriting the necessary classification capability from logistic regression, the problems of local minima         and tedious recursive search no longer exist in the proposed formulation. To handle possible over-fitting when using high         order models, the classifier is trained using multiple samples of uniformly scaled pattern features. Empirically, the classifier         is evaluated using a benchmark synthetic data from random sampling runs for initial statistical evidence regarding its classification         accuracy and computational efficiency. Additional experiments based on ten runs of 10-fold cross validations on 40 data sets         further support the effectiveness of the reciprocal-sigmoid model, where its classification accuracy is seen to be comparable         to several top classifiers in the literature. Main reasons for the good performance are attributed to effective use of reciprocal         sigmoid for embedding nonlinearities and effective use of bundled feature sets for smoothing the training error hyper-surface.      </content></document><document><year>2006</year><authors>Levente Kocsis1  | Csaba SzepesvГЎri1 </authors><title>Universal parameter optimisation in games based on SPSA      </title><content>Most game programs have a large number of parameters that are crucial for their performance. While tuning these parameters         by hand is rather difficult, efficient and easy to use generic automatic parameter optimisation algorithms are known only         for special problems such as the adjustment of the parameters of an evaluation function. The SPSA algorithm (Simultaneous         Perturbation Stochastic Approximation) is a generic stochastic gradient method for optimising an objective function when an         analytic expression of the gradient is not available, a frequent case in game programs. Further, SPSA in its canonical form         is very easy to implement. As such, it is an attractive choice for parameter optimisation in game programs, both due to its         generality and simplicity. The goal of this paper is twofold: (i) to introduce SPSA for the game programming community by         putting it into a game-programming perspective, and (ii) to propose and discuss several methods that can be used to enhance         the performance of SPSA. These methods include using common random numbers and antithetic variables, a combination of SPSA         with RPROP, and the reuse of samples of previous performance evaluations. SPSA with the proposed enhancements was tested in         some large-scale experiments on tuning the parameters of an opponent model, a policy and an evaluation function in our poker         program, MCRAISE. Whilst SPSA with no enhancements failed to make progress using the allocated resources, SPSA with the enhancements proved         to be competitive with other methods, including TD-learning; increasing the average payoff per game by as large as 0.19 times         the size of the amount of the small bet. From the experimental study, we conclude that the use of an appropriately enhanced         variant of SPSA for the optimisation of game program parameters is a viable approach, especially if no good alternative exist         for the types of parameters considered.      </content></document><document><year>2006</year><authors>Samer Abdallah1 | Mark S|ler1 | Christophe Rhodes2  | Michael Casey2 </authors><title>Using duration models to reduce fragmentation in audio segmentation      </title><content>We investigate explicit segment duration models in addressing the problem of fragmentation in musical audio segmentation.         The resulting probabilistic models are optimised using Markov Chain Monte Carlo methods; in particular, we introduce a modification         to Wolff&amp;#8217;s algorithm to make it applicable to a segment classification model with an arbitrary duration prior. We apply this         to a collection of pop songs, and show experimentally that the generated segmentations suffer much less from fragmentation         than those produced by segmentation algorithms based on clustering, and are closer to an expert listener&amp;#8217;s annotations, as         evaluated by two different performance measures.      </content></document><document><year>2006</year><authors>Mohammed J. Zaki1  | Charu C. Aggarwal2 </authors><title>XRules: An effective algorithm for structural classification of XML data      </title><content>XML documents have recently become ubiquitous because of their varied applicability in a number of applications. Classification         is an important problem in the data mining domain, but current classification methods for XML documents use IR-based methods         in which each document is treated as a bag of words. Such techniques ignore a significant amount of information hidden inside         the documents. In this paper we discuss the problem of rule based classification of XML data by using frequent discriminatory         substructures within XML documents. Such a technique is more capable of finding the classification characteristics of documents.         In addition, the technique can also be extended to cost sensitive classification. We show the effectiveness of the method         with respect to other classifiers. We note that the methodology discussed in this paper is applicable to any kind of semi-structured         data.      </content></document><document><year>2007</year><authors>Jan Drugowitsch1  | Alwyn M. Barry2 </authors><title>A formal framework and extensions for function approximation in learning classifier systems      </title><content>         Learning Classifier Systems (LCS) consist of the three components: function approximation, reinforcement learning, and classifier         replacement. In this paper we formalize the function approximation part, by providing a clear problem definition, a formalization         of the LCS function approximation architecture, and a definition of the function approximation aim. Additionally, we provide         definitions of optimality and what conditions need to be fulfilled for a classifier to be optimal. As a demonstration of the         usefulness of the framework, we derive commonly used algorithmic approaches that aim at reaching optimality from first principles,         and introduce a new Kalman filter-based method that outperforms all currently implemented methods, in addition to providing         further insight into the probabilistic basis of the localized model that a classifier provides. A global function approximation         in LCS is achieved by combining the classifier&amp;#8217;s localized model, for which we provide a simplified approach when compared         to current LCS, based on the Maximum Likelihood of a combination of all classifiers. The formalizations in this paper act         as the foundation of a currently actively developed formal framework that includes all three LCS components, promising a better         formal understanding of current LCS and the development of better LCS algorithms.               </content></document><document><year>2007</year><authors>Malik Magdon-Ismail1  | Joseph Sill2 </authors><title>A linear fit gets the correct monotonicity directions      </title><content>         Let f be a function on &amp;#8477;            d             that is monotonic in every variable. There are 2            d             possible assignments to the directions of monotonicity (two per variable). We provide sufficient conditions under which the         optimal linear model obtained from a least squares regression on f will identify the monotonicity directions correctly. We show that when the input dimensions are independent, the linear fit         correctly identifies the monotonicity directions. We provide an example to illustrate that in the general case, when the input         dimensions are not independent, the linear fit may not identify the directions correctly. However, when the inputs are jointly         Gaussian, as is often assumed in practice, the linear fit will correctly identify the monotonicity directions, even if the         input dimensions are dependent. Gaussian densities are a special case of a more general class of densities (Mahalanobis densities)         for which the result holds. Our results hold when f is a classification or regression function.                                             If a finite data set is sampled from the function, we show that if the exact linear regression would have yielded the correct               monotonicity directions, then the sample regression will also do so asymptotically (in a probabilistic sense). This result               holds even if the data are noisy.                           </content></document><document><year>2007</year><authors>Hsuan-Tien Lin1 | Chih-Jen Lin1  | Ruby C. Weng2 </authors><title>A note on Platt&amp;#8217;s probabilistic outputs for support vector machines      </title><content>         Platt&amp;#8217;s probabilistic outputs for Support Vector Machines (Platt, J. in Smola, A., et al. (eds.) Advances in large margin         classifiers. Cambridge, 2000) has been popular for applications that require posterior class probabilities. In this note, we propose an improved algorithm         that theoretically converges and avoids numerical difficulties. A simple and ready-to-use pseudo code is included.               </content></document><document><year>2007</year><authors>Shai Shalev-Shwartz1  | Yoram Singer1| 2 </authors><title>A primal-dual perspective of online learning algorithms      </title><content>         We describe a novel framework for the design and analysis of online learning algorithms based on the notion of duality in         constrained optimization. We cast a sub-family of universal online bounds as an optimization problem. Using the weak duality         theorem we reduce the process of online learning to the task of incrementally increasing the dual objective function. The         amount by which the dual increases serves as a new and natural notion of progress for analyzing online learning algorithms.         We are thus able to tie the primal objective value and the number of prediction mistakes using the increase in the dual.               </content></document><document><year>2007</year><authors>Andrew I. Schein1  | Lyle H. Ungar1 </authors><title>Active learning for logistic regression: an evaluation      </title><content>         Which active learning methods can we expect to yield good performance in learning binary and multi-category logistic regression         classifiers? Addressing this question is a natural first step in providing robust solutions for active learning across a wide         variety of exponential models including maximum entropy, generalized linear, log-linear, and conditional random field models.         For the logistic regression model we re-derive the variance reduction method known in experimental design circles as &amp;#8216;A-optimality.&amp;#8217; We then run comparisons against different variations of the most widely used heuristic schemes: query by committee         and uncertainty sampling, to discover which methods work best for different classes of problems and why. We find that among         the strategies tested, the experimental design methods are most likely to match or beat a random sample baseline. The heuristic         alternatives produced mixed results, with an uncertainty sampling variant called margin sampling and a derivative method called         QBB-MM providing the most promising performance at very low computational cost. Computational running times of the experimental         design methods were a bottleneck to the evaluations. Meanwhile, evaluation of the heuristic methods lead to an accumulation         of negative results. We explore alternative evaluation design parameters to test whether these negative results are merely         an artifact of settings where experimental design methods can be applied. The results demonstrate a need for improved active         learning methods that will provide reliable performance at a reasonable computational cost.               </content></document><document><year>2007</year><authors>Shai Fine1  | Yishay Mansour2 </authors><title>Active sampling for multiple output identification      </title><content>         We study functions with multiple output values, and use active sampling to identify an example for each of the possible output         values. Our results for this setting include: (1);Efficient active sampling algorithms for simple geometric concepts, such         as intervals on a line and axis parallel boxes. (2);A characterization for the case of binary output value in a transductive         setting. (3);An analysis of active sampling with uniform distribution in the plane. (4) An efficient algorithm for the Boolean         hypercube when each output value is a monomial.               </content></document><document><year>2007</year><authors>Fabrizio Riguzzi1 </authors><title>ALLPAD: approximate learning of logic programs with annotated disjunctions      </title><content>         Logic Programs with Annotated Disjunctions (LPADs) provide a simple and elegant framework for representing probabilistic knowledge         in logic programming. In this paper we consider the problem of learning ground LPADs starting from a set of interpretations         annotated with their probability. We present the system ALLPAD for solving this problem. ALLPAD modifies the previous system         LLPAD in order to tackle real world learning problems more effectively. This is achieved by looking for an approximate solution         rather than a perfect one. A number of experiments have been performed on real and artificial data for evaluating ALLPAD,         showing the feasibility of the approach.               </content></document><document><year>2007</year><authors>Faming Liang1 </authors><title>Annealing stochastic approximation Monte Carlo algorithm for;neural network training      </title><content>         We propose a;general-purpose stochastic optimization algorithm, the so-called annealing stochastic approximation Monte Carlo         (ASAMC) algorithm, for neural network training. ASAMC can be regarded as a;space annealing version of the stochastic approximation         Monte Carlo (SAMC) algorithm. Under mild conditions, we show that ASAMC can converge weakly at a;rate of &amp;#937;                   toward a;neighboring set (in the space of energy) of the global minimizers. ASAMC is compared with simulated annealing, SAMC,         and the BFGS algorithm for training MLPs on a;number of examples. The numerical results indicate that ASAMC outperforms the         other algorithms in both training and test errors. Like other stochastic algorithms, ASAMC requires longer training time than         do the gradient-based algorithms. It provides, however, an efficient approach to train MLPs for which the energy landscape         is rugged.               </content></document><document><year>2007</year><authors>Ying Yang1 | Geoff Webb1 | Kevin Korb1  | Kai Ming Ting1 </authors><title>Classifying under computational resource constraints: anytime classification using probabilistic estimators      </title><content>         In many online applications of machine learning, the computational resources available for classification will vary from time         to time. Most techniques are designed to operate within the constraints of the minimum expected resources and fail to utilize         further resources when they are available. We propose a novel anytime classification algorithm, anytime averaged probabilistic         estimators (AAPE), which is capable of delivering strong prediction accuracy with little CPU time and utilizing additional         CPU time to increase classification accuracy. The idea is to run an ordered sequence of very efficient Bayesian probabilistic         estimators (single improvement steps) until classification time runs out. Theoretical studies and empirical validations reveal         that by properly identifying, ordering, invoking and ensembling single improvement steps, AAPE is able to accomplish accurate         classification whenever it is interrupted. It is also able to output class probability estimates beyond simple 0/1-loss classifications,         as well as adeptly handle incremental learning.               </content></document><document><year>2007</year><authors>Vladimir Vovk1 </authors><title>Competing with wild prediction rules      </title><content>         We consider the problem of on-line prediction competitive with a benchmark class of continuous but highly irregular prediction         rules. It is known that if the benchmark class is a reproducing kernel Hilbert space, there exists a prediction algorithm         whose average loss over the first N examples does not exceed the average loss of any prediction rule in the class plus a &amp;#8220;regret term&amp;#8221; of O(N         &amp;#8722;1/2). The elements of some natural benchmark classes, however, are so irregular that these classes are not Hilbert spaces. In         this paper we develop Banach-space methods to construct a prediction algorithm with a regret term of O(N         &amp;#8722;1/p            ), where p&amp;#8712;[2,&amp;#8734;) and p&amp;#8722;2 reflects the degree to which the benchmark class fails to be a Hilbert space. Only the square loss function is considered.               </content></document><document><year>2007</year><authors>L. De Raedt2 | K. Kersting1 | A. Kimmig2 | K. Revoredo1  | H. Toivonen3 </authors><title>Compressing probabilistic Prolog programs      </title><content>         ProbLog is a recently introduced probabilistic extension of Prolog (De Raedt, et al. in Proceedings of the 20th international         joint conference on artificial intelligence, pp.;2468&amp;#8211;2473, 2007). A ProbLog program defines a distribution over logic programs by specifying for each clause the probability that it belongs         to a randomly sampled program, and these probabilities are mutually independent. The semantics of ProbLog is then defined         by the success probability of a query in a randomly sampled program.                                             This paper introduces the theory compression task for ProbLog, which consists of selecting that subset of clauses of a given               ProbLog program that maximizes the likelihood w.r.t. a set of positive and negative examples. Experiments in the context of               discovering links in real biological networks demonstrate the practical applicability of the approach.                           </content></document><document><year>2007</year><authors>Geoffrey I. Webb1 </authors><title>Discovering Significant Patterns      </title><content>         Pattern discovery techniques, such as association rule discovery, explore large search spaces of potential patterns to find         those that satisfy some user-specified constraints. Due to the large number of patterns considered, they suffer from an extreme         risk of type-1 error, that is, of finding patterns that appear due to chance alone to satisfy the constraints on the sample         data. This paper proposes techniques to overcome this problem by applying well-established statistical practices. These allow         the user to enforce a strict upper limit on the risk of experimentwise error. Empirical studies demonstrate that standard         pattern discovery techniques can discover numerous spurious patterns when applied to random data and when applied to real-world         data result in large numbers of patterns that are rejected when subjected to sound statistical evaluation. They also reveal         that a number of pragmatic choices about how such tests are performed can greatly affect their power.               </content></document><document><year>2007</year><authors>Homin K. Lee1 | Rocco A. Servedio1  | Andrew Wan1 </authors><title>DNF are teachable in the average case      </title><content>         We study the average number of well-chosen labeled examples that are required for a helpful teacher to uniquely specify a         target function within a concept class. This &amp;#8220;average teaching dimension&amp;#8221; has been studied in learning theory and combinatorics         and is an attractive alternative to the &amp;#8220;worst-case&amp;#8221; teaching dimension of Goldman and Kearns which is exponential for many         interesting concept classes. Recently Balbach showed that the classes of 1-decision lists and 2-term DNF each have linear         average teaching dimension.                                             As our main result, we extend Balbach&amp;#8217;s teaching result for 2-term DNF by showing that for any 1&amp;#8804;s&amp;#8804;2                  &amp;#920;(n), the well-studied concept classes of at-most-s-term DNF and at-most-s-term monotone DNF each have average teaching dimension O(ns). The proofs use detailed analyses of the combinatorial structure of &amp;#8220;most&amp;#8221; DNF formulas and monotone DNF formulas. We also               establish asymptotic separations between the worst-case and average teaching dimension for various other interesting Boolean               concept classes such as juntas and sparse GF               2 polynomials.                           </content></document><document><year>2007</year><authors>Gokhan Tur1 </authors><title>Extending boosting for large scale spoken language understanding      </title><content>         We propose three methods for extending the Boosting family of classifiers motivated by the real-life problems we have encountered.         First, we propose a semisupervised learning method for exploiting the unlabeled data in Boosting. We then present a novel         classification model adaptation method. The goal of adaptation is optimizing an existing model for a new target application,         which is similar to the previous one but may have different classes or class distributions. Finally, we present an efficient         and effective cost-sensitive classification method that extends Boosting to allow for weighted classes. We evaluated these         methods for call classification in the AT&amp;amp;T VoiceToneВ® spoken language understanding system. Our results indicate that it is possible to obtain the same classification performance         by using 30% less labeled data when the unlabeled data is utilized through semisupervised learning. Using model adaptation         we can achieve the same classification accuracy using less than half of the labeled data from the new application. Finally,         we present significant improvements in the &amp;#8220;important&amp;#8221; (i.e., higher weighted) classes without a significant loss in overall         performance using the proposed cost-sensitive classification method.               </content></document><document><year>2007</year><authors>Kai-Quan Shen1 | Chong-Jin Ong1 | Xiao-Ping Li1  | Einar P. V. Wilder-Smith2 </authors><title>Feature selection via sensitivity analysis of SVM probabilistic outputs      </title><content>         Feature selection is an important aspect of solving data-mining and machine-learning problems. This paper proposes a feature-selection         method for the Support Vector Machine (SVM) learning. Like most feature-selection methods, the proposed method ranks all features         in decreasing order of importance so that more relevant features can be identified. It uses a novel criterion based on the         probabilistic outputs of SVM. This criterion, termed Feature-based Sensitivity of Posterior Probabilities (FSPP), evaluates         the importance of a specific feature by computing the aggregate value, over the feature space, of the absolute difference         of the probabilistic outputs of SVM with and without the feature. The exact form of this criterion is not easily computable         and approximation is needed. Four approximations, FSPP1-FSPP4, are proposed for this purpose. The first two approximations         evaluate the criterion by randomly permuting the values of the feature among samples of the training data. They differ in         their choices of the mapping function from standard SVM output to its probabilistic output: FSPP1 uses a simple threshold         function while FSPP2 uses a sigmoid function. The second two directly approximate the criterion but differ in the smoothness         assumptions of criterion with respect to the features. The performance of these approximations, used in an overall feature-selection         scheme, is then evaluated on various artificial problems and real-world problems, including datasets from the recent Neural         Information Processing Systems (NIPS) feature selection competition. FSPP1-3 show good performance consistently with FSPP2         being the best overall by a slight margin. The performance of FSPP2 is competitive with some of the best performing feature-selection         methods in the literature on the datasets that we have tested. Its associated computations are modest and hence it is suitable         as a feature-selection method for SVM applications.               </content></document><document><year>2007</year><authors>Charles A. Micchelli1  | Massimiliano Pontil2 </authors><title>Feature space perspectives for learning the kernel      </title><content>In this paper, we continue our study of learning an optimal kernel in a prescribed convex set of kernels (Micchelli &amp;amp; Pontil,         2005) . We present a reformulation of this problem within a feature space environment. This leads us to study regularization         in the dual space of all continuous functions on a compact domain with values in a Hilbert space with a mix norm. We also         relate this problem in a special case to                    regularization.      </content></document><document><year>2007</year><authors>Jan Ramon1 | Tom Croonenborghs1 | Daan Fierens1 | Hendrik Blockeel1  | Maurice Bruynooghe1 </authors><title>Generalized ordering-search for learning directed probabilistic logical models      </title><content>         Recently, there has been an increasing interest in directed probabilistic logical models and a variety of formalisms for describing         such models has been proposed. Although many authors provide high-level arguments to show that in principle models in their         formalism can be learned from data, most of the proposed learning algorithms have not yet been studied in detail. We introduce         an algorithm, generalized ordering-search, to learn both structure and conditional probability distributions (CPDs) of directed         probabilistic logical models. The algorithm is based on the ordering-search algorithm for Bayesian networks. We use relational         probability trees as a representation for the CPDs. We present experiments on a genetics domain, blocks world domains and         the Cora dataset.               </content></document><document><year>2007</year><authors>Olivier Bousquet1  | AndrГ© Elisseeff2 </authors><title>Guest editorial: Learning theory      </title><content>Without Abstract</content></document><document><year>2007</year><authors>Stephen Muggleton1 | Ramon Otero2  | Simon Colton1 </authors><title>Guest editorial: special issue on Inductive Logic Programming      </title><content>Without Abstract</content></document><document><year>2007</year><authors>Fabien Lauer1  | GГ©rard Bloch1 </authors><title>Incorporating prior knowledge in support vector regression      </title><content>         This paper explores the incorporation of prior knowledge in support vector regresion by the addition of constraints. Equality         and inequality constraints are studied with the corresponding types of prior knowledge that can be considered for the method.         These include particular points with known values, prior knowledge on any derivative of the function either provided by a         prior model or available only at some specific points and bounds on the function or any derivative in a given domain. Moreover,         a new method for the simultaneous approximation of multiple outputs linked by some prior knowledge is proposed. This method         also allows consideration of different types of prior knowledge on single outputs while training on multiple outputs. Synthetic         examples show that incorporating a wide variety of prior knowledge becomes easy, as it leads to linear programs, and helps         to improve the approximation in difficult cases. The benefits of the method are finally shown on a real-life application,         the estimation of in-cylinder residual gas fraction in spark ignition engines, which is representative of numerous situations         met in engineering.               </content></document><document><year>2007</year><authors>Sebastian FrГ¶hler1  | Stefan Kramer1 </authors><title>Inductive logic programming for gene regulation prediction      </title><content>         We present a systems biology application of ILP, where the goal is to predict the regulation of a gene under a certain condition         from binding site information, the state of regulators, and additional information. In the experiments, the boosted Tilde         model is on par with the original model by Middendorf et al. based on alternating decision trees (ADTrees), given the same         information. Adding functional categorizations and protein-protein interactions, however, it is possible to improve the performance         substantially. We believe that decoding the regulation mechanisms of genes is an exciting new application of learning in logic,         requiring data integration from various sources and potentially contributing to a better understanding on a system level.               </content></document><document><year>2007</year><authors>Will Bridewell1 | Pat Langley1 | Ljup&amp;#269 o Todorovski2  | Sa&amp;#353 o D&amp;#382 eroski2 </authors><title>Inductive process modeling      </title><content>         In this paper, we pose a novel research problem for machine learning that involves constructing a process model from continuous data. We claim that casting learned knowledge in terms of processes with associated equations is desirable         for scientific and engineering domains, where such notations are commonly used. We also argue that existing induction methods         are not well suited to this task, although some techniques hold partial solutions. In response, we describe an approach to         learning process models from time-series data and illustrate its behavior in three domains. In closing, we describe open issues         in process model induction and encourage other researchers to tackle this important problem.               </content></document><document><year>2007</year><authors>Avrim Blum1 | Gabor Lugosi2  | Hans Ulrich Simon3 </authors><title>Introduction to the special issue on COLT 2006      </title><content>Without Abstract</content></document><document><year>2007</year><authors>Amy Greenwald1  | Michael L. Littman2</authors><title>Introduction to the special issue on learning and computational game theory      </title><content>Without Abstract</content></document><document><year>2007</year><authors>Bernard Haasdonk1  | Hans Burkhardt2 </authors><title>Invariant kernel functions for pattern analysis and;machine learning      </title><content>         In many learning problems prior knowledge about pattern variations can be formalized and beneficially incorporated into the         analysis system. The corresponding notion of invariance is commonly used in conceptionally different ways. We propose a more distinguishing treatment in particular in the active         field of kernel methods for machine learning and pattern analysis. Additionally, the fundamental relation of invariant kernels         and traditional invariant pattern analysis by means of invariant representations will be clarified. After addressing these         conceptional questions, we focus on practical aspects and present two generic approaches for constructing invariant kernels.         The first approach is based on a technique called invariant integration. The second approach builds on invariant distances.         In principle, our approaches support general transformations in particular covering discrete and non-group or even an infinite         number of pattern-transformations. Additionally, both enable a smooth interpolation between invariant and non-invariant pattern         analysis, i.e. they are a covering general framework. The wide applicability and various possible benefits of invariant kernels         are demonstrated in different kernel methods.               </content></document><document><year>2007</year><authors>Yuanqing Li1  | Cuntai Guan1</authors><title>Joint feature re-extraction and classification;using an;iterative;semi-supervised support vector machine algorithm      </title><content>         The focus of this paper is on joint feature re-extraction and classification in cases when the training data set is small.         An iterative semi-supervised support vector machine (SVM) algorithm is proposed, where each iteration consists both feature         re-extraction and classification, and the feature re-extraction is based on the classification results from the previous iteration.         Feature extraction is first discussed in the framework of Rayleigh coefficient maximization. The effectiveness of common spatial         pattern (CSP) feature, which is commonly used in Electroencephalogram (EEG) data analysis and EEG-based brain computer interfaces         (BCIs), can be explained by Rayleigh coefficient maximization. Two other features are also defined using the Rayleigh coefficient.         These features are effective for discriminating two classes with different means or different variances. If we extract features         based on Rayleigh coefficient maximization, a large training data set with labels is required in general; otherwise, the extracted         features are not reliable. Thus we present an iterative semi-supervised SVM algorithm embedded with feature re-extraction.         This iterative algorithm can be used to extract these three features reliably and perform classification simultaneously in         cases where the training data set is small. Each iteration is composed of two main steps: (i);the training data set is updated/augmented         using unlabeled test data with their predicted labels; features are re-extracted based on the augmented training data set.         (ii);The re-extracted features are classified by a standard SVM. Regarding parameter setting and model selection of our algorithm,         we also propose a semi-supervised learning-based method using the Rayleigh coefficient, in which both training data and test         data are used. This method is suitable when cross-validation model selection may not work for small training data set. Finally,         the results of data analysis are presented to demonstrate the validity of our approach.               </content></document><document><year>2007</year><authors>AndrГЎs Antos1 | Csaba SzepesvГЎri1| 3  | RГ©mi Munos2 </authors><title>Learning near-optimal policies with Bellman-residual minimization based fitted policy iteration and a single sample path      </title><content>         In this paper we consider the problem of finding a near-optimal policy in a continuous space, discounted Markovian Decision         Problem (MDP) by employing value-function-based methods when only a single trajectory of a fixed policy is available as the         input. We study a policy-iteration algorithm where the iterates are obtained via empirical risk minimization with a risk function         that penalizes high magnitudes of the Bellman-residual. Our main result is a finite-sample, high-probability bound on the         performance of the computed policy that depends on the mixing rate of the trajectory, the capacity of the function set as         measured by a novel capacity concept (the VC-crossing dimension), the approximation power of the function set and the controllability properties of the MDP. Moreover,         we prove that when a linear parameterization is used the new algorithm is equivalent to Least-Squares Policy Iteration. To         the best of our knowledge this is the first theoretical result for off-policy control learning over continuous state-spaces         using a single trajectory.               </content></document><document><year>2007</year><authors>Yevgeniy Vorobeychik1 | Michael P. Wellman1  | Satinder Singh1 </authors><title>Learning payoff functions in infinite games      </title><content>We consider a class of games with real-valued strategies and payoff information available only in the form of data from a         given sample of strategy profiles. Solving such games with respect to the underlying strategy space requires generalizing         from the data to a complete payoff-function representation. We address payoff-function learning as a standard regression problem,         with provision for capturing known structure (e.g., symmetry) in the multiagent environment. To measure learning performance,         we consider the relative utility of prescribed strategies, rather than the accuracy of payoff functions per se. We demonstrate         our approach and evaluate its effectiveness on two examples: a two-player version of the first-price sealed-bid auction (with         known analytical form), and a five-player market-based scheduling game (with no known solution). Additionally, we explore         the efficacy of using relative utility of strategies as a target of supervised learning and as a learning model selector.         Our experiments demonstrate its effectiveness in the former case, though not in the latter.      </content></document><document><year>2007</year><authors>Elad Hazan1 | Amit Agarwal2 | Satyen Kale2</authors><title>Logarithmic regret algorithms for online convex optimization      </title><content>         In an online convex optimization problem a decision-maker makes a sequence of decisions, i.e., chooses a sequence of points         in Euclidean space, from a fixed feasible set. After each point is chosen, it encounters a sequence of (possibly unrelated)         convex cost functions. Zinkevich (ICML 2003) introduced this framework, which models many natural repeated decision-making         problems and generalizes many existing problems such as Prediction from Expert Advice and Cover&amp;#8217;s Universal Portfolios. Zinkevich         showed that a simple online gradient descent algorithm achieves additive regret                  , for an arbitrary sequence of T convex cost functions (of bounded gradients), with respect to the best single decision in hindsight.                                             In this paper, we give algorithms that achieve regret O(log&amp;#8201;(T)) for an arbitrary sequence of strictly convex functions (with bounded first and second derivatives). This mirrors what has               been done for the special cases of prediction from expert advice by Kivinen and Warmuth (EuroCOLT 1999), and Universal Portfolios               by Cover (Math. Finance 1:1&amp;#8211;19, 1991). We propose several algorithms achieving logarithmic regret, which besides being more general are also much more efficient               to implement.                           </content></document><document><year>2007</year><authors>Ulrich RГјckert1  | Stefan Kramer1 </authors><title>Margin-based first-order rule learning      </title><content>         We present a new margin-based approach to first-order rule learning. The approach addresses many of the prominent challenges         in first-order rule learning, such as the computational complexity of optimization and capacity control. Optimizing the mean         of the margin minus its variance, we obtain an algorithm linear in the number of examples and a handle for capacity control         based on error bounds. A useful parameter in the optimization problem tunes how evenly the weights are spread among the rules.         Moreover, the search strategy for including new rules can be adjusted flexibly, to perform variants of propositionalization         or relational learning. The implementation of the system includes plugins for logical queries, graphs and mathematical terms.         In extensive experiments, we found that, at least on the most commonly used toxicological datasets, overfitting is hardly         an issue. In another batch of experiments, a comparison with margin-based ILP approaches using kernels turns out to be favorable.         Finally, an experiment shows how many features are needed by propositionalization and relational learning approaches to reach         a certain predictive performance.               </content></document><document><year>2007</year><authors>Rong Jin1  | Jian Zhang2 </authors><title>Multi-Class Learning by Smoothed Boosting      </title><content>         AdaBoost.OC has been shown to be an effective method in boosting &amp;#8220;weak&amp;#8221; binary classifiers for multi-class learning. It employs         the Error-Correcting Output Code (ECOC) method to convert a multi-class learning problem into a set of binary classification         problems, and applies the AdaBoost algorithm to solve them efficiently. One of the main drawbacks with the AdaBoost.OC algorithm         is that it is sensitive to the noisy examples and tends to overfit training examples when they are noisy. In this paper, we         propose a new boosting algorithm, named &amp;#8220;MSmoothBoost&amp;#8221;, which introduces a smoothing mechanism into the boosting procedure         to explicitly address the overfitting problem with AdaBoost.OC. We proved the bounds for both the empirical training error         and the marginal training error of the proposed boosting algorithm. Empirical studies with seven UCI datasets and one real-world         application have indicated that the proposed boosting algorithm is more robust and effective than the AdaBoost.OC algorithm         for multi-class learning.               </content></document><document><year>2007</year><authors>Erick Alphonse1  | Aomar Osmani1 </authors><title>On the connection between the phase transition of;the;covering test and the learning success rate in ILP      </title><content>         It is well-known that heuristic search in ILP is prone to plateau phenomena. An explanation can be given after the work of         Giordana and Saitta: the ILP covering test is NP-complete and therefore exhibits a sharp phase transition in its coverage         probability. As the heuristic value of a hypothesis depends on the number of covered examples, the regions &amp;#8220;yes&amp;#8221; and &amp;#8220;no&amp;#8221;         represent plateaus that need to be crossed during search without an informative heuristic value. Several subsequent works         have extensively studied this finding by running several learning algorithms on a large set of artificially generated problems         and argued that the occurrence of this phase transition dooms every learning algorithm to fail to identify the target concept.         We note however that only generate-and-test learning algorithms have been applied and that this conclusion has to be qualified         in the case of data-driven learning algorithms. Mostly building on the pioneering work of Winston on near-miss examples, we         show that, on the same set of problems, a top-down data-driven strategy can cross any plateau if near-misses are supplied         in the training set, whereas they do not change the plateau profile and do not guide a generate-and-test strategy. We conclude         that the location of the target concept with respect to the phase transition alone is not a reliable indication of the learning         problem difficulty as previously thought.               </content></document><document><year>2007</year><authors>Tadeusz Pietraszek1 </authors><title>On the use of ROC analysis for the optimization of;abstaining classifiers      </title><content>         Classifiers that refrain from classification in certain cases can significantly reduce the misclassification cost. However,         the parameters for such abstaining classifiers are often set in a rather ad-hoc manner. We propose a method to optimally build         a specific type of abstaining binary classifiers using ROC analysis. These classifiers are built based on optimization criteria         in the following three models: cost-based, bounded-abstention and bounded-improvement. We show that selecting the optimal         classifier in the first model is similar to known iso-performance lines and uses only the slopes of ROC curves, whereas selecting         the optimal classifier in the remaining two models is not straightforward. We investigate the properties of the convex-down         ROCCH (ROC Convex Hull) and present a simple and efficient algorithm for finding the optimal classifier in these models, namely,         the bounded-abstention and bounded-improvement models. We demonstrate the application of these models to effectively reduce         misclassification cost in real-life classification systems. The method has been validated with an ROC building algorithm and         cross-validation on 15 UCI KDD datasets.               </content></document><document><year>2007</year><authors>G. Blanchard1 | C. SchГ¤fer1| Y. Rozenholc2 | K.-R. MГјller1| 3</authors><title>Optimal dyadic decision trees      </title><content>We introduce a new algorithm building an optimal dyadic decision tree (ODT). The method combines guaranteed performance in         the learning theoretical sense and optimal search from the algorithmic point of view. Furthermore it inherits the explanatory         power of tree approaches, while improving performance over classical approaches such as CART/C4.5, as shown on experiments         on artificial and benchmark data.      </content></document><document><year>2007</year><authors>Tom Fawcett1  | Alex|ru Niculescu-Mizil2 </authors><title>PAV and the ROC convex hull      </title><content>         Classifier calibration is the process of converting classifier scores into reliable probability estimates. Recently, a calibration         technique based on isotonic regression has gained attention within machine learning as a flexible and effective way to calibrate         classifiers. We show that, surprisingly, isotonic regression based calibration using the Pool Adjacent Violators algorithm         is equivalent to the ROC convex hull method.               </content></document><document><year>2007</year><authors>Ata KabГЎn1 </authors><title>Predictive Modelling of Heterogeneous Sequence Collections by Topographic Ordering of Histories      </title><content>         We propose a model-based approach to the twofold problem of prediction and exploratory analysis of heterogeneous symbolic         sequence collections. Our model is based on seeking low entropy local representations joined together with a smooth nonlinear         mixing process. Low entropy components are desirable, as they tend to be both more interpretable and more predictable. The         nonlinear mixing in turn acts as a regulariser, and in addition, it creates a topographic ordering of the sequence histories,         which is useful for exploratory purposes. The combination of these two modelling elements is performed through the generative         probabilistic formalism, which ensures a flexible and technically sound predictive modelling framework. Unlike previous generative         topographic modelling approaches for discrete data, the estimation algorithm associated with our model is designed to scale         to large data sets by exploiting data sparseness. In addition, local convergence is guaranteed without the need for tuning         optimisation parameters or making approximations to the non-Gaussian likelihood. These characteristics make it the first generative         topographic model for discrete symbolic data with large scale real-world applicability. We analyse and discuss the relationship         of our approach with a number of models and methods. We empirically demonstrate robustness against varying sample sizes, leading         to significant improvements in terms of predictive performance over the state of the art. Finally we detail an application         to the prediction and exploratory analysis of a large real-world web navigation sequence collection.               </content></document><document><year>2007</year><authors>Stephen Muggleton1  | Alireza Tamaddoni-Nezhad1 </authors><title>QG/GA: a stochastic search for Progol      </title><content>         Most search techniques within ILP require the evaluation of a large number of inconsistent clauses. However, acceptable clauses         typically need to be consistent, and are only found at the &amp;#8220;fringe&amp;#8221; of the search space. A search approach is presented, based         on a novel algorithm called QG (Quick Generalization). QG carries out a random-restart stochastic bottom-up search which efficiently         generates a consistent clause on the fringe of the refinement graph search without needing to explore the graph in detail.         We use a Genetic Algorithm (GA) to evolve and re-combine clauses generated by QG. In this QG/GA setting, QG is used to seed         a population of clauses processed by the GA. Experiments with QG/GA indicate that this approach can be more efficient than         standard refinement-graph searches, while generating similar or better solutions.               </content></document><document><year>2007</year><authors>Alex|er Schmolck1  | Richard Everson1 </authors><title>Smooth relevance vector machine: a smoothness prior extension of the RVM      </title><content>         Enforcing sparsity constraints has been shown to be an effective and efficient way to obtain state-of-the-art results in regression         and classification tasks. Unlike the support vector machine (SVM) the relevance vector machine (RVM) explicitly encodes the         criterion of model sparsity as a prior over the model weights. However the lack of an explicit prior structure over the weight         variances means that the degree of sparsity is to a large extent controlled by the choice of kernel (and kernel parameters).         This can lead to severe overfitting or oversmoothing&amp;#8212;possibly even both at the same time (e.g. for the multiscale Doppler         data). We detail an efficient scheme to control sparsity in Bayesian regression by incorporating a flexible noise-dependent         smoothness prior into the RVM. We present an empirical evaluation of the effects of choice of prior structure on a selection         of popular data sets and elucidate the link between Bayesian wavelet shrinkage and RVM regression. Our model encompasses the         original RVM as a special case, but our empirical results show that we can surpass RVM performance in terms of goodness of         fit and achieved sparsity as well as computational performance in many cases. The code is freely available.               </content></document><document><year>2007</year><authors>Don Hush1 | Clint Scovel1  | Ingo Steinwart1 </authors><title>Stability of Unstable Learning Algorithms      </title><content>         We introduce graphical learning algorithms and use them to produce bounds on error deviance for unstable learning algorithms         which possess a partial form of stability. As an application we obtain error deviance bounds for support vector machines (SVMs)         with variable offset parameter.               </content></document><document><year>2007</year><authors>Daniel S. Yeung1 | Defeng Wang1 | Wing W. Y. Ng1 | Eric C. C. Tsang1  | Xizhao Wang2 </authors><title>Structured large margin machines: sensitive to data distributions      </title><content>         This paper proposes a new large margin classifier&amp;#8212;the structured large margin machine (SLMM)&amp;#8212;that is sensitive to the structure         of the data distribution. The SLMM approach incorporates the merits of &amp;#8220;structured&amp;#8221; learning models, such as radial basis         function networks and Gaussian mixture models, with the advantages of &amp;#8220;unstructured&amp;#8221; large margin learning schemes, such as         support vector machines and maxi-min margin machines. We derive the SLMM model from the concepts of &amp;#8220;structured degree&amp;#8221; and         &amp;#8220;homospace&amp;#8221;, based on an analysis of existing structured and unstructured learning models. Then, by using Ward&amp;#8217;s agglomerative         hierarchical clustering on input data (or data mappings in the kernel space) to extract the underlying data structure, we         formulate SLMM training as a sequential second order cone programming. Many promising features of the SLMM approach are illustrated,         including its accuracy, scalability, extensibility, and noise tolerance. We also demonstrate the theoretical importance of         the SLMM model by showing that it generalizes existing approaches, such as SVMs and M4s, provides novel insight into learning models, and lays a foundation for conceiving other &amp;#8220;structured&amp;#8221; classifiers.               </content></document><document><year>2007</year><authors>Peter GrГјnwald1  | John Langford2 </authors><title>Suboptimal behavior of Bayes and MDL in classification under misspecification      </title><content>We show that forms of Bayesian and MDL inference that are often applied to classification problems can be inconsistent. This means that there exists a learning problem such that for all amounts of data the generalization errors of the MDL classifier         and the Bayes classifier relative to the Bayesian posterior both remain bounded away from the smallest achievable generalization         error. From a Bayesian point of view, the result can be reinterpreted as saying that Bayesian inference can be inconsistent         under misspecification, even for countably infinite models. We extensively discuss the result from both a Bayesian and an         MDL perspective.      </content></document><document><year>2007</year><authors>Zhihua Zhang1| James T. Kwok2 | Dit-Yan Yeung2 </authors><title>Surrogate maximization/minimization algorithms and extensions      </title><content>         Surrogate maximization (or minimization) (SM) algorithms are a family of algorithms that can be regarded as a generalization         of expectation-maximization (EM) algorithms. An SM algorithm aims at turning an otherwise intractable maximization problem         into a tractable one by iterating two steps. The S-step computes a tractable surrogate function to substitute the original         objective function and the M-step seeks to maximize this surrogate function. Convexity plays a central role in the S-step.         SM algorithms enjoy the same convergence properties as EM algorithms. There are mainly three approaches to the construction         of surrogate functions, namely, by using Jensen&amp;#8217;s inequality, first-order Taylor approximation, and the low quadratic bound         principle. In this paper, we demonstrate the usefulness of SM algorithms by taking logistic regression models, AdaBoost and         the log-linear model as examples. More specifically, by using different surrogate function construction methods, we devise         several SM algorithms, including the standard SM, generalized SM, gradient SM, and quadratic SM algorithms, and their two         variants called the conditional surrogate maximization (CSM) and surrogate conditional maximization (SCM) algorithms.               </content></document><document><year>2007</year><authors>Giovanni Cavallanti1 | NicolГІ Cesa-Bianchi1  | Claudio Gentile2 </authors><title>Tracking the best hyperplane with a simple budget Perceptron      </title><content>Shifting bounds for on-line classification algorithms ensure good performance on any sequence of examples that is well predicted         by a sequence of changing classifiers. When proving shifting bounds for kernel-based classifiers, one also faces the problem         of storing a number of support vectors that can grow unboundedly, unless an eviction policy is used to keep this number under         control. In this paper, we show that shifting and on-line learning on a budget can be combined surprisingly well. First, we         introduce and analyze a shifting Perceptron algorithm achieving the best known shifting bounds while using an unlimited budget.         Second, we show that by applying to the Perceptron algorithm the simplest possible eviction policy, which discards a random         support vector each time a new one comes in, we achieve a shifting bound close to the one we obtained with no budget restrictions.         More importantly, we show that our randomized algorithm strikes the optimal trade-off  between budget B and norm U of the largest classifier in the comparison sequence. Experiments are presented comparing several linear-threshold algorithms         on chronologically-ordered textual datasets. These experiments support our theoretical findings in that they show to what         extent randomized budget algorithms are more robust than deterministic ones when learning shifting target data streams.      </content></document><document><year>2007</year><authors>Adam R. Klivans1  | Alex|er A. Sherstov1 </authors><title>Unconditional lower bounds for learning intersections of halfspaces      </title><content>         We prove new lower bounds for learning intersections of halfspaces, one of the most important concept classes in computational         learning theory. Our main result is that any statistical-query algorithm for learning the intersection of                    halfspaces in n dimensions must make                    queries. This is the first non-trivial lower bound on the statistical query dimension for this concept class (the previous         best lower bound was n                     &amp;#937;(log&amp;#8201;n)). Our lower bound holds even for intersections of low-weight halfspaces. In the latter case, it is nearly tight.                                             We also show that the intersection of two majorities (low-weight halfspaces) cannot be computed by a polynomial threshold               function (PTF) with fewer than n                                 &amp;#937;(log&amp;#8201;n/log&amp;#8201;log&amp;#8201;n) monomials. This is the first super-polynomial lower bound on the PTF length of this concept class, and is nearly optimal.               For intersections of k=&amp;#969;(log&amp;#8201;n) low-weight halfspaces, we improve our lower bound to                                which too is nearly optimal. As a consequence, intersections of even two halfspaces are not computable by polynomial-weight               PTFs, the most expressive class of functions known to be efficiently learnable via Jackson&amp;#8217;s Harmonic Sieve algorithm. Finally,               we report our progress on the weak learnability of intersections of halfspaces under the uniform distribution.                           </content></document><document><year>2005</year><authors>Gregory F. Cooper1  | Edward Herskovits2</authors><title>A Bayesian method for the induction of probabilistic networks from data</title><content>This paper presents a Bayesian method for constructing probabilistic networks from databases. In particular, we focus on constructing Bayesian belief networks. Potential applications include computer-assisted hypothesis testing, automated scientific discovery, and automated construction of probabilistic expert systems. We extend the basic method to handle missing data and hidden (latent) variables. We show how to perform probabilistic inference by averaging over the inferences of multiple belief networks. Results are presented of a preliminary evaluation of an algorithm for constructing a belief network from a database of cases. Finally, we relate the methods in this paper to previous work, and we discuss open problems.</content></document><document><year>2005</year><authors>Arthur J. Nevins1</authors><title>A branch and bound incremental conceptual clusterer</title><content>A computer program is described that is capable of learning multiple concepts and their structural descriptions from observations of examples. It decomposes this conceptual clustering problem into two modules. The first module is concerned with forming a generalization from a pair of examples by extracting their common structure and calculating an information measure for each structural description. The second module, which is the subject of this paper, incrementally incorporates these generalizations into a hierarchy of concepts. This second module operates without reference to any underlying representation language and utilizes only the information measure provided by the first module, while employing a branch and bound procedure to search the hierarchy for concepts from which to form new clusters. This ability to search the hierarchy is used as the basis of a hill climbing strategy which has as its goal the avoidance of local peaks so as to reduce the sensitivity of the program to the order in which the observations are encountered.</content></document><document><year>2005</year><authors>Thomas G. Dietterich1 | Hermann Hild2  | Ghulum Bakiri3</authors><title>A comparison of ID3 and backpropagation for English text-to-speech mapping</title><content>The performance of the error backpropagation (BP) and ID3 learning algorithms was compared on the task of mapping English text to phonemes and stresses. Under the distributed output code developed by Sejnowski and Rosenberg, it is shown that BP consistently out-performs ID3 on this task by several percentage points. Three hypotheses explaining this difference were explored: (a) ID3 is overfitting the training data, (b) BP is able to share hidden units across several output units and hence can learn the output units better, and (c) BP captures statistical information that ID3 does not. We conclude that only hypothesis (c) is correct. By augmenting ID3 with a simple statistical learning procedure, the performance of BP can be closely matched. More complex statistical procedures can improve the performance of both BP and ID3 substantially in this domain.</content></document><document><year>2005</year><authors>Alberto Segre1 | Charles Elkan2  | Alex|er Russell3 </authors><title>A Critical Look at Experimental Evaluations of EBL</title><content>A number of experimental evaluations of explanation-based learning(EBL) have been reported in the literature on machine learning. A close examination of the design of these experiments reveals certain methodological problems that could affect the conclusions drawn from the experiments. This article analyzes some of the more common methodological difficulties, and illustrates them using selected previous studies.</content></document><document><year>2005</year><authors>William C. Schmidt  | Charles X. Ling </authors><title>A Decision-Tree Model of Balance Scale Development</title><content>We present an alternative model of human cognitive development on the balance scale task. Study of this task has inspired a wide range of human and computational work. The task requires that children predict the outcome of placing a discrete number of weights at various distances on either side of a fulcrum. Our model, which features the symbolic learning algorithm C4.5 as a transition mechanism, exhibits regularities found in the human data including orderly stage progression, U-shaped development, and the torque difference effect. Unlike previous successful models of the task, the current model uses a single free parameter, is not restricted in the size of the balance scale that it can accommodate, and does not require the assumption of a highly structured output representation or a training environment biased towards weight or distance information. The model makes a number of predictions differing from those of previous computational efforts.</content></document><document><year>2005</year><authors>R. L&amp;oacute pez De M&amp;aacute ntaras1 </authors><title>A Distance-Based Attribute Selection Measure for Decision Tree Induction</title><content>This note introduces a new attribute selection measure for ID3-like inductive algorithms. This measure is based on a distance between partitions such that the selected attribute in a node induces the partition which is closest to the correct partition of the subset of training examples corresponding to this node. The relationship of this measure with Quinlan''s information gain is also established. It is also formally proved that our distance is not biased towards attributes with large numbers of values. Experimental studies with this distance confirm previously reported results showing that the predictive accuracy of induced decision trees is not sensitive to the goodness of the attribute selection measure. However, this distance produces smaller trees than the gain ratio measure of Quinlan, especially in the case of data whose attributes have significantly different numbers of values.</content></document><document><year>2005</year><authors>S. S. Keerthi1 | K. B. Duan2 | S. K. Shevade3  | A. N. Poo4 </authors><title>A Fast Dual Algorithm for Kernel Logistic Regression      </title><content>This paper gives a new iterative algorithm for kernel logistic regression. It is based on the solution of a dual problem using         ideas similar to those of the Sequential Minimal Optimization algorithm for Support Vector Machines. Asymptotic convergence         of the algorithm is proved. Computational experiments show that the algorithm is robust and fast. The algorithmic ideas can         also be used to give a fast dual algorithm for solving the optimization problem arising in the inner loop of Gaussian Process         classifiers.      </content></document><document><year>2005</year><authors>Michael J. Pazzani1  | Wendy Sarrett1 </authors><title>A framework for average case analysis of conjunctive learning algorithms</title><content>We present an approach to modeling the average case behavior of learning algorithms. Our motivation is to predict the expected accuracy of learning algorithms as a function of the number of training examples. We apply this framework to a purely empirical learning algorithm, (the one-sided algorithm for pure conjunctive concepts), and to an algorithm that combines empirical and explanation-based learning. The model is used to gain insight into the behavior of these algorithms on a series of problems. Finally, we evaluate how well the average case model performs when the training examples violate the assumptions of the model.</content></document><document><year>2005</year><authors>Wray Buntine2| 1  | Tim Niblett2 </authors><title>A further comparison of splitting rules for decision-tree induction</title><content>One approach to learning classification rules from examples is to build decision trees. A review and comparison paper by Mingers (Mingers, 1989) looked at the first stage of tree building, which uses a splitting rule to grow trees with a greedy recursive partitioning algorithm. That paper considered a number of different measures and experimentally examined their behavior on four domains. The main conclusion was that a random splitting rule does not significantly decrease classificational accuracy. This note suggests an alternative experimental method and presents additional results on further domains. Our results indicate that random splitting leads to increased error. These results are at variance with those presented by Mingers.</content></document><document><year>2005</year><authors>Larry Rendell1 </authors><title>A General Framework for Induction and a Study of Selective Induction</title><content>This paper has two major parts. The first is an extensive analysis of the problem of induction, and the second part is a detailed study of selective induction. Throughout the paper we integrate a number of notions, mainly from artificial intelligence, but also from pattern recognition and cognitive psychology. The result is a synthetic view which exploits uncertainty, task-guidance, and biases such as language restriction. Some of the main themes and contributions are as follows. (1) Practical induction is really a problem of efficacy and efficiency (power). (2) Search in a space of hypothetical concepts is governed by a credibility function which combines various knowledge sources in a single subjective probability or belief measure . (3) The amount of knowledge supplied by various sources can often be quantified; these sources include various biases and the learning system itself. (4) Induction is equivalent to discovery of a utility function u, which captures the purpose or goal of induction. (5) The difficulty of induction may be characterized by the form of u. Smooth or coherent functions mean selective induction, which has had the most attention in machine learning. (6) Systems for selective induction are more similar than commonly understood. By juxtaposing them we can discover similarities and improvements. (7) Our analysis suggests a number of incipient principles for powerful induction.</content></document><document><year>2005</year><authors>Glenn A. Iba </authors><title>A Heuristic Approach to the Discovery of Macro-Operators</title><content>This paper describes a heuristic approach to the discovery of useful macro-operators (macros) in problem solving. The approach has been implemented in a program, MACLEARN, that has three parts: macro-proposer, static filter, and dynamic filter. Learning occurs during problem solving, so that performance improves in the course of a single problem trial. Primitive operators and macros are both represented within a uniform representational framework that is closed under composition. This means that new macros can be defined in terms of others, which leads to a definitional hierarchy. The representation also supports the transfer of macros to related problems. MACLEARN is embedded in a supporting system that carries out best-first search. Experiments in macro learning were conducted for two classes of problems: peg solitaire (generalized Hi-Q puzzle), and tile sliding (generalized Fifteen puzzle). The results indicate that MACLEARN''S filtering heuristics all improve search performance, sometimes dramatically. When the system was given practice on simpler training problems, it learned a set of macros that led to successful solutions of several much harder problems.</content></document><document><year>2005</year><authors>Feng Zhang1 </authors><title>A High Order Cumulants Based Multivariate Nonlinear Blind Source Separation Method      </title><content>This article addresses the problem of identifying multiple linear and nonlinear patterns from multivariate noisy data represented         by an additive model. Following the proposed nonlinear model, the blind source separation (BSS) criterion, as a function of         high-order cumulants, is shown to produce a block-structured joint cumulant matrix by an orthogonal rotation. An intuitive         interpretation of this criterion is to rotate the elements of whitened principal component analysis (PCA) scores such that         they are as independent as possible. The resulting optimal joint cumulant matrix contains diagonal &amp;#8220;blocks&amp;#8221; that correspond         to the linear and nonlinear patterns caused by independent sources, from which linear patterns are recognized as in linear         BSS. The nonlinear patterns are identified by extracting their lower-dimensional manifolds via the principal curves method         and then transforming back to the original data space. As illustrated in the experimental study, the estimated linear and         nonlinear patterns will provide more accurate diagnosing of the root causes that contribute to the observed variability in         multivariate manufacturing.      </content></document><document><year>2005</year><authors>Cezary Z. Janikow1 </authors><title>A knowledge-intensive genetic algorithm for supervised learning</title><content>Supervised learning in attribute-based spaces is one of the most popular machine learning problems studied and, consequently, has attracted considerable attention of the genetic algorithm community. The fullmemory approach developed here uses the same high-level descriptive language that is used in rule-based systems. This allows for an easy utilization of inference rules of the well-known inductive learning methodology, which replace the traditional domain-independent operators and make the search task-specific. Moreover, a closer relationship between the underlying task and the processing mechanisms provides a setting for an application of more powerful task-specific heuristics. Initial results obtained with a prototype implementation for the simplest case of single concepts indicate that genetic algorithms can be effectively used to process high-level concepts and incorporate task-specific knowledge. The method of abstracting the genetic algorithm to the problem level, described here for the supervised inductive learning, can be also extended to other domains and tasks, since it provides a framework for combining recently popular genetic algorithm methods with traditional problem-solving methodologies. Moreover, in this particular case, it provides a very powerful tool enabling study of the widely accepted but not so well understood inductive learning methodology.</content></document><document><year>2005</year><authors>Claudio Carpineto1  | Giovanni Romano</authors><title>A Lattice Conceptual Clustering System and Its Application to Browsing Retrieval</title><content>The theory of concept (or Galois) lattices provides a simple and formal approach to conceptual clustering. In this paper we present GALOIS, a system that automates and applies this theory. The algorithm utilized by GALOIS to build a concept lattice is incremental and efficient, each update being done in time at most quadratic in the number of objects in the lattice. Also, the algorithm may incorporate background information into the lattice, and through clustering, extend the scope of the theory. The application we present is concerned with information retrieval via browsing, for which we argue that concept lattices may represent major support structures. We describe a prototype user interface for browsing through the concept lattice of a document-term relation, possibly enriched with a thesaurus of terms. An experimental evaluation of the system performed on a medium-sized bibliographic database shows good retrieval performance and a significant improvement after the introduction of background knowledge.</content></document><document><year>2005</year><authors>Kenji Yamanishi1 </authors><title>A learning criterion for stochastic rules</title><content>This paper proposes a learning criterion for stochastic rules. This criterion is developed by extending Valiant''s PAC (Probably Approximately Correct) learning model, which is a learning criterion for deterministic rules. Stochastic rules here refer to those which probabilistically asign a number of classes, {Y}, to each attribute vector X. The proposed criterion is based on the idea that learning stochastic rules may be regarded as probably approximately correct identification of conditional probability distributions over classes for given input attribute vectors. An algorithm (an MDL algorithm) based on the MDL (Minimum Description Length) principle is used for learning stochastic rules. Specifically, for stochastic rules with finite partitioning (each of which is specified by a finite number of disjoint cells of the domain and a probability parameter vector associated with them), this paper derives target-dependent upper bounds and worst-case upper bounds on the sample size required by the MDL algorithm to learn stochastic rules with given accuracy and confidence. Based on these sample size bounds, this paper proves polynomial-sample-size learnability of stochastic decision lists (which are newly proposed in this paper as a stochastic analogue of Rivest''s decision lists) with at mostk literals (k is fixed) in each decision, and polynomial-sample-size learnability of stochastic decision trees (a stochastic analogue of decision trees) with at mostk depth. Sufficient conditions for polynomial-sample-size learnability and polynomial-time learnability of any classes of stochastic rules with finite partitioning are also derived.</content></document><document><year>2005</year><authors>Steven Salzberg1 </authors><title>A Nearest Hyperrectangle Learning Method</title><content>This paper presents a theory of learning called nested generalized exemplar (NGE) theory, in which learning is accomplished by storing objects in Euclidean n-space, En, as hyperrectangles. The hyperrectangles may be nested inside one another to arbitrary depth. In contrast to generalization processes that replace symbolic formulae by more general formulae, the NGE algorithm modifies hyperrectangles by growing and reshaping them in a well-defined fashion. The axes of these hyperrectangles are defined by the variables measured for each example. Each variable can have any range on the real line; thus the theory is not restricted to symbolic or binary values.This paper describes some advantages and disadvantages of NGE theory, positions it as a form of exemplar-based learning, and compares it to other inductive learning theories. An implementation has been tested in three different domains, for which results are presented below: prediction of breast cancer, classification of iris flowers, and prediction of survival times for heart attack patients. The results in these domains support the claim that NGE theory can be used to create compact representations with excellent predictive accuracy.</content></document><document><year>2005</year><authors>Haim Shvaytser1 </authors><title>A Necessary Condition for Learning from Positive Examples</title><content>We present a simple combinatorial criterion for determining concept classes that cannot be learned in the sense of Valiant from a polynomial number of positive-only examples. The criterion is applied to several types of Boolean formulae in conjunctive and disjunctive normal form, to the majority function, to graphs with large connected components, and to a neural network with a single threshold unit. All are shown to be nonlearnable from positive-only examples.</content></document><document><year>2005</year><authors>Ahmad Emami1  | Frederick Jelinek1 </authors><title>A Neural Syntactic Language Model</title><content>This paper presents a study of using neural probabilistic models in a syntactic based language model. The neural probabilistic model makes use of a distributed representation of the items in the conditioning history, and is powerful in capturing long dependencies. Employing neural network based models in the syntactic based language model enables it to use efficiently the large amount of information available in a syntactic parse in estimating the next word in a string. Several scenarios of integrating neural networks in the syntactic based language model are presented, accompanied by the derivation of the training procedures involved. Experiments on the UPenn Treebank and the Wall Street Journal corpus show significant improvements in perplexity and word error rate over the baseline SLM. Furthermore, comparisons with the standard and neural net based N-gram models with arbitrarily long contexts show that the syntactic information is in fact very helpful in estimating the word string probability. Overall, our neural syntactic based model achieves the best published results in perplexity and WER for the given data sets.</content></document><document><year>2005</year><authors>J&amp;ouml rg-Uwe Kietz1  | Katharina Morik2 </authors><title>A Polynomial Approach to the Constructive Induction of Structural Knowledge</title><content>The representation formalism as well as the representation language is of great importance for the success of machine learning. The representation formalism should be expressive, efficient, useful, and applicable. First-order logic needs to be restricted in order to be efficient for inductive and deductive reasoning. In the field of knowledge representation, term subsumption formalisms have been developed which are efficient and expressive. In this article, a learning algorithm, KLUSTER, is described that represents concept definitions in this formalism. KLUSTER enhances the representation language if this is necessary for the discrimination of concepts. Hence, KLUSTER is a constructive induction program. KLUSTER builds the most specific generalization and a most general discrimination in polynomial time. It embeds these concept learning problems into the overall task of learning a hierarchy of concepts.</content></document><document><year>2005</year><authors>Jos&amp;eacute  Del R. Mill&amp;aacute n1  | Carme Torras2 </authors><title>A reinforcement connectionist approach to robot path finding in non-maze-like environments</title><content>This paper presents a reinforcement connectionist system which finds and learns the suitable situation-action rules so as to generate feasible paths for a point robot in a 2D environment with circular obstacles. The basic reinforcement algorithm is extended with a strategy for discovering stable solution paths. Equipped with this strategy and a powerful codification scheme, the path-finder (i) learns quickly, (ii) deals with continuous-valued inputs and outputs, (iii) exhibits good noise-tolerance and generalization capabilities, (iv) copes with dynamic environments, and (v) solves an instance of the path finding problem with strong performance demands.</content></document><document><year>2005</year><authors>Shin Ishii1 | Hajime Fujita2| Masaoki Mitsutake2| Tatsuya Yamazaki3| Jun Matsuda4 | Yoichiro Matsuno5</authors><title>A Reinforcement Learning Scheme for a Partially-Observable Multi-Agent Game</title><content>We formulate an automatic strategy acquisition problem for the multi-agent card game Hearts as a reinforcement learning problem. The problem can approximately be dealt with in the framework of a partially observable Markov decision process (POMDP) for a single-agent system. Hearts is an example of imperfect information games, which are more difficult to deal with than perfect information games. A POMDP is a decision problem that includes a process for estimating unobservable state variables. By regarding missing information as unobservable state variables, an imperfect information game can be formulated as a POMDP. However, the game of Hearts is a realistic problem that has a huge number of possible states, even when it is approximated as a single-agent system. Therefore, further approximation is necessary to make the strategy acquisition problem tractable. This article presents an approximation method based on estimating unobservable state variables and predicting the actions of the other agents. Simulation results show that our reinforcement learning method is applicable to such a difficult multi-agent problem.</content></document><document><year>2005</year><authors>Michael Pazzani1 </authors><title>A reply to Cohen''s book review of Creating a Memory of Causal Relationships</title><content>Progress in machine learning must consist of periods of exploration followed by periods of more thorough careful investigation of issues raised during exploration. The research reported inCreating a Memory of Causal Relationships is exploratory in that it addresses a problem that was not previously investigated in the mainstream of machine learning research. However, I feel that the problem studied was worthy of investigation and is worthy of continued investigation since it corresponds to an important part of the human learning process.</content></document><document><year>2005</year><authors>B. K. Natarajan1</authors><title>A reply to Hellerstein''s book review of Machine Learning: A Theoretical Approach</title><content>Without Abstract</content></document><document><year>2005</year><authors>J. Stephen Judd1</authors><title>A reply to Honavar''s book review of Neural Network Design and the Complexity of Learning</title><content>Without Abstract</content></document><document><year>2005</year><authors>Nada Lavra1  | Sao Deroski1 </authors><title>A Reply to Pazzani's Book Review of "Inductive Logic Programming: Techniques and Applications"</title><content>Without Abstract</content></document><document><year>2005</year><authors>Ray Bareiss1 </authors><title>A Reply To Reich's Book Review of Exemplar-Based Knowledge Acquisition</title><content>Without Abstract</content></document><document><year>2005</year><authors>Dean A. Pomerleau1</authors><title>A reply to Towell''s book review of Neural Network Perception for Mobile Robot Guidance</title><content>Without Abstract</content></document><document><year>2005</year><authors>Steven Minton1</authors><title>A Reply to Zito-Wolf''s Book Review of Learning Search Control Knowledge: An Explanation-Based Approach</title><content>Without Abstract</content></document><document><year>2005</year><authors>Tom Fawcett1  | Peter A. Flach2 </authors><title>A Response to Webb and Tings On the Application of ROC Analysis to Predict Classification Performance Under Varying Class Distributions</title><content>In an article in this issue, Webb and Ting criticize ROC analysis for its inability to handle certain changes in class distributions. They imply that the ability of ROC graphs to depict performance in the face of changing class distributions has been overstated. In this editorial response, we describe two general types of domains and argue that Webb and Tings concerns apply primarily to only one of them. Furthermore, we show that there are interesting real-world domains of the second type, in which ROC analysis may be expected to hold in the face of changing class distributions.</content></document><document><year>2005</year><authors>Russell Greiner1 | Bernard Silver2 | Sue Becker1  | Michael Gr&amp;uuml ninger1 </authors><title>A Review of Machine Learning at AAAI-87</title><content>Without Abstract</content></document><document><year>2005</year><authors>Rogers P. Hall | Brian Falkenhainer | Nicholas Flann| Steve Hampson | Robert Reinke | Jeff Shrager | Michael H. Sims  | Prasad Tadepalli </authors><title>A Review of the Fourth International Workshop on Machine Learning</title><content>Without Abstract</content></document><document><year>2005</year><authors>Nicholas S. Flann1 | Thomas G. Dietterich1</authors><title>A Study of Explanation-Based Methods for Inductive Learning</title><content>This paper formalizes a new learning-from-examples problem: identifying a correct concept definition from positive examples such that the concept is some specialization of a target concept defined by a domain theory. It describes an empirical study that evaluates three methods for solving this problem: explanation-based generalization (EBG), multiple example explanation-based generalization (mEBG), and a new method, induction over explanations (IOE). The study demonstrates that the two existing methods (EBG and mEBG) exhibit two shortcomings: (a) they rarely identify the correct definition, and (b) they are brittle in that their success depends greatly on the choice of encoding of the domain theory rules. The study demonstrates that the new method, IOE, does not exhibit these shortcomings. This method applies the domain theory to construct explanations from multiple training examples as in mEBG, but forms the concept definition by employing a similarity-based generalization policy over the explanations. IOE has the advantage that an explicit domain theory can be exploited to aid the learning process, the dependence on the initial encoding of the domain theory is significantly reduced, and the correct concepts can be learned from few examples. The study evaluates the methods in the context of an implemented system, called Wyl2, which learns a variety of concepts in chess including skewer and knight-fork.</content></document><document><year>2005</year><authors>George G. Robertson1| 2  | Rick L. Riolo2 </authors><title>A Tale of Two Classifier Systems</title><content>This paper describes two classifier systems that learn. These are rule-based systems that use genetic algorithms, which are based on an analogy with natural selection and genetics, as their principal learning mechanism, and an economic model as their principal mechanism for apportioning credit. CFS-C is a domain-independent learning system that has been widely tested on serial computers. CFS is a parallel implementation of CFS-C that makes full use of the inherent parallelism of classifier systems and genetic algorithms, and that allows the exploration of large-scale tasks that were formerly impractical. As with other approaches to learning, classifier systems in their current form work well for moderately-sized tasks but break down for larger tasks. In order to shed light on this issue, we present several empirical studies of known issues in classifier systems, including the effects of population size, the actual contribution of genetic algorithms, the use of rule chaining in solving higher-order tasks, and issues of task representation and dynamic population convergence. We conclude with a discussion of some major unresolved issues in learning classifier systems and some possible approaches to making them more effective on complex tasks.</content></document><document><year>2005</year><authors>Jyh-Han Lin1 | Jeffrey Scott Vitter2</authors><title>A Theory for Memory-Based Learning</title><content>A memory-based learning system is an extended memory management system that decomposes the input space either statically or dynamically into subregions for the purpose of storing and retrieving functional information. The main generalization techniques employed by memory-based learning systems are the nearest-neighbor search, space decomposition techniques, and clustering. Research on memory-based learning is still in its early stage. In particular, there are very few rigorous theoretical results regarding memory requirement, sample size, expected performance, and computational complexity. In this paper, we propose a model for memory-based learning and use it to analyze several methods&amp;#x2014; -covering, hashing, clustering, tree-structured clustering, and receptive-fields&amp;#x2014;for learning smooth functions. The sample size and system complexity are derived for each method. Our model is built upon the generalized PAC learning model of Haussler (Haussler, 1989) and is closely related to the method of vector quantization in data compression. Our main result is that we can build memory-based learning systems using new clustering algorithms (Lin &amp;amp; Vitter, 1992a) to PAC-learn in polynomial time using only polynomial storage in typical situations.</content></document><document><year>2005</year><authors>Jyh-Han Lin1  | Jeffrey Scott Vitter2 </authors><title>A theory for memory-based learning</title><content>A memory-based learning system is an extended memory management system that decomposes the input space either statically or dynamically into subregions for the purpose of storing and retrieving functional information. The main generalization techniques employed by memory-based learning systems are the nearest-neighbor search, space decomposition techniques, and clustering. Research on memory-based learning is still in its early stage. In particular, there are very few rigorous theoretical results regarding memory requirement, sample size, expected performance, and computational complexity. In this paper, we propose a model for memory-based learning and use it to analyze several methods&amp;#x2014; -covering, hashing, clustering, tree-structured clustering, and receptive-fields&amp;#x2014;for learning smooth functions. The sample size and system complexity are derived for each method. Our model is built upon the generalized PAC learning model of Haussler (Haussler, 1989) and is closely related to the method of vector quantization in data compression. Our main result is that we can build memory-based learning systems using new clustering algorithms (Lin &amp;amp; Vitter, 1992a) to PAC-learn in polynomial time using only polynomial storage in typical situations.</content></document><document><year>2005</year><authors>Jan M. Zytkow | Herbert A. Simon</authors><title>A Theory of Historical Discovery: The Construction of Componential Models</title><content>One of the major goals of 18th century chemistry was to determine the components of substances. In this paper we describe STAHL, a system that models significant portions of 18th century reasoning about compositional models. The system includes a number of heuristics for generating componential models from reactions, as well as error recovery mechanisms for dealing with inconsistent results. STAHL processes chemical reactions incrementally, and is therefore capable of reconstructing extended historic episodes, such as the century-long development of the phlogiston theory. We evaluate STAHL&amp;#x2019;s heuristics in the light of historical data, and conclude that the same reasoning mechanisms account for a variety of historical achievements, including Black&amp;#x2019;s models of mild alkali and Lavoisier&amp;#x2019;s oxygen theory. STAHL explains the generation of competing accounts of the same reactions, since the system&amp;#x2019;s reasoning chain depends on knowledge it has accumulated at earlier stages.</content></document><document><year>2005</year><authors>Daniel N. Osherson1 | Michael Stob2 | Scott Weinstein3</authors><title>A universal method of scientific inquiry</title><content>A paradigm of scientific discovery is defined within a first-order logical framework. Within this paradigm, the concept of successful scientific inquiry is formalized and investigated. Among other results, it is shown that a simple method of scientific inquiry is universal in the sense that it leads to success on every problem for which success is in principle possible.</content></document><document><year>2005</year><authors>Kurt Vanlehn1  | William Ball2 </authors><title>A Version Space Approach to Learning Context-free Grammars</title><content>In principle, the version space approach can be applied to any induction problem. However, in some cases the representation language for generalizations is so powerful that (1) some of the update functions for the version space are not effectively computable, and (2) the version space contains infinitely many generalizations. The class of context-free grammars is a simple representation that exhibits these problems. This paper presents an algorithm that solves both problems for this domain. Given a sequence of strings, the algorithm incrementally constructs a data structure that has nearly all the beneficial properties of a version space. The algorithm is fast enough to solve small induction problems completely, and it serves as a framework for biases that permit the solution of larger problems heuristically. The same basic approach may be applied to representations that include context-free grammars as special cases, such as And-Or graphs, production systems, and Horn clauses.</content></document><document><year>2005</year><authors>Scott Cost1  | Steven Salzberg1 </authors><title>A Weighted Nearest Neighbor Algorithm for Learning with Symbolic Features</title><content>In the past, nearest neighbor algorithms for learning from examples have worked best in domains in which all features had numeric values. In such domains, the examples can be treated as points and distance metrics can use standard definitions. In symbolic domains, a more sophisticated treatment of the feature space is required. We introduce a nearest neighbor algorithm for learning in domains with symbolic features. Our algorithm calculates distance tables that allow it to produce real-valued distances between instances, and attaches weights to the instances to further modify the structure of feature space. We show that this technique produces excellent classification accuracy on three problems that have been studied by machine learning researchers: predicting protein secondary structure, identifying DNA promoter sequences, and pronouncing English text. Direct experimental comparisons with the other learning algorithms show that our nearest neighbor algorithm is comparable or superior in all three domains. In addition, our algorithm has advantages in training speed, simplicity, and perspicuity. We conclude that experimental evidence favors the use and continued development of nearest neighbor algorithms for domains such as the ones studied here.</content></document><document><year>2005</year><authors>Scott Cost1  | Steven Salzberg1 </authors><title>A weighted nearest neighbor algorithm for learning with symbolic features</title><content>In the past, nearest neighbor algorithms for learning from examples have worked best in domains in which all features had numeric values. In such domains, the examples can be treated as points and distance metrics can use standard definitions. In symbolic domains, a more sophisticated treatment of the feature space is required. We introduce a nearest neighbor algorithm for learning in domains with symbolic features. Our algorithm calculates distance tables that allow it to produce real-valued distances between instances, and attaches weights to the instances to further modify the structure of feature space. We show that this technique produces excellent classification accuracy on three problems that have been studied by machine learning researchers: predicting protein secondary structure, identifying DNA promoter sequences, and pronouncing English text. Direct experimental comparisons with the other learning algorithms show that our nearest neighbor algorithm is comparable or superior in all three domains. In addition, our algorithm has advantages in training speed, simplicity, and perspicuity. We conclude that experimental evidence favors the use and continued development of nearest neighbor algorithms for domains such as the ones studied here.</content></document><document><year>2005</year><authors>Philip Laird1  | Evan Gamble2</authors><title>A PAC Algorithm for Making Feature Maps</title><content>Kohonen and others have devised network algorithms for computing so-called topological feature maps. We describe a new algorithm, called the CDF-Inversion(CDFI) Algorithm, that can be used to learn feature maps and, in the process, approximate an unknown probability distribution to within any specified accuracy. The primary advantages of the algorithm over previous feature-map algorithms are that it is simple enough to analyze mathematically for correctness and efficiency, and that it distributes the points of the map evenly, in a sense that can be made rigorous. Like other vector-quantization algorithms it is potentially useful for many applications, including monitoring and statistical modeling. While not a network algorithm, the CDFI algorithm is well-suited to implementation on parallel computers.</content></document><document><year>2005</year><authors>William W. Cohen1</authors><title>Abductive Explanation-Based Learning: A Solution to the Multiple Inconsistent Explanation Problem</title><content>One problem which frequently surfaces when applying explanation-based learning (EBL) to imperfect theories is the multiple inconsistent explanation problem. The multiple inconsistent explanation problem occurs when a domain theory produces multiple explanations for a training instance, only some of which are correct. Domain theories which suffer from the multiple inconsistent explanation problem can occur in many different contexts, such as when some information is missing and must be assumed: since such assumptions can be incorrect, incorrect explanations can be constructed. This paper proposes an extension of explanation-based learning, called abductive explanation-based learning (A-EBL) which solves the multiple inconsistent explanation problem by using set covering techniques and negative examples to choose among the possible explanations of a training example. It is shown by formal analysis that A-EBL has convergence properties that are only logarithmically worse than EBL/TS, a formalization of a certain type of knowledge-level EBL; A-EBL is also proven to be computationally efficient, assuming that the domain theory is tractable. Finally, experimental results are reported on an application of A-EBL to learning correct rules for opening bids in the game of contract bridge given examples and an imperfect domain theory.</content></document><document><year>2005</year><authors>William W. Cohen1 </authors><title>Abductive explanation-based learning: A solution to the multiple inconsistent explanation problem</title><content>One problem which frequently surfaces when applying explanation-based learning (EBL) to imperfect theories is themultiple inconsistent explanation problem. The multiple inconsistent explanation problem occurs when a domain theory produces multiple explanations for a training instance, only some of which are correct. Domain theories which suffer from the multiple inconsistent explanation problem can occur in many different contexts, such as when some information is missing and must be assumed: since such assumptions can be incorrect, incorrect explanations can be constructed. This paper proposes an extension of explanation-based learning, calledabductive explanation-based learning (A-EBL) which solves the multiple inconsistent explanation problem by using set covering techniques and negative examples to choose among the possible explanations of a training example. It is shown by formal analysis that A-EBL has convergence properties that are only logarithmically worse than EBL/TS, a formalization of a certain type of knowledge-level EBL; A-EBL is also proven to be computationally efficient, assuming that the domain theory is tractable. Finally, experimental results are reported on an application of A-EBL to learning correct rules for opening bids in the game of contract bridge given examples and an imperfect domain theory.</content></document><document><year>2005</year><authors>Joel D. Martin1  | Dorrit O. Billman2 </authors><title>Acquiring and combining overlapping concepts</title><content>This article presentsOloc, an incremental concept formation system that learns and uses overlapping concepts.Oloc learns probabilistic concepts that have overlapping extensions and does so to maximize expected predictive accuracy. When making predictions,Oloc can combine multiple overlapping concepts.</content></document><document><year>2005</year><authors>Jude W. Shavlik1 </authors><title>Acquiring Recursive and Iterative Concepts with Explanation-Based Learning</title><content>In explanation-based learning, a specific problem''s solution is generalized into a form that can be later used to solve conceptually similar problems. Most research in explanation-based learning involves relaxing constraints on the variables in the explanation of a specific example, rather than generalizing the graphical structure of the explanation itself. However, this precludes the acquisition of concepts where an iterative or recursive process is implicitly represented in the explanation by a fixed number of applications. This paper presents an algorithm that generalizes explanation structures and reports empirical results that demonstrate the value of acquiring recursive and iterative concepts. The BAGGER2 algorithm learns recursive and iterative concepts, integrates results from multiple examples, and extracts useful subconcepts during generalization. On problems where learning a recursive rule is not appropriate, the system produces the same result as standard explanation-based methods. Applying the learned recursive rules only requires a minor extension to a PROLOG-like problem solver, namely, the ability to explicitly call a specific rule. Empirical studies demonstrate that generalizing the structure of explanations helps avoid the recently reported negative effects of learning.</content></document><document><year>2005</year><authors>R|olph M. Jones1  | Kurt Vanlehn2 </authors><title>Acquisition of children''s addition strategies: A model of impasse-free, knowledge-level learning</title><content>When children learn to add, they count on their fingers, beginning with the simpleSum Strategy and gradually developing the more sophisticated and efficientMin strategy. The shift fromSum toMin provides an ideal domain for the study of naturally occurring discovery processes in cognitive skill acquisition. TheSum-to-Min transition poses a number of challenges for machine-learning systems that would model the phenomenon. First, in addition to theSum andMin strategies, Siegler and Jenkins (1989) found that children exhibit two transitional strategies, but not a strategy proposed by an earlier model. Second, they found that children do not invent theMin strategy in response to impasses, or gaps in their knowledge. Rather,Min develops spontaneously and gradually replaces earlier strategies. Third, intricate structural differences between theSum andMin strategies make it difficult, if not impossible, for standard, symbol-level machine-learning algorithms to model the transition. We present a computer model, calledGips, that meets these challenges.Gips combines a relatively simple algorithm for problem solving with a probabilistic learning algorithm that performs symbol-level and knowledge-level learning, both in the presence and absence of impasses. In addition,Gips makes psychologically plausible demands on local processing and memory. Most importantly, the system successfully models the shift fromSum toMin, as well as the two transitional strategies found by Siegler and Jenkins.</content></document><document><year>2005</year><authors>Marcos Salganicoff1 | Lyle H. Ungar2  | Ruzena Bajcsy2 </authors><title>Active Learning for Vision-Based Robot Grasping</title><content>Reliable vision-based grasping has proved elusive outside of controlled environments. One approach towards building more flexible and domain-independent robot grasping systems is to employ learning to adapt the robot's perceptual and motor system to the task. However, one pitfall in robot perceptual and motor learning is that the cost of gathering the learning set may be unacceptably high. Active learning algorithms address this shortcoming by intelligently selecting actions so as to decrease the number of examples necessary to achieve good performance and also avoid separate training and execution phases, leading to higher autonomy. We describe the IE-ID3 algorithm, which extends the Interval Estimation (IE) active learning approach from discrete to real-valued learning domains by combining IE with a classification tree learning algorithm (ID-3). We present a robot system which rapidly learns to select the grasp approach directions using IE-ID3 given simplified superquadric shape approximations of objects. Initial results on a small set of objects show that a robot with a laser scanner system can rapidly learn to pick up new objects, and simulation studies show the superiority of the active learning approach for a simulated grasping task using larger sets of objects. Extensions of the approach and future areas of research incorporating more sophisticated perceptual and action representation are discussed</content></document><document><year>2005</year><authors>S.R. Kulkarni1| S.K. Mitter2 | J.N. Tsitsiklis2</authors><title>Active Learning Using Arbitrary Binary Valued Queries</title><content>The original and most widely studied PAC model for learning assumes a passive learner in the sense that the learner plays no role in obtaining information about the unknown concept. That is, the samples are simply drawn independently from some probability distribution. Some work has been done on studying more powerful oracles and how they affect learnability. To find bounds on the improvement in sample complexity that can be expected from using oracles, we consider active learning in the sense that the learner has complete control over the information received. Specifically, we allow the learner to ask arbitrary yes/no questions. We consider both active learning under a fixed distribution and distribution-free active learning. In the case of active learning, the underlying probability distribution is used only to measure distance between concepts. For learnability with respect to a fixed distribution, active learning does not enlarge the set of learnable concept classes, but can improve the sample complexity. For distribution-free learning, it is shown that a concept class is actively learnable iff it is finite, so that active learning is in fact less powerful than the usual passive learning model. We also consider a form of distribution-free learning in which the learner knows the distribution being used, so that distribution-free refers only to the requirement that a bound on the number of queries can be obtained uniformly over all distributions. Even with the side information of the distribution being used, a concept class is actively learnable iff it has finite VC dimension, so that active learning with the side information still does not enlarge the set of learnable concept classes.</content></document><document><year>2005</year><authors>Marco Dorigo1</authors><title>ALECSYS and the AutonoMouse: Learning to Control a Real Robot by Distributed Classifier Systems</title><content>In this article we investigate the feasibility of using learning classifier systems as a tool for building adaptive control systems for real robots. Their use on real robots imposes efficiency constraints which are addressed by three main tools: parallelism, distributed architecture, and training. Parallelism is useful to speed up computation and to increase the flexibility of the learning system design. Distributed architecture helps in making it possible to decompose the overall task into a set of simpler learning tasks. Finally, training provides guidance to the system while learning, shortening the number of cycles required to learn. These tools and the issues they raise are first studied in simulation, and then the experience gained with simulations is used to implement the learning system on the real robot. Results have shown that with this approach it is possible to let the AutonoMouse, a small real robot, learn to approach a light source under a number of different noise and lesion conditions.</content></document><document><year>2005</year><authors>Marco Dorigo1 </authors><title>Alecsys and the AutonoMouse: Learning to control a real robot by distributed classifier systems</title><content>In this article we investigate the feasibility of using learning classifier systems as a tool for building adaptive control systems for real robots. Their use on real robots imposes efficiency constraints which are addressed by three main tools: parallelism, distributed architecture, and training. Parallelism is useful to speed up computation and to increase the flexibility of the learning system design. Distributed architecture helps in making it possible to decompose the overall task into a set of simpler learning tasks. Finally, training provides guidance to the system while learning, shortening the number of cycles required to learn. These tools and the issues they raise are first studied in simulation, and then the experience gained with simulations is used to implement the learning system on the real robot. Results have shown that with this approach it is possible to let the AutonoMouse, a small real robot, learn to approach a light source under a number of different noise and lesion conditions.</content></document><document><year>2005</year><authors>Raul E. Vald&amp;eacute s-P&amp;eacute rez1 </authors><title>Algebraic reasoning about reactions: Discovery of conserved properties in particle physics</title><content>Kocabas (1991) describes a situation from particle physics in which quantum properties and conservation laws are postulated from lists of observed and unobserved reactions. Kocabas also presents a program named BR-3 that can rediscover some accepted quantum properties from textbook data, although it fails on a more difficult example from the same source. This paper describes PAULI, a program that solves the same task as BR-3 but uses a different problem-solving model. PAULI produces different, simpler solutions than does BR-3, and it can also handle the problematic example. After comparing the two programs, we conclude that PAULI offers distinct advantages over its predecessor, which we attribute to analgebraic approach to reasoning about sets of reactions.</content></document><document><year>2005</year><authors>Wolfgang Maass1  | Gy&amp;ouml rgy Tur&amp;aacute n2| 3 </authors><title>Algorithms and lower bounds for on-line learning of geometrical concepts</title><content>The complexity of on-line learning is investigated for the basic classes of geometrical objects over a discrete (digitized) domain. In particular, upper and lower bounds are derived for the complexity of learning algorithms for axis-parallel rectangles, rectangles in general position, balls, halfspaces, intersections of half-spaces, and semi-algebraic sets. The learning model considered is the standard model for on-line learning from counterexamples.</content></document><document><year>2005</year><authors>Jan L. Talmon1| Herco Fonteijn1 | Peter J. Braspenning2</authors><title>An Analysis of the WITT Algorithm</title><content>In this article we present an analysis of the WITT algorithm for conceptual clustering as proposed by Hanson and Bauer (1989). We show that the measures proposed for the original WITT algorithm have serious shortcomings. We propose some alternatives for these measures, and, moreover, we make a further analysis of these alternatives such that setting the required thresholds will be less dependent of the characteristics of the cases that are to be clustered.</content></document><document><year>2005</year><authors>John Mingers1</authors><title>An Empirical Comparison of Pruning Methods for Decision Tree Induction</title><content>This paper compares five methods for pruning decision trees, developed from sets of examples. When used with uncertain rather than deterministic data, decision-tree induction involves three main stages&amp;#x2014;creating a complete tree able to classify all the training examples, pruning this tree to give statistical reliability, and processing the pruned tree to improve understandability. This paper concerns the second stage&amp;#x2014;pruning. It presents empirical comparisons of the five methods across several domains. The results show that three methods&amp;#x2014;critical value, error complexity and reduced error&amp;#x2014;perform well, while the other two may cause problems. They also show that there is no significant interaction between the creation and pruning methods.</content></document><document><year>2005</year><authors>John Mingers </authors><title>An Empirical Comparison of Selection Measures for Decision-Tree Induction</title><content>One approach to induction is to develop a decision tree from a set of examples. When used with noisy rather than deterministic data, the method involves three main stages &amp;#x2013; creating a complete tree able to classify all the examples, pruning this tree to give statistical reliability, and processing the pruned tree to improve understandability. This paper is concerned with the first stage &amp;#x2013; tree creation &amp;#x2013; which relies on a measure for goodness of split, that is, how well the attributes discriminate between classes. Some problems encountered at this stage are missing data and multi-valued attributes. The paper considers a number of different measures and experimentally examines their behavior in four domains. The results show that the choice of measure affects the size of a tree but not its accuracy, which remains the same even when attributes are selected randomly.</content></document><document><year>2005</year><authors>Dietrich Wettschereck1 | Thomas G. Dietterich1</authors><title>An Experimental Comparison of the Nearest-Neighbor and Nearest-Hyperrectangle Algorithms</title><content>Algorithms based on Nested Generalized Exemplar (NGE) theory (Salzberg, 1991) classify new data points by computing their distance to the nearest generalized exemplar (i.e., either a point or an axis-parallel rectangle). They combine the distance-based character of nearest neighbor (NN) classifiers with the axis-parallel rectangle representation employed in many rule-learning systems. An implementation of NGE was compared to the k-nearest neighbor (kNN) algorithm in 11 domains and found to be significantly inferior to kNN in 9 of them. Several modifications of NGE were studied to understand the cause of its poor performance. These show that its performance can be substantially improved by preventing NGE from creating overlapping rectangles, while still allowing complete nesting of rectangles. Performance can be further improved by modifying the distance metric to allow weights on each of the features (Salzberg, 1991). Best results were obtained in this study when the weights were computed using mutual information between the features and the output class. The best version of NGE developed is a batch algorithm (BNGE FWMI) that has no user-tunable parameters. BNGE FWMI's performance is comparable to the first-nearest neighbor algorithm (also incorporating feature weights). However, the k-nearest neighbor algorithm is still significantly superior to BNGE FWMI in 7 of the 11 domains, and inferior to it in only 2. We conclude that, even with our improvements, the NGE approach is very sensitive to the shape of the decision boundaries in classification problems. In domains where the decision boundaries are axis-parallel, the NGE approach can produce excellent generalization with interpretable hypotheses. In all domains tested, NGE algorithms require much less memory to store generalized exemplars than is required by NN algorithms.</content></document><document><year>2005</year><authors>Dietrich Wettschereck1  | Thomas G. Dietterich1 </authors><title>An experimental comparison of the nearest-neighbor and nearest-hyperrectangle algorithms</title><content>Algorithms based on Nested Generalized Exemplar (NGE) theory (Salzberg, 1991) classify new data points by computing their distance to the nearest generalized exemplar (i.e., either a point or an axis-parallel rectangle). They combine the distance-based character of nearest neighbor (NN) classifiers with the axis-parallel rectangle representation employed in many rule-learning systems. An implementation of NGE was compared to thek-nearest neighbor (kNN) algorithm in 11 domains and found to be significantly inferior to kNN in 9 of them. Several modifications of NGE were studied to understand the cause of its poor performance. These show that its performance can be substantially improved by preventing NGE from creating overlapping rectangles, while still allowing complete nesting of rectangles. Performance can be further improved by modifying the distance metric to allow weights on each of the features (Salzberg, 1991). Best results were obtained in this study when the weights were computed using mutual information between the features and the output class. The best version of NGE developed is a batch algorithm (BNGE FWMI) that has no user-tunable parameters. BNGE FWMI's performance is comparable to the first-nearest neighbor algorithm (also incorporating feature weights). However, thek-nearest neighbor algorithm is still significantly superior to BNGE FWMI in 7 of the 11 domains, and inferior to it in only 2. We conclude that, even with our improvements, the NGE approach is very sensitive to the shape of the decision boundaries in classification problems. In domains where the decision boundaries are axis-parallel, the NGE approach can produce excellent generalization with interpretable hypotheses. In all domains tested, NGE algorithms require much less memory to store generalized exemplars than is required by NN algorithms.</content></document><document><year>2005</year><authors>Ren&amp;eacute e Elio1  | Larry Watanabe2 </authors><title>An Incremental Deductive Strategy for Controlling Constructive Induction in Learning from Examples</title><content>This article describes LAIR, a constructive induction system that acquires conjunctive concepts by applying a domain theory to introduce new features into the evolving concept description. Each acquired concept is added to the domain theory, making LAIR a closed-loop learning system that weakens the inductive bias with each iteration of the learning loop. LAIR''s novel feature is the use of an incremental deductive strategy for constructive induction, reducing the amount of inference required for learning. A series of experiments manipulated features of learning tasks to assess this incremental method of constructive induction relative to an uncontrolled constructive induction process that extends each example description with all derivable features. These learning tasks differed in global characteristics of the domain theory, the training sequence, and the percentage of irrelevant features in the example descriptions. The results show that LAIR''s constructive induction approach saves considerable inferencing effort, with little or no cost in the number of examples needed to reach a learning criterion. The experimental results also underscored the importance of viewing a domain theory as a search space, identifying several factors that impact the deductive and inductive aspects of constructive induction, such as concept definition overlap, density of features, and fan-in and fan-out of inference chains. The paper also discusses LAIR''s operation as a pac-learner and its relation to other constructive induction techniques.</content></document><document><year>2005</year><authors>Bernd Nordhausen1  | Pat Langley2 </authors><title>An integrated framework for empirical discovery</title><content>In this article we present a framework that integrates three aspects of empirical discovery&amp;#x2014;the formation of taxonomies, the generation of qualitative laws, and the detection of numeric relations. We specify a control structure that integrates these component processes, embedding qualitative discovery within taxonomy formation, and embedding numeric discovery within both of these activities. We also describe the framework''s basic representation and organization of knowledge, which combines elements from recent work in machine discovery and qualitative physics. In addition, we describe IDS, a running system that instantiates this framework, and report its behavior on problems from the history of science. Finally, we discuss some limitations of the system as revealed by experimental studies, and propose some directions for future research.</content></document><document><year>2005</year><authors>Jianping Zhang1  | Ryszard S. Michalski2 </authors><title>An integration of rule induction and exemplar-based learning for graded concepts</title><content>This paper presents a method for learninggraded concepts. Our method uses a hybrid concept representation that integrates numeric weights and thresholds with rules and combines rules with exemplars. Concepts are learned by constructing general descriptions to represent common cases. These general descriptions are in the form of decision rules with weights on conditions, interpreted by a similarity measure and numeric thresholds. The exceptional cases are represented as exemplars. This method was implemented in the Flexible Concept Learning System (FCLS) and tested on a variety of problems. The testing problems included practical concepts, concepts with graded structures, and concepts that can be defined in the classic view. For comparison, a decision tree learning system, an instance-based learning system, and the basic rule learning variant of FCLS were tested on the same problems. The results have shown a statistically meaningful advantage of the proposed method over others both in terms of classification accuracy and description simplicity on several problems.</content></document><document><year>2005</year><authors>Satinder P. Singh1| 2  | Richard C. Yee1 </authors><title>An upper bound on the loss from approximate optimal-value functions</title><content>Many reinforcement learning approaches can be formulated using the theory ofMarkov decision processes and the associated method ofdynamic programming (DP). The value of this theoretical understanding, however, is tempered by many practical concerns. One important question is whether DP-based approaches that use function approximation rather than lookup tables can avoid catastrophic effects on performance. This note presents a result of Bertsekas (1987) which guarantees that small errors in the approximation of a task''s optimal value function cannot produce arbitrarily bad performance when actions are selected by a greedy policy. We derive an upper bound on performance loss that is slightly tighter than that in Bertsekas (1987), and we show the extension of the bound toQ-learning (Watkins, 1989). These results provide a partial theoretical rationale for the approximation of value functions, an issue of great practical importance in reinforcement learning.</content></document></documents>