<?xml version="1.0" encoding="UTF-8" standalone="no"?><documents><document><year>2004</year><authors>Peter Thomas1 </authors><title>2AD: The second international conference on Appliance Design, held at HP Laboratories, Bristol, UK, 11&amp;#x2013;13 May 2004</title><content>Without Abstract</content></document><document><year>2004</year><authors>ZhiYing Zhou1| Adrian David Cheok1  | JiunHorng Pan1</authors><title>3D story cube: an interactive tangible user interface for storytelling with 3D graphics and audio</title><content>Without Abstract</content></document><document><year>2004</year><authors>Dan Chalmers1 | Naranker Dulay1 | Morris Sloman1</authors><title>A framework for contextual mediation in mobile and ubiquitous computing applied to the context-aware adaptation of maps</title><content>Context has many aspects, which may vary widely, such as the device, environment and user. The perception of data in different contexts also varies widely. We present a new, flexible approach to meeting needs and limits arising from context: contextual mediation. In this paper limits are defined as goals over managed system resources. These can be met by the selection of data, taking into account preferences over its semantic and syntactic properties. The specification of this selection is presented in detail and the supporting framework is described. We illustrate our description with examples from a context-aware map application and present experimental results and experiences which demonstrate that contextual mediation enhances the usability of the application in restrictive contexts of use.</content></document><document><year>2004</year><authors>Andrea Szymkowiak1 | Kenny Morrison2| Peter Gregor2| Prveen Shah3| Jonathan J. Evans3 | Barbara A. Wilson3</authors><title>A memory aid with remote communication using distributed technology</title><content>Electronic memory aids have been used successfully to give reminders to individuals with memory problems. These aids usually present short action reminders that are acknowledged by the user. The recent enhancement of handheld computers with wireless technology has rendered them multi-functional and presents an opportunity to be exploited to meet the demands of the user. This paper describes the architecture of an electronic memory aid system we have developed and are currently evaluating with memory-impaired participants. In addition to providing action prompts, the developed system allows data entry not only on the device itself, but also from other stations. Hence, the memory-impaired user and third parties can remotely enter data into the device, depending on the skills of the user. The system also remotely monitors users acknowledgements of reminders and allows third parties to initiate further actions where appropriate.</content></document><document><year>2004</year><authors>Patrick Sauter1 | Gabriel V&amp;ouml gler2 | G&amp;uuml nther Specht1  | Thomas Flor2 </authors><title>A Model&amp;#x2013;View&amp;#x2013;Controller extension for pervasive multi-client user interfaces</title><content>This paper addresses the implementation of pervasive Java Web applications using a development approach that is based on the Model&amp;#x2013;View&amp;#x2013;Controller (MVC) design pattern. We combine the MVC methodology with a hierarchical task-based state transition model in order to achieve the distinction between the task state and the view state of an application. More precisely, we propose to add a device-independent TaskStateBean and a device-specific ViewStateBean for each task state as an extension to the J2EE Service to Worker design pattern. Furthermore, we suggest representing the task state and view state transition models as finite state automata in two sets of XML files. This paper shows that the distinction between an applications task state and view state is both intuitive and facilitates several, otherwise complex, tasks, such as changing devices on the fly.</content></document><document><year>2004</year><authors>Kenneth P. Fishkin1 </authors><title>A taxonomy for and analysis of tangible interfaces</title><content>There have been many research efforts devoted to tangible user interfaces (TUIs), but it has proven difficult to create a definition or taxonomy that allows us to compare and contrast disparate research efforts, integrate TUIs with conventional interfaces, or suggest design principles for future efforts. To address this problem, we present a taxonomy, which uses metaphor and embodiment as its two axes. This 2D space treats tangibility as a spectrum rather than a binary quantity. The further from the origin, the more tangible a system is. We show that this spectrum-based taxonomy offers multiple advantages. It unifies previous categorizations and definitions, integrates the notion of calm computing, reveals a previously un-noticed trend in the field, and suggests design principles appropriate for different areas of the spectrum.</content></document><document><year>2004</year><authors>Abhishek Prakash Tayal1  | L. M. Patnaik1</authors><title>An address assignment for the automatic configuration of mobile ad hoc networks</title><content>Mobile ad hoc networks (MANETs) are infrastructure-less, multi-hop wireless networks, which can be deployed without any pre-existing setup. MANETs are mobile in nature and any node can join and leave the network at any time. Due to mobility, MANETs must be able to configure themselves without human intervention. Configuration (such as address assignment) of a node in such a network is an important issue. In this paper, we present a solution for address assignment, which is distributed in nature and can be used for IP address configuration in MANETs. Each node can allocate the address independent of others. Although our solution uses broadcast messages, results show that by fixing a few parameter values we can reduce the number of broadcast messages. We simulate the protocol and results show that our solution yields better performance those of the earlier algorithms.</content></document><document><year>2004</year><authors>Christopher K. Hess1 | Roy H. Campbell1 </authors><title>An application of a context-aware file system</title><content>Ubiquitous computing environments stretch the requirements of traditional infrastructures used to facilitate the development of applications. Activities are often supported by collections of applications, some of which are automatically launched with little or no human intervention. This task-driven environment challenges existing application construction and data management techniques. In this paper, we describe a file system that organises application data based on contextual information, imports user data based on its physical presence, and supports format conversions to accommodate device context. We describe several applications that we have developed within our ubiquitous computing infrastructure and show how they leverage the novel features of our file system to simplify their complexity.</content></document><document><year>2004</year><authors>Scott M. Thayer1  | Peter Steenkiste2</authors><title>An Architecture for the Integration of Physical and Informational Spaces</title></document><document><year>2009</year><authors>Antonio Coronato1 | Massimo Esposito1| 2  | Giuseppe De Pietro1 </authors><title>A multimodal semantic location service for intelligent environments: an application for Smart Hospitals      </title><content>This paper presents semantic models, mechanisms and a service to locate mobile entities in Smart and Intelligent Environments.         The key feature of the service is the semantic integration of different positioning systems that not only enables the environment         to handle transparently such physical positioning systems, but also to reason on location information coming from different         systems and to combine it to obtain higher context information. Indeed, the service relies on the use of ontologies and rules         to define a uniform, unambiguous and well-defined model for the location information, independently of the particular positioning         system. Moreover, the location service performs logic and reasoning mechanisms to provide both physical and semantic locations         of mobile objects and to infer the finest granularity in the case when a mobile object is located by more than one positioning         system. Finally, we present an application of the proposed approach to the case of a Smart Hospital.      </content></document><document><year>2009</year><authors>David Morel|1 | Surya Nepal1| Hon Hwang1 | John Zic1</authors><title>A snapshot of trusted personal devices applicable to transaction processing      </title><content>In recent years, a clear trend has emerged where businesses need to provide flexible access to its services so as to increase         their usage by a much wider cross-section of users operating over public infrastructures but still within a trusted environment.         This trusted environment must be established between all participating users and service provider entities before any transactions         are carried out. To meet the challenge of enabling mobile users to work within a trusted environment on any untrusted machine,         the notion of a trusted personal device (TPD) has emerged. This paper provides a survey giving a snapshot of the growing body         of work ongoing in the area of TPDs and the services they support.      </content></document><document><year>2009</year><authors>Lucia Terrenghi1 | Aaron Quigley2  | Alan Dix3 </authors><title>A taxonomy for and analysis of multi-person-display ecosystems      </title><content>Interactive displays are increasingly being distributed in a broad spectrum of everyday life environments: they have very         diverse form factors and portability characteristics, support a variety of interaction techniques, and can be used by a variable         number of people. The coupling of multiple displays creates an interactive &amp;#8220;ecosystem of displays&amp;#8221;. Such an ecosystem is suitable for particular social         contexts, which in turn generates novel settings for communication and performance and challenges in ownership. This paper         aims at providing a design space that can inform the designers of such ecosystems. To this end, we provide a taxonomy that         builds on the size of the ecosystem and on the degree of individual engagement as dimensions. We recognize areas where physical         constraints imply certain kinds of social engagement, versus other areas where further work on interaction techniques for         coupling displays can open new design spaces.      </content></document><document><year>2009</year><authors>Satoshi Sakurai1 | Yoshifumi Kitamura1 | Sriram Subramanian2  | Fumio Kishino1 </authors><title>A visibility control system for collaborative digital table      </title><content>We propose a novel display system that presents information with different levels of visibility to multiple users for enhancing         collaborative multi-touch on digital tables by controlling visibility with a revolving polarizer. We first describe the system         and its multiple variations and then present several example applications showing the technique&amp;#8217;s benefits: the concealment         and classification of information for specific users. We then describe an example of an entertainment application and a tangible-polarizer         on display. In addition, we conduct experiments to learn the variations of visibilities depending on the conditions for investigating         application feasibilities. Finally, we discuss the future extensions of the configuration, its potential, and its limitations.         The following are the main contributions of this paper: (1) the discussion and clarification of the importance for multi-visibility         with multi-touch, (2) the proposal of our multi-visibility system and its usage, (3) the verification of multi-visibility         control through experiments.      </content></document><document><year>2009</year><authors>Chao Peng1| 2 | Yasuo Tan2| Naixue Xiong3 | Laurence T. Yang4| Jong Hyuk Park5 | Soon-Seok Kim6</authors><title>Adaptive video-on-demand broadcasting in ubiquitous computing environment      </title><content>Video-on-demand (VOD) is a service that allows users to view any video program from a server at the time of their choice,         such kind of services are expected to be popular in future ubiquitous computing environment. Lots of broadcasting protocols         for VOD services have been proposed, but they usually focus only on the tradeoff between bandwidth and delay, thus they are         usually not efficient for the local storage. Since the ubiquitous network is heterogeneous and users will have different resource         and communication capability, we need to address the storage issue in VOD systems. In this paper, we present several new effective         broadcasting schemes, which can intelligently adjust the solution according to available bandwidth and local storage to achieve         an ideal waiting time.      </content></document><document><year>2009</year><authors>Ching-Hsien Hsu1 | Shih-Chang Chen2 | Chia-Hao Yu2  | Jong Hyuk Park3 </authors><title>Alleviating reader collision problem in mobile RFID networks      </title><content>With the emergence of wireless RFID technologies, the problem of scheduling transmissions in dynamic RFID systems has been         arousing attention. In recent year, it has also instigated researches to propose different heuristic algorithms for scheduling         transactions between RFID readers and tags. In this paper, we present a two phase dynamic modulation (TPDM) technique, which         consists of regional scheduling and hidden terminal scheduling phases, aims to efficiently perform communications between         readers and tags in high density and mobile RFID networks. TPDM is a simple mechanism for coordinating simultaneous transmissions         among multiple readers and hidden terminals. A significant improvement of this approach is that TPDM can prevent reader collisions         by using a distributed self-scheduling scheme. An advantage of the proposed technique is that TPDM is adaptive in both static         and dynamic RFID environments. To evaluate the performance of the proposed technique, we have implemented the TPDM scheme         along with the Colorwave and Pulse protocols. The experimental results show that the TPDM scheduling techniques provide superior         and stable performance in both static and dynamic circumstance, especially in mobile and high density RFID environments. The         TPDM is shown to be effective in terms of throughput, system efficiency, and easy to implement.      </content></document><document><year>2009</year><authors>Youngsoo Kim1 | Sangbae Jeong2 | Daeyoung Kim1  | TomГЎs SГЎnchez LГіpez1 </authors><title>An efficient scheme of target classification and information fusion in wireless sensor networks      </title><content>In this paper, an efficient target classification and fusion scheme for wireless sensor networks (WSNs) is proposed and evaluated.         When a classification algorithm for WSN nodes is designed, parametric approaches such as Gaussian mixture model (GMM) should         be more preferred to non-parametric ones due to the hard limitation in resources. The GMM algorithm not only shows good performances         for target classification in WSNs but it also requires very small resources. Based on the classifier, a decision tree generated         by the classification and regression tree algorithm is used to fuse the information from heterogeneous sensors. This node-level         classification scheme provides a satisfactory classification rate, 94.10%, with little resources. Finally, a confidence-based         fusion algorithm improves the overall accuracy by fusing the information among sensor nodes. Our experimental results show         that the proposed group-level fusion algorithm improves the accuracy by an average of 4.17% accuracy with randomly selected         nodes.      </content></document><document><year>2009</year><authors>Ying Zhang1| 2| Houkuan Huang1| Dong Yang2| Hongke Zhang2| Han-Chieh Chao2| 3| 4  | Yueh-Min Huang5</authors><title>Bring QoS to P2P-based semantic service discovery for the Universal Network      </title><content>Services in the next generation Internet, Universal Network, is distinct from that in the current network. The reason is that         the former has QoS (quality of sevice) grading. In the universal network, different services have different QoS; therefore,         service discovery in the Universal Network is quite distinct from that of the present network. In this paper, we put QoS measurement         into service discovery so as to adapt to Universal Network. A lot of research works adopt semantic web technology, OWL-S (web         ontology language for services), which is innovative for service discovery. For the purpose of service discovery in Universal         Network, we append QoS descriptions to OWL-S. Such OWL-S with QoS information is called OWL&amp;#8211;QoS, which is the groundwork for         service discovery in the Universal Network. Secondly, we present a matching algorithm that allows matching on the basis of         capabilities and QoS descriptions of services. Moreover, we also adopt P2P as an infrastructure to fulfill the service discovery         because of the large amount of services in the network.      </content></document><document><year>2009</year><authors>Koen van Boerdonk1| Rob Tieben1| Sietske Klooster1 | Elise van den Hoven1 </authors><title>Contact through canvas: an entertaining encounter      </title><content>When meeting someone new, the first impression is often influenced by someone&amp;#8217;s physical appearance and other types of prejudice.         In this paper, we present TouchMeDare, an interactive canvas, which aims to provide an experience when meeting new people,         while preventing visual prejudice and lowering potential thresholds. The focus of the designed experience was to stimulate         people to get acquainted through the interactive canvas. TouchMeDare consists of a flexible, opaque canvas, which plays music         when touched simultaneously from both sides. Dynamic variation of this bodily contact is reflected through real-time adaptations         of the musical compositions. Two redesigns were qualitatively and quantitatively evaluated and a final version was placed         in the Lowlands Festival as a case study. Evaluation results showed that some explanation was needed for the initial interaction         with the installation. On the other hand, after this initial unfamiliarity passed, results showed that making bodily contact         through the installation did help people to get acquainted with each other and increased their social interaction.      </content></document><document><year>2009</year><authors>Leonardo Mostarda1 | Changyu Dong1  | Naranker Dulay1 </authors><title>Context-based authentication and transport of cultural assets      </title><content>We present a ubiquitous system that combines context information, security mechanisms and a transport infrastructure to provide         authentication and secure transport of works of art. Authentication is provided for both auctions and exhibitions, where users         can use their own mobile devices to authenticate works of art. Transport is provided by a secure protocol that makes use of         position&amp;#8211;time information and wireless sensors providing context information. The system has been used in several real case         studies in the context of the CUSPIS project and continues to be used as a commercial product for the transportation and exhibition         of cultural assets in Italy.      </content></document><document><year>2009</year><authors>Agustinus Borgy Waluyo1 | Isaac Pek1 | Xiang Chen1  | Wee-Soon Yeoh1 </authors><title>Design and evaluation of lightweight middleware for personal wireless body area network      </title><content>This paper presents a lightweight middleware to be used for wireless medical body area networks. The middleware is designed         to reside in mobile devices, and acts as a gateway to receive sensor data as well as to control a set of sensor devices attached         to the wearer. The main essence of the middleware is to simplify and accelerate the development of wireless healthcare applications         by providing highly reusable codes. The architecture of the middleware including its main functions such as data acquisition,         dynamic plug-and-play capabilities, on-the-fly sensor reconfiguration, and resource management (i.e., sensor sleep/wake-up,         critical self-wake) will be discussed. A security feature as a means to protect critical sensor data from malicious/unauthorized         parties has also been incorporated in our proposed middleware. The prototype system of the middleware has been built and is         presented in this paper together with its performance measurements.      </content></document><document><year>2009</year><authors>Alex|re Alapetite1 </authors><title>Dynamic 2D-barcodes for multi-device Web session migration including mobile phones      </title><content>This article introduces a novel Web architecture that supports session migration in multi-device Web applications, particularly         the case when a user starts a Web session on a computer and wishes to continue on a mobile phone. The proposed solution for         transferring the needed session identifiers across devices is to dynamically generate pictures of 2D-barcodes containing a         Web address and a session ID in an encoded form. 2D-barcodes are a cheap, fast and robust approach to the problem. They are         widely known and used in Japan, and are spreading in other countries. Variations on the topic are covered in the article,         including a possible migration from a mobile device to a computer (opposite direction), and between two or more mobile phones         (possibly back and forth). The results show that this HCI approach is inexpensive, efficient, and works with most camera-phones         on the market; the author does see any other mature technique with such assets.      </content></document><document><year>2009</year><authors>Steve Whittaker1 | Ofer Bergman1 | Paul Clough1</authors><title>Easy on that trigger dad: a study of long term family photo retrieval      </title><content>We examine the effects of new technologies for digital photography on people&amp;#8217;s longer term storage and access to collections         of personal photos. We report an empirical study of parents&amp;#8217; ability to retrieve photos related to salient family events from         more than a year ago. Performance was relatively poor with people failing to find almost 40% of pictures. We analyze participants&amp;#8217;         organizational and access strategies to identify reasons for this poor performance. Possible reasons for retrieval failure         include: storing too many pictures, rudimentary organization, use of multiple storage systems, failure to maintain collections         and participants&amp;#8217; false beliefs about their ability to access photos. We conclude by exploring the technical and theoretical         implications of these findings.      </content></document><document><year>2009</year><authors>Peter Weller1 | Leila Rakhmetova1| Qi Ma1 | Gerlinde M|ersloot2| 1</authors><title>Evaluation of a wearable computer system for telemonitoring in a critical environment      </title><content>This paper reports on the evaluation of a wearable computer system designed for use in a critical environment, namely the         intensive care unit of a hospital. The nature of the application raised ethical issues for testing in a clinical environment         and standard evaluation techniques could not easily be applied. The system was therefore evaluated by clinicians in a multi-tasking         environment with a simulated set of patient scenarios. Measures of suitability and wearability were applied. The results were         encouraging and the system was deemed suitable for further evaluation in the clinical setting, subject to ethical approval.      </content></document><document><year>2009</year><authors>Sahar Bayoumi1| Tony Pridmore1  | Boriana Koleva1 </authors><title>Exploiting ambient illumination to locate and recognise user behaviour in enclosed environments      </title><content>Experiences in pervasive computing environments often rely on estimates of the location and/or behaviour of participants to         tailor interaction and/or content to the particular user context. In this paper, we present a novel computer vision method         for the indirect monitoring of user position and behaviour. The technique classifies activities based on measurements of the         disruptions those activities cause in the surrounding ambient light field. The potential advantages of the method are increased         privacy, an ability to recognise high level behaviours and events, and applicability in dimly lit environments. Initial experiments         show the technique to be capable of recognising user position within an enclosed environment with at least 75% accuracy. A         study of time-based events further shows it to be capable of discriminating between different paths taken through an enclosed         space by different sized groups of users with 84% accuracy. We conclude by discussing possible applications of the technique         in pervasive computing environments.      </content></document><document><year>2009</year><authors>Simon Robinson1 | Parisa Eslambolchilar1  | Matt Jones1 </authors><title>Exploring casual point-and-tilt interactions for mobile geo-blogging      </title><content>People record and share their experiences through text, audio and video. Increasingly they do this blogging from mobile devices.         We illustrate a novel, mobile, low interaction cost approach to support the creation of a rich record of journeys made and         places encountered: by pointing and tilting a mobile, users indicate their interests in a location. We built three mobile         prototypes to explore the approach&amp;#8212;the first one combines gestures and visual map feedback; the second provides a simpler         visual interface; the third supports eyes-free interaction, allowing the user to simply point-and-tilt, with no visual display         required. We describe two field studies undertaken to understand the value of the interaction styles afforded, then continue         with a further user study to assess the interaction speed and accuracy between these interaction methods. We present the results         of these studies and raise issues relevant to their design and to the wider class of devices and services concerned with mobile         spatial information access.      </content></document><document><year>2009</year><authors>Joseph A. Paradiso1 | Jonathan Gips2 | Mathew Laibowitz1 | Sajid Sadi3 | David Merrill3 | Ryan Aylward1 | Pattie Maes3  | Alex Pentl|2 </authors><title>Identifying and facilitating social interaction with a wearable wireless sensor network      </title><content>We have designed a highly versatile badge system to facilitate a variety of interaction at large professional or social events         and serve as a platform for conducting research into human dynamics. The badges are equipped with a large LED display, wireless         infrared and radio frequency networking, and a host of sensors to collect data that we have used to develop features and algorithms         aimed at classifying and predicting individual and group behavior. This paper overviews our badge system, describes the interactions         and capabilities that it enabled for the wearers, and presents data collected over several large deployments. This data is         analyzed to track and socially classify the attendees, predict their interest in other people and demonstration installations,         profile the restlessness of a crowd in an auditorium, and otherwise track the evolution and dynamics of the events at which         the badges were run.      </content></document><document><year>2009</year><authors>Michael Rohs1 | Robert Schleicher1 | Johannes SchГ¶ning2 | Georg Essl1 | Anja Naumann1  | Antonio KrГјger2 </authors><title>Impact of item density on the utility of visual context in magic lens interactions      </title><content>This article reports on two user studies investigating the effect of visual context in handheld augmented reality interfaces.         A dynamic peephole interface (without visual context beyond the device display) was compared to a magic lens interface (with         video see-through augmentation of external visual context). The task was to explore items on a map and look for a specific         attribute. We tested different sizes of visual context as well as different numbers of items per area, i.e. different item         densities. Hand motion patterns and eye movements were recorded. We found that visual context is most effective for sparsely         distributed items and gets less helpful with increasing item density. User performance in the magic lens case is generally         better than in the dynamic peephole case, but approaches the performance of the latter the more densely the items are spaced.         In all conditions, subjective feedback indicates that participants generally prefer visual context over the lack thereof.         The insights gained from this study are relevant for designers of mobile AR and dynamic peephole interfaces, involving spatially         tracked personal displays or combined personal and public displays, by suggesting when to use visual context.      </content></document><document><year>2009</year><authors>David H. Nguyen1  | Gillian R. Hayes1 </authors><title>Information privacy in institutional and end-user tracking and recording technologies      </title><content>This paper presents an analysis of attitudes towards everyday tracking and recording technologies (e.g., credit cards, store         loyalty cards, store video cameras). This work focuses on both institutional and end-user tracking and recording technologies. In particular, this paper describes (1) an empirical interview and survey study of everyday         institutional tracking and recording technologies and (2) an analysis of these empirical data against a framework originally         used to describe tension points for end-user tracking and recording technologies. Results from the study demonstrate that         people can be highly concerned with information privacy while simultaneously reporting significantly less concern regarding the use of everyday technologies that have the capabilities         to collect, process, and disseminate personal information. The empirical results and theoretical analysis identify and begin         to explain this dissonance. Furthermore, we provide extensions to the analytic framework for capture and access technologies         to address differences, similarities, and interplay between institutional and end-user tracking and recording technologies.         The results of this paper contribute to the fields of personal and ubiquitous computing by providing significant insight relevant         to the evaluation, design, deployment, and adoption of new tracking and recording technologies.      </content></document><document><year>2009</year><authors>Seokhee Jeon1| Jane Hwang2| Gerard J. Kim3  | Mark Billinghurst4</authors><title>Interaction with large ubiquitous displays using camera-equipped mobile phones      </title><content>In the ubiquitous computing environment, people will interact with everyday objects (or computers embedded in them) in ways         different from the usual and familiar desktop user interface. One such typical situation is interacting with applications         through large displays such as televisions, mirror displays, and public kiosks. With these applications, the use of the usual         keyboard and mouse input is not usually viable (for practical reasons). In this setting, the mobile phone has emerged as an         excellent device for novel interaction. This article introduces user interaction techniques using a camera-equipped hand-held         device such as a mobile phone or a PDA for large shared displays. In particular, we consider two specific but typical situations         (1) sharing the display from a distance and (2) interacting with a touch screen display at a close distance. Using two basic         computer vision techniques, motion flow and marker recognition, we show how a camera-equipped hand-held device can effectively         be used to replace a mouse and share, select, and manipulate 2D and 3D objects, and navigate within the environment presented         through the large display.      </content></document><document><year>2009</year><authors>Hye-Young Kim1 | Hangbae Chang2  | Young-Sik Jeong3 </authors><title>Intra domain route optimization for ubiquitous network      </title><content>The main advantage of a wireless network is user mobility, which calls for efficient routing support at the network layer.         An architecture combines hierarchical mobile IPv6 and network mobility for a network mobile and mobile nodes move in tandem         and make a hierarchy in the wireless network to management of micro-mobility and seamless handoff. But the capability of the         architecture for intra domain route optimization is impaired. So we propose functionality in domain nodes to enable intra         domain path optimization for ubiquitous network. It is shown that intra domain cost effect is beneficial in every hierarchical         domain that spans mesh network topology. We address the key function for our proposed scheme and analyze the usefulness of         our proposed method using mathematically. We show that our proposed scheme performs much better than Network Mobility protocol,         especially when the number of mobile nodes or mobile routers or correspondent nodes increases in hierarchically nested in         ubiquitous networks.      </content></document><document><year>2009</year><authors>James R. Wallace1 | Stacey D. Scott1 | Taryn Stutz1 | Tricia Enns1  | Kori Inkpen2 </authors><title>Investigating teamwork and taskwork in single- and multi-display groupware systems      </title><content>Multi-display groupware (MDG) systems, which typically comprise both public and personal displays, promise to enhance collaboration,         yet little is understood about how they differ in use from single-display groupware (SDG) systems. While research has established         the technical feasibility of MDG systems, evaluations have not addressed the question of how users&amp;#8217; behave in such environments,         how their interface design can impact group behavior, or what advantages they offer for collaboration. This paper presents         a user study that investigates the impact of display configuration and software interface design on taskwork and teamwork.         Groups of three completed a collaborative optimization task in single- and multi-display environments, under different task         interface constraints. Our results suggest that MDG configurations offer advantages for performing individual task duties,         whereas SDG conditions offer advantages for coordinating access to shared resources. The results also reveal the importance         of ergonomic design considerations when designing co-located groupware systems.      </content></document><document><year>2009</year><authors>Delfina Mal|rino1 | Francesca Mazzoni2 | Daniele Riboni3 | Claudio Bettini3 | Michele Colajanni2  | Vittorio Scarano1 </authors><title>MIMOSA: context-aware adaptation for ubiquitous web access      </title><content>The ubiquitous computing scenario is characterized by heterogeneity of devices used to access services, and by frequent changes         in the user&amp;#8217;s context. Hence, adaptation according to the user&amp;#8217;s context and the used devices is necessary to allow mobile         users to efficiently exploit Internet-based services. In this paper, we present a distributed framework, named MIMOSA, that         couples a middleware for context-awareness with an intermediary-based architecture for content adaptation. MIMOSA provides         an effective and efficient solution for the adaptation of Internet services on the basis of a comprehensive notion of context,         by means of techniques for aggregating context data from distributed sources, deriving complex contextual situations from         raw sensor data, evaluating adaptation policies, and solving possible conflicts. The middleware allows programmers to modularly         build complex adaptive services starting from simple ones, and includes tools for assisting the user in declaring her preferences,         as well as mechanisms for detecting incorrect system behaviors due to a wrong choice of adaptation policies. The effectiveness         and efficiency of MIMOSA are shown through the development of a prototype adaptive service, and by extensive experimental         evaluations.      </content></document><document><year>2009</year><authors>Keni Bernardin1 | Hazim Kemal Ekenel1  | Rainer Stiefelhagen1 </authors><title>Multimodal identity tracking in a smart room      </title><content>Without Abstract</content></document><document><year>2009</year><authors>Nicola J. Bidwell1  | David Browning1</authors><title>Pursuing genius loci: interaction design and natural places      </title><content>Human computer interaction (HCI) has little explored everyday life and enriching experiences in rural, wilderness and other         predominantly &amp;#8220;natural&amp;#8221; places despite their socioeconomic importance. Beyond simply addressing the challenge arising from         applying an urban perspective to designing technologies for use in natural places, we wish to provoke integration of the natural         and computational worlds. To stimulate design that both draws upon and affords such integration, we propose seven themes we         have distilled from the literature and supplement these with our own research observations. Bodies Imagine and Remember recognizes         the inseparability of meanings and corporeal experience of natural places for design. Indexicality and Habitus refers to the         need for design to be sensitive to the processes by which natural features become intelligible in our actions and communication.         Values and Story-spaces observes the way representations and infrastructures, infused with particular values, become dominant.         Identity and Belonging, suggests the need to reconcile designs with couplings between physical settings, processes of community         and personal identity. Rhythm and Dynamism considers links between people&amp;#8217;s daily routines, nature&amp;#8217;s events and patterns and         spatial and social issues pertinent to design and in Revealing and Receding we suggest that design must simultaneously fade         into the background and provoke seeing natural places differently. Fragility, Liability and Spirituality refers to technological         opportunities to support positive relations within ecosystems and recognizing the limits of technological control.      </content></document><document><year>2009</year><authors>Mika Luimula1 | Kirsti SГ¤Г¤skilahti2 | Timo Partala3 | Sakari PieskГ¤1 | Juha AlaspГ¤Г¤1</authors><title>Remote navigation of a mobile robot in an RFID-augmented environment      </title><content>In the current article, we address the problem of constructing radiofrequency identification (RFID)-augmented environments         for mobile robots and the issues related to creating user interfaces for efficient remote navigation with a mobile robot in         such environments. First, we describe an RFID-based positioning and obstacle identification solution for remotely controlled         mobile robots in indoor environments. In the robot system, an architecture specifically developed by the authors for remotely         controlled robotic systems was tested in practice. Second, using the developed system, three techniques for displaying information         about the position and movements of a remote robot to the user were compared. The experimental visualization techniques displayed         the position of the robot on an indoor floor plan augmented with (1) a video view from a camera attached to the robot, (2)         display of nearby obstacles (identified using RFID technology) on the floor plan, and (3) both features. In the experiment,         test subjects controlled the mobile robot through predetermined routes as quickly as possible avoiding collisions. The results         suggest that the developed RFID-based environment and the remote control system can be used for efficient control of mobile         robots. The results from the comparison of the visualization techniques showed that the technique without a camera view (2)         was the fastest, and the number of steering motions made was smallest using this technique, but it also had the highest need         for physical human interventions. The technique with both additional features (3) was subjectively preferred by the users.         The similarities and differences between the current results and those found in the literature are discussed.      </content></document><document><year>2009</year><authors>Morgan Ames1| 2 | Dean Eckles1| 2| Mor Naaman3| Mirjana Spasojevic2 | Nancy Van House4</authors><title>Requirements for mobile photoware      </title><content>What is the future of digital imaging? Mobile imaging technologies have been changing rapidly and will continue to do so.         We explore new developments in cameraphone photography with the goal of improving the design of the next generation of mobile         imaging devices. We equipped 26 diverse participants with cameraphones, photo uploading and sharing software, and access to         online photo-accounts for 3&amp;#8211;5;months. This study allowed us to identify emerging practices in mobile photoware. We report         on new and continuing practices across the lifespan of photos in this new imaging environment, including image capture, upload,         annotation, archiving, sharing, and viewing. Based on these results, we develop design criteria and implications for designers         and makers of mobile devices, mobile imaging and sharing software, and desktop and online photo software.      </content></document><document><year>2009</year><authors>Binod Vaidya1 | Sang-Soo Yeo2 | Dong-You Choi3  | SeungJo Han3 </authors><title>Robust and secure routing scheme for wireless multihop network      </title><content>Mobile ad hoc network (MANET) is an appealing technology that has attracted lots of research efforts. On-demand routing protocol         such as AODV may suffer from frequent topological changes. Due to frequent communication failures, multipath MANET is preferred         than single-path MANET in many applications as former is used for achieving robustness and load balancing and improving reliability.         Although multipath MANET is attractive solution, there are still some major flaws that prevent commercial growth. Security         is one of these main barriers; MANETs are known to be particularly vulnerable to security attack. The paper presents a design         of robust and secure framework for multipath MANET. In this paper, we propose not only a robust multipath routing protocol         but also an extended security scheme. We discuss security analysis for proposed security scheme. And we also conduct simulation         to evaluate such a framework through different performance metrics. Results show that the proposed routing protocol achieves         better performance in terms of various metrics than other protocols.      </content></document><document><year>2009</year><authors>Aaron Quigley1| 2 | Sriram Subramanian3  | Shahram Izadi4 </authors><title>Special issue on interaction with coupled and public displays      </title><content>Without Abstract</content></document><document><year>2009</year><authors>Jong Hyuk Park1 | Jianhua Ma2 | Laurence T. Yang3  | Anind K. Dey4 </authors><title>Special issue on &amp;#8220;Intelligent systems and services for ubiquitous computing&amp;#8221;      </title><content>Without Abstract</content></document><document><year>2009</year><authors>Florian Echtler1 | Simon Nestler1 | Andreas Dippon1  | Gudrun Klinker1 </authors><title>Supporting casual interactions between board games on public tabletop displays and mobile devices      </title><content>As more interactive surfaces enter public life, casual interactions from passersby are bound to increase. Most of these users         can be expected to carry a mobile phone or PDA, which nowadays offers significant computing capabilities of its own. This         offers new possibilities for interaction between these users&amp;#8217; private displays and large public ones. In this paper, we present         a system that supports such casual interactions. We first explore a method to track mobile phones that are placed on a horizontal         interactive surface by examining the shadows which are cast on the surface. This approach detects the presence of a mobile         device, as opposed to any other opaque object, through the signal strength emitted by the built-in Bluetooth transceiver without         requiring any modifications to the devices&amp;#8217; software or hardware. We then go on to investigate interaction between a Sudoku         game running in parallel on the public display and on mobile devices carried by passing users. Mobile users can join a running         game by placing their devices on a designated area. The only requirement is that the device is in discoverable Bluetooth mode.         After a specific device has been recognized, a client software is sent to the device which then enables the user to interact         with the running game. Finally, we explore the results of a study which we conducted to determine the effectiveness and intrusiveness         of interactions between users on the tabletop and users with mobile devices.      </content></document><document><year>2009</year><authors>Hong Chen1  | Qun Jin1 </authors><title>Ubiquitous Personal Study: a framework for supporting information access and sharing      </title><content>The information resources on the Web are diversified, the amount of which is increasing rapidly. Demands for selecting useful         information from the Internet, managing personal contents, and sharing contents under control have risen. In this study, we         propose the Ubiquitous Personal Study, a framework of personalized virtual study to support accessing, managing, organizing,         sharing and recommending information. In this paper, we focus on discussing the framework, and design and implementation issues         on how to implement it with Web 2.0 mash-up technology and Open Source Software.      </content></document><document><year>2009</year><authors>Dzmitry Aliakseyeu1 | AndrГ©s Lucero2  | Jean-Bernard Martens3 </authors><title>Users&amp;#8217; quest for an optimized representation of a multi-device space      </title><content>A plethora of reaching techniques, intended for moving objects between locations distant to the user, have recently been proposed         and tested. One of the most promising techniques is the Radar View. Up till now, the focus has been mostly on how a user can         interact efficiently with a given radar map, not on how these maps are created and maintained. It is, for instance, unclear         whether or not users would appreciate the possibility of adapting such radar maps to particular tasks and personal preferences.         In this paper, we address this question by means of a prolonged user study with the Sketch Radar prototype. The study demonstrates         that users do indeed modify the default maps in order to improve interactions for particular tasks. It also provides insights         into how and why the default physical map is modified.      </content></document><document><year>2008</year><authors>John Krumm1 </authors><title>A survey of computational location privacy      </title><content>This is a literature survey of computational location privacy, meaning computation-based privacy mechanisms that treat location         data as geometric information. This definition includes privacy-preserving algorithms like anonymity and obfuscation as well         as privacy-breaking algorithms that exploit the geometric nature of the data. The survey omits non-computational techniques         like manually inspecting geotagged photos, and it omits techniques like encryption or access control that treat location data         as general symbols. The paper reviews studies of peoples&amp;#8217; attitudes about location privacy, computational threats on leaked         location data, and computational countermeasures for mitigating these threats.      </content></document><document><year>2008</year><authors>Marc Langheinrich1 </authors><title>A survey of RFID privacy approaches      </title><content>A bewildering number of proposals have offered solutions to the privacy problems inherent in RFID communication. This article         tries to give an overview of the currently discussed approaches and their attributes.      </content></document><document><year>2008</year><authors>Erich Bruns1  | Oliver Bimber1 </authors><title>Adaptive training of video sets for image recognition on mobile phones      </title><content>We present an enhancement towards adaptive video training for PhoneGuide, a digital museum guidance system for ordinary camera-equipped         mobile phones. It enables museum visitors to identify exhibits by capturing photos of them. In this article, a combined solution         of object recognition and pervasive tracking is extended to a client&amp;#8211;server-system for improving data acquisition and for         supporting scale-invariant object recognition. A static as well as a dynamic training technique are presented that preprocess         the collected object data differently and apply two types of neural networks (NN) for classification. Furthermore, the system         enables a temporal adaptation for ensuring a continuous data acquisition to improve the recognition rate over time. A formal         field experiment reveals current recognition rates and indicates the practicability of both methods under realistic conditions         in a museum.      </content></document><document><year>2008</year><authors>Sarah Spiekermann1  | Marc Langheinrich2 </authors><title>An update on privacy in ubiquitous computing      </title><content>Without Abstract</content></document><document><year>2008</year><authors>Steven Strachan1  | Roderick Murray-Smith2 </authors><title>Bearing-based selection in mobile spatial interaction      </title><content>We introduce a mobile spatial interactive application that uses a combination of a GPS, inertial sensing, gestural interaction,         probabilistic models and Monte Carlo sampling, with vibration and audio feedback. This system allows the probing or querying         of targets in a local area, based on a model of the local environment and specific context variables of interest, to enable         a rich, embodied and location&amp;#8211;aware spatial interaction. An experiment was conducted to investigate how spatial target selection         at different distances, target separations and target widths is affected by a system with added &amp;#8216;typical&amp;#8217; noise characteristics.         Results showed that the successful selection of targets in the virtual environment is maximised with a combination of high         angular separation and angular width.      </content></document><document><year>2008</year><authors>Hannu Verkasalo1 </authors><title>Contextual patterns in mobile service usage      </title><content>Mobile services differ from other services because of their temporal and spatial attributes. Mobile services additionally         differ from each other in their value-added to the end-user. Some services&amp;#8212;such as emailing and voice&amp;#8212;are more business oriented.         On the other hand, various free-time oriented services are provided in new smartphones, such as imaging and music playback.         The present paper studies how mobile services are used in different contexts. For this, the paper develops a specialized algorithm         that can be used with handset-based usage data acquired straight from end-users in an established panel study process. Educated         guesses can be drawn on the user context based on the developed algorithm. In the present exercise usage contexts were divided         into home, office and &amp;#8220;on the move&amp;#8221;. The algorithm is used with exemplary data from Finland and the UK covering 324 consumers         in 2006. More than 70% of contextual use cases are correctly classified based on raw data. According to exemplary results         particularly multimedia services are used &amp;#8220;on the move&amp;#8221;, whereas legacy mobile services experience more evenly distributed         usage across all contexts. The algorithm that identifies context based on raw data provides a new angle to mobile end-user         research. In the future, the accuracy of the algorithm will be improved with the integration of seamless cell-id logging and         GPS data.      </content></document><document><year>2008</year><authors>Mika Raento1| 2  | Antti Oulasvirta2 </authors><title>Designing for privacy and self-presentation in social awareness      </title><content>Social awareness applications are based on the idea of a group sharing real-time context information via personal and ubiquitous         terminals. Studies of such applications have shown that users are not only concerned with the preservation privacy through         non-disclosure. Instead, disclosure is manipulated for the constant presentation of self to the group in everyday social situations.         Basing on 3;years of research with the mobile social awareness system ContextContacts, established findings in social psychology         and ubiquitous computing, we propose a number of design principles to support users in this management of privacy and presentation.         These principles are to apply even if disclosure is automated, and include support for lightweight permissions, assuming reciprocity,         appearing differently to different audiences, providing for feedback on presentation and allowing lying. These principles         are applied in interaction design and protocol engineering for the next version of a mobile awareness system called ContextContacts.      </content></document><document><year>2008</year><authors>Antti Oulasvirta1 | Sara Estl|er1  | Antti Nurminen1 </authors><title>Embodied interaction with a 3D versus 2D mobile map      </title><content>In comparison to 2D maps, 3D mobile maps involve volumetric instead of flat representation of space, realistic instead of         symbolic representation of objects, more variable views that are directional and bound to a first-person perspective, more         degrees of freedom in movement, and dynamically changing object details. We conducted a field experiment to understand the         influence of these qualities on a mobile spatial task where buildings shown on the map were to be localized in the real world.         The representational differences were reflected in how often users interact with the physical environment and in when they         are more likely to physically turn and move the device, instead of using virtual commands. 2D maps direct users into using         reliable and ubiquitous environmental cues like street names and crossings, and 2D better affords the use of pre-knowledge         and bodily action to reduce cognitive workload. Both acclaimed virtues of 3D mobile maps&amp;#8212;rapid identification of objects and         ego-centric alignment&amp;#8212;worked poorly due reasons we discuss. However, with practice, some 3D users learned to shift to 2D-like         strategies and could thereby improve performance. We conclude with a discussion of how representational differences in mobile         maps affect strategies of embodied interaction.      </content></document><document><year>2008</year><authors>Anna StГҐhl1 | Kristina HГ¶Г¶k1 | Martin Svensson1 | Alex S. Taylor2  | Marco Combetto2</authors><title>Experiencing the Affective Diary      </title><content>A diary is generally considered to be a book in which one keeps a regular record of events and experiences that have some         personal significance. As such, it provides a useful means to privately express inner thoughts or to reflect on daily experiences,         helping in either case to put them in perspective. Taking conventional diary keeping as our starting point, we have designed         and built a digital diary, named Affective Diary, with which users can scribble their notes, but that also allows for bodily memorabilia to be recorded from body sensors and mobile media to be collected from users&amp;#8217; mobile phones. A premise that underlies the presented work is one that views our bodily experiences         as integral to how we come to interpret and thus make sense of the world. We present our investigations into this design space         in three related lines of inquiry: (1) a theoretical grounding for affect and bodily experiences; (2) a user-centred design         process, arriving at the Affective Diary system; and (3) an exploratory end-user study of the Affective Diary with 4 users         during several weeks of use. Through these three inquiries, our overall aim has been to explore the potential of a system         that interleaves the physical and cultural features of our embodied experiences and to further examine what media-specific         qualities such a design might incorporate. Concerning the media-specific qualities, the key appears to be to find a suitable         balance where a system does not dictate what should be interpreted and, at the same time, lends itself to enabling the user         to participate in the interpretive act. In the exploratory end-user study users, for the most part, were able to identify         with the body memorabilia and together with the mobile data, it enabled them to remember and reflect on their past. Two of         our subjects went even further and found patterns in their own bodily reactions that caused them to learn something about         themselves and even attempt to alter their own behaviours.      </content></document><document><year>2008</year><authors>Gerhard Schall1 | Erick Mendez1 | Ernst Kruijff1 | Eduardo Veas1 | Sebastian Junghanns2 | Bernhard Reitinger3  | Dieter Schmalstieg1 </authors><title>Handheld Augmented Reality for underground infrastructure visualization      </title><content>In this paper, we present an Augmented Reality (AR) system for aiding field workers of utility companies in outdoor tasks         such as maintenance, planning or surveying of underground infrastructure. Our work addresses these issues using spatial interaction         and visualization techniques for mobile AR applications and as well as for a new mobile device design. We also present results         from evaluations of the prototype application for underground infrastructure spanning various user groups. Our application         has been driven by feedback from industrial collaborators in the utility sector, and includes a translation tool for automatically         importing data from utility company databases of underground assets.      </content></document><document><year>2008</year><authors>Paul De Hert1 | Serge Gutwirth1 | Anna Moscibroda1 | David Wright1  | Gloria GonzГЎlez Fuster1 </authors><title>Legal safeguards for privacy and data protection in ambient intelligence      </title><content>To get the maximum benefit from ambient intelligence (AmI), we need to anticipate and react to possible drawbacks and threats         emerging from the new technologies in order to devise appropriate safeguards. The SWAMI project took a precautionary approach         in its exploration of the privacy risks in AmI and sought ways to reduce them. It constructed four &amp;#8220;dark scenarios&amp;#8221; showing         possible negative implications of AmI, notably for privacy protection. Legal analysis of the depicted futures showed the shortcomings         of the current legal framework in being able to provide adequate privacy protection in the AmI environment. In this paper,         the authors, building upon their involvement in SWAMI research as well as the further advancement of EU privacy analysis,         identify various outstanding issues regarding the legal framework that still need to be resolved in order to deal with AmI         in an equitable and efficacious way. This article points out some of the lacunae in the legal framework and postulates several         privacy-specific safeguards aimed at overcoming them.      </content></document><document><year>2008</year><authors>Tomohiro Amemiya1 | Taro Maeda2 | Hideyuki Ando1</authors><title>Location-free haptic interaction for large-area social applications      </title><content>In this paper, we discuss the potential of force perception technologies for realizing hand-held devices in the field of social         systems. We propose and develop an interactive force-sensation-based navigation system for waiters based on a force perception         technology that we have proposed. The navigation system consists of our new hand-held haptic interface and a camera-based         position and posture identification system. Since the proposed compact haptic interface does not require external grounding,         it can be used outside the laboratory and does not interrupt human activity. We verify the feasibility of the system in trials         where we collected the responses of system users.      </content></document><document><year>2008</year><authors>David Dearman1 | Kori M. Inkpen2  | Khai N. Truong1 </authors><title>Mobile map interactions during a rendezvous: exploring the implications of automation       </title><content>Location awareness can help facilitate a rendezvous of two or more persons. To further enhance the rendezvous experience,         we conducted two complementary field studies to identify what information in a location-aware map application is important to rendezvous individuals (study 1) and to explore the use of         autofocus, our automation technique to reduce user interactions with the rendezvous application while still providing relevant information         to assist users with their navigation task (study 2). Overall, our results highlight the importance of maintaining the visibility         of the user&amp;#8217;s location in relation to that of their partner(s) and rendezvous location. Additionally, we show that automation         is useful in the context of a rendezvous application, but that the considerations are significantly more nuanced than originally         conceived. We discuss unique instances when and why the automation process broke-down or did not perform as required by users. The results of this work demonstrate the potential         for automation in a location-aware rendezvous application and identify important design considerations for future work in         this area.      </content></document><document><year>2008</year><authors>Peter FrГ¶hlich1 | Rainer Simon1 | Lynne Baillie1</authors><title>Mobile Spatial Interaction      </title><content>Without Abstract</content></document><document><year>2008</year><authors>Derek Reilly1 | Bonnie Mackay1| Carolyn Watters1 | Kori Inkpen1</authors><title>Planners, navigators, and pragmatists: collaborative wayfinding using a single mobile phone      </title><content>Shared use of mobile devices is increasingly prevalent in both research prototypes and in practice, however, little is known         as to how to support best this interaction paradigm. In this paper, we present a study examining how pairs share a single         mobile phone during a collaborative wayfinding activity. We provide a classification of strategies, role relationships and         phone interactions employed to conduct the wayfinding activities in our study. While acknowledging that the factors determining         how the phone was shared are nuanced and intertwined, our results illustrate how differences in the mobile application&amp;#8217;s interface         influenced shared use, wayfinding strategy and outcome.      </content></document><document><year>2008</year><authors>Marco (M.C.) Rozendaal1 | David V. Keyson2  | Huib de Ridder2 </authors><title>Product features and task effects on experienced richness, control and engagement in voicemail browsing      </title><content>A recent focus is on creating engaging user experiences with digital products and services such as voicemail. This study aims         to design towards increased levels of engagement in voicemail browsing by using the &amp;#8216;Richness, Control and Engagement&amp;#8217; (RC         &amp;amp; E) framework. This framework explains the levels of engagement in terms of the levels of richness and control that are shaped         by the features of a product and the user&amp;#8217;s expertise. A product was developed that utilized gestures and sound to access         digital voicemail contents. An experiment was conducted in which 28 participants interacted with the product while varying         (1) the number of features of the user interface, (2) the amount of voicemail content and (3) the type of task. Results showed         that the levels of engagement could be predicted according to the levels of richness and control experienced when a task-term         was added to the framework. Implications of the refined RC &amp;amp; E framework for interaction design practice are discussed.      </content></document><document><year>2008</year><authors>Sarah Spiekermann1| 2 </authors><title>RFID and privacy: what consumers really want and fear      </title><content>This article investigates the conflicting area of user benefits arising through item level radio frequency identification         (RFID) tagging and a desire for privacy. It distinguishes between three approaches feasible to address consumer privacy concerns.         One is to kill RFID tags at store exits. The second is to lock tags and have user unlock them if they want to initiate reader         communication (user model). The third is to let the network access users&amp;#8217; RFID tags while adhering to a privacy protocol (network         model). The perception and reactions of future users to these three privacy enhancing technologies (PETs) are compared in         the present article and an attempt is made to understand the reasoning behind their preferences. The main conclusion is that         users do not trust complex PETs as they are envisioned today. Instead, they prefer to kill RFID chips at store exits even         if they appreciate after sales services. Enhancing trust through security and privacy &amp;#8216;visibility&amp;#8217; as well as PET simplicity         may be the road to take for PET engineers in UbiComp.      </content></document><document><year>2008</year><authors>Hans Gellersen1 | Carl Fischer1| Dominique Guinard2| Roswitha Gostner1| Gerd Kortuem1| Christian Kray3| Enrico Rukzio1 | Sara Streng4</authors><title>Supporting device discovery and spontaneous interaction with spatial references      </title><content>The RELATE interaction model is designed to support spontaneous interaction of mobile users with devices and services in their         environment. The model is based on spatial references that capture the spatial relationship of a user&amp;#8217;s device with other co-located devices. Spatial references are obtained by         relative position sensing and integrated in the mobile user interface to spatially visualize the arrangement of discovered         devices, and to provide direct access for interaction across devices. In this paper we discuss two prototype systems demonstrating         the utility of the model in collaborative and mobile settings, and present a study on usability of spatial list and map representations         for device selection.      </content></document><document><year>2008</year><authors>Xu Sun1  | Andrew May1 </authors><title>The role of spatial contextual factors in mobile personalization at large sports events      </title><content>This paper presents three field studies undertaken at large sports events in UK and China, with the aim of improving the user         experience at these types of events through the design of personally relevant mobile services. These field studies investigated:         which aspects of spatial context were relevant within the confines of a large sporting event, how their relevance differed         according to sports event and language/culture, and how they could be used to prescribe the behaviour of a personalizable/adaptive         mobile device. Spatial aspects of context were found to be highly significant within the large sports arena. They can be used         to maximize the relevance of information and communication services delivered to a spectator over a mobile device. A range         of design implications are discussed.      </content></document><document><year>2008</year><authors>Leopoldina Fortunati1  | Anna Maria Manganelli2 </authors><title>The social representation of telecommunications      </title><content>Without Abstract</content></document><document><year>2008</year><authors>Norman Sadeh1 | Jason Hong1 | Lorrie Cranor1 | Ian Fette1| Patrick Kelley1 | Madhu Prabaker1 | Jinghai Rao1</authors><title>Understanding and capturing people&amp;#8217;s privacy policies in a mobile social networking application      </title><content>A number of mobile applications have emerged that allow users to locate one another. However, people have expressed concerns         about the privacy implications associated with this class of software, suggesting that broad adoption may only happen to the         extent that these concerns are adequately addressed. In this article, we report on our work on PeopleFinder, an application that enables cell phone and laptop users to selectively share their locations with others (e.g. friends,         family, and colleagues). The objective of our work has been to better understand people&amp;#8217;s attitudes and behaviors towards         privacy as they interact with such an application, and to explore technologies that empower users to more effectively and         efficiently specify their privacy preferences (or &amp;#8220;policies&amp;#8221;). These technologies include user interfaces for specifying rules         and auditing disclosures, as well as machine learning techniques to refine user policies based on their feedback. We present         evaluations of these technologies in the context of one laboratory study and three field studies.      </content></document><document><year>2008</year><authors>Vassilis Kostakos1 | Tom Nicolai2| Eiko Yoneki3| Eamonn O&amp;#8217 Neill1| Holger Kenn2 | Jon Crowcroft3</authors><title>Understanding and measuring the urban pervasive infrastructure      </title><content>The increasing popularity of mobile computing devices has allowed for new research and application areas. Specifically, urban         areas exhibit an elevated concentration of such devices enabling potential ad-hoc co-operation and sharing of resources among         citizens. Here, we argue that people, architecture and technology together provide the infrastructure for these applications         and an understanding of this infrastructure is important for effective design and development. We focus on describing the         metrics for describing this infrastructure and elaborate on a set of observation, analysis and simulation methods for capturing,         deriving and utilising those metrics.      </content></document><document><year>2001</year><authors>Jason I. Hong1 | James A. L|ay1</authors><title>A Context/Communication Information Agent               </title><content> We are developing a Context/Communication Information Agent (CIA), an autonomous software agent that proactively searches         for the right information at the right time. Our goal is to design and evaluate a system that leverages what people naturally         do, using this knowledge to retrieve information, and presenting it with a minimal cost of disruption to the users. In this         paper, we describe the results a low-fidelity prototype performed in a meeting situation, the design space for such an application,         and our plans for continued investigation.      </content></document><document><year>2001</year><authors>Joseph F. McCarthy1</authors><title>Active Environments: Sensing and Responding to Groups of People               </title><content> Most environments are passive&amp;#8211; deaf, dumb and blind, unaware of their inhabitants and unable to assist them in a meaningful way. However, with the advent         of ubiquitous computing &amp;#8211; ever smaller, cheaper and faster computational devices embedded in a growing variety of &amp;#8220;smart&amp;#8221;         objects &amp;#8211; it is becoming increasingly possible to create active environments: physical spaces that can sense and respond appropriately to the people and activities taking place within them.         Most of the early ubiquitous computing applications focus on how individuals interact with their environments as they work on foreground tasks. In contrast, this paper focuses on how groups of people affect and are affected by background aspects of their environments.      </content></document><document><year>2001</year><authors>Nitin Sawhney1| Sean Wheeler1 | Chris Schm|t1</authors><title>Aware Community Portals: Shared Information Appliances for Transitional Spaces               </title><content> People wish to maintain a level of awareness of timely information, including presence of others in the workplace and other         social settings. We believe this provides better exchange, coordination and contact within a community, especially as people         work in asynchronous times and distributed locations. The challenge is to develop lightweight techniques for awareness, interaction         and communication using shared information appliances. In this paper, we describe the design of an exploratory responsive display projected within a shared workspace at the MIT         Media Lab. The system uses visual sensing to provide relevant information and constructs traces of people&amp;#8217;s activity over         time. Such aware portals may be deployed in casual workplace domains, distributed workgroups, and everyday public spaces.      </content></document><document><year>2001</year><authors>Barry Brumitt1 | Steven Shafer1</authors><title>Better Living Through Geometry               </title><content> Mark Weiser described ubiquitous computing as &amp;#8220;invisible, everywhere computing that does not live on a personal device of         any sort, but is in the woodwork everywhere&amp;#8221;[1]. The EasyLiving project is concerned with development of an architecture and         technologies for ubiquitous computing environments that allow the dynamic aggregation of diverse I/O devices into a single         coherent user experience. Though the need for research in distributed computing, perception and interfaces is widely recognised,         the importance of an explicit geometric world model for enhancing the user&amp;#8217;s experience of a ubiquitous computing system has         not been well-articulated. This paper describes three scenarios that benefit from geometric context and introduces the EasyLiving         Geometric Model.      </content></document><document><year>2001</year><authors>Filomena Papa1 | S|ra Spedaletti1</authors><title>Broadband Cellular Radio Telecommunication Technologies in Distance Learning: A Human Factors Field Study      </title><content> This paper presents a virtual classroom field experiment utilising broadband cellular radio telecommunication technologies         and involving real users. The aim of the investigation was to experiment in the field cellular broadband systems in realising         virtual classroom situations. In particular, we investigated learners&amp;#8217; performance and usability aspects of the multimedia         tele-education system including ease of use, usefulness, telepresence and users&amp;#8217; satisfaction about the system. Results confirmed         the effectiveness of the multimedia system in terms of both technical and psychological features. Some operational results         and practical solutions were obtained as well. They included the basic features of multimedia systems used in virtual classroom         and the correct procedures for training teachers and learners in the equipment use.      </content></document><document><year>2001</year><authors>Tore Urnes1| Arne S. Hatlen1| PГҐl S. Malm1 | Г&#152;ystein Myhre1</authors><title>Building Distributed Context-Aware Applications               </title><content> Context-aware applications gather information from sensors about their users and operating environment. Sensor handling is         a complicated issue that makes it hard and time-consuming to develop context-aware applications. This paper shows how dynamic         discovery protocols can be employed to deal with the physical distribution of sensors and the need to share sensors between         many applications. We report on our experiences from building a position-aware application using the dynamic discovery protocol         that is part of the Jini software infrastructure for distributed systems.      </content></document><document><year>2001</year><authors>Thai-Lai Pham1| Georg Schneider1| Stuart Goose1 | Arturo Pizano1</authors><title>Composite Device Computing Environment: A Framework for Situated Interaction Using Small Screen Devices               </title><content> Contemporary small screen devices are used as personal companion or communication devices. However, their physical dimensions         constrain the processing, communication and user interface capabilities. Thus, rich content presentation and diverse service         access via small screen appliances is limited accordingly. This paper introduces the Composite Device Computing Environment         (CDCE) that provides a framework for dynamically detecting and utilising surrounding computing resources to overcome the small         screen device limitations. CDCE includes the communication infrastructure in addition to supporting alternative models for         interactivity between small screen clients and surrounding computing resources.      </content></document><document><year>2001</year><authors>N. Green1| R. H. R. Harper1| G. Murtagh1 | G. Cooper1</authors><title>Configuring the Mobile User: Sociological and Industry Views      </title><content> This article considers the role of the consumer in the diffusion of mobile telecommunications technologies. There is presently         little research on the consumption and use of mobile technologies, and the aim of the present paper is to facilitate discussion         about the way consumer behaviour is currently understood in industry and academia. The paper considers key themes in social         science research on mobile ICTs, and understandings of the consumer held by those in the mobile industry. Bringing these understandings         together, we reiterate the now well attested view that the diffusion and consumption of mobile telephony and computing cannot         be understood without investigating the contexts and processes of their use in everyday life.      </content></document><document><year>2001</year><authors>Peter Ljungstr|1</authors><title>Context Awareness and Mobile Phones               </title><content> This paper investigates some aspects of how context-awareness can support users of mobile phones, in particular the calling         party. The use of mobile and stationary phones is discussed in relation to situational properties of a phone conversation,         especially with regards to who might benefit from context-awareness in this context. An initial hypothesis is that mobile         phone users communicate context information to each other (verbally) to a much higher degree than do stationary phone users.         Mobile phone users could benefit much from context awareness technology, in particular when about to make a call, if they         can receive context information regarding the person they are trying to reach prior to establishing the call. We argue that         such technology should require low amounts of explicit user interaction, and could lead to less disrupting calls in inappropriate         moments, as well as less frustration for the calling party when a call is not answered.      </content></document><document><year>2001</year><authors>P. J. Brown1 | G. J. F. Jones1</authors><title>Context-aware Retrieval: Exploring a New Environment for Information Retrieval and Information Filtering      </title><content> The opportunities for context-aware computing are fast expanding. Computing systems can be made aware of their environment         by monitoring attributes such as their current location, the current time, the weather, or nearby equipment and users. Context-aware         computing often involves retrieval of information: it introduces a new aspect to technologies for information delivery; currently         these technologies are based mainly on contemporary approaches to information retrieval and information filtering. In this         paper, we consider how the closely related, but distinct, topics of information retrieval and information filtering relate         to context-aware retrieval. Our thesis is that context-aware retrieval is as yet a sparsely researched and sparsely understood         area, and we aim in this paper to make a start towards remedying this.      </content></document><document><year>2001</year><authors>Leysia Palen1| Marilyn Salzman2 | Ed Youngs2</authors><title>Discovery and Integration of Mobile Communications in Everyday Life      </title><content> We report on the results of a study in which 19 new mobile telephone users were closely tracked for the first six weeks after         service acquisition. Results show that novices tend to rapidly modify their perceptions of social appropriateness around mobile         phone use, that actual nature of use frequently differs from initial predictions, and that comprehension of service-based         technologies can be problematic. We also describe instances and features of mobile telephony practice. When in use, mobile         phones occupy multiple social spaces simultaneously, spaces with norms that sometimes conflict: the physical space of the         mobile phone user and the virtual space of the conversation.      </content></document><document><year>2001</year><authors>A. E. Bl|ford1 | T. R. G. Green2</authors><title>Group and Individual Time Management Tools: What You Get is Not What You Need      </title><content> Some studies of diaries and scheduling systems have considered how individuals use diaries with a view to proposing requirements         for computerised time management tools. Others have focused on the criteria for success of group scheduling systems. Few have         paid attention to how people use a battery of tools as an ensemble. This interview study reports how users exploit paper,         personal digital assistants (PDAs) and a group scheduling system for their time management. As with earlier studies, we find         many shortcomings of different technologies, but studying the ensemble rather than individual tools points towards a different         conclusion: rather than aiming towards producing electronic time management tools that replace existing paper-based tools,         we should be aiming to understand the relative strengths and weaknesses of each technology and look towards more seamless         integration between tools. In particular, the requirements for scheduling and those for more responsive, fluid time management         conflict in ways that demand different kinds of support.      </content></document><document><year>2001</year><authors>Rich Ling1</authors><title>Guest Editorial: Mobile Communication and the Reformulation of the Social Order      </title><content>Without Abstract</content></document><document><year>2001</year><authors>Naohiko Kohtake1| Jun Rekimoto2 | Yuichiro Anzai1</authors><title>InfoPoint: A Device that Provides a Uniform User Interface to Allow Appliances to Work Together over a Network      </title><content> This paper proposes a new hand-held device called &amp;#8220;InfoPoint&amp;#8221; that allows appliances to work together over a network. We         have applied the idea of &amp;#8220;drag-and-drop&amp;#8221; operation as provided in the GUIs of PC and workstation desktop environment. InfoPoint         provides a unified interface that gives different types of appliances &amp;#8220;drag-and-drop&amp;#8221;-like behaviour for the transfer of data.         Moreover, it can transfer data from/to non-appliances such as pieces of paper. As a result, InfoPoint allows appliances to         work together, in the real-world environment, in terms of data transfer. A prototype of InfoPoint has been implemented and         several experimental applications have been investigated. InfoPoint has shown its applicability in a variety of circumstances.         We believe that the idea proposed in this paper will be a significant technology in the network of the future.      </content></document><document><year>2001</year><authors>Ion Constas1 | Despina Papadopoulos1</authors><title>Interface-Me: Pursuing Sociability Through Personal Devices      </title><content> In this paper we describe the fundamental principles that guide our work process at 5050 Ltd, in developing concepts and         prototypes for personal technology devices. We maintain that in designing personal devices it is critical to address the social         interaction elements of the user experience. We introduce the term &amp;#8220;social functionality&amp;#8221; to refer to those aspects of a device         that are specifically designed to elicit sociability and serendipity. It also refers to those aspects which enable users to         communicate or represent individuating characteristics through the use of their device. Social functionality is seen as a         critical success factor in the design of future personal devices. Introducing social functionality in personal technology         devices requires a multidisciplinary approach. Design and technology are seen as inseparable elements of the development process.         The mbracelet1, a wearable prototype we developed for, and in association with, NCR&amp;#8217;s The Knowledge Lab, is used as a case in point.      </content></document><document><year>2001</year><authors>Thomas Pederson1</authors><title>Magic Touch: A Simple Object Location Tracking System Enabling the Development of Physical-Virtual Artefacts in Office Environments               </title><content> A novel method for tracking physical activities is presented. The method is based on the assumption that all changes to the         physical environment are done by users themselves, and that these actions can be tracked using wearable computer technology         placed on human hands. Various limitations of the proposed method are discussed. Acknowledging these limitations, a range         of possible applications are presented, e.g. a set of Physical-Virtual Artefacts intended to decrease the gap between the         physical and virtual environments within offices. Also, some aspects of the modelling of user actions in office environments         are discussed.      </content></document><document><year>2001</year><authors>J. Cassell1 | K. Ryokai1</authors><title>Making Space for Voice: Technologies to Support Children&amp;#8217;s Fantasy and Storytelling      </title><content> Fantasy play and storytelling serve an important role in young children&amp;#8217;s development. While computers are increasingly present         in the world of young children, there is a lack of computational tools to support children&amp;#8217;s voices in everyday storytelling,         particularly in the context of fantasy play. We believe that there is a need for computational systems that engage in story-listening         rather than story-telling. This paper introduces StoryMat, a system that supports and listens to children&amp;#8217;s voices in their         own storytelling play. StoryMat offers a child-driven, story-listening space by recording and recalling children&amp;#8217;s narrating         voices, and the movements they make with their stuffed animals on a colourful story-evoking quilt. Empirical research with         children shows that StoryMat fosters developmentally advanced forms of storytelling of the kind that has been shown to provide         a bridge to written literacy, and provides a space where children engage in fantasy storytelling collaboratively with or without         a playmate. The paper addresses the importance of supporting young children&amp;#8217;s fantasy play and suggests a new way for technology         to play an integral part in that activity.      </content></document><document><year>2001</year><authors>Christian Licoppe1 | Jean Philippe Heurtin1</authors><title>Managing One&amp;#8217;s Availability to Telephone Communication Through Mobile Phones: A French Case Study of the Development Dynamics         of Mobile Phone Use      </title><content> This paper provides empirical results concerning the negotiation of access and joinability by mobile phone users. It shows         how access is embedded in a gift-giving economy (giving one&amp;#8217;s number for example). It also shows that the more users make         themselves available on the mobile phone, the more their mobile phone traffic increases (both incoming and outgoing). This         remarkable result is discussed in terms of the reciprocity involved in the management of mobile phone relationships.      </content></document><document><year>2001</year><authors>Peter Coschurba1| Joachim Baumann1| Uwe Kubach1 | Alex|er Leonhardi1</authors><title>Metaphors and Context-Aware Information Access               </title><content> Metaphors are often used to provide the user with a mental model to ease the use of computers. An example of such a metaphor         is the commonly used &amp;#8220;Desktop Metaphor&amp;#8221;. Metaphors also can be used to ease context-aware information access for the users         of mobile information systems. In this paper we present a taxonomy that allows the categorisation of such metaphors. Furthermore,         we give an overview of existing metaphors and their implementations. After introducing some new metaphors we conclude our         considerations with a classification of new and existing metaphors using our taxonomy.      </content></document><document><year>2001</year><authors>Daniela Petrelli1| Elena Not1| Massimo Zancanaro1| Carlo Strapparava1 | Oliviero Stock1</authors><title>Modelling and Adapting to Context               </title><content> One of the hardest points in context-aware applications is deciding what reactions a system has to a certain context. In         this paper, we introduce an architecture used in two context-aware museum guides. We discuss how the context is modelled and         we briefly present a rule-based mechanism to trigger system actions. A rule-based system offers the flexibility required to         be context-sensitive in the broadest sense since many context features can be considered and evaluated at the same time. This         architecture is very flexible and easily supports a fast prototyping approach.      </content></document><document><year>2001</year><authors>Anthony Jameson1</authors><title>Modelling both the Context and the User               </title><content> Research into context-aware computing risks losing sight of the user. This paper discusses how different types of information         about a user, ranging from information about the current context to information about the user&amp;#8217;s long-term properties, can         simultaneously be relevant to a given adaptation decision. Pointers are given to two areas of research that can help with         the integration of a broader range of information into context-aware systems: research on user-adaptive systems and on decision-theoretic         methods.      </content></document><document><year>2001</year><authors>Alex|ra Weilenmann1</authors><title>Negotiating Use: Making Sense of Mobile Technology      </title><content> This paper is based on a study of the ways in which a group negotiated the use of a new mobile technology. The group was         made up of ski instructors who, during a one-week ski trip, were equipped with a mobile awareness device called the Hummingbird.         The group was studied using ethnomethodologically inspired qualitative methods, with the focus on the group members&amp;#8217; different         views of the Hummingbird&amp;#8217;s intended use. Negotiations of use occurred using two methods: talk and action. The users negotiated issues such as where and when to use the technology, and whether to consider the Hummingbird a work tool or a gadget for social events. Further, the empirical         results clearly show how negotiations of new, mobile technology differ from stationary technology.      </content></document><document><year>2001</year><authors>Patrice L. (Tamar) Weiss1| Carolynn P. Whiteley2| Jutta Treviranus3 | Deborah I. Fels2</authors><title>PEBBLES: A Personal Technology for Meeting Educational, Social and Emotional Needs of Hospitalised Children      </title><content> Wayne Gretzky&amp;#8217;s PEBBLESTM (Providing Education By Bringing Learning Environments to Students) is a unique example of a personal technology, one in         which PC-based video-conferencing is used to make a real-time link between a hospitalised child and his or her regular classroom.         The system provides an opportunity for children who are in isolated situations, such as hospitals, to maintain a meaningful         link with their regular educational and social environments, thereby minimising many of the secondary problems that may develop         as a result of long-term illness and hospitalisation. The objective of this paper is to illustrate the impact that PEBBLES         had on one child who directly benefited from the system and on the people with whom she interacted (classmates, parents, teachers         and hospital staff). These results were used to explore how exposure to this personal technology influenced the behaviours         and attitudes of those involved in this study. The results indicate that, overall, PEBBLES has a very positive effect on both         the young and adult participants; the most dramatic effect of all was on the ill child who used PEBBLES to attend school.      </content></document><document><year>2001</year><authors>Anind K. Dey1| Gerd Kortuem2| David R. Morse3 | Albrecht Schmidt4</authors><title>Situated Interaction and Context-Aware Computing               </title><content>Without Abstract</content></document><document><year>2001</year><authors>P. Marti1| F. Gabrielli1 | F. Pucci1</authors><title>Situated Interaction in Art               </title><content> This paper describes metaphors and design strategies used to conceive and develop a hand-held, location-aware tourist guide         that delivers information related to the surrounding space mainly by reacting to the physical movements of the visitors. The         guide is designed to minimise the boundary between the physical space and the related information through a number of situated         and contextual-aware interaction mechanisms. These mechanisms are conceived to support the activity both at individual and         social level.      </content></document><document><year>2001</year><authors>Lars HallnГ¤s1 | Johan RedstrГ¶m1</authors><title>Slow Technology &amp;#8211; Designing for Reflection      </title><content> As computers are increasingly woven into the fabric of everyday life, interaction design may have to change &amp;#8211; from creating         only fast and efficient tools to be used during a limited time in specific situations, to creating technology that surrounds         us and therefore is a part of our activities for long periods of time. We present slow technology: a design agenda for technology aimed at reflection and moments of mental rest rather than efficiency in performance. The         aim of this paper is to develop a design philosophy for slow technology, to discuss general design principles and to revisit         some basic issues in interaction design from a more philosophical point of view. We discuss examples of soniture and informative art as instances of slow technology and as examples of how the design principles can be applied in practice.      </content></document><document><year>2001</year><authors>Sabine Geldof1 | Jacques Terken2</authors><title>Talking Wearables Exploit Context               </title><content> This paper addresses the issue of how natural language generation technology can contribute to less intrusive wearable devices.         Based on the investigation of how humans adapt the form of their utterances to the context of their hearer, we propose a strategy         to relate (physical) context to the automated generation of natural language utterances. First we emphasise that different         dimensions of context need to be taken into account and illustrate this with examples of lexical choice. Then we elaborate         a strategy for determining sentence structure and prosody annotation based on the context relating to focus of attention.         Our approach sets up an experimental basis in the context of an advice-giving wearable device (parrot).      </content></document><document><year>2001</year><authors>Kristof Van Laerhoven1 | Kofi Aidoo1</authors><title>Teaching Context to Applications               </title><content> Although mobile devices keep getting smaller and more powerful, their interface with the user is still based on that of the         regular desktop computer. This implies that interaction is usually tedious, while interrupting the user is not really desired         in ubiquitous computing. We propose adding an array of hardware sensors to the system that, together with machine learning         techniques, make the device aware of its context while it is being used. The goal is to make it learn the context-descriptions         from its user on the spot, while minimising user-interaction and maximising reliability.      </content></document><document><year>2001</year><authors>S. Arbanowski1| S. van der Meer1| S. Steglich1 | R. Popescu-Zeletin1</authors><title>The Human Communication Space: Towards I-centric Communications               </title><content> In the last few years, a variety of concepts for service integration and corresponding systems have been developed. On the         one hand, they aim for the interworking and integration of classical telecommunications and data communications services.         On the other, they are focusing on universal service access from a variety of end-user systems. Many of the technical problems,         resulting from the service integration, and service personalisation have been solved during the last years. However, all these         systems are driven by the concept of providing several technologies to users by keeping the peculiarity of each service.                     &amp;#8195;Looking at humans&amp;#8217; communication behaviour and their communication space, it is obvious that human beings interact habitually               in a set of contexts with their environment. The individual information preferences and needs, persons to interact with, and               the set of devices controlled by each individual define their personal communication space. Following this view, a new approach               is to build communication systems not on the basis of specific technologies, but on the analysis of the individual communication               spaces. The result is a communication system adapted to the demands of each individual (I-centric). The communication system               will act on behalf of users&amp;#8217; demands, reflecting recent actions to enable profiling and self-adaptation to contexts and situations.            </content></document><document><year>2001</year><authors>Leopoldina Fortunati1</authors><title>The Mobile Phone: An Identity on the Move      </title><content> This paper analyses the shifting identity of the mobile phone in the light of research carried out in 1996 on a representative         population sample from five major European countries: Italy, UK, France, Germany and Spain. A total of 6609 people were interviewed         by means of a telephone survey. The mobile phone emerged as a charismatic technology compared to other mobile technologies         (laptop and car phone) and as a leading technology that, in just a few years, has appropriated 11% of total telephone traffic.         It has &amp;#8220;dragged&amp;#8221; its widespread presence and amount of use from the workplace to the domestic sphere, although in Italy, where         it has had greatest success, its widespread use has been detached from its use in the workplace. Another emerging result is         that the use of the mobile phone is not correlated to strong residential mobility in individuals.      </content></document><document><year>2001</year><authors>Anind K. Dey1</authors><title>Understanding and Using Context               </title><content> Context is a poorly used source of information in our computing environments. As a result, we have an impoverished understanding         of what context is and how it can be used. In this paper, we provide an operational definition of context and discuss the         different ways in which context can be used by context-aware applications. We also present the Context Toolkit, an architecture         that supports the building of these context-aware applications. We discuss the features and abstractions in the toolkit that         make the task of building applications easier. Finally, we introduce a new abstraction, a situation which we believe will         provide additional support to application designers.      </content></document><document><year>2001</year><authors>Keith Cheverst1| Nigel Davies1| Keith Mitchell1 | Christos Efstratiou1</authors><title>Using Context as a Crystal Ball: Rewards and Pitfalls               </title><content> Context-awareness can be used to simplify a user&amp;#8217;s understanding of, and interaction with, interactive systems. In effect,         through adaptation, context-aware systems can migrate complexity away from the user and into the system (or agent). However,         the incorporation of context-awareness raises a number of issues. For example, users are required to trust the behaviour of         the system&amp;#8217;s intelligence and this requires the system to have predictable behaviour and the ability to successfully and consistently         preempt the user&amp;#8217;s goal. Unfortunately, the agent may incorrectly preempt the user&amp;#8217;s goal, owing to either flawed intelligence         or to incorrect or out-of-date contextual information. In such circumstances the user is likely to feel frustration because         the system will either appear overly prescriptive or, worse still, present incorrect results. This paper considers these issues,         a number of which are described in anecdotal form, based on our experiences in developing and evaluating the context-aware         GUIDE system.      </content></document><document><year>2001</year><authors>JГ¶rg Roth1 | Claus Unger1</authors><title>Using Handheld Devices in Synchronous Collaborative Scenarios      </title><content> In this paper we present a platform specially designed for groupware applications running on handheld devices. Common groupware         platforms request desktop computers as underlying hardware platforms. The fundamentally different nature of handheld devices         has a great impact on the platform, e.g. resource limitations have to be considered, the network is slow and unstable. Often,         personal data are stored on handheld devices, thus mechanisms have to ensure privacy. These considerations led to the QuickStep         platform. Sample applications developed with QuickStep demonstrate the strengths of the QuickStep environment.      </content></document><document><year>2001</year><authors>Odd-Wiking Rahlff1| Rolf Kenneth Rolfsen1 | Jo Herstad2</authors><title>Using Personal Traces in Context Space: Towards Context Trace Technology               </title><content> Wearables are often described with a focus on providing the user with wearable information access and communication means.         The contextual information retrieval aspect is, however, an essential feature of such systems, as in, for example, the Remembrance Agent [1] where manually entered search-terms         are used for presenting relevant situational information, or as in different location-based systems [2]. In this position paper we outline a general framework of contextually aware wearable systems, and suggest how such mechanisms,         collecting massive traces of the user context, may lead to several other interesting uses in what we will call context trace technology.               </content></document><document><year>2001</year><authors>Andrew Fano1</authors><title>What are a Location&amp;#8217;s &amp;#8220;File&amp;#8221; and &amp;#8220;Edit&amp;#8221; Menus?               </title><content> The promise of mobile devices lies not in their capacity to duplicate the capabilities of desktop machines, but rather in         their promise of enabling location-specific tasks. One of the challenges that must be addressed if they are to be used in         this way is how intuitive interfaces for mobile devices can be designed that enable access to location-specific services usable         across locations. We are developing a prototype mobile valet application that presents location-specific services organised         around the tasks associated with a location. The basic elements of the interface exploits commonalties in the way we address         tasks at various locations just as the familiar &amp;#8220;file&amp;#8221; and &amp;#8220;edit&amp;#8221; menus in various software applications exploit regularities         in software tasks.      </content></document><document><year>2001</year><authors>Allison Druin1 | Kori Inkpen2</authors><title>When are Personal Technologies for Children?      </title><content> This paper will discuss the various issues surrounding personal technologies for children. Three critical questions will         be discussed: Why can technology be important for children? What activities can technology support? And what changes should         be considered for the future?      </content></document><document><year>2001</year><authors>Rich Ling1</authors><title>&amp;#8220;We Release Them Little by Little&amp;#8221;: Maturation and Gender Identity as Seen in the Use of Mobile Telephony      </title><content> This paper examines the social meaning behind the adoption of mobile telephones by teenagers in Norway. Through this adoption         process one can see the way in which youths are developing their adult identity as well as their gendered identity. The primary         database used in this analysis is from two telephone questionnaires of Norwegian youth aged 13&amp;#8211;20 carried out in October and         December 1998. A total of 2007 interviews are included. The survey instrument covered teenagers&amp;#8217; ownership of mobile telephones,         payment forms and the use of mobile telephones to send and receive Short Message System (SMS) text messages. In addition,         the analysis draws on a survey of 1001 Norwegian parents and ethnographic interviews of 12 families.      </content></document><document><year>2006</year><authors>John Soldatos1 | Nikolaos Dimakis1 | Kostas Stamatis1  | Lazaros Polymenakos1 </authors><title>A breadboard architecture for pervasive context-aware services in smart spaces: middleware components and prototype applications      </title><content>We present an architectural framework along with a set of middleware elements, facilitating the integration of perceptual         components, sensors, actuators, and context-modeling scripts, comprising sophisticated ubiquitous computing applications in         smart spaces. The architecture puts special emphasis on the integration of perceptual components contributed by a variety         of technology providers, which has not been adequately addressed in legacy architectures. Moreover, the introduced architecture         allows for intelligent discovery and management of resources. Along with the description of this breadboard architecture,         we present its non-functional features and assess its performance. We also outline a rich set of practical prototype pervasive         services that have been built, based on this architecture. These services emphasize on providing non-obtrusive human-centric         assistance (e.g., memory aids, meeting recordings, pertinent information) in the scope of meetings, lectures and presentation,         Experiences from building these services manifest the benefits of the introduced architecture.      </content></document><document><year>2006</year><authors>Yuk Kuen Wong1  | Chao Jung Hsu1 </authors><title>A confidence-based framework for business to consumer (B2C) mobile commerce adoption      </title><content>The Technology Acceptance Model (TAM) has been considered to be fundamental in determining the acceptance of new technology         in the past decades. The two beliefs, ease of use and usefulness, in the model may not, however, fully explain the consumers&amp;#8217;         behavior in an emerging environment, such as mobile commerce (m-commerce). This paper aims to develop a framework for m-commerce         adoption in consumer decision-making processes. In this paper TAM has been adopted and extended to analyze successful m-commerce         adoption. The key elements of the proposed confidence-based framework for B2C m-commerce adoption include psychological and         behavioral factors. Psychological factors include history-based confidence, institution-based confidence and personality-based         confidence. Behavioral factors include perceived ease of use and perceived usefulness of the mobile application and technology.      </content></document><document><year>2006</year><authors>Olivier Liechti1  | Tadao Ichikawa1</authors><title>A digital photography framework enabling affective awareness in home communication</title><content>By transforming the personal computer into a communication appliance, the Internet has initiated the true home computing revolution. As a result, Computer Mediated Communication (CMC) technologies are increasingly used in domestic settings, and are changing the way people keep in touch with their relatives and friends. This article first looks at how CMC tools are currently used in the home, and points at some of their benefits and limitations. Most of these tools supportexplicit interpersonal communication, by providing a new medium for sustaining conversations. The need for tools supportingimplicit interaction between users, in more natural and effottless ways, is then argued for. The idea of affective awareness is introduced as a general sense of being in touch with one's family and friends. Finally, the KAN-G framework, which enables affective awareness through the exchange of digital photographs, is described. Various components, which make the capture, distribution, observation and annotation of snapshots easy and effortless, are discussed.</content></document><document><year>2006</year><authors>Olivier Liechti1 | Mark Sifer1 | Tadao Ichikawa1</authors><title>A non-obtrusive user interface for increasing social awareness on the World Wide Web</title><content>Arguing for the need of increasing social awareness on the World Wide Web, we describe a user interface based on the metaphor of windows bridging electronic and physical spaces. We present a system that, with the aim of making online activity perceptible in the physical world, makes it possible tohear people visiting one's website. The system takes advantage of theseamless andcontinuous network connection offered by handheld Web-appliances such as personal digital assistants.</content></document><document><year>2006</year><authors>Sten L. Amundsen1  | Frank Eliassen1 </authors><title>A resource and context model for mobile middleware      </title><content>Mobile computing systems should be self-managed to simplify operation and maintenance plus meet user&amp;#8217;s expectation with respect         to Quality of Service (QoS). When architecting self-managed mobile computing systems, one must take a holistic view on both         QoS management and the entities in the mobile environment. This paper presents a novel model that includes both resources         and context elements. To illustrate the usefulness of the model, it is applied to a video streaming application by: (1) modelling         context elements and resources in the environment, (2) specifying context dependencies and QoS characteristics of the application,         and (3) designing weakly integrated resource and context managers. We describe a middleware that uses the developed managers         when evaluating context dependencies and predict offered QoS of alternative implementations of the application. In order to         select the one that can operate in the current environment and that best satisfies given user preferences.      </content></document><document><year>2006</year><authors>Steven Feiner1 | Blair MacIntyre1| Tobias H&amp;ouml llerer1 | Anthony Webster1</authors><title>A touring machine: Prototyping 3D mobile augmented reality systems for exploring the urban environment</title><content>We describe a prototype system that combines the overlaid 3D graphics of augmented reality with the untethered freedom of mobile computing. The goal is to explore how these two technologies might together make possible wearable computer systems that can support users in their everyday interactions with the world. We introduce an application that presents information about our university's campus, using a head-tracked, see-through, head-worn, 3D display, and an untracked, opaque, hand-held, 2D display with stylus and trackpad. We provide an illustrated explanation of how our prototype is used, and describe our rationale behind designing its software infrastructure and selecting the hardware on which it runs.</content></document><document><year>2006</year><authors>John Underkoffler1 </authors><title>A view from the Luminous Room</title><content>A new body of research, concerning the divergence of information systems away from today's ubiquitous notion of computer, is emerging. Though the various threads of inquiry diverge significantly in their approach, each generally seeks some intimate integration of computational resources with its user's immediate or extended environment. We introduce here a new project called theLuminous Room, which uses dynamically controlled video projection to permit information access and manipulation throughout an architectural space. A description of the working components of the system is followed by an explication of the philosophies that provide both motivation and a conceptual scaffolding for the work. Finally, we offer speculations about the way in which formal architecture and environmental information systems like theLuminous Room might co-develop.</content></document><document><year>2006</year><authors>Thad Starner1 | Joshua Weaver1 | Alex Pentl|1</authors><title>A wearable computer-based American sign Language Recogniser</title><content>Modern wearable computer designs package workstation-level performance in systems small enough to be worn as clothing. These machines enable technology to be brought where it is needed most for the handicapped: everyday mobile environments. This paper describes a research effort to make a wearable computer that can recognise (with the possible goal of translating) sentence-level American Sign Language (ASL) using only a baseball cap mounted camera for input. Current accuracy exceeds 97% per word on a 40-word lexicon.</content></document><document><year>2006</year><authors>E. Egea-LГіpez1 | J. Vales-Alonso1 | A. S. MartГ­nez-Sala1 | J. GarcГ­a-Haro1 | P. PavГіn-MariГ±o1  | M. V. Bueno Delgado1 </authors><title>A wireless sensor networks MAC protocol for real-time applications      </title><content>Wireless sensor networks (WSN) are designed for data gathering and processing, with particular requirements: low hardware         complexity, low energy consumption, special traffic pattern support, scalability, and in some cases, real-time operation.         In this paper we present the virtual TDMA for sensors (VTS) MAC protocol, which intends to support the previous features,         focusing particularly on real-time operation. VTS adaptively creates a TDMA arrangement with a number of timeslots equal to         the actual number of nodes in range. Thus, VTS achieves an optimal throughput performance compared to TDMA protocols with         fixed size of frame. The frame is set up and maintained by a distributed procedure, which allows sensors to asynchronously         join and leave the frame. In addition, duty cycle is increased or decreased in order to keep latency constant below a given         deadline. Therefore, a major advantage of VTS is that it guarantees a bounded latency, which allows soft real-time applications.      </content></document><document><year>2006</year><authors>Giulio Jacucci1 | Antti Oulasvirta1 | Antti Salovaara1</authors><title>Active construction of experience through mobile media: a field study with implications for recording and sharing      </title><content>To fully appreciate the opportunities provided by interactive and ubiquitous multimedia to record and share experiences, we         report on an ethnographic investigation on the settings and nature of human memory and experience at a large-scale event.         We studied two groups of spectators at a FIA World Rally Championship in Finland, both equipped with multimedia mobile phones.         Our analysis of the organization of experience-related activities in the mass event focuses on the active role of technology-mediated         memories in constructing experiences. Continuity, reflexivity with regard to the Self and the group, maintaining and re-creating         group identity, protagonism and active spectatorship were important social aspects of the experience and were directly reflected         in how multimedia was used. Particularly, we witnessed multimedia-mediated forms of expression, such as staging, competition,         storytelling, joking, communicating presence, and portraying others; and the motivation for these stemmed from the engaging,         processual, and shared nature of experience. Moreover, we observed how temporality and spatiality provided a platform for         constructing experiences. The analysis advocates applications that not only store or capture human experience for sharing         or later use but also actively participates in the very construction of experience. The approach conveys several valuable         design implications.      </content></document><document><year>2006</year><authors>Adaptation in mobile workflow management systems</authors><title>Workflow management systems (WFMS) are an emerging technology for supporting the coordinated execution of business processes by a group of users. One goal of introducing a WFMS into an enterprise is to integrate all personnel working on a business process into the system. This article describes a new approach to the integration of mobile users into a WFMS. This is of special interest because key personnel such as sales representatives and executives are often travelling and can only be integrated into the WFMS through mobile computing technologies. After introducing an architecture for mobile WFMS, we focus on the handling of one specific feature of mobile systems: the high diversity of environments in which mobile users operate. For handling this feature we have to implement adaptable software systems. In our approach, we start by introducing a formal model of mobile systems. This model offers a basis for the use of optimisation techniques to realise an adaptive mobile WFMS.</title></document><document><year>2007</year><authors>Konstantinos Moustakas1| 2 | Georgios Nikolakis1 | Dimitrios Tzovaras1 | Sebastien Carbini3 | Olivier Bernier3  | Jean Emmanuel Viallet3 </authors><title>3D content-based search using sketches      </title><content>This paper presents a novel interactive framework for 3D content-based search and retrieval using as query model an object         that is dynamically sketched by the user. In particular, two approaches are presented for generating the query model. The         first approach uses 2D sketching and symbolic representation of the resulting gestures. The second utilizes non-linear least         squares minimization to model the 3D point cloud that is generated by the 3D tracking of the user&amp;#8217;s hands, using superquadrics.         In the context of the proposed framework, three interfaces were integrated to the sketch-based 3D search system including         (a) an unobtrusive interface that utilizes pointing gesture recognition to allow the user manipulate objects in 3D, (b) a         haptic&amp;#8211;VR interface composed by 3D data gloves and a force feedback device, and (c) a simple air&amp;#8211;mouse. These interfaces were         tested and comparative results were extracted according to usability and efficiency criteria.      </content></document><document><year>2007</year><authors>Andreas Komninos1  | Mark D. Dunlop2 </authors><title>A calendar based Internet content pre-caching agent for small computing devices      </title><content>We described in earlier publications the principles of a system where Internet content would be pre-cached, based on contextual         information obtained from a user&amp;#8217;s electronic calendar. The model for such a system envisioned a set of cooperating agents,         distributed on a user&amp;#8217;s desktop and mobile device, which would be responsible for making decisions on the context and preferences         of the user, and downloading the relevant internet content through a land-based broadband connection and storing it on the         mobile device. This paper presents and discusses established pre-caching techniques and their suitability for use on mobile         information access scenarios. It proceeds in describing the implementation details of an alternative approach, a calendar-based         pre-caching system and presents the findings of tests that were made with human subjects on such a system.      </content></document><document><year>2007</year><authors>Yngve Dahl1  | Dag SvanГ¦s1 </authors><title>A comparison of location and token-based interaction techniques for point-of-care access to medical information      </title><content>This paper compares the usability of some location and token-based interaction techniques for systems that provide point-of-care         access to medical information. The investigation is based around a scenario from clinical work&amp;#8212;administration of medicine to patients. Four interaction techniques that match the scenario are identified. We demonstrate how these techniques can be concretized         through functional prototypes. The prototypes were tested with health workers in a full-scale model of a section of a hospital         ward. The usability issues emerging from the tests were related to required user attention, predictability of system behavior,         and integration with the work situation. We found that the usability of the interaction techniques to a large degree depended         on specific physical and social conditions of the use situation. This result is an incentive to consider a broad set of sensor-based         interaction techniques and devices for such systems, and to select the best few of these for implementation.      </content></document><document><year>2007</year><authors>Philip R. Ross1 | C. J. Overbeeke1| 2| Stephan A. G. Wensveen1 | Caroline M. Hummels3</authors><title>A designerly critique on enchantment      </title><content>To develop the concept of user experience in HCI, McCarthy et al. introduce the notion of enchantment in interaction design.         They describe five sensibilities that support exploration and evaluation in design for enchantment. In this paper, we discuss         design for enchantment in light of our approach to design for interaction, called design for meaningful mediation. Based on         our experiences from case studies, we argue that &amp;#8216;considering the whole person with feelings, desires and anxieties&amp;#8217;, one         of the sensibilities McCarthy et al. formulate, influences the desirability and realisation of the other four sensibilities.         By way of case studies, we show how we explored the link between &amp;#8216;the whole person&amp;#8217; and desired interaction experience in         a designerly way. We place enchantment in a context of other interaction experiences and demonstrate possible design techniques         relevant to design for interaction experiences, including enchantment.      </content></document><document><year>2007</year><authors>I. G. Damousis1 | D. Tzovaras1  | M. G. Strintzis1| 2 </authors><title>A fuzzy expert system for the early warning of accidents due to driver hypo-vigilance      </title><content>In this paper a fuzzy expert system for the prediction of hypovigilance-related accidents is presented. The system uses physiological         modalities in order to detect signs of extreme hypovigilance. An advantage of such a system is its extensibility regarding         the physiological modalities and features that it can use as inputs. In that way, even though at present only eyelid-related         features are exploited, in the future and for prototypes designed for professionals other physiological modalities, such as         EEG can be easily integrated into the existing system in order to make it more robust and reliable.      </content></document><document><year>2007</year><authors>Angelo Gaeta1 | Matteo Gaeta2  | Pierluigi Ritrovato1 </authors><title>A grid based software architecture for delivery of adaptive and personalised learning experiences      </title><content>This paper is centred on one of the main results of the ELeGI project, namely its software architecture for the delivery of         personalised formal-learning experiences. The architecture has been designed and developed: (1) taking into account a general         model for the personalisation of learning experiences, allowing us to obtain a solution that is flexible with respect to the         pedagogies, and (2) on top of service oriented grid technologies, allowing us to obtain several advantages in the process         of creation and delivery of personalised learning experience like, for instance, ubiquitous and seamless access to heterogeneous         learning resources distributed over the network. In order to validate our result, the first prototype of the ELeGI architecture         has been deployed on a virtual organisation consisting of three geographically distributed nodes. Each node of the VO provides         services and learning resources that have been adopted in the creation and delivery of a personalised learning experience         about the Torricelli&amp;#8217;s law and based on the virtual scientific experiment model. The case of study has been successfully executed         and has given us a proof of our assumptions related to the added value of the service oriented grid mainly in terms of: (1)         capabilities to access educational resources distributed over the network, that is relevant in achieving the personalisation         of learning experiences, and (2) high level of dynamicity and adaptiveness in the creation and delivery processes of a personalised         learning experience.      </content></document><document><year>2007</year><authors>Yuichiro Takeuchi1  | Masanori Sugimoto1 </authors><title>A user-adaptive city guide system with an unobtrusive navigation interface      </title><content>In this paper, we describe an intelligent location-aware city guide system, which adapts to each user&amp;#8217;s preferences, and uses         an intuitive &amp;#8220;metal detector&amp;#8221; interface for navigation. Our system analyzes each user&amp;#8217;s past location data history to estimate         individual preferences, and allows users to find shops that match their tastes in the same way a metal detector would be used         to detect metal objects. The procedure with which the system picks out shops that match each user&amp;#8217;s preferences includes a         newly developed place learning algorithm, which can efficiently find frequented places, complete with their proper names (e.g.         &amp;#8220;The Ueno Royal Museum&amp;#8221;). We have conducted a series of evaluation tests at a popular shopping district inside Tokyo, and         the results validate the effectiveness of our overall approach.      </content></document><document><year>2007</year><authors>Paul Lefrere1 </authors><title>Activity-based scenarios for and approaches to ubiquitous e-Learning      </title><content>This paper presents scenarios for ubiquitous e-Learning in heterogeneous networks. It concludes by arguing for the development         of a learning-focused analogue, activity-based e-Learning extensions (ABLE), of activity-based computing (ABC). The goal would         be to offer the learning-support/performance-support equivalent of ABC&amp;#8217;s support for human activities in a ubiquitous computing         environment, relevant to areas that are hard to model today: informal on-the-job learning; peer-to-peer support and informal         sharing of content in ad hoc work groups; formal and informal ways to capture and share knowledge-focused insights and processes;         content and systems to aid reflection. Just as ABC supplements traditional computing approaches (in ABC, data- and application-oriented)         to suit &amp;#8220;multiple, parallel and mobile work activities&amp;#8221; (Bardram et al. in Support for ABC in a personal computing operating         system. CHI 2006 proceedings. MontrГ©al, QuГ©bec, Canada, 22&amp;#8211;27 April 2006, pp 211&amp;#8211;220), so ABLE could supplement traditional         e-Learning approaches (often largely content-focused, sometimes little more than page-turning) to suit those same work activities,         and make e-Learning potentially more resilient to interruptions, more fun and more memorable.      </content></document><document><year>2007</year><authors>Brian P. Bailey1 | Jacob T. Biehl1| Damon J. Cook1 | Heather E. Metcalf1</authors><title>Adapting paper prototyping for designing user interfaces for multiple display environments      </title><content>A multiple display environment (MDE) networks personal and shared devices to form a virtual workspace, and designers are just         beginning to grapple with the challenges of developing interfaces tailored for these environments. To develop effective interfaces         for MDEs, designers must employ methods that allow them to rapidly generate and test alternative designs early in the design         process. Paper prototyping offers one promising method, but needs to be adapted to effectively simulate the use of multiple         displays and allow testing with groups of users. In this paper, we share experiences from two projects in which paper prototyping         was utilized to explore interfaces for MDEs. We identify problems encountered when applying the traditional method, describe         how these problems were overcome, and distill our experiences into recommendations that others can draw upon. By following         our recommendations, designers need only make minor modifications to the existing method to better realize benefits of paper         prototyping for MDEs.      </content></document><document><year>2007</year><authors>Mario Romero1 | Zachary Pousman1  | Michael Mateas1 </authors><title>Alien presence in the home: the design of Tableau Machine      </title><content>We introduce a design strategy, alien presence, which combines work in human&amp;#8211;computer interaction, artificial intelligence,         and media art to create enchanting experiences involving reflection over and contemplation of daily activities. An alien presence         actively interprets and characterizes daily activity and reflects it back via generative, ambient displays that avoid simple         one-to-one mappings between sensed data and output. We describe the alien presence design strategy for achieving enchantment,         and report on Tableau Machine, a concrete example of an alien presence design for domestic spaces. We report on an encouraging         formative evaluation indicating that Tableau Machine does indeed support reflection and actively engages users in the co-construction         of meaning around the display.      </content></document><document><year>2007</year><authors>Michael Kenteris1 | Damianos Gavalas1  | Daphne Economou1 </authors><title>An innovative mobile electronic tourist guide application      </title><content>&amp;#8220;Mobile tourism&amp;#8221; represents a relatively new trend in the field of tourism and involves the use of mobile devices as electronic         tourist guides. While much of the underlying technology is already available, there are still open challenges with respect         to design, usability, portability, functionality and implementation aspects. Most existing &amp;#8220;mobile tourism&amp;#8221; solutions either         represent of-the-shelf applications with rigidly defined content or involve portable devices with networking capabilities         that access tourist content with the requirement of constant airtime, i.e., continuous wireless network coverage. This paper         presents the design and implementation issues of a &amp;#8220;mobile tourism&amp;#8221; research prototype, which brings together the main assets         of the two aforementioned approaches. Namely, it enables the creation of portable tourist applications with rich content that         matches user preferences. The users may download these personalized applications (optimized for their specific device&amp;#8217;s model)         either directly to their mobile device or first to a PC and then to a mobile terminal (through infrared or bluetooth). Thereafter,         network coverage is not further required as the applications execute in standalone mode and may be updated when the user returns         online. The dynamically created tourist applications also incorporate a &amp;#8220;push model&amp;#8221;, wherein new tourist content is forwarded         to the mobile terminal with minimal user intervention as soon as it is added or updated by the administrator. Our prototype         has been developed on the top of Java 2 Micro Edition (J2ME) which offers an ideal platform for the development of full-fledged,         interactive and portable applications tailored for resource-constrained mobile devices. The paper presents our development         experiences with J2ME and highlights its main advantages and shortcomings in relation to the implementation of such kind of         applications. Finally, an empirical evaluation of user experience with the mobile application prototype is presented.      </content></document><document><year>2007</year><authors>Patrick de la Hamette1  | Gerhard TrГ¶ster1 </authors><title>Architecture and applications of the FingerMouse: a smart stereo camera for wearable computing HCI      </title><content>18;mm)         and can be worn on the body, capturing the user&amp;#8217;s hand and processing in real-time its coordinates as well as a 1-bit image         of the hand segmented from the background. Alternatively, the system serves as a smart depth camera, delivering foreground         segmentation and tracking, depth maps and standard images, with a processing latency smaller than 1;ms. This paper describes         the FingerMouse functionality and its applications, and how the specific architecture outperforms other systems in size, latency         and power consumption.      </content></document><document><year>2007</year><authors>Ylva GislГ©n1| Jonas LГ¶wgren1  | Ulf Myrestam2</authors><title>Avatopia: a cross-media community for societal action      </title><content>A cross-media platform was designed for a community of young teenagers oriented towards societal change. The platform involved         an interactive web-forum featuring creative and communicative collaborative tools in a 3D avatar environment, and a weekly         show in national public-service television. Informal assessment of the work indicated that (1) an integrated spiral of production         and consumption across the two media channels involved is a viable design concept to support community building, (2) off-the-shelf         avatar technology and consumer-grade Internet connectivity can form a feasible infrastructure for collaborative storytelling         tools, and (3) a participatory design process wherein participants transition into the role of mentors and norm carriers upon         deployment can be a feasible way to support subcultural community building towards &amp;#8220;difficult&amp;#8221; topics, even though it entails         considerable resource demands. All of these findings are potentially transferable to other design domains and audiences.      </content></document><document><year>2007</year><authors>Marko T. Heikkinen1 | Johanna Still1 </authors><title>Benefits and challenges of new mobile service development in R&amp;amp;D network      </title><content>The competitive environment of organizations has changed remarkably in line with rapid technological development and globalization         of markets. This has lead to a situation where the amount of resources and knowledge needed in the development of new offerings         has become overwhelming for a single organization. Consequently, nowadays organizations&amp;#8212;both commercial and non-commercial&amp;#8212;are         performing research and development activities in networks consisting of multiple types of actors. This is also the case in         industries developing new services for consumers&amp;#8217; mobile handhelds. This paper introduces a network view to new mobile service         development and argues that a thorough understanding of acting in the network environment is a pre-requisite for successful         mobile service creation. This viewpoint is emphasized in an information-rich case study, which describes the formation and         operations of a network, which created a new mobile service for a sports team.      </content></document><document><year>2007</year><authors>Martijn H. Vastenburg1 | David V. Keyson1  | Huib de Ridder1 </authors><title>Considerate home notification systems: a field study of acceptability of notifications in the home      </title><content>A field study in ten homes was conducted to understand what influences users&amp;#8217; acceptability of notifications in the home environment.         The key finding is that perceived message urgency is the primary indicator of acceptability of notifications in the home&amp;#8212;if         people think a message is urgent, they want the message to be shown immediately, regardless of what they are doing at the         time of notification. The study also shows that the acceptability of low-urgent and medium-urgent messages could be improved         by taking into account mental activity load at the time of notification. No effect of physical activity was found on acceptability.         The results suggest that to improve the scheduling of notifications in the home, notification systems need a mechanism assessing         both the message urgency and the mental activity load, whereas physical activity can be ignored. From a methodological point         of view, it is difficult to measure acceptability of notifications in a realistic setting, given the need to balance experimental         control with realistic context. The present paper suggests a way to introduce controlled notifications and subjective measurements         of acceptability in homes.      </content></document><document><year>2007</year><authors>Steve Whittaker1 | Simon Tucker1| Kumutha Swampillai1 | Rachel Laban1</authors><title>Design and evaluation of systems to support interaction capture and retrieval      </title><content>Although many recent systems have been built to support Information Capture and Retrieval (ICR), these have not generally         been successful. This paper presents studies that evaluate two different hypotheses for this failure, firstly that systems         fail to address user needs and secondly that they provide only rudimentary support for ICR. Having first presented a taxonomy         of different systems built to support ICR, we then describe a study that attempts to identify user needs for ICR. On the basis         of that study we carried out two user-oriented evaluations. In the first, we carried out a task-based evaluation of a state-of-the-art         ICR system, finding that it failed to provide users with abstract ways to view meetings data, and did not present users with         information categories that they considered to be important. In a second study, we introduce a new method for comparative         evaluation of different techniques for accessing meetings data. The second study showed that simple interface techniques that         extracted key information from meetings were effective in allowing users to extract gist from meetings data. We conclude with         a discussion of outstanding issues and future directions for ICR research.      </content></document><document><year>2007</year><authors>Alex|ra Zafiroglu1  | Michele Chang2 </authors><title>Digital homes on wheels: designing for the unimagined home      </title><content>Design for the digital home is often predicated on an ideal, imagined domestic space that is expansive, stable, occupied by         a &amp;#8220;busy&amp;#8221; nuclear family, and does not always match existing, real-life digital homes. Using American retirees living full         time in recreational vehicles as our case study of actual digital homes, we argue that designing suitable and appropriate         technologies for the home must be done with particular attention to the home as embodied, rather than the home as ideal. The         challenges and advantages of designing for embodied homes are detailed in this paper. We contend that appropriate design must         seriously engage not only the material body of the house, but the social fabric&amp;#8212;the complex sets of social relationships and         identities and practices they support&amp;#8212;that make a house a home. An analysis of the salient aspects of the material body and         social fabric of full time retired RVer household leads to bespoke design considerations for these real-life digital homes.      </content></document><document><year>2007</year><authors>Tom Djajadiningrat1| 2 | Ben Matthews1  | Marcelle Stienstra1 </authors><title>Easy doesn&amp;#8217;t do it: skill and expression in tangible aesthetics      </title><content>In this paper, we articulate the role of movement within a perceptual-motor view of tangible interaction. We argue that the         history of human&amp;#8211;product interaction design has exhibited an increasing neglect of the intrinsic importance of movement. On         one hand, human&amp;#8211;product interaction design has shown little appreciation in practice of the centrality of our bodily engagement         in the world. This has resulted in technologies that continue to place demands on our cognitive abilities, and deny us the         opportunity of building bodily skill. On the other hand, the potential for movement in products to be a meaningful component         of our interaction with them has also been ignored. Both of these directions (design for bodily engagement and the expressiveness         of product movements) are sketched out, paying particular respect for their potential to impact both interaction aesthetics         and usability. We illustrate a number of these ideas with examples.      </content></document><document><year>2007</year><authors>Peter Wright1 | Mark Blythe2  | John McCarthy3 </authors><title>Editorial      </title><content>Without Abstract</content></document><document><year>2007</year><authors>Christophe Salzmann1 | Denis Gillet1 | Philippe Mullhaupt1</authors><title>End-to-end adaptation scheme for ubiquitous remote experimentation      </title><content>Remote experimentation is an effective e-learning paradigm for supporting hands-on education using laboratory equipment at         distance. The current trend is to enable remote experimentation in mobile and ubiquitous learning. In such a context, the         remote experimentation software should enable effective telemonitoring and teleoperation, no matter the kind of device used         to access the equipment. It should also be sufficiently lenient so as to handle the rapidly evolving wireless and mobile communication         environment. While the current Internet bandwidth allows remote experimentation to work flawlessly on fixed connections such         as LANs, mobile users suffer from both the versatile nature of wireless communications and the limitation of the mobile devices.         These conditions impose that the remote experimentation software should integrate adaptation features. For effective ubiquitous         remote experimentation, it should ideally be guaranteed that the information representing the state of the remote equipment         is rendered (to the end user) at the same pace at which it has been acquired, yet possibly at the cost of a somewhat minimal         time delay between the acquisition and rendering phases. In this respect, an end-to-end adaptation scheme is proposed that         explicitly handles the inherent variability of the connection and the versatility of the mobile devices considered in ubiquitous         remote experimentation. Instead of relying on a stochastic approach, the proposed adaptation scheme relies on a deterministic         mass-balance equivalence model. The effectiveness of the proposed adaptation scheme is demonstrated in critical conditions         corresponding to remote experimentation carried out using a PDA over a Bluetooth link.      </content></document><document><year>2007</year><authors>Wilfried M. Post1 | Mirjam A. A. Huis in &amp;#8217 t Veld1  | Sylvia A. A. van den Boogaard1</authors><title>Evaluating meeting support tools      </title><content>Many attempts are underway for developing meeting support tools, but less attention is paid to the evaluation of meetingware.         This article describes the development and testing of an instrument for evaluating meeting tools. First, we specified the         object of evaluation&amp;#8212;meetings&amp;#8212;by means of a set of input, process, and outcome factors. Then, we designed the process of evaluation,         consisting of, first, the generation of meeting behavior in the form of a controlled series of meetings within the context         of a project and, second, the measurement of the identified meeting factors. To measure these factors, a rating scale, questionnaires,         and information flow analysis were used. Next, the instrument was tested, and the factors for successful meetings were determined         in 13 projects in which four participants had to meet four times. The evaluation instrument proved to be a reliable and useful         aid for the development and improvement of meeting tools.      </content></document><document><year>2007</year><authors>David Pinelle1  | Carl Gutwin2 </authors><title>Evaluating teamwork support in tabletop groupware applications using collaboration usability analysis      </title><content>Tabletop groupware systems have natural advantages for collaboration, but they present a challenge for application designers         because shared work and interaction progress in different ways than in desktop systems. As a result, tabletop systems still         have problems with usability. We have developed a usability evaluation technique, T-CUA, that focuses attention on teamwork         issues and that can help designers determine whether prototypes provide adequate support for the basic actions and interactions         that are fundamental to table-based collaboration. We compared T-CUA with expert review in a user study where 12 evaluators         assessed an early tabletop prototype using one of the two evaluation methods. The group using T-CUA found more teamwork problems         and found problems in more areas than those using expert review; in addition, participants found T-CUA to be effective and         easy to use. The success of T-CUA shows the benefits of using a set of activity primitives as the basis for discount usability         techniques.      </content></document><document><year>2007</year><authors>Daniel Johnson1  | John Gardner2| 3 </authors><title>Exploring mindlessness as an explanation for the media equation: a study of stereotyping in computer tutorials      </title><content>This study extends previous media equation research by empirically testing the mindlessness explanation of media equation         behaviour. The current study explored the potential moderating effect of mood on media equation behaviour. Specifically, the         study assessed whether participants&amp;#8217; tendency to stereotype when interacting with a computer varied as a function of mood.         Seventy-six undergraduate students were exposed to either a positive or negative mood manipulation and then completed a computer-based         tutorial on car engines. The tutorial was presented using either a male or female synthesised voice. Participants&amp;#8217; affective         state, attitudes and opinions were assessed via questionnaire. Female participants in a positive mood showed a greater propensity         to gender-stereotype computers than female participants in a negative mood, suggesting that media equation behaviour is more         likely to result when people are in a mindless state. Male participants, however, did not show the same pattern of behaviour.      </content></document><document><year>2007</year><authors>Leah Buechley1  | Michael Eisenberg1</authors><title>Fabric PCBs, electronic sequins, and socket buttons: techniques for e-textile craft      </title><content>The blossoming research field of electronic textiles (or e-textiles) seeks to integrate ubiquitous electronic and computational elements into fabric. This paper concerns one of the most challenging         aspects of the design and construction of e-textile prototypes: namely, engineering the attachment of traditional hardware         components to textiles. We present three new techniques for attaching off-the-shelf electrical hardware to e-textiles: (a)         the design of fabric PCBs or iron-on circuits to attach electronics directly to a fabric substrate; (b) the use of electronic sequins to create wearable displays and other artifacts; and (c) the use of socket buttons to facilitate connecting pluggable devices to textiles. In this work we have focused on using easily obtained materials and         developing user-friendly techniques; our aim is to develop methods that will make e-textile technology available to crafters,         students, and hobbyists. This paper describes the techniques and employs them as a springboard for a wider-ranging discussion         of &amp;#8220;e-textile craft&amp;#8221;.      </content></document><document><year>2007</year><authors>Ilias Maglogiannis1 | Demosthenes Vouyioukas1 | Chris Aggelopoulos1</authors><title>Face detection and recognition of natural human emotion using Markov random fields      </title><content>This paper presents an integrated system for emotion detection. In this research effort, we have taken into account the fact         that emotions are most widely represented with eye and mouth expressions. The proposed system uses color images and it is         consisted of three modules. The first module implements skin detection, using Markov random fields models for image segmentation         and skin detection. A set of several colored images with human faces have been considered as the training set. A second module         is responsible for eye and mouth detection and extraction. The specific module uses the HLV color space of the specified eye         and mouth region. The third module detects the emotions pictured in the eyes and mouth, using edge detection and measuring         the gradient of eyes&amp;#8217; and mouth&amp;#8217;s region figure. The paper provides results from the system application, along with proposals         for further research.      </content></document><document><year>2007</year><authors>Shun-yuan Yeh1 | Keng-hao Chang2 | Chon-in Wu1 | Hao-hua Chu1  | Jane Yung-jen Hsu1 </authors><title>GETA sandals: a footstep location tracking system      </title><content>This paper presents the design, implementation, and evaluation of a footstep based indoor location system. The traditional Japanese GETA sandals are equipped with force, ultrasonic, orientation, RFID sensors and an accelerometer         to produce a wearable location tracking         system that demand little infrastructure in the deployed environment. In its basic form, a user simply puts on GETA sandals to enable         tracking of his/her locations relative to a starting point (e.g., a building entrance), making it easy for deployment everywhere.         The footstep location system is based on dead-reckoning, which works by measuring and tracking displacement vectors along a trail of footsteps. Each displacement vector is formed by drawing a line between each pair of footsteps, and the         position of a user can be calculated by summing up the current and all previous displacement vectors. Unlike most existing         indoor location systems, the footstep based method does not suffer from problems with obstacles, multi-path effects, signal         noises, signal interferences, and dead spots. There are two technical challenges in the proposed design: (1) location error         accumulates over distance traveled, and (2) displacement measurements are sporadic during stair climbing. The first problem         is addressed by a light RFID infrastructure, while the second problem is remedied by incorporating an accelerometer into the         system. Experiments on GETA prototype are conducted to evaluate the positional accuracy of our system.      </content></document><document><year>2007</year><authors>Theodoros N. Arvanitis1 | Argeroula Petrou2 | James F. Knight1 | Stavros Savas3 | Sofoklis Sotiriou3 | Michael Gargalakos4  | Elpida Gialouri4 </authors><title>Human factors and qualitative pedagogical evaluation of a mobile augmented reality system for science education used by learners         with physical disabilities      </title><content>Technology-enhanced learning, employing novel forms of content representation and education service delivery by enhancing         the visual perception of the real environment of the user, is favoured by proponents of educational inclusion for learners         with physical disabilities. Such an augmented reality computer-mediated learning system has been developed as part of an EU         funded research project, namely the CONNECT project. The CONNECT project brings together schools and science centres, and         produces novel information and communication technologies based on augmented reality (AR) and web-based streaming and communication,         in order to support learning in a variety of settings. The CONNECT AR interactive learning environment can assist users to         better contextualize and reinforce their learning in school and in other settings where people learn (i.e. science centres         and home). The CONNECT concept and associated technologies encourage users to visit science centres and perform experiments         that are not possible in school. They can also build on these experiences back at school and at home with visual augmentations         that they are communicated through web-based streaming technology. This paper particularly focuses on a user-centred evaluation         approach of human factors and pedagogical aspects of the CONNECT system, as applied to a special needs user group. The main         focus of the paper is on highlighting the human factors issues and challenges, in terms of wearability and technology acceptance,         while elaborating on some qualitative aspects of the pedagogical effectiveness of the instructional medium that AR technology         offers for this group of learners.      </content></document><document><year>2007</year><authors>Andy Crabtree1  | Tom Rodden1 </authors><title>Hybrid ecologies: understanding cooperative interaction in emerging physical-digital environments      </title><content>We consider the emergence of hybrid ecologies, which marry mixed reality environments and ubiquitous computing environments         together to bridge the physical-digital divide. Hybrid ecologies are new class of digital ecology that merge multiple environments,         physical and digital, together. Collaboration in these emerging environments is characterized by &amp;#8216;fragmented interaction&amp;#8217;         in that it is mediated by interaction mechanisms that are differentially distributed. Unpacking the collaborative nature of         fragmented interaction requires that we uncover the ordinary interactional competences that users exploit to make differentially         distributed mechanisms of interaction work and the distributed practices that articulate &amp;#8216;seamful&amp;#8217; representations and provide         for awareness and coordination.      </content></document><document><year>2007</year><authors>Anxo Cereijo RoibГЎs1 | David Geerts2| Elizabeth Furtado3| 4 | Licia Calvi2</authors><title>Implications of the socio-physical contexts when interacting with mobile media      </title><content>Without Abstract</content></document><document><year>2007</year><authors>Elise van den Hoven1  | Berry Eggen2</authors><title>Informing augmented memory system design through autobiographical memory theory      </title><content>Autobiographical memory (AM) is the &amp;#8220;memory for the events in one&amp;#8217;s life&amp;#8221; [1]. Often it is assumed that in order to remember all those events, you just need to record everything and when you replay         these recordings you will remember those events. You can compare this with a library metaphor that has been used to explain         AM according to the record-keeping approach. However, after many years of AM-research it was concluded that AM is stored in         a different manner, namely according to the constructionist approach, which often is initiated by memory cues. This paper         explains these AM theories, surveys literature on existing augmented memory systems and describes our own work in this area.         All this input is combined into eight design recommendations for future augmented memory systems.      </content></document><document><year>2007</year><authors>Joachim Neumann1 | Josep R. Casas1 | Du&amp;#353 an Macho1  | Javier Ruiz Hidalgo1 </authors><title>Integration of audiovisual sensors and technologies in a smart room      </title><content>At the Technical University of Catalonia (UPC), a smart room has been equipped with 85 microphones and 8 cameras. This paper         describes the setup of the sensors, gives an overview of the underlying hardware and software infrastructure and indicates         possibilities for high- and low-level multi-modal interaction. An example of usage of the information collected from the distributed         sensor network is explained in detail: the system supports a group of students that have to solve a lab assignment related         problem.      </content></document><document><year>2007</year><authors>Dimitrios Tzovaras1 | Konstantinos Moustakas1| 2 | Georgios Nikolakis1  | Michael G. Strintzis1| 2 </authors><title>Interactive mixed reality white cane simulation for the training of the blind and the visually impaired      </title><content>This paper presents a mixed reality tool developed for the training of the visually impaired based on haptic and auditory         feedback. The proposed approach focuses on the development of a highly interactive and extensible Haptic Mixed Reality training         system that allows visually impaired to navigate into real size Virtual Reality environments. The system is based on the use         of the CyberGrasp&amp;#8482; haptic device. An efficient collision detection algorithm based on superquadrics is also integrated into         the system so as to allow real time collision detection in complex environments. A set of evaluation tests is designed in         order to identify the importance of haptic, auditory and multimodal feedback and to compare the MR cane against the existing         Virtual Reality cane simulation system.      </content></document><document><year>2007</year><authors>Sabiha Ghellal1  | Irma Lindt2 </authors><title>Interactive movie elements in a pervasive game      </title><content>This paper presents our research initiatives around new user experiences in the area of pervasive mixed reality crossmedia         gaming. In a prototypical game, The Epidemic Menace, we combined static and interactive story telling elements to create a         mixed reality experience. As part of this research initiative we also investigated how elements of the real world and virtual         worlds could produce a new environment where physical and digital objects can co-exist and interact with each other, we wanted         to evaluate how linear stories could be integrated into a game flow and how they could be used to extend game experiences.         A new form of interactive entertainment that is not limited to hardware based games or linear storylines but includes a truly         interactive TV experience was one of our goals.      </content></document><document><year>2007</year><authors>K. Karpouzis1 | J. Soldatos2  | D. Tzovaras3 </authors><title>Introduction to the special issue on emerging multimodal interfaces      </title><content>Without Abstract</content></document><document><year>2007</year><authors>Mark D. Dunlop1  | Michelle Montgomery Masters1</authors><title>Investigating five key predictive text entry with combined distance and keystroke modelling      </title><content>This paper investigates text entry on mobile devices using only five-keys. Primarily to support text entry on smaller devices         than mobile phones, this method can also be used to maximise screen space on mobile phones. Reported combined Fitt&amp;#8217;s law and         keystroke modelling predicts similar performance with bigram prediction using a five-key keypad as is currently achieved on         standard mobile phones using unigram prediction. User studies reported here show similar user performance on five-key pads         as found elsewhere for novice nine-key pad users.      </content></document><document><year>2007</year><authors>Julian R|all1 | Oliver Amft1 | JГјrgen Bohn2  | Martin Burri1 </authors><title>LuxTrace: indoor positioning using building illumination      </title><content>Tracking location is challenging due to the numerous constraints of practical systems including, but not limited to global         cost, device volume and weight, scalability and accuracy; these constraints are typically more severe for systems that should         be wearable and used indoors. We investigate the use of wearable solar cells to track changing light conditions (a concept         that we named LuxTrace) as a source of user displacement and activity data. We evaluate constraints of this approach and present         results from an experimental validation of displacement and activity estimation. The results indicate that a distance estimation         accuracy of 21;cm (80% quantile) can be achieved. A simple method to combine LuxTrace with complementary absolute location         estimation methods is also presented. We apply carpet-like distributed RFID tags to demonstrate online learning of new lighting         environments.      </content></document><document><year>2007</year><authors>J. -C. Martin1 | G. Caridakis2 | L. Devillers1 | K. Karpouzis2  | S. Abrilian1 </authors><title>Manual annotation and automatic image processing of multimodal emotional behaviors: validating the annotation of TV interviews      </title><content>There have been a lot of psychological researches on emotion and nonverbal communication. Yet, these studies were based mostly         on acted basic emotions. This paper explores how manual annotation and image processing can cooperate towards the representation         of spontaneous emotional behavior in low-resolution videos from TV. We describe a corpus of TV interviews and the manual annotations         that have been defined. We explain the image-processing algorithms that have been designed for the automatic estimation of         movement quantity. Finally, we explore how image processing can be used for the validation of manual annotations.      </content></document><document><year>2007</year><authors>Anton Nijholt1 | Job Zwiers1  | Jan Peciva2 </authors><title>Mixed reality participants in smart meeting rooms and smart home environments      </title><content>Human&amp;#8211;computer interaction requires modeling of the user. A user profile typically contains preferences, interests, characteristics,         and interaction behavior. However, in its multimodal interaction with a smart environment the user displays characteristics         that show how the user, not necessarily consciously, verbally and nonverbally provides the smart environment with useful input         and feedback. Especially in ambient intelligence environments we encounter situations where the environment supports interaction         between the environment, smart objects (e.g., mobile robots, smart furniture) and human participants in the environment. Therefore         it is useful for the profile to contain a physical representation of the user obtained by multi-modal capturing techniques.         We discuss the modeling and simulation of interacting participants in a virtual meeting room, we discuss how remote meeting         participants can take part in meeting activities and they have some observations on translating research results to smart         home environments.      </content></document><document><year>2007</year><authors>Eiman Kanjo1 | Steve Benford1 | Mark Paxton1 | Alan Chamberlain1 | Danae Stanton Fraser2 | Dawn Woodgate2 | David Crellin3  | Adrain Woolard4 </authors><title>MobGeoSen: facilitating personal geosensor data collection and visualization using mobile phones      </title><content>Mobile sensing and mapping applications are becoming more prevalent because sensing hardware is becoming more portable and         more affordable. However, most of the hardware uses small numbers of fixed sensors that report and share multiple sets of         environmental data which raises privacy concerns. Instead, these systems can be decentralized and managed by individuals in         their public and private spaces. This paper describes a robust system called MobGeoSens which enables individuals to monitor         their local environment (e.g. pollution and temperature) and their private spaces (e.g. activities and health) by using mobile         phones in their day to day life. The MobGeoSen is a combination of software components that facilitates the phone&amp;#8217;s internal         sensing devices (e.g. microphone and camera) and external wireless sensors (e.g. data loggers and GPS receivers) for data         collection. It also adds a new dimension of spatial localization to the data collection process and provides the user with         both textual and spatial cartographic displays. While collecting the data, individuals can interactively add annotations and         photos which are automatically added and integrated in the visualization file/log. This makes it easy to visualize the data,         photos and annotations on a spatial and temporal visualization tool. In addition, the paper will present ways in which mobile         phones can be used as noise sensors using an on-device microphone. Finally, we present our experiences with school children         using the above mentioned system to measure their exposure to environmental pollution.      </content></document><document><year>2007</year><authors>Andreas Schrader1 | Darren V. Carlson1  | Dominik Busch2 </authors><title>Modular framework support for context-aware mobile cinema      </title><content>In this paper we describe a novel approach for interactive cinema based on context-aware narration using handheld computers.         The paper describes both the artistic approach and the ubiquitous computing framework developed to realize the scenario. This         framework has been used in various projects, including the described video production course at the ISNM, where five interactive         cinema concepts have been developed and shown during a public demonstration. In our approach, a new type of user experience         has been established by placing the viewer inside the movie&amp;#8217;s physical locations during playback. Moreover, the developed         ubiquitous computing framework provides a foundation for future work in the area of ad-hoc, service-oriented Ubicomp scenarios.      </content></document><document><year>2007</year><authors>L. Malatesta1 | A. Raouzaiou1 | K. Karpouzis1  | S. Kollias1 </authors><title>MPEG-4 facial expression synthesis      </title><content>The current work will describe an approach to synthesize expressions, including intermediate ones, via the tools provided         in the MPEG-4 standard based on real measurements and on universally accepted assumptions of their meaning, taking into account         results of Whissel&amp;#8217;s study. Additionally, MPEG-4 facial animation parameters are used in order to evaluate theoretical predictions         for intermediate expressions of a given emotion episode, based on Scherer&amp;#8217;s appraisal theory. MPEG-4 FAPs and action units         are combined in modeling the effects of appraisal checks on facial expressions and temporal evolution issues of facial expressions         are investigated. The results of the synthesizing process can then be applied to Embodied Conversational Agents (ECAs), rendering         their interaction with humans, or other ECAs, more affective.      </content></document><document><year>2007</year><authors>Alex|re Benoit1| Laurent Bonnaud1| Alice Caplier1 | Phillipe Ngo1| Lionel Lawson2| Daniela G. Trevisan2| Vjekoslav Levacic3| CГ©line Mancas4 | Guillaume Chanel5</authors><title>Multimodal focus attention and stress detection and feedback in an augmented driver simulator      </title><content>This paper presents a driver simulator, which takes into account the information about the user&amp;#8217;s state of mind (level of         attention, fatigue state, stress state). The user&amp;#8217;s state of mind analysis is based on video data and biological signals.         Facial movements such as eyes blinking, yawning, head rotations, etc., are detected on video data: they are used in order         to evaluate the fatigue and the attention level of the driver. The user&amp;#8217;s electrocardiogram and galvanic skin response are         recorded and analyzed in order to evaluate the stress level of the driver. A driver simulator software is modified so that         the system is able to appropriately react to these critical situations of fatigue and stress: some audio and visual messages         are sent to the driver, wheel vibrations are generated and the driver is supposed to react to the alert messages. A multi-threaded         system is proposed to support multi-messages sent by the different modalities. Strategies for data fusion and fission are         also provided. Some of these components are integrated within the first prototype of OpenInterface: the multimodal similar         platform.      </content></document><document><year>2007</year><authors>Keni Bernardin1 | Hazim Kemal Ekenel1  | Rainev Stiefelhagen1 </authors><title>Multimodal identity tracking in a smart room      </title><content>The automatic detection, tracking, and identification of multiple people in intelligent environments are important building         blocks on which smart interaction systems can be designed. Those could be, e.g., gesture recognizers, head pose estimators         or far-field speech recognizers and dialog systems. In this paper, we present a system which is capable of tracking multiple         people in a smart room environment while inferring their identities in a completely automatic and unobtrusive way. It relies         on a set of fixed and active cameras to track the users and get close-ups of their faces for identification, and on several         microphone arrays to determine active speakers and steer the attention of the system. Information coming asynchronously from         several sources, such as position updates from audio or visual trackers and identification events from identification modules,         is fused at higher level to gradually refine the room&amp;#8217;s situation model. The system has been trained on a small set of users         and showed good performance at acquiring and keeping their identities in a smart room environment.      </content></document><document><year>2007</year><authors>Fabio Pianesi1 | Massimo Zancanaro1 | Elena Not1 | Chiara Leonardi1 | Vera Falcon1  | Bruno Lepri1 </authors><title>Multimodal support to group dynamics      </title><content>The complexity of group dynamics occurring in small group interactions often hinders the performance of teams. The availability         of rich multimodal information about what is going on during the meeting makes it possible to explore the possibility of providing         support to dysfunctional teams from facilitation to training sessions addressing both the individuals and the group as a whole.         A necessary step in this direction is that of capturing and understanding group dynamics. In this paper, we discuss a particular         scenario, in which meeting participants receive multimedia feedback on their relational behaviour, as a first step towards         increasing self-awareness. We describe the background and the motivation for a coding scheme for annotating meeting recordings         partially inspired by the Bales&amp;#8217; Interaction Process Analysis. This coding scheme was aimed at identifying suitable observable         behavioural sequences. The study is complemented with an experimental investigation on the acceptability of such a service.      </content></document><document><year>2007</year><authors>Matt Jones1 | Steve Jones2 | Gareth Bradley2 | Nigel Warren2 | David Bainbridge2  | Geoff Holmes2 </authors><title>ONTRACK: Dynamically adapting music playback to support navigation      </title><content>Listening to music on personal, digital devices whilst mobile is an enjoyable, everyday activity. We explore a scheme for         exploiting this practice to immerse listeners in navigation cues. Our prototype, ONTRACK, continuously adapts audio, modifying         the spatial balance and volume to lead listeners to their target destination. First we report on an initial lab-based evaluation         that demonstrated the approach&amp;#8217;s efficacy: users were able to complete tasks within a reasonable time and their subjective         feedback was positive. Encouraged by these results we constructed a handheld prototype. Here, we discuss this implementation         and the results of field-trials. These indicate that even with a low-fidelity realisation of the concept, users can quite         effectively navigate complicated routes.      </content></document><document><year>2007</year><authors>Cristina Hava Muntean1  | Gabriel-Miro Muntean2 </authors><title>Open corpus architecture for personalised ubiquitous e-learning      </title><content>As the e-learning area matures, there are a growing number of e-learning content providers that produce and distribute material         that covers a large range of topics, differs in quality and is represented in various formats. Lately, different devices and         various network technologies allow extensive user access to educational content almost anywhere, anytime and from any device.         Ubiquitous e-learning has the potential to provide continuous and context-based, educational material to human learners anytime,         anywhere and on any device. Since each person has different expectations related to the content, the performance of the delivery         and display of that content, it is desirable for an ubiquitous e-learning environment to provide user-oriented personalisation         of e-learning material. However very often there are multiple sources of e-learning material at various web locations (open         corpus resources) that cover the same topic, but differ in terms of quality, formatting and even cost. It is very difficult         for learners to select the content that best suits their interests and goals, characteristics of the device used and delivery         network as well as their cost budget. This paper proposes an innovative ubiquitous e-learning environment called Performance-based         E-learning Adaptive Cost-efficient Open Corpus frameworK (PEACOCK) that provides support for the selection and distribution         of personalised e-learning rich media content (e.g. multimedia, pictures, graphics and text) to e-learners such as it will         best suit users&amp;#8217; interests and goals, meet their formatting preferences and cost constraints, while considering the limitations         introduced by the end-user devices and the delivery networks to the user. PEACOCK&amp;#8217;s main goal is to maximise the users&amp;#8217; e-learning         experience and increase their learning satisfaction and learning outcome.      </content></document><document><year>2007</year><authors>Erika Reponen1 | Pertti Huuskonen1  | Kristijan Mihalic2 </authors><title>Primary and secondary context in mobile video communication      </title><content>The new video capabilities of mobile phones are starting to change the field of mobile communication. It is now dramatically         easier to publish video in quasi-real time. We discuss how this change will affect the way people perceive video-recording,         in terms of privacy, transparency, and the notion of context. We use a model of primary and secondary contexts to analyze         usage situations, highlighting newly relevant research issues.      </content></document><document><year>2007</year><authors>A. Pnevmatikakis1 | J. Soldatos1 | F. Talantzis1  | L. Polymenakos1 </authors><title>Robust multimodal audio&amp;#8211;visual processing for advanced context awareness in smart spaces      </title><content>Identifying people and tracking their locations is a key prerequisite to achieving context awareness in smart spaces. Moreover,         in realistic context-aware applications, these tasks have to be carried out in a non-obtrusive fashion. In this paper we present         a set of robust person-identification and tracking algorithms, based on audio and visual processing. A main characteristic         of these algorithms is that they operate on far-field and un-constrained audio&amp;#8211;visual streams, which ensure that they are         non-intrusive. We also illustrate that the combination of their outputs can lead to composite multimodal tracking components,         which are suitable for supporting a broad range of context-aware services. In combining audio&amp;#8211;visual processing results, we         exploit a context-modeling approach based on a graph of situations. Accordingly, we discuss the implementation of realistic         prototype applications that make use of the full range of audio, visual and multimodal algorithms.      </content></document><document><year>2007</year><authors>Tacha Serif1| Gheorghita Ghinea1 | Lampros Stergioulas1| Sherry Y. Chen1| Thanassis Tiropanis2 | Sofia Tsekeridou2</authors><title>Satellite-based delivery of educational content to geographically isolated communities: a service based approach      </title><content>Enabling learning for members of geographically isolated communities presents benefits in terms of promoting regional development         and cost savings for governments and companies. However, notwithstanding recent advances in e-Learning, from both technological         and pedagogical perspectives, there are very few, if any, recognised methodologies for user-led design of satellite-based         e-learning infrastructures. In this paper, we present a methodology for designing a satellite and wireless based network infrastructure         and learning services to support distance learning for such isolated communities. This methodology entails (a) the involvement         of community members in the development of targeted learning services from an early stage, and (b) a service-oriented approach         to learning solution deployment. Results show, that, while the technological premises of distance learning can be accommodated         by hybrid satellite/wireless infrastructures, this has to be complemented with (a) high-quality audio&amp;#8211;visual educational material,         and (b) the opportunity for community members to interact with other community members either as groups (common-room oriented         scenarios) or individuals (home-based scenarios), thus providing an impetus for learner engagement in both formal and informal         activities.      </content></document><document><year>2007</year><authors>Mette Ramsgard Thomsen1 </authors><title>Sites of flux: imagining space in the dance-architectures of The Changing Room and Sea Unsea      </title><content>This paper presents the conceptualization of an event space of interaction. Referring to enchantment as a means of describing         an indeterminate and evolving state of interaction, where the meaning of the interactive object or environment remains open         ended and exploratory, this paper explores how contemporary architectural concepts of space and inhabitation can allow for         a new framing of interactive experiences. Presenting the two dance-architectures The Changing Room and Sea Unsea as case studies, the paper seeks to demonstrate challenges to the way space and place are understood in Human&amp;#8211;Computer Interaction.      </content></document><document><year>2007</year><authors>Jacques Terken1 | Sriram Subramanian2  | Massimo Zancanaro3 </authors><title>Special issue on user-centred design and evaluation of ubiquitous groupware      </title><content>Without Abstract</content></document><document><year>2007</year><authors>Gheorghita Ghinea1 | Lampros Stergioulas1 | Sherry Chen1 | Thanassis Tiropanis2  | Sofia Tsekeridou2 </authors><title>Special issue on &amp;#8220;Ubiquitous e-Learning Solutions over Heterogeneous Networks&amp;#8221;      </title><content>Without Abstract</content></document><document><year>2007</year><authors>Florian &amp;#8216 Floyd&amp;#8217  Mueller1 | Gunnar Stevens2 | Alex Thorogood1 | Shannon O&amp;#8217 Brien1  | Volker Wulf2| 3 </authors><title>Sports over a Distance      </title><content>Sport is a domain full of movement-based interactions. These interactions typically have positive health effects as well as         an impact on social bonding. We have investigated ways in which computer augmented devices can lead to new sport experiences         and explored opportunities to combine physical activities with remote social bonding. Three prototypes have been implemented         which showcase movement-based interaction in sports. &amp;#8220;Breakout for Two&amp;#8221; allows geographically distant users to play a physically         exhausting ball game together. &amp;#8220;FlyGuy&amp;#8221; gives users a hang-glide experience controllable through body movement. &amp;#8220;Push&amp;#8217;N&amp;#8217;Pull&amp;#8221;         uses isometric exercise equipment over a network to encourage users to complete a cooperative game whilst performing intense         muscular actions. A comparison of these applications shows that such movement-based interaction in a networked environment         allows players in different locations to achieve a work out and also to socialize. Based on these projects, we conclude with         practical design implications for future Exertion Interfaces.      </content></document><document><year>2007</year><authors>Mark Blythe1  | Peter Wright1 </authors><title>Technology scruples: why intimidation will not save the recording industry and how enchantment might      </title><content>While the recording industry continues to lobby for increasingly draconian laws to protect their interests, users of digital         technology continue to share files and copy protected music. This paper considers the ethics of copying and argues that legal         measures are unlikely to solve the music industry&amp;#8217;s problems in the age of digital reproduction. It begins with a review of         the legal arguments around copyright legislation and notes that the law is currently unclear and contested. Adapting the game         &amp;#8220;scruples&amp;#8221; to questions of what is and is not considered theft, a qualitative study reflects on the ways that ethical positions         around new media are reached and articulated. The findings relate ethical positions constructed around notions of resistance,         intangibility and identity. It is argued that the global online population cannot be policed without consent and that mechanics         of artist reimbursement must be developed that account for consumers&amp;#8217; technology scruples. File sharing is then considered         not as a legal problem but as a design challenge and a strategy of enchantment is suggested. The design concept of a digital         music box is outlined to illustrate strategies of enchantment rather than litigation and intimidation.      </content></document><document><year>2007</year><authors>Phoebe Sengers1 | Kirsten Boehner1| Michael Mateas2 | Geri Gay1</authors><title>The disenchantment of affect      </title><content>In computing design, experience is often broken down, compartmentalized, and engineered: a process that often disenchants         the original experience. In this paper, we demonstrate the possibility to design for experience, not by formalizing and rationalizing         it, but instead by supporting open-ended engagement and appropriation. We illustrate this approach through Affector, a case         study in affective computing, in which we focus on user interpretation and construction of emotional experience over its computational         modeling. We derive design and evaluation strategies for enchantment that focus on supporting the ongoing construction and         interpretation of experience by human participants over the course of interaction. We suggest that enchanting experiences         may be designed only by approaching enchantment obliquely: not by engineering it in, but by providing opportunities where         it may emerge.      </content></document><document><year>2007</year><authors>MГіrna NГ­ ChonchГєir1  | John McCarthy1</authors><title>The enchanting potential of technology: a dialogical case study of enchantment and the Internet      </title><content>Although user experience is now widely accepted as a central concern in human&amp;#8211;computer interaction and interaction design,         its conceptual and methodological implications are still being worked out. Enchantment has become emblematic in this process         by pointing to the enlivening potential of technology in people-technology relations. As part of an ongoing project to deepen         our understanding of enchantment in user experience, this paper presents a case study of one person&amp;#8217;s enchantment with their         Internet uses. The analysis suggests three salient aspects of this enchantment: responsive crossing of boundaries; dialogue         in personal transformation; and the potential endlessness and depths of enchantment. It also suggests that some characteristics         of interaction with the particular medium facilitate enchantment: personal control over self-presentation; the paradox of         being able to carefully craft meaning from what is normally chaotic; the possibility of finding and constructing personal         narratives online; playing in a vast pool of information. Reflection on the results of this single case analysis points to         the value for understanding user experience of in-depth single-case analyses that focus on the personal and particular.      </content></document><document><year>2007</year><authors>Kher Hui Ng1 | Boriana Koleva1 | Steve Benford1</authors><title>The iterative development of a tangible pin-board to symmetrically link physical and digital documents      </title><content>There is an asymmetry in many tangible interfaces: while physical objects can be used to manipulate digital information, the         reverse is often not possible&amp;#8212;the digital world cannot push back. We introduce a new push-back tangible technology, a pin-board         that physically ejects paper documents. This is realized by extending the Pin&amp;amp;Play technology to support &amp;#8216;pouts&amp;#8217;, addressable         pin-like devices that can remove themselves from a board using muscle wire actuators. We describe how this technology has         been developed through two iterations of prototyping, application and formative study. An initial study revealed how potential         mismatches between the physical and digital characteristics of pouts caused difficulties with users predicting pop-out events         and reasoning about the state of pouts. This led us to extend pouts to reveal more of their internal state, an approach verified         through a second study. It also raises more general issues for the design of pushback tangible technologies and ubiquitous         interfaces.      </content></document><document><year>2007</year><authors>Leopoldina Fortunati1  | Anna Maria Manganelli2 </authors><title>The social representation of telecommunications      </title><content>Without Abstract</content></document><document><year>2007</year><authors>Anna L. Cox1| Paul A. Cairns1 | Alison Walton1 | Sasha Lee1</authors><title>Tlk or txt? Using voice input for SMS composition      </title><content>This paper reports a series of investigations, which aim to test the appropriateness of voice recognition as an interaction         method for mobile phone use. First, a KLM model was used in order to compare the speed of using voice recognition against         using multi-tap and predictive text (the two most common methods of text entry) to interact with the phone menus and compose         a text message. The results showed that speech is faster than the other two methods and that a combination of input methods         provides the quickest task completion times. The first experiment used a controlled message creation task to validate the         KLM predictions. This experiment also confirmed that the result was not due to a speed/accuracy trade off and that participants         preferred to use the combination of input methods rather than a single method for menu interaction and text composition. The         second experiment investigated the effect of limited visual feedback (when walking down the road or driving a car for example)         on interaction, providing further evidence in support of speech as a useful input method. These experiments not only indicate         the usefulness of voice in SMS input but also that users could also be satisfied with voice input in hands-busy, eyes-busy         situations.      </content></document><document><year>2007</year><authors>Bert Bongers1| 2  | Gerrit C. van der Veer3 </authors><title>Towards a Multimodal Interaction Space: categorisation and applications      </title><content>Based on many experiences of developing interactive systems by the authors, a framework for the description and analysis of         interaction has been developed. The dimensions of this multimodal interaction space have been identified as sensory modalities, modes and levels of interaction. To illustrate and validate this framework, development of multimodal interaction styles is carried out and interactions         in the real world are studied, going from theory to practice and back again. The paper describes the framework and two recent         projects, one in the field of interactive architecture and another in the field of multimodal HCI research. Both projects         use multiple modalities for interaction, particularly movement based interaction styles.      </content></document><document><year>2007</year><authors>Ann Light1 </authors><title>Transports of delight? What the experience of receiving (mobile) phone calls can tell us about design      </title><content>This paper takes a phenomenological approach to analysing people&amp;#8217;s accounts of receiving phone calls, drawing on Heidegger         and Feenberg. Accounts of calls received on a mobile phone are compared with those on landlines, charting progress from location-centred         to person-centred phoning. A range of naturally-occurring contexts are discussed in terms of the experience of balancing the         activities of talking on the phone with activities in the immediate environment, and the enchantment sustained or sacrificed.         The study suggests that recipients&amp;#8217; enchantment with phoning is affected by their freedom and desire to project towards the         caller and create shared spaces, and reveals some factors that impact on the transitions of attention required to do so. It         concludes with the design implications of taking this view of interactions with and through phones.      </content></document><document><year>2007</year><authors>Adrian David Cheok1  | Yue Li1</authors><title>Ubiquitous interaction with positioning and navigation using a novel light sensor-based information transmission system      </title><content>This paper describes a novel light sensor-based information transmission system for indoor positioning and navigation with         particular benefits for mobile and wearable computers. It can seamlessly extend outdoor GPS tracking to the indoor environment.         In a novel manner, fluorescent light is used as the medium to transmit information, which is encoded by using a pulse-frequency         modulation technique. The user receives the encoded light information through a photo-receiver. The information is passed         into the wearable or mobile computer after the data is decoded. This information allows positioning information to be given         to indoor mobile and wearable computers. We design an economical transmitter circuit by adding few components to a commercial         electronic ballast circuit for fluorescent lamps with price of less than US $10. The propose system can be used in indoor         guidance and navigation applications. Exemplary applications are included in the paper, with experimented results detailed.      </content></document><document><year>2007</year><authors>Jaakko T. Lehikoinen1 | Juha Lehikoinen1 | Pertti Huuskonen1</authors><title>Understanding privacy regulation in ubicomp interactions      </title><content>Ubiquitous computing contains a huge promise for more intelligent services that are available anywhere and are able to dynamically         adapt to the users&amp;#8217; current context. However, what necessarily follows such an environment is the compromising of the users&amp;#8217;         privacy. We aim at analyzing this complex issue by applying and extending Altman&amp;#8217;s theoretical privacy framework, well known         in social sciences, to privacy in ubicomp. Altman understands privacy as a two-way interactive process, which makes the approach         promising in analyzing ubicomp where people, devices and the environment interact with each other. We point out similarities         between the existing model and the features of ubicomp environment, and verify the results by applying and analyzing the resulting         extended framework to typical ubicomp use cases. Based on the analysis, we argue that privacy in ubicomp can be modeled similarly         to privacy in general by extending the model to cover such factors as mediation and non-human actors.      </content></document><document><year>2007</year><authors>Desney S. Tan1 | Darren Gergle2 | Regan M|ryk3 | Kori Inkpen3 | Melanie Kellar3 | Kirstie Hawkey3  | Mary Czerwinski1 </authors><title>Using job-shop scheduling tasks for evaluating collocated collaboration      </title><content>Researchers have begun to explore tools that allow multiple users to collaborate across multiple devices in collocated environments.         These tools often allow users to simultaneously place and interact with information on shared displays. Unfortunately, there         is a lack of experimental tasks to evaluate the effectiveness of these tools for information coordination in such scenarios.         In this article, we introduce job-shop scheduling as a task that could be used to evaluate systems and interactions within         computer-supported collaboration environments. We describe properties that make the task useful, as well as evaluation measures         that may be used. We also present two experiments as case studies to illustrate the breadth of scenarios in which this task         may be applied. The first experiment shows the differences when users interact with different communicative gesturing schemes,         while the second demonstrates the benefits of shared visual information on large displays. We close by discussing the general         applicability of the tasks.      </content></document><document><year>2007</year><authors>Elaine M. Huang1| 2 | Elizabeth D. Mynatt3  | Jay P. Trimble4 </authors><title>When design just isn&amp;#8217;t enough: the unanticipated challenges of the real world for large collaborative displays      </title><content>Large interactive displays for supporting workgroup collaboration comprise a growing area of ubiquitous computing research         and many such systems have been designed and deployed in laboratory studies and research settings. Such displays face difficulties         in real-world deployments, as they are often supplemental technologies as opposed to primary tools for work activities. In         this work, we investigate the integration and uptake of the NASA MERBoards, shared interactive displays that were deployed         to support science tasks in the Mars Exploration Rover (MER) missions. We examine the hurdles to adoption imposed specifically         by the real-world circumstances of the deployment that were external to the design of the system, and explain how these concerns         apply to the general deployment of shared ubicomp technologies in the real world.      </content></document><document><year>2003</year><authors>Juha Lehikoinen1 | Mika RГ¶ykkee1</authors><title>1D selection of 2D objects in head-worn displays      </title><content>&amp;#8194;In current desktop user interfaces, selection is usually accomplished easily with a mouse or a similar two-dimensional locator.         In wearable computing, however, controlling two dimensions simultaneously gets significantly harder: a change in one dimension         results easily in an undesired change in the other dimension as well when the user is occupied with a parallel task &amp;#8211; such         as walking. We present a way to overcome this problem by applying one-dimensional selection for graphical user interfaces         in head-worn displays. Our new interaction technique allows a wearable computer user to perform object selection tasks easily         and accurately. The technique is based on a visible circle on the screen. The user controls the circle, altering its radius         with a one-dimensional valuator. The midpoint of the circle is in the middle of the screen. The object currently on the perimeter         of the circle is highlighted and can be selected. Our preliminary usability evaluation, applying our custom evaluation method         designed especially for walking users, indicates that the proposed technique is usable also when walking.      </content></document><document><year>2003</year><authors>Claudio S. Pinhanez1 | Aaron F. Bobick2</authors><title>Interval scripts: a programming paradigm for interactive environments and agents      </title><content>&amp;#8194;In this paper we present interval scripts, a new paradigm for the programming of interactive environments and computer characters. In this paradigm, actions and states         of the users and the system computational agents are associated with temporal intervals. Programming is accomplished by establishing         temporal relationships as constraints between the intervals. Unlike previous temporal constraint-based programming languages,         we employ a strong temporal algebra based in Allen's interval algebra with the ability to express mutually exclusive intervals         and to define complex temporal structures. To avoid the typical computational complexity of strong temporal algebras we propose         a method, PNF propagation, that projects the network implicit in the program into a simpler, 3-valued (past, now, future) network where constraint propagation can be conservatively approximated in linear time. The interval scripts paradigm is         the basis of ISL, or Interval Scripts Language, that was used to build three large-scale, computer-vision-based interactive installations with complex interactive dramatic         structures. The success in implementing these projects provides evidence that the interval scripts paradigm is a powerful         and expressive programming method for interactive environments.      </content></document><document><year>2003</year><authors>Roger C. F. Tucker1| Marianne Hickey1 | Nick Haddock1</authors><title>Speech-as-data technologies for personal information devices      </title><content>&amp;#8194;For small, portable devices, speech input has the advantages of low-cost and small hardware, can be used on the move or whilst         the eyes &amp;amp; hands are busy, and is natural and quick. Rather than rely on imperfect speech recognition we propose that information         entered as speech is kept as speech and suitable tools are provided to allow quick and easy access to the speech-as-data records.         This paper summarises our work on the technologies needed for these tools &amp;#8211; for organising, browsing, searching and compressing         the stored speech. These technologies go a long way towards giving stored speech the characteristics of text without the associated         input problems.      </content></document><document><year>2003</year><authors>J. Waycott1 | A. Kukulska-Hulme1</authors><title>Students' experiences with PDAs for reading course materials      </title><content>&amp;#8194;The availability of text reading and editing software for Personal Digital Assistants (PDAs) makes it timely to consider         whether PDAs are useful tools for reading learning materials. This paper describes a study that evaluated the use of PDAs         for reading by students on a Masters course run by the UK Open University. The evaluation consisted of pre- and post-questionnaires,         and follow-up interviews. In addition, students discussed their experiences in a computer-based conference. Findings show         that while the portability of the device was welcomed by students, and the electronic format was advantageous, limitations         such as the small screen size, navigation difficulties, and slow and error-prone methods for entering text, made it difficult         to read and interact with documents on the PDA. The paper recommends that further research consider the value of PDAs as reading         devices in the context of other potential ways that PDAs can be used as learning tools.      </content></document><document><year>2003</year><authors>Diomidis D. Spinellis1</authors><title>The information furnace: consolidated home control      </title><content>&amp;#8194;The Information Furnace is a basement-installed PC-type device that integrates existing consumer home-control, infotainment,         security and communication technologies to transparently provide accessible and value-added services. A modern home contains         a large number of sophisticated devices and technologies. Access to these devices is currently provided through a wide variety         of disparate interfaces. As a result, end users face a bewildering array of confusing user-interfaces, access modes and price         structures. In addition, as most devices function in isolation, important opportunities to exploit synergies between their         functionalities are lost. The information furnace distributes data, provides services, and controls an apartment's digital         devices. Emphasis is placed on accessibility and on exploiting the synergies that inevitably come up when these technologies         and services are housed under a single roof. The prototype implementation I outline integrates on a FreeBSD server the distribution         of MP3-encoded music to DNARD/NetBSD thin clients, an answering machine, a burglar alarm, an Internet router, a fax server,         a backup server, and intelligent control of a PBX.      </content></document><document><year>2003</year><authors>Eija Kaasinen1</authors><title>User needs for location-aware mobile services      </title><content>&amp;#8194;Mobile contexts of use vary a lot, and may even be continuously changing during use. The context is much more than location,         but its other elements are still difficult to identify or measure. Location information is becoming an integral part of different         mobile devices. Current mobile services can be enhanced with location-aware features, thus providing the user with a smooth         transition towards context-aware services. Potential application fields can be found in areas such as travel information,         shopping, entertainment, event information and different mobile professions. This paper studies location-aware mobile services         from the user's point of view. The paper draws conclusions about key issues related to user needs, based on user interviews,         laboratory and field evaluations with users, and expert evaluations of location-aware services. The user needs are presented         under five main themes: topical and comprehensive contents, smooth user interaction, personal and user-generated contents,         seamless service entities and privacy issues.      </content></document><document><year>2002</year><authors>Michael Beigl1| Tobias Zimmer1 | Christian Decker1</authors><title>A Location Model for Communicating and Processing of Context               </title><content> Location is one of the most important elements of context in ubiquitous computing. In this paper we describe a location model, a spatial-aware communication model and an implementation of the models that exploit location for processing and communicating context. The location model presented describes a location         tree, which contains human-readable semantic and geometric information about an organisation and a structure to describe the         current location of an object or a context. The proposed system is dedicated to work not only on more powerful devices like         handhelds, but also on small computer systems that are embedded into everyday artefact (making them a digital artefact). Model and design decisions were made on the basis of experiences from three prototype setups with several applications,         which we built from 1998 to 2002. While running these prototypes we collected experiences from designers, implementers and users and formulated them as guidelines in this paper. All the prototype applications heavily use location information for providing their functionality. We found         that location is not only of use as information for the application but also important for communicating context. In this         paper we introduce the concept of spatial-aware communication where data is communicated based on the relative location of         digital artefacts rather than on their identity.      </content></document><document><year>2002</year><authors>Natalia Marmasse1 | Chris Schm|t1</authors><title>A User-Centered Location Model               </title><content> This paper discusses the user-centered location model used in comMotion. In this context, the location model refers to a set of learned places (destinations), which coincide to a latitude and a         longitude, that the user has categorized. It also includes knowledge of the routes between the destinations and the time it         takes to travel them. The model is based on user experience, i.e. his patterns of mobility, so no two models are the same.         We also discuss the pattern recognition models implemented for route learning, route prediction and estimation of time to         arrival.      </content></document><document><year>2002</year><authors>Juha Lehikoinen1 | Riku Suomela1</authors><title>Accessing Context in Wearable Computers               </title><content> We present an easy interaction technique for accessing location-based contextual data shown on a head-worn wearable computer         display. Our technique, called Context Compass, is based on a regular compass metaphor. Each object belonging to the user&amp;#8217;s         current context is visualised on a linear compass shown on the screen. The object directly in front of the user is shown in         the middle of the compass and can be activated. Whenever the user turns his or her head, the objects on the screen move accordingly.         Therefore, an object can be selected by simply turning one&amp;#8217;s head towards it. Context Compass consumes a minimal amount of         screen space, making it ideal for usage with see-through head-worn displays. An initial pilot study, applying a newly developed         usability method customised especially for Context Compass, revealed that Context Compass can be learned virtually immediately.         Further, the method itself proved to be successful in evaluating techniques such as Context Compass.      </content></document><document><year>2002</year><authors>Simon Holl|1| David R. Morse1 | Henrik Gedenryd1</authors><title>AudioGPS: Spatial Audio Navigation with a Minimal Attention Interface               </title><content> In this paper we describe a prototype spatial audio user interface for a Global Positioning System (GPS). The interface is         designed to allow mobile users to carry out location tasks while their eyes, hands or attention are otherwise engaged. Audio         user interfaces for GPS have typically been designed to meet the needs of visually impaired users, and generally, though not         exclusively, employ speech-audio. In contrast, our prototype system uses a simple form of non-speech, spatial audio. This         paper analyses various candidate audio mappings for location and distance information. A variety of tasks, design considerations,         design trade-offs and opportunities are considered. The findings from pilot empirical testing are reported. Finally, opportunities         for improvements to the system and for future evaluation are explored.      </content></document><document><year>2002</year><authors>Stavros Antifakos1 | Bernt Schiele1</authors><title>Beyond Position Awareness               </title><content> Location models are merely based on positional information. Using wireless sensor networks, however, allows us to extract         information which can be related to different levels of semantic proximity of different devices. Based on this observation,         the paper proposes a semantic proximity hierarchy based on a wireless sensor network. In this paper, we argue that the proposed         proximity hierarchy adds a new and complementary dimension to pure positional location information. The paper discusses the         proposed hierarchy, gives application examples and some preliminary experimental results.      </content></document><document><year>2002</year><authors>Shahram Izadi1| Mike Fraser1| Steve Benford1| Martin Flintham1| Chris Greenhalgh1| Tom Rodden1 | Holger SchnГ¤delbach1</authors><title>Citywide: Supporting Interactive Digital Experiences Across Physical Space               </title><content> The Citywide project is exploring ways in which technology can provide people with rich and engaging digital experiences         as they move through physical space, including historical experiences, performances and games. This paper describes some initial         results and experiences with this project based upon two prototype demonstrators. In the first, we describe an application         in which a search party explores an archaeological site, uncovering enacted scenes within the virtual world that are of a         historical relevance to their particular physical location. In the second, we describe a museum experience where participants         explore an outdoors location, hunting for buried virtual artifacts that they then bring back to a museum for a more detailed         study. Our demonstrators employ a varied set of devices, including mobile wireless interfaces for locating hotspots of virtual         activity when outdoors, to give different experiences of the virtual world depending upon location, task, available equipment         and accuracy of tracking. We conclude by discussing some of the potential advantages of using an underlying shared virtual         world to support interactive experiences across extended physical settings.      </content></document><document><year>2002</year><authors>Tony Manninen1</authors><title>Contextual Virtual Interaction as Part of Ubiquitous Game Design and Development               </title><content> This paper relates to the problems of designing rich interaction, in the context of multi-player games, that would adequately         support communication, control and co-ordination. The aspects of fun and rich experiences, usually required within the entertainment         context, are easily overlooked in technologically driven system design. The concepts of a future ubiquitous game can be difficult         to comprehend and evaluate in cases where a fully functioning physical prototype is not an option. One solution for the problem         is Contextual Virtual Reality Prototyping that adds the missing context to the design simulations. The product can be designed         and demonstrated in the corresponding environment, thus making it easier to understand the use-cases of, for example, a mobile         device that has various location-dependent features. The main contribution of this research is the design and development         approach that supports the creation of rich interaction. The primary emphasis of the approach is to avoid purely technologically         driven design and development, but rather to provide a supporting, or even a guiding, approach that focuses on the creative         process and conceptual understanding of rich interaction. This conceptually grounded content production-oriented approach         to interactive system design is described and evaluated.      </content></document><document><year>2002</year><authors>Thomas Rist1 | Patrick Br|meier1</authors><title>Customizing Graphics for Tiny Displays of Mobile Devices               </title><content> Advances in mobile devices and wireless telecommunication infrastructure already provide mobile users with access to online         information sources and services. Compared to the PC world, however, mobile access is still quite restricted, especially with         regard to the display of graphical representations, such as images, drawings, diagrams, maps and logos. Since graphical representations         are increasingly used in the World Wide Web for the purpose of information presentation, the adaptation of graphics for tiny         displays is a challenge that should not be neglected. The current contribution discusses several transformation approaches         which might be employed to accomplish this adaptation task.      </content></document><document><year>2002</year><authors>Karl-Petter &amp;#272 kesson1 | Andreas Nilsson2</authors><title>Designing Leisure Applications for the Mundane Car-Commute               </title><content> Commuting by car from home to work can be very time consuming. We have conducted a study to explore what people are doing,         and want to do, while commuting. People use their time in the car on a wide variety of activities with great innovation. There         was no unanimous activity that everyone wanted, rather a wide variety of activities were requested. Three different categories         of activity were identified which we refer to as mundane, vocational and traffic related. To demonstrate a possible IT service         supporting commuters, a prototype based on speech output and a simple input mechanism from a wheel was developed. This service         moves sampling of music from the conventional shop into the car. The prototype was informally tested with users, which resulted         in a number of improvements. Preliminary user results indicate good functionality, a comprehensive interaction interface.      </content></document><document><year>2002</year><authors>Staffan BjГ¶rk1| Jussi Holopainen2| Peter Ljungstr|1 | Karl-Petter Г…kesson3</authors><title>Designing Ubiquitous Computing Games &amp;#8211; A Report from a Workshop Exploring Ubiquitous Computing Entertainment               </title><content> We report from a Research Atelier that explored how ubiquitous computing could be applied to fun and entertainment. The Atelier         lasted for five days, starting with two days of scenario development and brainstorming activities. This led to three fairly         concrete &amp;#8211; though very different &amp;#8211; game ideas. The background and motivation for the Atelier is described, as well as the         method used and the games developed.      </content></document><document><year>2002</year><authors>David A. Ross1 | Bruce B. Blasch1</authors><title>Development of a Wearable Computer Orientation System               </title><content> People with severe visual impairment need a means of remaining oriented to their environment as they move through it. A series         of indoor and outdoor trials using a variety of technologies and interfaces led to the development and evaluation of three         promising wearable orientation interfaces: a virtual sonic beacon, speech output, and a shoulder-tapping system. Street crossing         was used as a critical test situation in which to evaluate these interfaces. The shoulder-tapping system was found most universally         usable. Results indicated that, given the great variety of co-morbidities within this population, which is comprised of mostly         older persons, optimal performance and flexibility may best be obtained in a design that combines the best elements of both         the speech and shoulder-tapping interfaces.      </content></document><document><year>2002</year><authors>Luca Chittaro1 | Paolo Dal Cin1</authors><title>Evaluating Interface Design Choices on WAP Phones: Navigation and Selection               </title><content> Wireless Application Protocol (WAP) phones are a growing relevant part of the mobile market, and the number of WAP services         offered is rapidly increasing. Usability is crucial for these services, which must be easily operated on small screens and         keyboards. Unfortunately, there are very few published studies on the evaluation of WAP devices and services on users. This         paper presents a user study that evaluates two important interface design choices for WAP services (implementation of single-choice         selection, and navigation among the different cards of a WAP site), neither of which has been investigated thoroughly in the         literature or in design practice.      </content></document><document><year>2002</year><authors>Giulio Iacucci1 | Kari Kuutti1</authors><title>Everyday Life as a Stage in Creating and Performing Scenarios for Wireless Devices               </title><content> Scenarios in HCI are widely used and discussed as written or visual narratives. In this paper, we discuss fruitful conditions         for the creation and performance of scenarios particularly for the concept design of mixed realities or wireless devices.         Designers are attempting new ways of engaging people in design and experiencing ideas in early design phases. Examples range         from exploring scenarios using mock-ups or Wizard-of-Oz techniques, to testing scenarios with prototypes. In our design projects,         scenarios were created and performed with participants following them in their daily activities. Discussing these sessions,         which we called SPES (Situated and Participative Enactment of Scenarios), we highlight as promising conditions to create scenarios:         the everyday life as a stage and the opportunity for participants to exercise reflection-in-action.      </content></document><document><year>2002</year><authors>Keith Cheverst1| Keith Mitchell1 | Nigel Davies1</authors><title>Exploring Context-aware Information Push               </title><content> Despite much interest over recent years in the area of context-aware computing, there are still a number of significant gaps         in our understanding of the HCI issues associated with such systems. One particular issue that remains relatively unexplored         is how to design around the apparently conflicting goals of adapting to changes in context while at the same time adhering         to the principle of predictability. In this paper, we describe our exploration into this issue through two alternative designs         of an interactive context-aware tourist guide. One original design was based around information pull, i.e. the emphasis is         on the user to decide when context-aware information is presented. Our second design incorporates the notion of information         push whereby the actual presentation of context-aware information is triggered by contextual events, e.g. changes in the user&amp;#8217;s         location or changes to the opening times of attractions. Through the evaluation of these alternative designs we hope to gain         a better understanding of the usability implications relating to push vs. pull in both this specific domain and in interactive         context-aware systems in general.      </content></document><document><year>2002</year><authors>Mari Korkea-aho1| Haitao Tang2 | Reijo Sulonen1</authors><title>Expressing Location Information for Applications in the Internet               </title><content> As part of the Spatial Location Protocol activity in the Internet Engineering Task Force (IETF), we have been working on         how to express location information in an interoperable way in the Internet. The objective of this paper is to share our ideas         on concepts for enabling interoperability and reuse of location information. These concepts can also be used in the area of         ubiquitous computing.      </content></document><document><year>2002</year><authors>Bruce Thomas1| Ben Close1| John Donoghue1| John Squires1| Phillip De Bondi1 | Wayne Piekarski1</authors><title>First Person Indoor/Outdoor Augmented Reality Application: ARQuake               </title><content> This paper presents a first person outdoor/indoor augmented reality application ARQuake that we have developed. ARQuake is         an extension of the desktop game Quake, and as such we are investigating how to convert a desktop first person application         into an outdoor/indoor mobile augmented reality application. We present an architecture for a low cost, moderately accurate         six degrees of freedom tracking system based on GPS, digital compass, and fiducial vision-based tracking. Usability issues         such as monster selection, colour, input devices, and multi-person collaboration are discussed.      </content></document><document><year>2002</year><authors>Nizami Cummins1</authors><title>Integrating E-Commerce and Games               </title><content> This paper investigates how many users of commercial interactive systems are not properly agents within the interactive narrative,         largely due to the dynamics of branding in cyberspace. Parallels are drawn between the dynamic personalization of e-CRM engines         and context aware computing systems. Several seminal games are discussed as examples of systems in which very different relationships         exist between users and the system. Arguments are made for designing e-commerce interactive systems that install into games,         inside the game narrative.      </content></document><document><year>2002</year><authors>Joachim Go&amp;#946 mann1 | Marcus Specht1</authors><title>Location Models for Augmented Environments               </title><content> In this paper we describe two projects on contextualized computer systems and audio augmented environments we are currently         working on at the Fraunhofer Institutes FIT and IMK. In this paper we will only focus on the world models and the augmentation         layer. Both projects are based on completely different technologies, and use different representation methods and interaction         facilities. While in hippie users are moving with small laptop computers or wearable computers with a small visual display,         in LISTEN users will have only a wireless headphone displaying spatially rendered sound-scenes.      </content></document><document><year>2002</year><authors>Martin Bauer1| Christian Becker1 | Kurt Rothermel1</authors><title>Location Models from the Perspective of Context-Aware Applications and Mobile Ad Hoc Networks               </title><content> Location models are crucial for providing location-dependent data to context-aware applications. In this paper, we present         two approaches for modeling location information taken from an infrastructure-based and an ad hoc network-based application scenario. From these approaches we derive requirements for a general location modeling language         for ubiquitous computing.      </content></document><document><year>2002</year><authors>Georg Strom1</authors><title>Mobile Devices as Props in Daily Role Playing               </title><content> Mobile devices such as cameras or mobile phones can be used as props; actively to convey a specific impression to people         in the vicinity and to feel better when interacting with them. Based on field studies and interviews, three aspects of users         acting with mobile devices are described: warm versus cold devices; how a mobile device conveys a specific impression by association         to similar devices and specific situations of use; and how the characteristics of a mobile device may open or restrict the         body language of the user.      </content></document><document><year>2002</year><authors>Robert Headon1 | Rupert Curwen2</authors><title>Movement Awareness for Ubiquitous Game Control               </title><content> This paper describes a sensing system for recognising and characterising human movements and its application to ubiquitous         gaming. In particular this paper considers the control of computer games through players interacting with the physical environment         around them in a natural and appropriate manner. This pushes the interface into the environment, and pulls ubiquitous computing         into the game. This is achieved using a sentient computing system. Such a system senses the location, motions, actions and         even physiological responses of users. This sensory data can be used to interface and control a game. A good example is 3D         first-person games and we demonstrate a system in which actions in the game are mapped to similar actions in the real world.      </content></document><document><year>2002</year><authors>FranГ§oise Decortis1 | Antonio Rizzo2</authors><title>New Active Tools for Supporting Narrative Structures               </title><content> Constructing stories is a type of playing that involves mobilizing the storyteller&amp;#8217;s imagination and finding original ways         to convey narrative intentions. When a child invents a story, there is a natural interaction with the local environment and         the use of various means of expression. We adopted a user-centered approach to design POGO, a playful environment which utilizes         the child&amp;#8217;s physical environment and sensory modalities. Pogo is a system of active tools that enable children to create stories         by connecting physical and virtual environments. By providing children with the possibility of capturing and manipulating         images and various media, and combining them in sequential form, Pogo triggered new strategies in the construction of narrative         logic, time and space, in the construction of the episodes and in the visual narration.      </content></document><document><year>2002</year><authors>H. Thimbleby1 | M. Jones2</authors><title>Obituary for a Fax      </title><content> The continual failure of personal technology highlights the growing problem of obsolete, irreparable and non-recyclable toxic         waste. Moore&amp;#8217;s Law is a symptom of failure as much as a promise of better technology. Better design could avoid the problems.      </content></document><document><year>2002</year><authors>Stephen Brewster1</authors><title>Overcoming the Lack of Screen Space on Mobile Computers               </title><content> One difficulty for interface design on mobile computers is lack of screen space caused by their small size. This paper describes         a small pilot study and two formal experiments that investigate the usability of sonically-enhanced buttons of different sizes.         The underlying hypothesis being that presenting information about the buttons in sound would increase their usability and         allow their size to be reduced. An experimental interface was created that ran on a 3Com Palm III mobile computer and used         a simple calculator-style interface to enter data. The buttons of the calculator were changed in size between 4Г—4, 8Г—8 and         16Г—16 pixels and used a range of different types of sound from basic to complex. Results showed that sounds significantly         improved usability for both standard and small button sizes &amp;#8211; more data could be entered with sonically-enhanced buttons and         subjective workload reduced. More sophisticated sounds that presented more information about the state of the buttons were         shown to be more effective than the standard Palm III sounds. The results showed that if sound was added to buttons then they         could be reduced in size from 16Г—16 to 8Г—8 pixels without much loss in quantitative performance. This reduction in size, however,         caused a significant increase in subjective workload. Results also showed that when a mobile device was used in a more realistic         situation (whilst walking outside) usability was significantly reduced (with increased workload and less data entered) than         when used in a usability laboratory. These studies show that sound can be beneficial for usability and that care must be taken         to do testing in realistic environments to get a good measure of mobile device usability.      </content></document><document><year>2002</year><authors>JГ¶rg Roth1</authors><title>Patterns of Mobile Interaction               </title><content> The design of systems for mobile scenarios covers a wide range of issues, ranging from mobile networking to user interface         design for mobile devices. Mobile applications often run distributed on several connected devices, used by many users simultaneously.         Considering all issues related to mobile scenarios, a designer might be overwhelmed. As a solution, we propose a specific         kind of design patterns which we call mobility patterns, derived from successful mobile applications. They allow a designer to re-use design elements as building blocks in their         own designs. After describing the idea of mobility patterns, we give a brief overview of patterns we have identified so far.         Two patterns are described in more detail with the help of our research platforms QuickStep and Pocket DreamTeam.      </content></document><document><year>2002</year><authors>O. de Bruijn1| R. Spence1 | M. Y. Chong1</authors><title>RSVP Browser: Web Browsing on Small Screen Devices               </title><content> In this paper, we illustrate the use of space-time trade-offs for information presentation on small screens. We propose the         use of Rapid Serial Visual Presentation (RSVP) to provide a rich set of navigational information for Web browsing. The principle         of RSVP browsing is applied to the development of a Web browser for small screen devices, the RSVP browser. The results of         an experiment in which Web browsing with the RSVP browser is compared with that of a typical WAP browser suggests that RSVP         browsing may indeed offer alternative to other forms of Web browsing on small screen devices.      </content></document><document><year>2002</year><authors>Ana Paiva1| Gerd Andersson2| Kristina HГ¶Г¶k2| DГЎrio Moura&amp;#732 o1| Marco Costa1 | Carlos Martinho1</authors><title>SenToy in FantasyA: Designing an Affective Sympathetic Interface to a Computer Game               </title><content> We describe the design process of an affective control toy, named SenToy, used to control a synthetic character in a computer game. SenToy allows players to influence the emotions of a synthetic         character placed in FantasyA, a 3D virtual game. By expressing gestures associated with anger, fear, surprise, sadness and         joy through SenToy, players influence the emotions of the character they control in the game. When designing SenToy we hypothesized         that players would manipulate the toy to express emotions using a particular set of gestures. Those gestures were drawn from         literature on how we express emotions through bodily movements and from emotion theories. To evaluate our idea we performed         a Wizard Of Oz study [1]. The results of the study show that there are behaviours that players easily pick up for expressing         emotions through the gestures with the toy, though not necessarily the ones extracted from literature. The study also provided         some indication on what type of toy we should build, in particular, its &amp;#8216;look and feel&amp;#8217;.      </content></document><document><year>2002</year><authors>Florian Michahelles1 | Michael Samulowitz2</authors><title>         Smart CAPs for Smart Its &amp;#8211; Context Detection for Mobile Users               </title><content> Context detection for mobile users plays a major role for enabling novel, human-centric interfaces. For this, we introduce         a context detection scheme applicable in a self-organized sensor network, which is formed of disseminated, computer empowered         sensors, referred to as Smart-Its [1]. Context-detection takes place without requiring any central point of control, and supports push as well as pull modes.         Our solution is based on an in-network composition approach relying on so-called smart Context-Aware Packets (sCAPs). These packets act as a uniform interchange format, and allow single sensors to share sensed data and to cooperate to build         up a meaningful context model from manifold inputs. sCAPs travel through the sensor network governed by an enclosed retrieving plan, specifying which sensors to visit in order to gain a specific piece of context information. For enhanced flexibility, the         retrieving plan itself may be dynamically altered in accordance with past sensor readings.      </content></document><document><year>2002</year><authors>J. Rantanen1| J. ImpioВЁ2| T. Karinsalo2| M. Malmivaara2| A. Reho2| M. Tasanen2 | J. Vanhala1</authors><title>Smart Clothing Prototype for the Arctic Environment               </title><content> Continuous miniaturisation of electronic components has made it possible to create smaller and smaller electrical devices         which can be worn and carried all the time. Together with developing fibre and textile technologies, this has enabled the         creation of truly usable smart clothes that resemble clothes more than wearable computing equipment. These intelligent clothes         are worn like ordinary clothing and provide help in various situations according to the application area. This paper describes         the design and implementation of a survival smart clothing prototype for the arctic environment. Concept development, electrical         design, and non-electrical features are discussed. The suit provides communication, positioning, and navigation aids for the         user. Depending on the measurements of the human and the environment, the suit decides whether an emergency message should         be sent. The user can control the system with a user interface called a Yo-Yo. The functionality of the suit has been tested         in an arctic environment.      </content></document><document><year>2002</year><authors>Kay RГ¶mer1 | Svetlana Domnitcheva1</authors><title>Smart Playing Cards: A Ubiquitous Computing Game               </title><content> We present the &amp;#8216;Smart Playing Cards&amp;#8217; application, a ubiquitous computing game that augments a classical card game with information         technological functionality by attaching RFID tags to the cards. We also mention requirements that such an application makes         on a supporting software infrastructure for ubiquitous computing.      </content></document><document><year>2002</year><authors>Michael Beigl1</authors><title>Special Issue on Location Modeling in Ubiquitous Computing               </title><content/></document><document><year>2002</year><authors>Mark Billinghurst1</authors><title>Special Issue on Wearable Computing               </title><content>       </content></document><document><year>2002</year><authors>Mark Dunlop1 | Stephen Brewster2</authors><title>The Challenge of Mobile Devices for Human Computer Interaction               </title><content>       </content></document><document><year>2002</year><authors>Mike Sharples1| Dan Corlett1 | Oliver Westmancott1</authors><title>The Design and Implementation of a Mobile Learning Resource               </title><content> The convergence of mobile communications and handheld computers offers the opportunity to develop technology that will assist         individuals and groups to learn anytime, anywhere. We describe the theory-informed design, implementation and evaluation of         a handheld learning device. It is intended to support children to capture everyday events such as images, notes and sounds,         to relate them to web-based learning resources, to organise these into a visual knowledge map, and to share them with other         learners and teachers. A working prototype system, for children aged 9&amp;#8211;11, is discussed and evaluated, as an exemplar of personal         mobile systems for life-long learning.      </content></document><document><year>2002</year><authors>Anne Ekholm1</authors><title>The Design of In-car Communication and Information Applications               </title><content>       </content></document><document><year>2002</year><authors>Cliff R|ell1 | Henk L. Muller1</authors><title>The Well Mannered Wearable Computer               </title><content> In this paper we describe continuing work being carried out as part of the Bristol Wearable Computing Initiative. We are         interested in the use of context sensors to improve the usefulness of wearable computers. A CyberJacket incorporating a Tourist Guide application has been built, and we have experimented with location and movement sensing devices         to improve its performance. In particular, we have researched processing techniques for data from accelerometers which enable         the wearable computer to determine the user&amp;#8217;s activity. We have experimented with, and review, techniques already employed         by others; and then propose new methods for analysing the data delivered by these devices. We try to minimise the number of         devices needed, and use a single X-Y accelerometer device. Using our techniques we have adapted our CyberJacket and Tourist         Guide to include a multimedia presentation which gives the user information using different media depending on the user&amp;#8217;s         activity as well as location.      </content></document><document><year>2002</year><authors>Adrian David Cheok1| Xubo Yang1| Zhou Zhi Ying1| Mark Billinghurst2 | Hirokazu Kato3</authors><title>Touch-Space: Mixed Reality Game Space Based on Ubiquitous, Tangible, and Social Computing               </title><content> This paper presents a novel computer entertainment system which recaptures human touch and physical interaction with the         real-world environment as essential elements of the game play, whilst also maintaining the exciting fantasy features of traditional         computer entertainment. Our system called &amp;#8216;Touch-Space&amp;#8217; is an embodied (ubiquitous, tangible, and social) computing based         Mixed Reality (MR) game space which regains the physical and social aspects of traditional game play. In this novel game space,         the real-world environment is an essential and intrinsic game element, and the human&amp;#8217;s physical context influences the game         play. It also provides the full spectrum of game interaction experience ranging from the real physical environment (human         to human and human to physical world interaction), to augmented reality, to the virtual environment. It allows tangible interactions         between players and virtual objects, and collaborations between players in different levels of reality. Thus, the system re-invigorates         computer entertainment systems with social human-to-human and human-to-physical touch interactions.      </content></document><document><year>2002</year><authors>Diego LoВґpez de Ipin&amp;#732 a1| Paulo R. S. MendonГ§a2| Andy Hopper1 | Andy Hopper3</authors><title>TRIP: A Low-Cost Vision-Based Location System for Ubiquitous Computing               </title><content>Sentient Computing provides computers with perception so that they can react and provide assistance to user activities. Physical         spaces are made sentient when they are wired with networks of sensors capturing context data, which is communicated to computing         devices spread through the environment. These devices interpret the information provided and react by performing the actions         expected by the user. Among the types of context information provided by sensors, location has proven to be especially useful. Since location is an important context that changes whenever the user moves, a reliable         location-tracking system is critical to many sentient applications. However, the sensor technologies used in indoor location         tracking are expensive and complex to deploy, configure and maintain. These factors have prevented a wider adoption of Sentient         Computing in our living and working spaces. This paper presents TRIP, a low-cost and easily deployable vision-based sensor         technology addressing these issues. TRIP employs off-the-shelf hardware (low-cost CCD cameras and PCs) and printable 2-D circular         markers for entity identification and location. The usability of TRIP is illustrated through the implementation of several         sentient applications.      </content></document><document><year>2002</year><authors>M. Mikkonen1| S. VaВЁyrynen2| V. Ikonen|2 | M. O. HeikkilaВЁ1</authors><title>User and Concept Studies as Tools in Developing Mobile Communication Services for the Elderly               </title><content> The basis of this study was the ageing of the population all over the world. The study concentrated on finding out the key         service needs of elderly people. The service needs from the end users&amp;#8217; as well as the experts&amp;#8217; perspective were gathered by         means of various group methods such ideation sessions. Four mobile communication service concepts were created using these         groups&amp;#8217; opinions. After diverse communication, these concepts were tested by the elderly. The research methods comprised a         user study and a concept study.                     &amp;#8195;Based on the results, the needs could be prioritised. Additionally, the main trend of the results confirmed the opinions               presented in the literature. One important finding was the positive opinions about additional value of wireless devices and               services. This knowledge can be used in mobile communication product development. Most of the elderly are ready to accept               new forms of mobile communication service. Ease of use and actual need of the services are important criteria. The elderly               are ready to begin using the services as long as they truly facilitate independent living.            </content></document><document><year>2002</year><authors>M. T. Raghunath1 | Ch|ra Narayanaswami1</authors><title>User Interfaces for Applications on a Wrist Watch               </title><content> Advances in technology have made it possible to package a reasonably powerful processor and memory subsystem coupled with         an ultra high-resolution display and wireless communication into a wrist watch. This introduces a set of challenges in the         nature of input devices, navigation, applications, and other areas. This paper describes a wearable computing platform in         a wrist watch form-factor we have developed. We built two versions: one with a low resolution liquid crystal display; and         another with a ultra high resolution organic light emitting diode display. In this paper we discuss the selection of the input         devices and the design of applications and user interfaces for these two prototypes, and the compare the two versions.      </content></document><document><year>2002</year><authors>Francesco Bellotti1| Riccardo Berta1| Aless|ro De Gloria1 | Massimiliano Margarone1</authors><title>Using 3D Sound to Improve the Effectiveness of the Advanced Driver Assistance Systems               </title><content> Future generation cars will be characterized by a wide range of Information Technology (IT) services providing safety and         infotainment. This makes the car an information intensive environment where the visual channel is overloaded, putting the         safety of drivers and passengers in jeopardy. We propose the use of a 3D auditory display to provide information from the         Advanced Driver Assistance Systems. This reduces the eye-off-road time, exploiting the human capability to associate sounds         with positions in space. Preliminary lab tests reveal the suitability of this approach. The system still has to be carefully         tuned and personalized to achieve usability and reliability, but we think that it provides a complementary channel that is         specially useful in low visibility conditions.      </content></document><document><year>2002</year><authors>W. W. Mayol1| B. J. Tordoff1 | D. W. Murray1</authors><title>Wearable Visual Robots               </title><content> Research work reported in the literature in wearable visual computing has used exclusively static (or non-active) cameras,         making the imagery and image measurements dependent on the wearer&amp;#8217;s posture and motions. It is assumed that the camera is         pointing in a good direction to view relevant parts of the scene at best by virtue of being mounted on the wearer&amp;#8217;s head,         or at worst wholly by chance. Even when pointing in roughly the correct direction, any visual processing relying on feature         correspondence from a passive camera is made more difficult by the large, uncontrolled inter-image movements which occur when         the wearer moves, or even breathes. This paper presents a wearable active visual sensor which is able to achieve a level of         decoupling of camera movement from the wearer&amp;#8217;s posture and motions by a combination of inertial and visual sensor feedback         and active control. The issues of sensor placement, robot kinematics and their relation to wearability are discussed. The         performance of the prototype robot is evaluated for some essential visual tasks. The paper also discusses potential applications         for this kind of wearable robot.      </content></document><document><year>2002</year><authors>Stuart Goose1 | Safia Djennane1</authors><title>WIRE3: Driving Around the Information Super-Highway               </title><content> Interactive voice browsers offer an alternative paradigm that affords ubiquitous mobile access to the WWW using a wide range         of consumer devices. This technology can facilitate a safe, &amp;#8220;hands-free&amp;#8221; browsing environment that is of importance both to         car drivers and various mobile and technical professionals. This paper describes the challenges of architecting an interactive         voice browser that combines digital audio with the features of a speech synthesizer to make structural elements of the document         explicit to the listener. The aesthetics of the audio rendition can simultaneously help reduce the monotony factor and enhance         comprehension. The evolution of the voice browser gave rise to a new conceptual model of the HTML document structure and its         mapping to a 3D audio space. A number of novel features are discussed for improving both the user&amp;#8217;s comprehension of the HTML         document structure and their orientation within it. These factors, in turn, can improve the effectiveness of the browsing         experience.      </content></document><document><year>2005</year><authors>Raino Vastam&amp;auml ki1 | Irmeli Sinkkonen1 | Cecilia Leinonen1</authors><title>A behavioural model of temperature controller usage and energy saving</title><content>Temperature controllers are typical devices in most office-buildings, but the intended users very seldom use them. It has been a constant observation during our research that all common temperature controllers to date are quite impossible to use and understand correctly. With the proper use of temperature controllers comfort could be improved and a lot of energy could be saved. This paper presents a model of first use of an OOBE device, in which the actors beliefs are included. A list of conditions for energy saving actions, a design decision matrix and a model of action circle is presented in this article. The model indicates that the users action can be extinguished at various points during the action circle. However, sufficient and understandable initial feedback on the devices interface is the key to correct novel use.</content></document><document><year>2005</year><authors>Lucia Terrenghi1 | Matthias Kranz2 | Paul Holleis2  | Albrecht Schmidt2 </authors><title>A cube to learn: a tangible user interface for the design of a learning appliance      </title><content>In this paper we introduce the design and development of the Learning Cube as a novel tangible learning appliance. Using the         common shape of a cube we implemented a general learning platform that supports test based quizzes where questions and answers         can be text or image based. Exploiting the physical affordances of the cube and augmenting it with embedded sensors and LCD         displays placed on each face, we present different learning appliances as playful learning interfaces for children. Based         on the initial observations of the experience with children, we argue that breaking conventions about how a computer has to         look like, and providing children with a playful interface is a promising approach to embed and integrate technology into         children&amp;#8217;s everyday context and activities.      </content></document><document><year>2005</year><authors>Christian Decker1 | Till Riedel1 | Michael Beigl1  | Albert Krohn1 </authors><title>A file system for system programming in ubiquitous computing</title><content>In Ubiquitous computing, small embedded sensor and computing nodes are the main enabling technologies. System programming for such small embedded systems is a challenging task involving various hardware components with different characteristics. This paper presents a file system which organizes all computational and sensory functionality of a sensor node as resources in a uniform name space. It further provides a lightweight and uniform access model for all these resources. This mechanism forms an abstraction from different hardware, makes functions re-useable and simplifies the development on such systems. With ParticleFS a concrete file system implementation on a sensor node platform is shown. Application cases demonstrate sensor logging, an interactive shell, executables, a pipe mechanism and remote access capabilities of the ParticleFS.</content></document><document><year>2005</year><authors>Shang Ping Lee1| Adrian David Cheok1| 2 | Teh Keng Soon James1| Goh Pae Lyn Debra1| Chio Wen Jie1| Wang Chuang1 | Farzam Farbiz1</authors><title>A mobile pet wearable computer and mixed reality system for human&amp;#8211;poultry interaction through the internet</title><content>Poultry are one of the most badly treated animals in the modern world. It has been shown that they have high levels of both cognition and feelings and as a result there has been a recent trend of promoting poultry welfare. There is also a tradition of keeping poultry as pets in some parts of the world. However, in modern cities and societies, it is often difficult to maintain contact with pets, particularly for office workers. We propose and describe a novel cybernetics system to use mobile and Internet technology to improve human&amp;#8211;pet interaction. It can also be used for people who are allergic to touching animals and thus cannot stroke them directly. This interaction encompasses both visualization and tactile sensation of real objects.</content></document><document><year>2005</year><authors>Anastasia Karanastasi1 | Fotis G. Kazasis1 | Stavros Christodoulakis1</authors><title>A natural language model for managing TV-Anytime information in mobile environments</title><content>The TV-Anytime standard describes the structures of categories of digital TV program metadata, as well as user profile metadata for TV programs. We describe a natural language (NL) model for the users to interact with the TV-Anytime metadata and preview TV programs from their mobile devices. The language utilises completely the TV-Anytime metadata specifications (upper ontologies), as well as domain-specific ontologies. The interaction model does not use clarification dialogues, but it uses the user profiles as well as TV-Anytime metadata information and ontologies to rank the possible responses in case of ambiguities. We describe implementations of the model that run on a PDA and on a mobile phone, and manage the metadata on a remote TV-Anytime-compatible TV set. We present user evaluations of the approach. Finally, we propose a generalised implementation framework that can be used to easily provide NL interfaces for mobile devices for different applications and ontologies.</content></document><document><year>2005</year><authors>Christian S|or1  | Gudrun Klinker1 </authors><title>A rapid prototyping software infrastructure for user interfaces in ubiquitous augmented reality</title><content>Recent user interface concepts, such as multimedia, multimodal, wearable, ubiquitous, tangible, or augmented-reality-based (AR) interfaces, each cover different approaches that are all needed to support complex human&amp;#x2013;computer interaction. Increasingly, an overarching approach towards building what we call ubiquitous augmented reality (UAR) user interfaces that include all of the just mentioned concepts will be required. To this end, we present a user interface architecture that can form a sound basis for combining several of these concepts into complex systems. We explain in this paper the fundamentals of DWARFs user interface framework (DWARF standing for distributed wearable augmented reality framework) and an implementation of this architecture. Finally, we present several examples that show how the framework can form the basis of prototypical applications.</content></document><document><year>2005</year><authors>Joep Frens1 </authors><title>A rich user interface for a digital camera      </title><content>In this design prospectus a digital camera with a rich user interface is presented. Rich interfaces borrow from tangible interaction         and the concept of affordances. Next, a working prototype of this camera is presented. Finally, four systematic variations         of the interface for this camera are shown.      </content></document><document><year>2005</year><authors>Tatsuo Nakajima1  | Ichiro Satoh2 </authors><title>A software infrastructure for supporting spontaneous and personalized interaction in home computing environments</title><content>Our daily lives are expected to change dramatically due to the popularity of ubiquitous computing technologies. These will make it possible to integrate various aspects of our lives. However, a new approach is required to seamlessly deal with devices embedded in our environments. Future embedded systems will embody a new approach that will take into account a variety of new issues, for example, spontaneous interaction, personalization, privacy protection, and interoperability. In this paper, we propose a personal home server that will make it possible to coordinate home appliances. Since everyone will have a different personal home server, it will allow us to personalize how the appliances are used according to individual preferences. Our personal home server can seamlessly discover and configure appliances at any locations, such as at railroad stations, cars, and streets as well as houses. We also discuss its design and implementation and present its current status.</content></document><document><year>2005</year><authors>Koen Vanthournout1 | Geert Deconinck1 | Ronnie Belmans1</authors><title>A taxonomy for resource discovery</title><content>Resource discovery systems become more and more important as distributed systems grow and as their pool of resources becomes more variable. As such, an increasing amount of networked systems provide a discovery service. This paper provides a taxonomy for resource discovery systems by defining their design aspects. This allows comparison of the designs of the deployed discovery services and is intended as an aid to system designers when selecting an appropriate mechanism. The surveyed systems are divided into four classes that are separately described. Finally, we identify a hiatus in the design space and point out genuinely distributed resource discovery systems that support dynamic and mobile resources and use attribute-based naming as a main direction for future research in this area.</content></document><document><year>2005</year><authors>Juha Kela1 | Panu KorpipГ¤Г¤1| Jani MГ¤ntyjГ¤rvi1| Sanna Kallio1| Giuseppe Savino2 | Luca Jozzo2  | Sergio Di Marca2 </authors><title>Accelerometer-based gesture control for a design environment</title><content>Accelerometer-based gesture control is studied as a supplementary or an alternative interaction modality. Gesture commands freely trainable by the user can be used for controlling external devices with handheld wireless sensor unit. Two user studies are presented. The first study concerns finding gestures for controlling a design environment (Smart Design Studio), TV, VCR, and lighting. The results indicate that different people usually prefer different gestures for the same task, and hence it should be possible to personalise them. The second user study concerns evaluating the usefulness of the gesture modality compared to other interaction modalities for controlling a design environment. The other modalities were speech, RFID-based physical tangible objects, laser-tracked pen, and PDA stylus. The results suggest that gestures are a natural modality for certain tasks, and can augment other modalities. Gesture commands were found to be natural, especially for commands with spatial association in design environment control.</content></document><document><year>2005</year><authors>Dan Smith1 | Ling Ma1  | Nick Ryan2 </authors><title>Acoustic environment as an indicator of social and physical context      </title><content>Acoustic environments provide many valuable cues for context-aware computing applications. From the acoustic environment we         can infer the types of activity, communication modes and other actors involved in the activity. Environmental or background         noise can be classified with a high degree of accuracy using recordings from microphones commonly found in PDAs and other         consumer devices. We describe an acoustic environment recognition system incorporating an adaptive learning mechanism and         its use in a noise tracker. We show how this information is exploited in a mobile context framework. To illustrate our approach         we describe a context-aware multimodal weather forecasting service, which accepts spoken or written queries and presents forecast         information in several forms, including email, voice and sign languages.      </content></document><document><year>2005</year><authors>Jakob E. Bardram1 </authors><title>Activity-based computing: support for mobility and collaboration in ubiquitous computing</title><content>This paper presents the design philosophy of activity-based computing (ABC), which addresses mobility and cooperation in human work activities. Furthermore, it presents the ABC framework, which is a ubiquitous computing infrastructure supporting ABC. The idea of ABC and the aim of the ABC framework is to: (1) support human activity by managing its collection of work tasks on a computer, (2) support mobility by distributing activities across heterogeneous computing environments, (3) support asynchronous collaboration by allowing several people to participate in an activity, and (4) support synchronous, real-time collaboration by enabling desktop conferencing by sharing the activity across several clients. During a period of two years, the ABC framework has been co-designed and evaluated in close cooperation with a range of clinicians in a hospital.</content></document><document><year>2005</year><authors>Ruth Kikin-Gil1 </authors><title>Affective is effective: how information appliances can mediate relationships within communities and increase one&amp;#8217;s social         effectiveness      </title><content>Technology is already used as a mediator in social relationships, but current appliances are rarely designed with social context         in mind. In this paper, I propose alternative methods for designing products and services in a way that will empower their         users within their social context and increase their social effectiveness. I will argue that incorporating human emotional         needs in the design process considerations lead to a finished design that responds better to the user&amp;#8217;s needs.      </content></document><document><year>2005</year><authors>Martin Colbert1 </authors><title>Age differences rendezvousing: reminders for side-stepping      </title><content>This paper reports a diary study of the use of mobile telephones for rendezvousing by young adults (aged 18&amp;#8211;30) and mature         adults (aged 31&amp;#8211;45) in the UK. A number of age differences were found. Specifically, 31&amp;#8211;45s more frequently: (1) attributed         problems rendezvousing to the overrunning of previous activities, and to the spontaneous performance of additional tasks (&amp;#8216;side-stepping&amp;#8217;);         (2) reported that &amp;#8216;problem&amp;#8217; rendezvous resulted in unnecessary sacrifices; and (3) changed plans for the rendezvous. These         differences arose, because additional family commitments encouraged 31&amp;#8211;45s to pack their daily programme of activities more         tightly than 18&amp;#8211;30s. Mobile phones might better target 31&amp;#8211;45s, if they, for example, enhanced To Do Lists with context-sensitive         reminders, in the first instance, reminders triggered by location (GSM network cellID) and logging off from PCs.      </content></document><document><year>2005</year><authors>Wolfgang Trumler1 | Jan Petzold1 | Faruk Bagci1 | Theo Ungerer1</authors><title>AMUN: an autonomic middleware for the Smart Doorplate Project      </title><content>We envision future office buildings that partly or fully implement a flexible office organization where office rooms are dynamically         assigned to currently present employees. Such organizational principles save required office space, therefore decrease costs,         but require a sophisticated software system that is highly dynamic, scalable, context-aware, self-configuring, self-optimizing         and self-healing. We propose an autonomic/organic middleware approach for such ubiquitous indoor environments with an extensive         monitoring at different system levels and demonstrate the software by using our Smart Doorplate Project that is designed to         support a flexible office organization.      </content></document><document><year>2005</year><authors>Markus C. Huebscher1  | Julie A. McCann1</authors><title>An adaptive middleware framework for context-aware applications      </title><content>We describe a middleware framework for the adaptive delivery of context information to context-aware applications. The framework         abstracts the applications from the sensors that provide context. Further applications define utility functions on the quality         of context attributes that describe the context providers. Then, given multiple alternatives for providing the same type of         context, the middleware applies the utility function to each alternative and choose the one with maximum utility. By allowing         applications to delegate the selection of context source to the middleware, our middleware can implement autonomic properties,         such as self-configuration when new context providers appear and resilience to failures of context providers.      </content></document><document><year>2005</year><authors>Linda M. Gallant1 </authors><title>An ethnography of communication approach to mobile product testing</title><content>Product testing of mobile communication technology has typically employed the same research methodologies that were traditionally applied to stationary technology. An approach that does not primarily rely on physical location to study mobile communication technologies is thus needed. The stable component of mobile communication technology is not physical space but human communication. Therefore, a research model is developed based on an ethnography of communication approach, which designates &amp;#8220;talk&amp;#8221; (i.e., symbolic communication) as the primary and essential unit of measurement while making stationary physical location secondary. This allows design teams to enter a user &amp;#8220;speech community&amp;#8221; anywhere. Eight participants tested both the stationary and mobile version of customer relationship management software for sales. All participants were professional salespeople, comprising a speech community. Users articulated their &amp;#8220;local&amp;#8221; speech community meaning systems in the form of scenarios of use, which can guide product design and marketing. The findings show that proof-of-concept testing of mobile versions of desktop software can be done in conjunction with the usability testing for stationary technology.</content></document><document><year>2005</year><authors>Nicholas A. Bradley1  | Mark D. Dunlop1 </authors><title>An Experimental Investigation into Wayfinding Directions for Visually Impaired People      </title><content>In recent years, there has been an escalation of orientation and wayfinding technologies and systems for visually impaired         people. These technological advancements, however, have not been matched by a suitable investigation of human-computer interaction         (e.g. designing navigation aids for people who form different cognitive maps for navigation). The aim of this study is to         investigate whether a group of sighted participants and a group of visually impaired participants experience a difference         in mental and physical demands when given two different sets of verbal instructions directing them to four landmarks. The         content of the first set of instructions was proportioned to route descriptions derived from sighted people, and the second         set proportioned to descriptions derived from visually impaired people. The objective assessment involved measuring the time         taken by participants to reach landmarks and the number of deviations that occurred. A NASA&amp;#8211;Task Load Index questionnaire         provided an indication of participants subjective perception of workload. The results revealed that instructions formed from         visually impaired people resulted in a lower weighted workload score, less minor deviations, and quicker times for visually         impaired participants. In contrast, these instructions were found to cause a higher weighted workload score for sighted participants.         The results are discussed in relation to the issue of personalisation of mobile context-aware systems for visually impaired         people.      </content></document><document><year>2005</year><authors>Jennifer A. Rode1 </authors><title>Appliances for whom? Considering place      </title><content>We discuss homes as potential settings for the products of appliance design. We catalog the large international and regional         differences. We look at differences in terms of infrastructure: heating, plumbing, electricity, and telephony. We examine         differences in the home itself in terms of number of household members, and size of dwelling. We explore the implications         of this variation for future ethnographies as well as product creation as we ask the question &amp;#8220;appliances for whom?&amp;#8221;      </content></document><document><year>2005</year><authors>Alex|ros Karypidis1  | Spyros Lalis1 </authors><title>Automated context aggregation and file annotation for PAN-based computing</title><content>This paper presents a method for automatically annotating files created on portable devices with contextual metadata. We achieve this through the combination of two system components. One is a context dissemination mechanism which allows devices in a personal area network (PAN) to maintain a shared aggregate contextual perception. The other is a storage management system that uses such context information to automatically decorate files created on personal devices with annotations. As a result, the user is able to flexibly browse and lookup files that were generated on the move, based on the contextual situation at the time of their creation. What is equally important is that the user is relieved from the cumbersome task of having to manually provide annotations in an explicit fashion. This is especially valuable when generating files on the move, using U/I-restricted portable devices.</content></document><document><year>2005</year><authors>A Lee Gilbert1 | Sun|a Sangwan1 | Hilda Han Mei Ian1</authors><title>Beyond usability: the OoBE dynamics of mobile data services markets</title><content>With processors imbedded in appliances, cars, books, and other retail products, modern society has entered the world of pervasive computing. Yet few consumers are able to set up new digital devices and integrate them into everyday life. From this perspective, the data-enabled mobile phone leads the way. In many markets, mobile phones have a product life cycle of 12;months or less. Some subscribers are able to put their new phones to immediate and full use. For others, the learning curve is so steep that they move on to a replacement without having learned to exploit the functionality available in the first one. This work applies earlier findings by IMARC researchers in segmenting mobile data services (MDS) markets, interprets recent survey data, and synthesizes a model to guide design of the Out-of-the-Box Experience (OoBE) for mobile data subscribers. This integrative model can be applied across cultures to help service developers, facilitators and operators design, distribute and communicate new MDS to fulfill the demand side requirements of potential adopters, and to guide packaging design to improve user experiences during the early stages of use.</content></document><document><year>2005</year><authors>Trish Keaton1 | Sylvia M. Dominguez2  | Ali H. Sayed2 </authors><title>Browsing the environment with the SNAP&amp;amp;TELL wearable computer system      </title><content>This paper provides an overview of a multi-modal wearable computer system, SNAP&amp;amp;TELL. The system performs real-time gesture         tracking, combined with audio-based control commands, in order to recognize objects in an environment, including outdoor landmarks.         The system uses a single camera to capture images, which are then processed to perform color segmentation, fingertip shape         analysis, robust tracking, and invariant object recognition, in order to quickly identify the objects encircled and SNAPped         by the user&amp;#8217;s pointing gesture. In addition, the system returns an audio narration, TELLing the user information concerning         the object&amp;#8217;s classification, historical facts, usage, etc. This system provides enabling technology for the design of intelligent         assistants to support &amp;#8220;Web-On-The-World&amp;#8221; applications, with potential uses such as travel assistance, business advertisement,         the design of smart living and working spaces, and pervasive wireless services and internet vehicles.      </content></document><document><year>2005</year><authors>Trish Keaton1 | Sylvia M. Dominguez2  | Ali H. Sayed2 </authors><title>Browsing the environment with the SNAP&amp;amp;TELL wearable computer system      </title><content>Without Abstract</content></document><document><year>2005</year><authors>Ruth Kikin-Gil1 </authors><title>BuddyBeads: techno-jewelry for non-verbal communication within teenager girls groups      </title><content>The extremity in teenagers&amp;#8217; attitudes and actions coupled with the opportunities of mobile communication creates new behaviors         and re-shapes existing ones. But, however meaningful the phone is in teenagers&amp;#8217; lives, it is not designed to support their         need for emotional communication and group identity. The BuddyBeads project suggests alternative communication forms among teenagers, which emphasize their social structures, behaviors and         needs. BuddyBeads are techno-jewelry items that facilitate non-verbal and emotional communication among group members, through codes and signals         which the group decided upon together. Each group member has a matching jewelry piece and can use it to communicate her emotional         state to the other group members.      </content></document><document><year>2005</year><authors>Eamonn O&amp;#8217 Neill1 | Manasawee Kaenampornpan1 | Vassilis Kostakos1 | Andrew Warr1  | Dawn Woodgate1 </authors><title>Can we do without GUIs? Gesture and speech interaction with a patient information system</title><content>We have developed a gesture input system that provides a common interaction technique across mobile, wearable and ubiquitous computing devices of diverse form factors. In this paper, we combine our gestural input technique with speech output and test whether or not the absence of a visual display impairs usability in this kind of multimodal interaction. This is of particular relevance to mobile, wearable and ubiquitous systems where visual displays may be restricted or unavailable. We conducted the evaluation using a prototype for a system combining gesture input and speech output to provide information to patients in a hospital Accident and Emergency Department. A group of participants was instructed to access various services using gestural inputs. The services were delivered by automated speech output. Throughout their tasks, these participants could see a visual display on which a GUI presented the available services and their corresponding gestures. Another group of participants performed the same tasks but without this visual display. It was predicted that the participants without the visual display would make more incorrect gestures and take longer to perform correct gestures than the participants with the visual display. We found no significant difference in the number of incorrect gestures made. We also found that participants with the visual display took longer than participants without it. It was suggested that for a small set of semantically distinct services with memorable and distinct gestures, the absence of a GUI visual display does not impair the usability of a system with gesture input and speech output.</content></document><document><year>2005</year><authors>Marios C. Angelides1  | Kurt Englmeier2 </authors><title>Collaborative design of web service networks in a multilingual user community</title><content>This paper presents the WS&amp;#x2013;Talk (Web Service&amp;#x2013;Talk) interface layer, which is a structured natural language interface for the inter-service communication that extends the find, bind, and execute paradigm of web service interaction. This open building block can be implemented by both the service designers who, as providers, are more concerned with the architecture of the underlying service model and the service requesters who, as users, will seek to specify web services as solutions to specific problems. Through a semantic layer, WS&amp;#x2013;Talk transforms service descriptions or requests that have been expressed in natural language into task-specific web-serviced specifications. Whilst the objective of bringing together the service providers with relevant task-competent end-users in the architectural design of web service applications is, on the one hand, to build connected interoperable applications, on the other hand, the WS&amp;#x2013;Talk layer enables service requesters and providers to design and implement new ad hoc services or fine-tune existing ones.</content></document><document><year>2005</year><authors>Olufisayo Omojokun1 | Jeffrey S. Pierce2 | Charles L. Isbell2  | Prasun Dewan1 </authors><title>Comparing end-user and intelligent remote control interface generation      </title><content>Traditional remote controls typically allow users to activate functionality of a single device. Given that users activate         a subset of functionality across devices to accomplish a particular task, it is attractive to consider a remote control directly         supporting this behavior. We present qualitative and quantitative results from a study of two promising approaches creating         such a remote control: end-user programming and machine learning. In general, results show that each approach possesses advantages         and disadvantages, and that neither is optimal.      </content></document><document><year>2005</year><authors>Michael Kirchhof1  | Sebastian Linz1 </authors><title>Component-based development of Web-enabled eHome services</title><content>In this paper we will take a look at the inside of connected homes, which build up complex IT systems. The building blocks of such systems are electronic devices, networks, and services, which empower the user to interact with his environment. Web-enabled eHome services offer functionality to the user by abstracting from devices and realize connectivity in three dimensions: (1) inner connectivity, (2) outer connectivity, and (3) integrative connectivity. Generations of Web-enabled eHome services have been developed based on proprietary hard- and software. Today, an extensible and modular platform is required for forward-looking design and implementation of such services. We describe a new view on component-based development of Web-enabled eHome services. While there is an adequate framework (open service gateway initiative) for the development of state-of-the-art Web-enabled eHome services, there is no knowledge about the system and service structure and its architecture in detail. We propose an 3-layer system structure (called PowerArchitecture), which incorporates several established design ideas and show how this cookbook makes system architects and developers life easier.</content></document><document><year>2005</year><authors>Pieter Jan Stappers1 </authors><title>Creative connections: user, designer, context, and tools      </title><content>The design symposium &amp;#8216;creative connections discusses the designers&amp;#8217; tools in the conceptual phase. Over the past few decades,         many considerations, which hitherto occured before or after conceptualizing have become an integrated part of concept development.         Examples are studies of users and contexts, and expressive new materials. Also, design tools are becoming increasingly, almost         exclusively, computer-based. But current computer tools lack fluency, directness, and bodily involvement of the traditional         paper tools, properties which are essential in the creative activities of conceptualizing, The symposium, and its four attached         bazaar papers, deal with new tools that are being developed, and old tools that are evolving, to help designers at coping         with this complexity of factors.      </content></document><document><year>2005</year><authors>Karen Holtzblatt1 </authors><title>Customer-centered design for mobile applications</title><content>Designing applications for mobile platforms presents unique and harder challenges than traditional software design. Users of such devices expect to be able to run such applications with no training, no traditional packaging elements such as quick start cards, and no help system. Customer-centered design is probably the only way such applications can be designed successfully. This paper presents our experience using customer-centered design to create a sophisticated mobile application&amp;#x2014;mSports Baseball. We describe the application and detail how we modified contextual Design (CD), our customer-centered design process, to produce an application users could enjoy with no training and no help.</content></document><document><year>2005</year><authors>Hassan A. Artail1  | Mackram Raydan1 </authors><title>Device-aware desktop web page transformation for rendering on handhelds      </title><content>This paper illustrates a new approach to automatic re-authoring of web pages for rendering on small-screen devices. The approach         is based on automatic detection of the device type and screen size from the HTTP request header to render a desktop web page         or a transformed one for display on small screen devices, for example, PDAs. Known algorithms (transforms) are employed to         reduce the size of page elements, to hide parts of the text, and to transform tables into text while preserving the structural         format of the web page. The system comprises a preprocessor that works offline and a just-in-time handler that responds to         HTTP requests. The preprocessor employs Cascading Style Sheets (CSS) to set default attributes for the page and prepares it         for the handler. The latter is responsible for downsizing graphical elements in the page, converting tables to text, and inserting         visibility attributes and JavaScript code to allow the user of the client device to interact with the page and cause parts         of the text to disappear or reappear. A system was developed that implements the approach and was used it to collect performance         results and conduct usability testing. The importance of the approach lies in its ability to display hidden parts of the web         page without having to revisit the server, thus reducing user wait times considerably, saving battery power, and cutting down         on wireless network traffic.      </content></document><document><year>2005</year><authors>Charles Rich1 | C|ace Sidner1| Neal Lesh1| Andrew Garl|1| Shane Booth1 | Markus Chimani1</authors><title>DiamondHelp: a new interaction design for networked home appliances      </title><content>Ordinary people already have great difficulty using the advanced features of digitally enhanced household products, and the         problem is getting worse as more features are continually being added. This usability problem cannot be solved using only         the tiny displays and limited control buttons typically found on home appliances. By using a home network to share a larger         and more powerful display, we can provide a new type of collaborative interface in which the product actively helps the user,         especially with complex features that are only occasionally used. In this design competition prospectus, we concentrate on         the key design principles underlying DiamondHelp. The generic DiamondHelp architecture has been implemented in Java; a prototype         live demonstration similar to one of the animated simulations is currently under development.      </content></document><document><year>2005</year><authors>Andrei Voinikonis1 | Klaus Irmscher1  | Hendrik Schulze1 </authors><title>Distributed processing of reminding tasks within the mobile memory aid system, MEMOS</title><content>The mobile extensible memory and orientation system (MEMOS) is a nomadic computing system designed to support patients with disturbances in the prospective memory. The system consists of two parts which are loosely connected via general packet radio service (GPRS): a mobile electronic device [personal memory assistant (PMA)] to remind the patient of important tasks and a base station that coordinates the activities of caregivers and notifies them about the result of the task execution. A major requirement of MEMOS is the autonomous operation of the PMA. This is accomplished by avoiding mobile transactions, the specification of temporal aspects in the task description, introduction of different states for tasks of the PMA and the base station and by splitting task and result management. Special extensible markup language (XML) based languages were developed for data exchange between the base station and the PMA to reflect the temporal aspects of the tasks and for logging the results of task execution.</content></document><document><year>2005</year><authors>Mirco Musolesi1 | Cecilia Mascolo1  | Stephen Hailes1 </authors><title>EMMA: Epidemic Messaging Middleware for Ad hoc networks      </title><content>The characteristics of mobile environments, with the possibility of frequent disconnections and fluctuating bandwidth, have         forced a rethink of traditional middleware. In particular, the synchronous communication paradigms often employed in standard         middleware do not appear to be particularly suited to ad hoc environments, in which not even the intermittent availability         of a backbone network can be assumed. Instead, asynchronous communication seems to be a generally more suitable paradigm for         such environments. Message oriented middleware for traditional systems has been developed and used to provide an asynchronous         paradigm of communication for distributed systems, and, also for some specific mobile computing systems recently. In this         paper, we present our experience in designing, implementing, and evaluating Epidemic Messaging Middleware for Ad hoc networks         (EMMA), an adaptation of Java Message Service (JMS) for mobile ad hoc environments, discussing in detail the design challenges         and the solutions that have been adopted.      </content></document><document><year>2005</year><authors>Mattias EsbjГ¶rnsson1 </authors><title>From ethnography on infrastructure management to initial user feedback on PlaceMemo      </title><content>This paper reports design requirements derived from an ethnographic fieldwork on road inspectors, the design of a mobile service         supporting infrastructure management, and initial user feedback. Seeing that the road inspectors are truly mobile, acting         in vast settings full of objects with variable status, they lack overview of their upcoming tasks. The PlaceMemo prototype         allows them to place geographically coupled voice annotations in their work setting. The voice memos are played through their         entire length before reaching the precise position of the recording, and are also accessible when being geographically distant.         By handing out the prototype to a number of users, we successfully demonstrate that this lightweight context-aware system         facilitates their mobile work. They obtain an overview supporting the advance preparation of inspection tours, and can easily         access earlier recordings while driving, in order to be reminded and to prepare stops in time.      </content></document><document><year>2005</year><authors>Adrian Friday1 | Manuel Roman1| Christian Becker1 | Jalal Al-Muhtadi1</authors><title>Guidelines and open issues in systems support for Ubicomp: reflections on UbiSys 2003 and 2004      </title><content>Without Abstract</content></document><document><year>2005</year><authors>T. Serif1  | G. Ghinea1</authors><title>HMD versus PDA: a comparative study of the user out-of-box experience</title><content>The out-of-box experience (OOBE) has been identified as a significant factor contributing to user perception and acceptance of products and technologies. Whilst there has been considerable emphasis placed on formalising methodological procedures for evaluating the OOBE and on the creation of positive user experiences through appropriate interfaces and applications, relatively little work has been undertaken examining how the OOBE is impacted when the experience itself covers a range of (possibly interconnected) devices. In this paper we report the results of an empirical study which examined the OOBE when a Personal Digital Assistant (PDA) and Head Mounted Device (HMD) were configured and then connected for inter-operability purposes. Our findings show that type of device has a considerable impact on the OOBE, with the ask of interconnecting devices having a detrimental effect on the OOBE. The OOBE, however, is in main unaffected by user type and gender.</content></document><document><year>2005</year><authors>Phil Turner1 | Garry Milne2| Manfred Kubitscheck1| Ian Penman2 | Susan Turner1</authors><title>Implementing a wireless network of PDAs in a hospital setting</title><content>This paper discusses the introduction of a wireless network of personal digital assistants into a specialist unit of a hospital in Edinburgh. All of the technology has been used off-the-shelf and out-of-the-box. While we are able to report that the heterogeneous elements of this implementation have been integrated, work well together and that the users of the system are happy with it, the hospital context itself introduced a number of significant practical issues. Hospitals are understandably very concerned about the security and confidentiality of patient records and with the potential for mutual interference between the wireless PDAs and other sensitive, wireless telemetric medical systems. Having dealt with these ultimately tractable infrastructural issues we also note the importance of identifying the killer application of the PDAs in achieving a critical mass of end users, and indicate areas for further work.</content></document><document><year>2005</year><authors>Stefania B|ini1  | Fabio Sartori1</authors><title>Improving the effectiveness of monitoring and control systems exploiting knowledge-based approaches</title><content>This paper illustrates how the adoption of techniques typical of artificial intelligence (AI) could improve the performance of monitoring and control systems (MCSs). Traditional MCSs are designed according to a three-level architectural pattern in which intelligent devices are usually devoted to evaluate whether the data acquired by a set of sensors could be interpreted as anomalous or not. Possible mistakes in the evaluation process, due to faulty sensors or external factors, can cause the generation of undesirable false alarms. To solve this problem, the traditional three-tier architecture of MCSs has been extended with a fourth level, named the correlation level, where an intelligent module, usually a knowledge-based system, collects the local interpretations made by each evaluation device, building a global view of the monitored field. In this way, possible local mistakes are identified by the comparison with other local interpretations.</content></document><document><year>2005</year><authors>Duan Varan1 | Andrew Turk1 | Sam Bucolo2 | Deb Polson2 | Margot Brereton3 | Jared Donovan3 | Kim Montgomery4  | Gael McIndoe4 </authors><title>Interactive lounge: an interdisciplinary approach to the design of a gestural interaction device      </title><content>Among the many new opportunities that digital technologies are enabling are an increased capacity for viewers to interact         not only with the program content, but with an increasingly wide array of other digital applications. Within this context         this project has developed a new interaction device (incorporating gestural platform technology) and user interfaces to facilitate         interactive access to digital media in a lounge room setting. This paper provides an overview of an interdisciplinary design         process applied by Australasian CRC for Interaction Design (ACID) researchers&amp;#8212;in order to develop the device and present in         detail its unique features.      </content></document><document><year>2005</year><authors>Nigel Derrett1 </authors><title>Is automation automatically a good thing?      </title><content>This paper is a response to Bill Sharpe&amp;#8217;s keynote speech at 2AD. It discusses when automation in appliances and computer programs         is good and when it is bad. It also proposes the use of speech recognition technology as a way to program agents.      </content></document><document><year>2005</year><authors>Derek Reilly1 | Malcolm Rodgers1| Ritchie Argue1| Mike Nunes1 | Kori Inkpen1</authors><title>Marked-up maps: combining paper maps and electronic information resources      </title><content>Mobile devices have been used as tools for navigation and geographic information retrieval with some success. However, screen         size, glare, and the cognitive demands of the interface are often cited as weaknesses when compared with traditional tools         such as paper maps and guidebooks. In this paper, a simple mixed media approach is presented which tries to address some of         these concerns by combining paper maps with electronic guide resources. Information about a landmark or region is accessed         by waving a handheld computer equipped with an radio frequency identification (RFID) reader above the region of interest on         a paper map. We discuss our prototyping efforts, including lessons learned about using RFID for mixed media interfaces. We         then present and discuss evaluations conducted in the field and in a comparative, exploratory study. Results indicate that         the method is promising for tourism and other activities requiring mobile, geographically-related information access.      </content></document><document><year>2005</year><authors>Daniel Saakes1 </authors><title>Material light: exploring expressive materials      </title><content>The control of material appearance has become richer than before, giving designers new expressive freedom. Designers need         tools and techniques to handle this freedom when designing products. We present a simple but powerful technique to explore         material expression in the conceptual phase of the design process. Colours and patterns are projected on foam and paper models         to enable designers to quickly visualise and judge materials in context of the products shape.      </content></document><document><year>2005</year><authors>Juha Lehikoinen1 | Ilkka Salminen1 | Antti Aaltonen1 | Pertti Huuskonen1  | Juha Kaario1 </authors><title>Meta-searches in peer-to-peer networks</title><content>We propose a method for carrying out enhanced collaborative searches, called meta-searches, in peer-to-peer networks. In addition to performing regular searches, our method supports searches based on other network users&amp;#8217; previous searches on the same or similar topic. In essence, when a user performs a search, s/he will receive not only the usual result set, but also information on other users&amp;#8217; previous results, as well as relevancy information (such as how many times a resource that appeared in the result set was successfully downloaded). The core components of meta-search are query relevancy calculation, query matching algorithms, and relevancy file format. In this paper we discuss the underlying concepts and principles, and describe the component design in detail. Meta-search provides a way of benefiting from other users&amp;#8217; successful searches without any additional effort, thus potentially improving the efficiency and experience of a search.</content></document><document><year>2005</year><authors>Tae Seung Ha1 | Ji Hong Jung1  | Sung Yong Oh1 </authors><title>Method to analyze user behavior in home environment      </title><content>The development of computing technology affects the environmental change of residential area a lot in a many ways. In other         words, we believe that Ubiquitous computing technology will change our very vision of our homes. The most distinct phenomenon         of Ubiquitous environment is that the number of personal computers will increase mainfold. That means in the near future we         will coexist with computers in routine life and people will have more computers to manage. In terms of User Interface, the         interaction between systems and users in home-network environment should step up the next level which is different from present         method of using computer. Therefore, Ubiquitous environment should be embodied for people and it must be started with understanding         users and grasping sophisticated and fundamental needs of them. In this research study, we have attempted to give shape to         &amp;#8216;Method to Analyze User Behavior&amp;#8217; to make embodiment of user interface in Ubiquitous environment by considering and analyzing         user&amp;#8217;s behavior patterns. With this aim, we have extracted contexts at home from a case study and will suggest analyzing method         by classifying data of the study.      </content></document><document><year>2005</year><authors>Timo Jokela1 | Jussi Koivumaa2 | Jani Pirkola2 | Petri Salminen3  | Niina Kantola1 </authors><title>Methods for quantitative usability requirements: a case study on the development of the user interface of a mobile phone</title><content>Quantitative usability requirements are a critical but challenging, and hence an often neglected aspect of a usability engineering process. A case study is described where quantitative usability requirements played a key role in the development of a new user interface of a mobile phone. Within the practical constraints of the project, existing methods for determining usability requirements and evaluating the extent to which these are met, could not be applied as such, therefore tailored methods had to be developed. These methods and their applications are discussed.</content></document><document><year>2005</year><authors>Sotirios Terzis1 | Paddy Nixon4 | Nitya Narasimhan2  | Tim Walsh3 </authors><title>Middleware for pervasive and ad hoc computing      </title><content>Without Abstract</content></document><document><year>2005</year><authors>Eduardo Souto1 | Germano GuimarГЈes1 | Glauco Vasconcelos1 | Mardoqueu Vieira1 | Nelson Rosa1 | Carlos Ferraz1  | Judith Kelner1 </authors><title>Mires: a publish/subscribe middleware for sensor networks      </title><content>A wireless sensor network (WSN) consists of a large number of small devices with computational power, wireless communication         and sensing capability. These networks have been developed for a wide range of applications, such as habitat monitoring, object         tracking, precision agriculture, building monitoring and military systems. Meanwhile, middleware systems have also been proposed         in to facilitate both the development of these applications and provide common application services. The development of middleware         for sensor networks, however, places new challenges on middleware developers due to the low availability of resources and         processing capacity of the sensor nodes. In this context, this paper presents the design and implementation of a middleware         for WSN named Mires. Mires incorporates characteristics of message-oriented middleware by allowing applications communicate         in a publish/subscribe way. In order to illustrate the proposed middleware, we have also developed an environment-monitoring         application and a data aggregation service.      </content></document><document><year>2005</year><authors>Miguel Bruns Alonso1  | David V. Keyson1 </authors><title>MusicCube: a physical experience with digital music      </title><content>Listening to digital music on a computer has led to a loss of part of the physical experience associated with earlier media         formats such as CDs and LPs. This paper presents a series of steps and decisions that led to the design of MusicCube, a tangible         user interface that allows users to control digitally stored music on a computer by means of gestures and positioning. Interaction         with the MusicCube is enriched by offering feedback through multi-coloured light effects and clicking sounds together with         computer-generated speech. Despite some ergonomic shortcomings, when comparing to the iPod, users appreciated the design and         enjoyed using it.      </content></document><document><year>2005</year><authors>Albrecht Schmidt1 </authors><title>Network alarm clock (The 3AD International Design Competition)      </title><content>The network alarm clock is a novel design for an appliance that provides alarm clock functionality. Network alarm clocks are         connected over a wireless network to other network alarm clocks of people in the social network of a user. The wake-up time         of the alarm is related to presence information (e.g., who is up already, who is still asleep) from other users. A typical         wake-up setting is: wake me between 7;am and 10;am when more than half of my family are already up. With a tangible interface         the alarm can be enabled or disabled. When enabled this assumes the user has gone to bed; when disabled after ringing it is         assumed the user is up. This information is used as a presence information for others.      </content></document><document><year>2005</year><authors>Maya Rodrig1  | Anthony LaMarca2 </authors><title>Oasis: an architecture for simplified data management and disconnected operation</title><content>Oasis is an asymmetric peer-to-peer data management system tailored to the requirements of pervasive computing. Drawing upon applications from the literature, we motivate three high-level requirements: availability, manageability, and programmability. Oasis addresses these requirements by employing a peer-to-peer network of weighted replicas and performing background self-tuning. In this paper, we describe our architecture, our consistency-control mechanism, and an initial implementation. Our performance evaluation and the implementation of three applications suggest that Oasis offers good availability and performance while providing a simple API and a familiar consistency model.</content></document><document><year>2005</year><authors>Andrea Maurino1  | Stefano Modafferi1 </authors><title>Partitioning rules for orchestrating mobile information systems</title><content>New mobile technologies such as Bluetooth or Wi-Fi suffer from many limitations and problems, especially when they are used in combination, whereas they are quite stable in small networks. The lack of specialised mobile middleware requires new methods in the design and execution of mobile information systems. We propose a two-phase approach to manage a mobile business process by partitioning a given workflow into several workflows, with each one governed by a controller. In the first phase, we introduce synchronisation tasks between different controllers. In the second phase, we create for each controller a local process view. Thanks to added tasks, the overall execution of all local workflows achieve the same result as the original one. The mobile scenario and the necessity for more automation lead us to choose the Business Process Execution Language for Web Services (BPEL4WS) as the language for the process definition.</content></document><document><year>2005</year><authors>Krupa Nathwani1  | Ken Eason1 </authors><title>Perceptions versus expectations of multimedia messaging service (MMS)</title><content>Previously mobile industry has been unsuccessful in predicting services available on mobile phones that consumers would want to use. Short messaging service (SMS), for example, developed as a major service to the surprise of service providers. Wireless application protocol (WAP) despite heavy marketing and high hopes was not successful. The study presented examines consumer attitudes to using multimedia messaging service (MMS). An experiment is reported which tests whether people who had the opportunity to use MMS formed different perceptions of it to those who were only shown an animated PowerPoint presentation. The results demonstrated that the group who used MMS had more positive perceptions. However, the results from both groups suggest there are important barriers to overcome for use to be extensive: for example, the price of the service and of the handsets would be a disincentive and the service would need to be available to use across networks.</content></document><document><year>2005</year><authors>Giovanni Cannata1 </authors><title>Phymail Box: an information appliance that checks and prints only important emails      </title><content>Phymail Box is an information appliance that checks and prints important emails according to the user&amp;#8217;s preferences. It allows         people to manage the email experience in a new way, making it easier and more pleasant to use than other available systems      </content></document><document><year>2005</year><authors>Froukje Sleeswijk Visser1  | Victor Visser1</authors><title>Re-using users: co-create and co-evaluate      </title><content>Although user participation has become a standard ingredient of modern product design, in most cases users participate only         for a moment, e.g. one afternoon. In this poster we report a case where we had users, who had participated in a generative         study, return after 4;months to evaluate the resulting concept design. Our experience in this study suggests that the &amp;#8216;returning         participants&amp;#8217; had retained the sensitivity for the product context that was built up during the first study.      </content></document><document><year>2005</year><authors>Nathan Eagle1  | Alex (S|y) Pentl|1 </authors><title>Reality mining: sensing complex social systems      </title><content>We introduce a system for sensing complex social systems with data collected from 100 mobile phones over the course of 9;months.         We demonstrate the ability to use standard Bluetooth-enabled mobile telephones to measure information access and use in different         contexts, recognize social patterns in daily user activity, infer relationships, identify socially significant locations,         and model organizational rhythms.      </content></document><document><year>2005</year><authors>Antti Aaltonen1  | Juha Lehikoinen1 </authors><title>Refining visualization reference model for context information      </title><content>Context-awareness can be used to decrease the need for interaction with a mobile device. This is increasingly important since         the functionality of mobile devices and personal digital assistants gets more and more complex while the input and output         capabilities remain restricted. An important aspect of context-awareness is to present the current context to the user. We         propose a model for visualizing contextual information on the mobile terminal screen. The model is a refinement of a well-known         visualization reference model; it takes into account the specific characteristics of mobile use and context information. We         present the design of the model in detail, and discuss its applicability for a variety of contexts and tasks by providing         a full-fledged use case.      </content></document><document><year>2005</year><authors>Christian M&amp;uuml ller-Schloer1 | Theo Ungerer2 </authors><title>Selected papers of the ARCS04 conference: an introduction</title><content>Without Abstract</content></document><document><year>2005</year><authors>Ilkka Arminen1 </authors><title>Social functions of location in mobile telephony</title><content>Location appears to be one of the most important aspects of context in mobile communication. It is a complex piece of information involving several levels of detail. Location intertwines with other relevant aspects of context: the parties&amp;#8217; present activity, relative time and identities. The analysis of mobile conversations provides insights into the functions of &amp;#8220;location&amp;#8221; for mobile users. Most mobile calls involve a sequence in which location is reported. Location is made relevant by the parties&amp;#8217; activities. Location telling takes place in five different activity contexts during mobile calls. Location may be an index of interactional availability, a precursor for mutual activity, part of an ongoing activity, or it may bear emergent relevance for the activity or be presented as a social fact. Typically, joint activities make relevant spatio-temporal location such as distance in minutes from the meeting point via the vehicle used. For users, location does not appear to be relevant in purely geographical terms.</content></document><document><year>2005</year><authors>Jamie Billing1  | Tracy Cordingley1 </authors><title>Some Kind of Analogtivity: anti-simulation through design      </title><content> they are the result of a critical investigation into the emerging design issues surrounding &amp;#8216;interaction&amp;#8217;         and &amp;#8216;transparency&amp;#8217;. By using &amp;#8216;popular&amp;#8217; language of product design as a vehicle, they exist as &amp;#8216;cultural offerings&amp;#8217; exploring         an alternative future for technological products not necessarily governed by science and economics.      </content></document><document><year>2005</year><authors>Peter Thomas1| 2 </authors><title>Special issue of personal and ubiquitous computing: papers from 3AD&amp;#8212;the second international conference on appliance design      </title><content>Without Abstract</content></document><document><year>2005</year><authors>Pekka Ketola1 </authors><title>Special issue on out-of-box experience and consumer devices</title><content>Computer equipment is hard to choose, install, maintain, and, especially, operate (Landauer 1995 In: The trouble with computers: usefulness, usability, and productivity). How many cables did you have to connect (and organise) before the personal office system was properly installed and put into use? How many set-up procedures and agreements did you have to complete before you could access your e-mail with your mobile phone or PDA? Did you lose any documents or applications when you replaced your old computer with a new one? Computers, mobile devices and information technology products are sometimes difficult to put into use because of the several operations required prior to their first use.</content></document><document><year>2005</year><authors>Luciano Baresi1 | Schahram Dustdar2 | Harald Gall3  | Maristella Matera1 </authors><title>Special issue on ubiquitous mobile information and collaboration systems (UMICS)</title><content>Without Abstract</content></document><document><year>2005</year><authors>Antti Pirhonen1 </authors><title>Supporting a user facing a novel application: learnability in OOBE</title><content>Learnability is a key factor in the out-of-box (OOBE) experience. This paper is a conceptual analysis of learnability in the context of OOBE. We first analyse the concept of learnability in terms of different views of learning. Then we discuss how metaphors could be utilised as a way of making learnable products which provide a positive OOBE. We also present a method for analysing individual learning processes during the first few moments with a new product 7 and illustrate the use of the method with a description of the evaluation of a sample design. Finally, we derive some design guidelines relevant to OOBE.</content></document><document><year>2005</year><authors>Mikael B. Skov1  | Rune Th. HГёegh1 </authors><title>Supporting information access in a hospital ward by a context-aware mobile electronic patient record      </title><content>Context-awareness holds promise for improving the utility of software products. Context-aware mobile systems encompass the         ability to automatically discover and react to changes in an environment. Most contemporary context-aware mobile systems aim         to support users in private situations, for example, as tourist guides. Thus, we still lack an understanding of the impact         of context-awareness in professional work situations. In this paper, we explore context-awareness for mobile electronic patient         records through the design of a context-aware mobile prototype called MobileWard. The aim of MobileWard is to support nurses         in conducting morning procedures in a hospital ward. MobileWard is context-aware as it is able to discover and react autonomously         according to changes in the environment and since it integrates the ability to provide information and services to the user         where the relevancy depends on the user&amp;#8217;s task. We evaluate MobileWard in two usability evaluations to assess the usefulness         of the system and we find that context-awareness holds some promising opportunities, but that it also introduces some potential         interaction problems when users are mobile and working in a professional environment. Implications and limitations of the         proposed solution are further discussed.      </content></document><document><year>2005</year><authors>Oliver Storz1 | Adrian Friday1  | Nigel Davies1 </authors><title>Supporting ordering and consistency in a distributed Event Heap for Ubiquitous Computing      </title><content>The Stanford Event Heap has been shown to provide appropriate support for constructing interactive workspace applications.         Given this success it is natural to consider the Event Heap as a platform to support other classes of Ubiquitous Computing         applications. In this paper we argue that the distributed, spontaneous nature of these applications places additional demands         on the Event Heap that require extensions to both the engineering and API. Suitable extensions are described and their use         to support a typical Ubicomp application is discussed.      </content></document><document><year>2005</year><authors>Philip Ross1  | David V. Keyson2 </authors><title>The case of sculpting atmospheres: towards design principles for expressive tangible interaction in control of ambient systems      </title><content>According to the vision of Ambient Intelligence, technology will seamlessly merge into people&amp;#8217;s everyday activities and environments.         A challenge facing designers of such systems is to create interfaces that fit in people&amp;#8217;s everyday contexts and incorporate         the values of daily life. This paper focuses on tangible expressive interaction as one possible approach towards linking everyday         experiences to intuitive forms of interaction and presents a number of principles for expressive interaction design in this         field. A case study of a tangible expressive interface to control a living room atmosphere projection system (orchestrating         living room lighting, audio and video-art) is presented to illustrate and reflect upon the design principles. Furthermore,         the case study describes possible techniques towards integrating the design principles into a design method.      </content></document><document><year>2005</year><authors>John McCarthy1 | Peter Wright2| Jayne Wallace3 | Andy Dearden4</authors><title>The experience of enchantment in human&amp;#8211;computer interaction</title><content>Improving user experience is becoming something of a rallying call in human&amp;#8211;computer interaction but experience is not a unitary thing. There are varieties of experiences, good and bad, and we need to characterise these varieties if we are to improve user experience. In this paper we argue that enchantment is a useful concept to facilitate closer relationships between people and technology. But enchantment is a complex concept in need of some clarification. So we explore how enchantment has been used in the discussions of technology and examine experiences of film and cell phones to see how enchantment with technology is possible. Based on these cases, we identify the sensibilities that help designers design for enchantment, including the specific sensuousness of a thing, senses of play, paradox and openness, and the potential for transformation. We use these to analyse digital jewellery in order to suggest how it can be made more enchanting. We conclude by relating enchantment to varieties of experience.</content></document><document><year>2005</year><authors>Sarah Olofsson1 | Veronica Carlsson1  | Jessica SjГ¶l|er1 </authors><title>The friend locator: supporting visitors at large-scale events      </title><content>According to festival visitors, the best way to experience a music festival is to be together with friends. However, when         at a crowded festival, visitors tend to lose each other especially when a lot of people are in motion. This paper reports         upon findings made in an ethnographic field study that was carried out during Sweden&amp;#8217;s largest music event, the Hultsfred         Rock Festival. The study was part of an international research and development project, called the Wireless Festival, which         focuses on solutions for large-scale events. The aim of our study was to determine who the typical visitor to the festival         was, identify what was important for festival visitors and finally to observe the visitors use of mobile phones. Our findings         imply the festival visitors&amp;#8217; need for a friend locator appliance. An early design solution for such appliance is discussed         in relation to the findings made.      </content></document><document><year>2005</year><authors>Erez Kikin-Gil1 </authors><title>The Light-Wall: tangible user interfaces for learning systems thinking      </title><content>This paper presents the design of the Light-Wall, a tangible user interface aimed at teaching children the core principles         of systems thinking. This document presents the design problem, process and solution.      </content></document><document><year>2005</year><authors>Panos Markopoulos1 | Bert Bongers1| Erik van Alphen1| Jasper Dekker1| Wouter van Dijk1| Sebastiaan Messemaker1| Joep van Poppel1| Bram van der Vlist1| Dirk Volman1 | Gilles van Wanrooij1</authors><title>The PhotoMirror appliance: affective awareness in the hallway      </title><content>This paper presents the design of PhotoMirror an intra-home communication appliance for supporting informal, lightweight communication         and awareness between home inhabitants. The PhotoMirror captures and displays images of trivial daily events and rituals reflecting         the commotion and activities of home inhabitants.      </content></document><document><year>2005</year><authors>Jakob E. Bardram1 </authors><title>The trouble with login: on usability and computer security in ubiquitous computing      </title><content>Logging in by typing usernames and passwords is by far the most common way to access modern computer systems. However, such         contemporary user authentication mechanisms are inappropriate in a ubiquitous computing environment, where users constantly         are accessing a wide range of different devices. This paper introduces new concepts for user authentication in ubiquitous         computing, such as the notion of proximity-based user authentication and silent login. The design of these new mechanisms is part of the design of a ubiquitous computing infrastructure for hospitals, which is         grounded in field studies of medical work in hospitals. The paper reports from field studies of clinicians using an electronic         patient record (EPR) and describes severe usability problems associated with its login procedures. The EPR&amp;#8217;s login mechanisms         do not recognize the nature of medical work as being nomadic, interrupted, and cooperative around sharing common material.         The consequence is that login is circumvented and security is jeopardized.      </content></document><document><year>2005</year><authors>Corrie van der Lelie1 </authors><title>The value of storyboards in the product design process      </title><content>In the realm of product design, communication between designer, client, design team and future users is of great importance.         Throughout the design process, ideas and concepts are generated and must be conveyed to these people to evoke comments, judgement         or acceptance, depending on the process phase. Storyboards are a valuable aid to the designer in this task by providing a         common visual language that people from different backgrounds can &amp;#8216;read&amp;#8217; and understand. However, the visualisation style         of the storyboards influences the reactions. Where open and sketchy storyboards are inviting comments, sleek and detailed         presentations can be overwhelming. Storyboards not only help the product designer to get a grip on target groups, context,         product use and timing, but also in communicating about these aspects with all people involved.      </content></document><document><year>2005</year><authors>William W. Gaver1 </authors><title>The video window: my life with a ludic system      </title><content>The video window is a video screen hanging next to a window on my bedroom wall, showing the image from a camera mounted to         show the skyline from outside that same window. In this paper, I describe the appeal of living with such a system, and the         intermingled aesthetic, utilitarian and practical issues involved in its creation and the experience it offers.      </content></document><document><year>2005</year><authors>Fabio Crestani1| Mark Dunlop1| Matt Jones2| Steve Jones2  | Stefano Mizzaro3</authors><title>Theme issue on interactive mobile information access      </title><content>Without Abstract</content></document><document><year>2005</year><authors>Christian Seitz1 | Michael Berger1 | Bernhard Bauer2</authors><title>Towards a general approach to mobile profile based distributed grouping</title><content>In this paper, we present a new kind of mobile ad hoc application, which we call mobile profile based distributed grouping (MoPiDiG), which is a combination of mobile clustering and data clustering. In MoPiDiG, each mobile host is endowed with a user profile and, while the users move around, hosts with similar profiles are found and a robust mobile group is formed. The members of a group are able to cooperate with each other or attain a goal together. In this article, MoPiDiG is defined and compared with related approaches. Furthermore, a modular architecture and algorithms are presented to build arbitrary MoPiDiG applications.</content></document><document><year>2005</year><authors>Colin English1 | Sotirios Terzis1 | Paddy Nixon1</authors><title>Towards self-protecting ubiquitous systems: monitoring trust-based interactions      </title><content>The requirement for spontaneous interaction in ubiquitous computing creates security issues over and above those present in         other areas of computing, deeming traditional approaches ineffective. As a result, to support secure collaborations entities         must implement self-protective measures. Trust management is a solution well suited to this task as reasoning about future         interactions is based on the outcome of past ones. This requires monitoring of interactions as they take place. Such monitoring         also allows us to take corrective action when interactions are proceeding unsatisfactorily. In this vein, we first present         a trust-based model of interaction based on event structures. We then describe our ongoing work in the development of a monitor         architecture which enables self-protective actions to be carried out at critical points during principal interaction. Finally,         we discuss some potential directions for future work.      </content></document><document><year>2005</year><authors>Martin Modahl1| 3 | Bikash Agarwalla1 | T. Scott Saponas2 | Gregory Abowd1  | Umakishore Ramach|ran1 </authors><title>UbiqStack: a taxonomy for a ubiquitous computing software stack      </title><content>This paper describes a taxonomy for a ubiquitous computing software stack called UbiqStack. Through the lens of the UbiqStack taxonomy we survey a variety of subsystems designed to be the building blocks from which         sophisticated infrastructures for ubiquitous computing are assembled. Our experience shows that many of these building blocks         fit neatly into one of the five UbiqStack categories, each containing functionally-equivalent components. Effectively identifying         the best-fit &amp;#8220;Lego pieces&amp;#8221;, which in turn determines the composite functionality of the resulting infrastructure, is critical.         The selection process, however, is impeded by the lack of convention for labeling these classes of building blocks. The lack         of clarity with respect to what ready-made subsystems are available within each class often results in naive re-implementation         of ready-made components, monolithic and clumsy implementations, and implementations that impose non-standard interfaces onto         the applications above. This paper describes the UbiqStack classes of subsystems and explores each in light of the experience         gained over 2;years of active development of both ubiquitous computing applications and software infrastructures for their         deployment.      </content></document><document><year>2005</year><authors>Stina Nyl|er1 | Markus Bylund1  | Annika Waern1 </authors><title>Ubiquitous service access through adapted user interfaces on multiple devices</title><content>The Ubiquitous Interactor (UBI) addresses the problems of design and development that arise from services that need to be accessed from many different devices. In the UBI, a service can present itself with different user interfaces on different devices. This is done by a separation of the user&amp;#x2013;service interaction and presentation. The interaction is kept the same for all devices, and different presentation information is provided for different devices. This way, tailored user interfaces for many different devices can be created without multiplying the development and maintenance work. In this paper, we describe the design of the UBI, the system implementation, and two services implemented for the system: a calendar service and a stockbroker service.</content></document><document><year>2005</year><authors>Hideki Hayashi1 | Takahiro Hara1  | Shojiro Nishio1 </authors><title>Updated data dissemination methods for updating old replicas in ad hoc networks</title><content>In this paper, we propose two updated data dissemination methods to not only reduce the number of accesses to old replicas, but also to improve the data accessibility in ad hoc networks where data items are updated regularly. In the first method, when a mobile host updates a data item, it disseminates the updated data item after the flooding of with invalidation reports. In the second method, two newly connected mobile hosts disseminate updated data items with each other after the flooding with invalidation reports.</content></document><document><year>2005</year><authors>Anthony J. Saliba1 | Michael A. Beresford1 | Milosh Ivanovich1  | Paul Fitzpatrick1 </authors><title>User-perceived quality of service in wireless data networks      </title><content>For so long, the term quality of service (QoS) has been a pursuit area for network engineers trying to dimension wireless         networks to run in the most efficient way possible. Of late, there has been a trend reversal, looking at the user perceptions         of the network performance to decide where dimensioning can have the greatest impact. This paper demonstrates the importance         of defining the concept of user-perceived QoS and linking this to specific wireless data network parameters for some anticipated         valuable applications. It has been shown that a quantitative rating can be obtained for a variety of important factors in         the assessment of service quality, and mapped to specific values of multiple network parameters. We found QoS to be application-specific,         where various applications require different levels of network performance to satisfy users. The role of physical location         was also examined, investigating the influence of being indoors versus outdoors on the user perception of QoS.      </content></document><document><year>2005</year><authors>Stan Kurkovsky1  | Karthik Harihar1 </authors><title>Using ubiquitous computing in interactive mobile marketing      </title><content>Unique features of handheld devices, including their mobility, personalization and location-awareness engender new types of         applications for mobile commerce, such as mobile advertising. Mobile marketing and advertising applications deliver promotional         information to consumers based on their preferences and location. In this paper, we present SMMART, a context-aware, adaptive         and personalized m-commerce application designed to deliver targeted promotions to the users of mobile devices about the products         they like while guarding the users&amp;#8217; identity and protecting them from any unsolicited messages. Promotions distributed by         SMMART are personalized by performing intelligent matching of the user&amp;#8217;s shopping interests to current promotions available         at a retail site. SMMART can adapt to changing preferences of its user by inconspicuously monitoring his or her shopping habits.         We describe a fully functional prototype of SMMART built for Pocket PCs running Windows CE with .NET Compact Framework. This         paper also presents a study demonstrating end-user usability and economic viability of SMMART.      </content></document></documents>