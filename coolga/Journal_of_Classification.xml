<?xml version="1.0" encoding="UTF-8" standalone="no"?><documents><document><year>1999</year><authors>Abba M  Krieger  | Paul E  Green </authors><title>a generalized rand-index method for consensus clustering of separate partitions of the same data base </title><content>t;; clusters, based on j distinct, contributory partitions (or, equivalently, j polytomous attributes). we describe a new model/algorithm for implementing this objective. the method's objective function incorporates a modified rand measure, both in initial cluster selection and in subsequent refinement of the starting partition. the method is applied to both synthetic and real data. the performance of the proposed model is compared to latent class analysis of the same data set. </content></document><document><year>1999</year><authors>Vladimir Makarenkov  | Bruno Leclerc </authors><title>an algorithm for the fitting of a tree metric according to a weighted least-squares criterion </title><content>;;</content></document><document><year>1999</year><authors>Michael D  Lee </authors><title>an extraction and regularization approach to additive clustering </title><content>;;</content></document><document><year>1999</year><authors>Hiroshi Yadohisa | Akinobu Takeuchi  | Koichi Inada </authors><title>developing criteria for measuring space distortion in combinatorial cluster analysis and methods for controlling the distortion </title><content>;;</content></document><document><year>1999</year><authors>Lynette A  Hunt  | Kaye E  Basford </authors><title>fitting a mixture model to three-mode three-way data with categorical and continuous variables </title><content>;;</content></document><document><year>1999</year><authors>P  J  F  Groenen | W  J  Heiser  | J  J  Meulman </authors><title>global optimization in least-squares multidimensional scaling by distance smoothing </title><content>;;</content></document><document><year>1999</year><authors>Michael J  Brusco </authors><title>morph-based local-search heuristics for large-scale combinatorial data analysis </title><content>;;</content></document><document><year>1999</year><authors>J  C  Gower | J  J  Meulman  | G  M  Arnold </authors><title>nonmetric linear biplots </title><content>;;</content></document><document><year>1999</year><authors>L  Andries van der Ark | Peter G  M  van der Heijden  | Dirk Sikkel </authors><title>on the identifiability in the latent budget model </title><content>end-member model;;. a major drawback of the latent budget model is that, in general, the model is not identifiable, which complicates the interpretation of the model considerably. this paper studies the geometry and identifiability of the latent budget model. knowledge of the geometric structure of the model is used to specify an appropriate criterion to identify the model. the results are illustrated by an empirical data set. </content></document><document><year>1999</year><authors>Maurizio Vichi </authors><title>one-mode classification of a three-way data matrix </title><content>x;; is the automatic hierarchical classification of one mode (units or variables or occasions) of x on the basis of the other two. in this paper the case of omc of units according to variables and occasions is discussed. omc is the synthesis of a set of hierarchical classifications delta obtained from x; e.g., the omc of units is the consensus (synthesis) among the set of dendograms individually defined by clustering units on the basis of variables, separately for each given occasion of x. however, because delta is often formed by a large number of classifications, it may be unrealistic that a single synthesis is representative of the entire set. in this case, subsets of similar (homegeneous) dendograms may be found in delta so that a consensus representative of each subset may be identified. this paper proposes, partition and least squares consensus classifications analysis (parlscla) of a set of r hierarchical classifications delta. parlscla identifies the best least-squares partition of delta into m (1 &amp;lt;= m &amp;lt;= r) subsets of homogeneous dendograms and simultaneously detects the closest consensus classification (a median classification called least squares consensus dendogram (lscd) for each subset. parlscla is a generalization of the problem to find a least-squares consensus dendogram for delta. parlscla is formalized as a mixed-integer programming problem and solved with an iterative, two-step algorithm. the method proposed is applied to an empirical data set. </content></document><document><year>1999</year><authors>Peter M  Hooper </authors><title>reference point logistic classification </title><content>;;</content></document><document><year>1999</year><authors>F  James Rohlf </authors><title>shape statistics: procrustes superimpositions and tangent spaces </title><content>;;</content></document><document><year>1997</year><authors>Henk A  L  Kiers  </authors><title>a modification of the sindclus algorithm for fitting the adclus and indclus models </title><content>abstract;;the sindclus algorithm for fitting the adclus and indclus models deals with a parameter matrix that occurs twice in the model by considering the two occurrences as independent parameter matrices. this procedure has been justified empirically by the observation that upon convergence of the algorithm to the global optimum, the two independently treated parameter matrices turn out to be equal. in the present paper, results are presented that contradict this finding, and a modification of sindclus is presented which obviates the need for independently treating two occurrences of the same parameter matrix. </content></document><document><year>1997</year><authors>Akinori Okada   | Tadashi Imaizumi </authors><title>asymmetric multidimensional scaling of two-mode three-way proximities </title><content>abstract;;an asymmetric multidimensional scaling model and an associated nonmetric algorithm to analyze two-mode three-way proximities (object г— object г— source) are introduced. the model consists of a common object configuration and two kinds of weights, i.e., for both symmetry and asymmetry. in the common object configuration, each object is represented by a point and a circle (sphere, hypersphere) in a euclidean space. the common object configuration represents pairwise proximity relationships between pairs of objects for the &amp;#8216;group&amp;#8217; of all sources. each source has its own symmetry weight and a set of asymmetry weights. symmetry weights represent individual differences among sources of data in symmetric proximity relationships, and asymmetry weights represent individual differences among sources in asymmetric proximity relationships. the associated nonmetric algorithm, based on kruskal&amp;#8217;s (1964b) nonmetric multidimensional scaling algorithm, is an extension of the algorithm for the asymmetric multidimensional scaling of one mode two-way proximities developed earlier (okada and imaizumi 1987). as an illustrative example, we analyze intergenerational occupational mobility from 1955 to 1985 in japan among eight occupational categories. </content></document><document><year>1997</year><authors>Ana M  Pires  | JoГЈo A  Branco </authors><title>comparison of multinomial classification rules </title><content>;;</content></document><document><year>1997</year><authors>B  Monjardet |   </authors><title>concordance between two linear orders: the spearman and kendall coefficients revisited </title><content>abstract;;this paper discusses the two classic measures of concordance between two linear orders l and l&amp;#8242;, the kendall tau and the spearman rho, equivalently, the kendall and spearman distances between such orders. we give an expression for &amp;#961;(l,l&amp;#8242;)&amp;#8722;&amp;#964;(l,l&amp;#8242;) as a function of the parameters of the partial order l&amp;#8746;l&amp;#8242;, which allows the determination of extremal values for this difference and an investigation of when tau and rho are equal. this expression for &amp;#961;(l,l&amp;#8242;)&amp;#8722;&amp;#964;(l,l&amp;#8242;) is derived from a relation between the kendall and spearman distances between linear orders that is equivalent to both the guilbaud (1980) formula linking rho, tau, and a third coefficient sigma, and daniels&amp;#8217;s (1950) inequality. we also prove an apparently new monotonicity property of rho. in the conclusion we point out possible extensions and add general historical comments. </content></document><document><year>1997</year><authors>Tom A B  Snijders  | Krzysztof Nowicki </authors><title>estimation and prediction for stochastic blockmodels for graphs with latent block structure </title><content>a posteriori;; blockmodeling for graphs is proposed. the model assumes that the vertices of the graph are partitioned into two unknown blocks and that the probability of an edge between two vertices depends only on the blocks to which they belong. statistical procedures are derived for estimating the probabilities of edges and for predicting the block structure from observations of the edge pattern only. ml estimators can be computed using the em algorithm, but this strategy is practical only for small graphs. a bayesian estimator, based on the gibbs sampling, is proposed. this estimator is practical also for large graphs. when ml estimators are used, the block structure can be predicted based on predictive likelihood. when gibbs sampling is used, the block structure can be predicted from posterior predictive probabilities. a side result is that when the number of vertices tends to infinity while the probabilities remain constant, the block structure can be recovered correctly with probability tending to 1. </content></document><document><year>1997</year><authors>Jan de Leeuw  | Patrick J F  Groenen </authors><title>inverse multidimensional scaling </title><content>;;</content></document><document><year>1997</year><authors>Yoshio Takane   | Henk A  L  Kiers </authors><title>latent class dedicom </title><content>abstract;;a probabilistic dedicom model was proposed for mobility tables. the model attempts to explain observed transition probabilities by a latent mobility table and a set of transition probabilities from latent classes to observed classes. the model captures asymmetry in observed mobility tables by asymmetric latent mobility tables. it may be viewed as a special case of both the latent class model and dedicom with special constraints. a maximum penalized likelihood (mpl) method was developed for parameter estimation. the em algorithm was adapted for the mpl estimation. two examples were given to illustrate the proposed method. </content></document><document><year>1997</year><authors>Alain GuГ©noche </authors><title>order distance associated with a hierarchy </title><content>;;</content></document><document><year>1997</year><authors>Andrew R  Webb  </authors><title>radial basis functions for exploratory data analysis: an iterative majorisation approach for minkowski distances based on multidimensional scaling </title><content>abstract;;this paper considers the use of radial basis functions for exploratory data analysis. these are used to model a transformation from a high-dimensional observation space to a low-dimensional one. the parameters of the model are determined by optimising a loss function defined to be the stress function in multidimensional scaling. the metric for the low-dimensional space is taken to be the minkowski metric with order parameter 1&amp;lt;-p&amp;lt;-2. a scheme based on iterative majorisation is proposed. </content></document><document><year>1997</year><authors>Victor Chepoi   | Bernard Fichet </authors><title>recognition of robinsonian dissimilarities </title><content>abstract;;we present an o(n 3)-time, o(n 2)-space algorithm to test whether a dissimilarity d on an n-object set x is robinsonian, i.e., x admits an ordering such that i&amp;#8804;j&amp;#8804;k implies that d(x i,xk)&amp;#8805;max {d(xi,xj),d(xj,xk)}. </content></document><document><year>1997</year><authors>Charles J  Alpert  | Andrew B  Kahng </authors><title>splitting an ordering into a partition to minimize diameter </title><content>k;; consisting of k clusters, with k &amp;gt; 2. bottom-up agglomerative approaches are also commonly used to construct partitions, and we discuss these in terms of worst-case performance for metric data sets. our main contribution derives from a new restricted partition formulation that requires each cluster to be an interval of a given ordering of the objects being clustered. dynamic programming can optimally split such an ordering into a partition pk for a large class of objectives that includes min-diameter. we explore a variety of ordering heuristics and show that our algorithm, when combined with an appropriate ordering heuristic, outperforms traditional algorithms on both random and non-random data sets. </content></document><document><year>1997</year><authors>Kamel Jedidi | Harsharanjeet S  Jagpal  | Wayne S  DeSarbo </authors><title>stemm: a general finite mixture structural equation model </title><content>;;</content></document><document><year>1997</year><authors>C M  Cuadras | J  Fortiana  | F  Oliva </authors><title>the proximity of an individual to a population with applications in discriminant analysis </title><content>;;</content></document><document><year>1997</year><authors>F B  Baulieu </authors><title>two variant axiom systems for presence/absence based dissimilarity coefficients </title><content>;;</content></document><document><year>2009</year><authors>J  Douglas Carroll  | James E  Corter  </authors><title>a graph-theoretic method for organizing overlapping clusters into trees, multiple trees, or extended trees </title><content>abstract;;a clustering that consists of a nested set of clusters may be represented graphically by a tree. in contrast, a clustering that includes non-nested overlapping clusters (sometimes termed a &amp;#8220;nonhierarchical&amp;#8221; clustering) cannot be represented by a tree. graphical representations of such non-nested overlapping clusterings are usually complex and difficult to interpret. carroll and pruzansky (1975, 1980) suggested representing non-nested clusterings with multiple ultrametric or additive trees. corter and tversky (1986) introduced the extended tree (extree) model, which represents a non-nested structure as a tree plus overlapping clusters that are represented by marked segments in the tree. we show here that the problem of finding a nested (i.e., tree-structured) set of clusters in an overlapping clustering can be reformulated as the problem of finding a clique in a graph. thus, clique-finding algorithms can be used to identify sets of clusters in the solution that can be represented by trees. this formulation provides a means of automatically constructing a multiple tree or extended tree representation of any non-nested clustering. the method, called &amp;#8220;clustrees&amp;#8221;, is applied to several non-nested overlapping clusterings derived using the mapclus program (arabie and carroll 1980). </content></document><document><year>2009</year><authors>Guoqi Qian  | Yuehua Wu   | Qing Shao  </authors><title>a procedure for estimating the number of clusters in logistic regression clustering </title><content>abstract;;this paper studies the problem of estimating the number of clusters in the context of logistic regression clustering. the classification likelihood approach is employed to tackle this problem. a model-selection based criterion for selecting the number of logistic curves is proposed and its asymptotic property is also considered. the small sample performance of the proposed criterion is studied by monto carlo simulation. in addition, a real data example is presented. </content></document><document><year>2009</year><authors>Boris Mirkin |  |  | Phipps Arabie  | Lawrence J  Hubert </authors><title>additive two-mode clustering: the error-variance approach revisited </title><content>abstract;;the additive clustering approach is applied to the problem of two-mode clustering and compared with the recent error-variance approach of eckes and orlik (1993). although the schemes of the computational algorithms look very similar in both of the approaches, the additive clustering has been shown to have several advantages. specifically, two technical limitations of the error-variance approach (see eckes and orlik 1993, p. 71) have been overcome in the framework of the additive clustering. </content></document><document><year>2009</year><authors>VГ©ronique Campbell  | Pierre Legendre  | FranГ§ois-Joseph Lapointe </authors><title>assessing congruence among ultrametric distance matrices </title><content>abstract;;recently, a test of congruence among distance matrices (cadm) has been developed. the null hypothesis is the incongruence among all data matrices. it has been shown that cadm has a correct type i error rate and good power when applied to independently-generated distance matrices. in this study, we investigate the suitability of cadm to compare ultrametric distance matrices. we tested the type i error rate and power of cadm with randomly generated dendrograms and their associated ultrametric distance matrices. we show that the test has correct type i error rates and good power. to obtain the significance level of the statistic, a single (as in the mantel test) or a double (as in the double permutation test, dpt) permutation procedure was used. the power of cadm remained identical when the two permutation methods were compared. this study clearly demonstrates that cadm can be used to determine whether different dendrograms convey congruent information. </content></document><document><year>2009</year><authors>Cristina Rueda  | Miguel A  FernГЎndez   | Bonifacio Salvador  </authors><title>bayes discriminant rules with ordered predictors </title><content>abstract;;we propose and discuss improved bayes rules to discriminate between two populations using ordered predictors. to address the problem we propose an alternative formulation using a latent space that allows to introduce the information about the order in the theoretical rules. the rules are first defined when the marginal densities are fully known and then under normality when the parameters are unknown and training samples are available. several numerical examples and simulations in the paper illustrate the methodology and show that the new rules handle the information appropriately. we compare the new rules with the classical bayes and fisher rules in these examples and we show that the misclassification probability is smaller for the new rules. the method is also applied to data from a diabetes study where we again show that the new rules improve over the usual fisher rule. </content></document><document><year>2009</year><authors>Juan Manuel Vilar  | JosГ© Antonio Vilar   | Sonia PГ©rtega  </authors><title>classifying time series data: a nonparametric approach </title><content>abstract;;a general nonparametric approach to identify similarities in a set of simultaneously observed time series is proposed. the trends are estimated via local polynomial regression and classified according to standard clustering procedures. the equality of the trends is checked using several nonparametric test statistics whose asymptotic distributions are approximated by a bootstrap procedure. once the estimated trends are removed from the model, the residual series are grouped by means of a nonparametric cluster method specifically designed for time series. such a method is based on a disparity measure between local linear smoothers of the spectra of the series. the performance of the proposed methodology is illustrated by means of its application to a particular financial data example. the dependence of the observations is a crucial factor in this work and is taken into account throughout the study. </content></document><document><year>2009</year><authors>FranГ§ois-Joseph Lapointe  | Pierre Legendre </authors><title>comparison tests for dendrograms: a comparative evaluation </title><content>abstract;;classifications are generally pictured in the form of hierarchical trees, also called dendrograms. a dendrogram is the graphical representation of an ultrametric (=cophenetic) matrix; so dendrograms can be compared to one another by comparing their cophenetic matrices. three methods used in testing the correlation between matrices corresponding to dendrograms are evaluated. the three permutational procedures make use of different aspects of the information to compare dendrograms: the mantel procedure permutes label positions only; the binary tree methods randomize the topology as well; the double-permutation procedure is based on all the information included in a dendrogram, that is: topology, label positions, and cluster heights. theoretical and empirical investigations of these methods are carried out to evaluate their relative performance. simulations show that the mantel test is too conservative when applied to the comparison of dendrograms; the methods of binary tree comparisons do slightly better; only the doublepermutation test provides unbiased type i error. </content></document><document><year>2009</year><authors>Michael Greenacre   | Paul Lewi </authors><title>distributional equivalence and subcompositional coherence in the analysis of compositional data, contingency tables and ratio-scale measurements </title><content>abstract;;we consider two fundamental properties in the analysis of two-way tables of positive data: the principle of distributional equivalence, one of the cornerstones of correspondence analysis of contingency tables, and the principle of subcompositional coherence, which forms the basis of compositional data analysis. for an analysis to be subcompositionally coherent, it suffices to analyze the ratios of the data values. a common approach to dimension reduction in compositional data analysis is to perform principal component analysis on the logarithms of ratios, but this method does not obey the principle of distributional equivalence. we show that by introducing weights for the rows and columns, the method achieves this desirable property and can be applied to a wider class of methods. this weighted log-ratio analysis is theoretically equivalent to &amp;#8220;spectral mapping&amp;#8221;, a multivariate method developed almost 30;years ago for displaying ratio-scale data from biological activity spectra. the close relationship between spectral mapping and correspondence analysis is also explained, as well as their connection with association modeling. the weighted log-ratio methodology is used here to visualize frequency data in linguistics and chemical compositional data in archeology. </content></document><document><year>2009</year><authors>Matthijs J  Warrens  </authors><title>k-adic similarity coefficients for binary (presence/absence) data </title><content>abstract;; k-adic formulations (for groups of objects of size k) of a variety of 2-adic similarity coefficients (for pairs of objects) for binary (presence/absence) data are presented. the formulations are not functions of 2-adic similarity coefficients. instead, the main objective of the the paper is to present k-adic formulations that reflect certain basic characteristics of, and have a similar interpretation as, their 2-adic versions. two major classes are distinguished. the first class is referred to as bennani-heiser similarity coefficients, which contains all coefficients that can be defined using just the matches, the number of attributes that are present and that are absent in k objects, and the total number of attributes. the coefficients in the second class can be formulated as functions of dice&amp;#8217;s association indices. </content></document><document><year>2009</year><authors>Bruno Leclerc </authors><title>minimum spanning trees for tree metrics: abridgements and adjustments </title><content>abstract;;two properties of tree metrics are already known in the literature: tree metrics on a setx withn elements have 2n&amp;#8722;3 degrees of freedom; a tree metric has robinson form with regard to its minimum spanning tree (mst), or to any such mst if several of them exist. starting from these results, we prove that a tree metrict is entirely defined by its restriction to some setb of 2n&amp;#8722;3 entries. this set is easily determined from the table oft and includes then&amp;#8722;1 entries of an mst. a fast method for the adjustment of a tree metric to any given metricd is then obtained. this method extends to dissimilarities. </content></document><document><year>2009</year><authors>Joost van Rosmalen  | Patrick J  F  Groenen | Javier Trejos  | William Castillo </authors><title>optimization strategies for two-mode partitioning </title><content>abstract;;two-mode partitioning is a relatively new form of clustering that clusters both rows and columns of a data matrix. in this paper, we consider deterministic two-mode partitioning methods in which a criterion similar to k-means is optimized. a variety of optimization methods have been proposed for this type of problem. however, it is still unclear which method should be used, as various methods may lead to non-global optima. this paper reviews and compares several optimization methods for two-mode partitioning. several known methods are discussed, and a new fuzzy steps method is introduced. the fuzzy steps method is based on the fuzzy c-means algorithm of bezdek (1981) and the fuzzy steps approach of heiser and groenen (1997) and groenen and jajuga (2001). the performances of all methods are compared in a large simulation study. in our simulations, a two-mode k-means optimization method most often gives the best results. finally, an empirical data set is used to give a practical example of two-mode partitioning. </content></document><document><year>2009</year><authors>Alessio Farcomeni  </authors><title>robust double clustering: a method based on alternating concentration steps </title><content>abstract;;we propose two algorithms for robust two-mode partitioning of a data matrix in the presence of outliers. first we extend the robust k-means procedure to the case of biclustering, then we slightly relax the definition of outlier and propose a more flexible and parsimonious strategy, which anyway is inherently less robust. we discuss the breakdown properties of the algorithms, and illustrate the methods with simulations and three real examples. </content></document><document><year>2009</year><authors>Eric J  Beh   | Luigi D       Ambra  </authors><title>some interpretative tools for non-symmetrical correspondence analysis </title><content>abstract;;non-symmetrical correspondence analysis (nsca) is a very practical statistical technique for the identification of the structure of association between asymmetrically related categorical variables forming a contingency table. this paper considers some tools that can be used to numerically and graphically explore in detail the association between these variables and include the use of confidence regions, the establishment of the link between nsca and the analysis of variance of categorical variables, and the effect of imposing linear constraints on a variable. </content></document><document><year>2009</year><authors>Donatella Vicari   | Maurizio Vichi  </authors><title>structural classification analysis of three-way dissimilarity data </title><content>abstract;;the paper presents a methodology for classifying three-way dissimilarity data, which are reconstructed by a small number of consensus classifications of the objects each defined by a sum of two order constrained distance matrices, so as to identify both a partition and an indexed hierarchy. specifically, the dissimilarity matrices are partitioned in homogeneous classes and, within each class, a partition and an indexed hierarchy are simultaneously fitted. </content></document><document><year>2009</year><authors>F  Murtagh  | M  HernГЎndez-Pajares </authors><title>the kohonen self-organizing map method: an assessment </title><content>abstract;;the &amp;#8220;self-organizing map&amp;#8221; method, due to kohonen, is a well-known neural network method. it is closely related to cluster analysis (partitioning) and other methods of data analysis. in this article, we explore some of these close relationships. a number of properties of the technique are discussed. comparisons with various methods of data analysis (principal components analysis, k-means clustering, and others) are presented. </content></document><document><year>2009</year><authors>S  Joly  | G  Le CalvГ© </authors><title>three-way distances </title><content>abstract;;in this paper, dissimilarity relations are defined on triples rather than on dyads. we give a definition of a three-way distance analogous to that of the ordinary two-way distance. it is shown, as a straightforward generalization, that it is possible to define three-way ultrametric, three-way star, and three-way euclidean distances. special attention is paid to a model called the semi-perimeter model. we construct new methods analogous to the existing ones for ordinary distances, for example: principal coordinates analysis, the generalized prim (1957) algorithm, hierarchical cluster analysis. </content></document><document><year>2008</year><authors>Michael J  Brusco   | Douglas Steinley  </authors><title>a binary integer program to maximize the agreement between partitions </title><content>abstract;;this research note focuses on a problem where the cluster sizes for two partitions of the same object set are assumed known; however, the actual assignments of objects to clusters are unknown for one or both partitions. the objective is to find a contingency table that produces maximum possible agreement between the two partitions, subject to constraints that the row and column marginal frequencies for the table correspond exactly to the cluster sizes for the partitions. this problem was described by h. messatfa (journal of classification, 1992, pp. 5&amp;#8211;15), who provided a heuristic procedure based on the linear transportation problem. we present an exact solution procedure using binary integer programming. we demonstrate that our proposed method efficiently obtains optimal solutions for problems of practical size. </content></document><document><year>2008</year><authors>Fred R  McMorris   | Robert C  Powers  </authors><title>a characterization of majority rule for hierarchies </title><content>abstract;;the majority rule has been a popular method for producing a consensus classification from several different classifications, when the classifications are all on the same set of objects and are structured as hierarchies. in this note, a new axiomatic characterization is proved for this consensus method on hierarchies. </content></document><document><year>2008</year><authors>Erik Meijer |    | Jelmer Y  Ypma </authors><title>a simple identification proof for a mixture of two univariate normal distributions </title><content>abstract;;a simple proof of the identification of a mixture of two univariate normal distributions is given. the proof is based on the equivalence of local identification with positive definiteness of the information matrix and the equivalence of the latter to a condition on the score vector that is easily checked for this model. two extensions using the same line of proof are also given. </content></document><document><year>2008</year><authors>Matthijs J  Warrens  </authors><title>bounds of resemblance measures for binary (presence/absence) variables </title><content>abstract;;bounds of association coefficients for binary variables are derived using the arithmetic-geometric-harmonic mean inequality. more precisely, it is shown which presence/absence coefficients are bounds with respect to each other. using the new bounds it is investigated whether a coefficient is in general closer to either its upper or its lower bound. </content></document><document><year>2008</year><authors>Nedret Billor | Asheber Abebe  | Asuman Turkmen  | Sai V  Nudurupati </authors><title>classification based on depth transvariations </title><content>abstract;;suppose y, a d-dimensional (d&amp;#8201;&amp;#8805;&amp;#8201;1) vector, is drawn from a mixture of k (k&amp;#8201;&amp;#8805;&amp;#8201;2) populations, given by &amp;#8719;1, &amp;#8719;2,&amp;#8230;,&amp;#8719; k . we wish to identify the population that is the most likely source of the point y. to solve this classification problem many classification rules have been proposed in the literature. in this study, a new nonparametric classifier based on the transvariation probabilities of data depth is proposed. we compare the performance of the newly proposed nonparametric classifier with classical and maximum depth classifiers using some benchmark and simulated data sets. </content></document><document><year>2008</year><authors>Patrick Erik Bradley  </authors><title>degenerating families of dendrograms </title><content>abstract;;dendrograms used in data analysis are ultrametric spaces, hence objects of nonarchimedean geometry. it is known that there exist p-adic representations of dendrograms. completed by a point at infinity, they can be viewed as subtrees of the bruhat-tits tree associated to the p-adic projective line. the implications are that certain moduli spaces known in algebraic geometry are in fact p-adic parameter spaces of dendrograms, and stochastic classification can also be handled within this framework. at the end, we calculate the topology of the hidden part of a dendrogram. </content></document><document><year>2008</year><authors>Bettina GrГјn   | Friedrich Leisch  </authors><title>identifiability of finite mixtures of multinomial logit models with varying and fixed effects </title><content>abstract;;unique parametrizations of models are very important for parameter interpretation and consistency of estimators. in this paper we analyze the identifiability of a general class of finite mixtures of multinomial logits with varying and fixed effects, which includes the popular multinomial logit and conditional logit models. the application of the general identifiability conditions is demonstrated on several important special cases and relations to previously established results are discussed. the main results are illustrated with a simulation study using artificial data and a marketing dataset of brand choices. </content></document><document><year>2008</year><authors>Adrien Jamain   | David J  H|  </authors><title>mining supervised classification performance studies: a meta-analytic investigation </title><content>abstract;;there have been many comparative studies of classification methods in which real datasets are used as a gauge to assess the relative performance of the methods. since these comparisons often yield inconclusive or limited results on how methods perform, it is often believed that a broader approach combining these studies would shed some light on this difficult question. this paper describes such an attempt: we have sampled the available literature and created a dataset of 5807 classification results. we show that one of the possible ways to analyze the resulting data is an overall assessment of the classification methods, and we present methods for that particular aim. the merits and demerits of such an approach are discussed, and conclusions are drawn which may assist future research: we argue that the current state of the literature hardly allows large-scale investigations. </content></document><document><year>2008</year><authors>George Kokolakis   | Dimitris Fouskakis  </authors><title>on the discrepancy measures for the optimal equal probability partitioning in bayesian multivariate micro-aggregation </title><content>abstract;;data holders, such as statistical institutions and financial organizations, have a very serious and demanding task when producing data for official and public use. it&amp;#8217;s about controlling the risk of identity disclosure and protecting sensitive information when they communicate data-sets among themselves, to governmental agencies and to the public. one of the techniques applied is that of micro-aggregation. in a bayesian setting, micro-aggregation can be viewed as the optimal partitioning of the original data-set based on the minimization of an appropriate measure of discrepancy, or distance, between two posterior distributions, one of which is conditional on the original data-set and the other conditional on the aggregated data-set. assuming d-variate normal data-sets and using several measures of discrepancy, it is shown that the asymptotically optimal equal probability m-partition of , with m 1/d &amp;#8712; , is the convex one which is provided by hypercubes whose sides are formed by hyperplanes perpendicular to the canonical axes, no matter which discrepancy measure has been used. on the basis of the above result, a method that produces a sub-optimal partition with a very small computational cost is presented. </content></document><document><year>2008</year><authors>Matthijs J  Warrens  </authors><title>on the equivalence of cohen&amp;#8217;s kappa and the hubert-arabie adjusted rand index </title><content>abstract;;it is shown that one can calculate the hubert-arabie adjusted rand index by first forming the fourfold contingency table counting the number of pairs of objects that were placed in the same cluster in both partitions, in the same cluster in one partition but in different clusters in the other partition, and in different clusters in both, and then computing cohen&amp;#8217;s &amp;#954; on this fourfold table. </content></document><document><year>2008</year><authors>Matthijs J  Warrens  </authors><title>on the indeterminacy of resemblance measures for binary (presence/absence) data </title><content>abstract;;many similarity coefficients for binary data are defined as fractions. for certain resemblance measures the denominator may become zero. if the denominator is zero the value of the coefficient is indeterminate. it is shown that the seriousness of the indeterminacy problem differs with the resemblance measures. following batagelj and bren (1995) we remove the indeterminacies by defining appropriate values in critical cases. </content></document><document><year>2008</year><authors>Adi Ben-Israel   | Cem Iyigun  </authors><title>probabilistic d-clustering </title><content>abstract;;we present a new iterative method for probabilistic clustering of data. given clusters, their centers and the distances of data points from these centers, the probability of cluster membership at any point is assumed inversely proportional to the distance from (the center of) the cluster in question. this assumption is our working principle. the method is a generalization, to several centers, of theweiszfeld method for solving the fermat&amp;#8211;weber location problem. at each iteration, the distances (euclidean, mahalanobis, etc.) from the cluster centers are computed for all data points, and the centers are updated as convex combinations of these points, with weights determined by the above principle. computations stop when the centers stop moving. </content></document><document><year>2008</year><authors>Jan Schepers |   | Eva Ceulemans  | Iven Van Mechelen </authors><title>selecting among multi-mode partitioning models of different complexities: a comparison of four model selection criteria </title><content>abstract;;multi-mode partitioning models for n-way n-mode data reduce each of the n modes in the data to a small number of clusters that are mutually exclusive. given a specific n-mode data set, one may wonder which multi-mode partitioning model (i.e., with which numbers of clusters for each mode) yields the most useful description of this data set and should therefore be selected. in this paper, we address this issue by investigating four possible model selection heuristics: multi-mode extensions of calinski and harabasz&amp;#8217;s (1974) and kaufman and rousseeuw&amp;#8217;s (1990) indices for one-mode k-means clustering and multi-mode partitioning versions of timmerman and kiers&amp;#8217;s (2000) diffit and ceulemans and kiers&amp;#8217;s (2006) numerical convex hull based model selection heuristic for three-mode principal component analysis. the performance of these four heuristics is systematically compared in a simulation study, which shows that the diffit and numerical convex hull heuristics perform satisfactory in the two-mode partitioning case and very good in the threemode partitioning case. </content></document><document><year>2008</year><authors>Alberto FernГЎndez  | Sergio GГіmez |   </authors><title>solving non-uniqueness in agglomerative hierarchical clustering using multidendrograms </title><content>abstract;;in agglomerative hierarchical clustering, pair-group methods suffer from a problem of non-uniqueness when two or more distances between different clusters coincide during the amalgamation process. the traditional approach for solving this drawback has been to take any arbitrary criterion in order to break ties between distances, which results in different hierarchical classifications depending on the criterion followed. in this article we propose a variable-group algorithm that consists in grouping more than two clusters at the same time when ties occur. we give a tree representation for the results of the algorithm, which we call a multidendrogram, as well as a generalization of the lance andwilliams&amp;#8217; formula which enables the implementation of the algorithm in a recursive way. </content></document><document><year>2008</year><authors>Alain Hertz   | Sacha Varone  </authors><title>the metric cutpoint partition problem </title><content>abstract;;let g&amp;#8201;=&amp;#8201;(v, e,w) be a graph with vertex and edge sets v and e, respectively, and w: e &amp;#8594; a function which assigns a positive weight or length to each edge of g. g is called a realization of a finite metric space (m, d), with m&amp;#8201;=&amp;#8201;{1, ..., n} if and only if {1, ..., n} &amp;#8838; v and d(i, j) is equal to the length of the shortest chain linking i and j in g &amp;#8704;i, j&amp;#8201;=&amp;#8201;1, ..., n. a realization g of (m, d), is called optimal if the sum of its weights is minimal among all the realizations of (m, d). a cutpoint in a graph g is a vertex whose removal strictly increases the number of connected components of g. the metric cutpoint partition problem is to determine if a finite metric space (m, d) has an optimal realization containing a cutpoint. we prove in this paper that this problem is polynomially solvable. we also describe an algorithm that constructs an optimal realization of (m, d) from optimal realizations of subspaces that do not contain any cutpoint. </content></document><document><year>2001</year><authors>FranГ§ois-Joseph Lapointe  | Theodore Garl|| Jr  </authors><title>a generalized permutation model for the analysis of cross-species data </title><content>;;</content></document><document><year>2001</year><authors>Michael J  Brusco </authors><title>a simulated annealing heuristic for unidimensional and multidimensional (city-block) scaling of symmetric proximity matrices </title><content>;;</content></document><document><year>2001</year><authors>Iwin Leenen  | Iven Van Mechelen </authors><title>an evaluation of two algorithms for hierarchical classes analysis </title><content>k;;. in this procedure, a least-squares loss function in terms of discrepancies between d and m is minimized. the present paper describes the original hierarchical classes algorithm proposed by de boeck and rosenberg (1988), which is based on an alternating greedy heuristic, and proposes a new algorithm, based on an alternating branch-and-bound procedure. an extensive simulation study is reported in which both algorithms are evaluated and compared according to goodness-of-fit to the data and goodness-of-recovery of the underlying true structure. furthermore, three heuristics for selecting models of different ranks for a given d are presented and compared. the simulation results show that the new algorithm yields models with slightly higher goodness-of-fit and goodness-of-recovery values. </content></document><document><year>2001</year><authors>Thomas J  Smith </authors><title>constructing ultrametric and additive trees based on the l 1 norm </title><content>l;; 1) criterion. examples of ultrametric and additive trees fitted to two extant data sets are given, plus a monte carlo analysis to assess the impact of both typical data error and extreme values on fitted trees. solutions are compared to the least-squares (l 2) approach of hubert and arabie (1995a), with results indicating that (with these data) the l 1 and l 2 optimization strategies perform very similarly. a number of observations are made concerning possible uses of an l 1 approach, the nature and number of identified locally optimal solutions, and metric recovery differences between ultrametrics and additive trees. </content></document><document><year>2001</year><authors>Lynette A  Hunt  | Kaye E  Basford </authors><title>fitting a mixture model to three-mode three-way data with missing information </title><content>;;</content></document><document><year>2001</year><authors>Anil Chaturvedi | Paul E  Green  | J  Douglas Caroll </authors><title>k-modes clustering </title><content>0;; norm (defined as the limit of an lp norm as p approaches zero). in monte carlo simulations, both k-modes and the latent class procedures (e.g., goodman 1974) performed with equal efficiency in recovering a known underlying cluster structure. however, k-modes is an order of magnitude faster than the latent class procedure in speed and suffers from fewer problems of local optima than do the latent class procedures. for data sets involving a large number of categorical variables, latent class procedures become computationally extremly slow and hence infeasible. </content></document><document><year>2001</year><authors>Herbert K  H  Lee </authors><title>model selection for neural network classification </title><content>;;</content></document><document><year>2001</year><authors>Jean-Pierre BarthГ©lemy  | FranГ§ois Brucker </authors><title>np-hard approximation problems in overlapping clustering </title><content>lp ;;-norm (p &amp;lt; &amp;#8734;). these problems also correspond to the approximation by a strongly robinson dissimilarity or by a dissimilarity fulfilling the four-point inequality (bandelt 1992; diatta and fichet 1994). the results are extended to circular strongly robinson dissimilarities, indexed k-hierarchies (jardine and sibson 1971, pp. 65-71), and to proper dissimilarities satisfying the bertrand and janowitz (k + 2)-point inequality (bertrand and janowitz 1999). unidimensional scaling (linear or circular) is reinterpreted as a clustering problem and its hardness is established, but only for the l 1 norm. </content></document><document><year>2001</year><authors>Vladimir Makarenkov  | Pierre Legendre </authors><title>optimal variable weighting for ultrametric and additive trees and k-means partitioning: methods and software </title><content>k;;-means partitioning. we also describe some new features and improvements to the algorithm proposed by de soete. monte carlo simulations have been conducted using different error conditions. in all cases (i.e., ultrametric or additive trees, or k-means partitioning), the simulation results indicate that the optimal weighting procedure should be used for analyzing data containing noisy variables that do not contribute relevant information to the classification structure. however, if the data involve error-perturbed variables that are relevant to the classification or outliers, it seems better to cluster or partition the entities by using variables with equal weights. a new computer program, ovw, which is available to researchers as freeware, implements improved algorithms for optimal variable weighting for ultrametric and additive tree clustering, and includes a new algorithm for optimal variable weighting for k-means partitioning. </content></document><document><year>2001</year><authors>Peter M  Hooper </authors><title>reference point logistic regression and the identification of dna functional sites </title><content>;;</content></document><document><year>2006</year><authors>Jos M F  Ten Berge   | Henk A L  Kiers  </authors><title>a comparison of two methods for fitting the indclus model </title><content>abstract;;chaturvedi and carroll have proposed the sindclus method for fitting the indclus model. it is based on splitting the two appearances of the cluster matrix in the least squares fit function and relying on convergence to a solution where both cluster matrices coincide. kiers has proposed an alternative method which preserves equality of the cluster matrices throughout. this paper shows that the latter method is generally to be preferred. however, because the method has a serious local minimum problem, alternative approaches should be contemplated. </content></document><document><year>2006</year><authors>Luis Angel Garcia-Escudero   | Alfonso Gordaliza  </authors><title>a proposal for robust curve clustering </title><content>functional data sets appear in many areas of science. although each data point may be seen as a large finite-dimensional vector it is preferable to think of them as functions, and many classical multivariate techniques have been generalized for this kind of data. a widely used technique for dealing with functional data is to choose a finite-dimensional basis and find the best projection of each curve onto this basis. therefore, given a functional basis, an approach for doing curve clustering relies on applying the k-means methodology to the fitted basis coefficients corresponding to all the curves in the data set. unfortunately, a serious drawback follows from the lack of robustness of k-means. trimmed k-means clustering (cuesta-albertos, gordaliza, and matran 1997) provides a robust alternative to the use of k-means and, consequently, it may be successfully used in this functional framework. the proposed approach will be exemplified by considering cubic b-splines bases, but other bases can be applied analogously depending on the application at hand. </content></document><document><year>2006</year><authors>Didier Fraix-Burnet  | Philippe Choler  | Emmanuel J P  Douzery   | Anne Verhamme  </authors><title>astrocladistics: a phylogenetic analysis of galaxy evolution i. character evolutions and galaxy histories </title><content>abstract;;this series of papers is intended to present astrocladistics in some detail and evaluate this methodology in reconstructing phylogenies of galaxies. being based on the evolution of all the characters describing galaxies, it is an objective way of understanding galaxy diversity through evolutionary relationships. in this first paper, we present the basic steps of a cladistic analysis and show both theoretically and practically that it can be applied to galaxies. for illustration, we use a sample of 50 simulated galaxies taken from the galics database, which are described by 91 observables (dynamics, masses and luminosities). these 50 simulated galaxies are indeed 10 different galaxies taken at 5 cosmological epochs, and they are free of merger events. the astrocladistic analysis easily reconstructs the true chronology of evolution relationships within this sample. it also demonstrates that burst characters are not relevant for galaxy evolution as a whole. a companion paper is devoted to the formalization of the concepts of formation and diversification in galaxy evolution. </content></document><document><year>2006</year><authors>Didier Fraix-Burnet  | Philippe Choler  | Emmanuel J P  Douzery   | Anne Verhamme  </authors><title>astrocladistics: a phylogenetic analysis of galaxy evolution ii. formation and diversification of galaxies </title><content>abstract;;this series of papers is intended to evaluate astrocladistics in reconstructing phylogenies of galaxies. the objective of this second paper is to formalize the concept of galaxy formation and to identify the processes of diversification. we show that galaxy diversity can be expected to organize itself in a hierarchy. in order to better understand the role of mergers, we have selected a sample of 43 galaxies from the galics database built from simulations with a hybrid model for galaxy formation studies. these simulated galaxies, described by 119 characters and considered as representing still undefined classes, have experienced different numbers of merger events during evolution. our cladistic analysis yields a robust tree that proves the existence of a hierarchy. mergers, like interactions (not taken into account in the galics simulations), are probably a strong driver for galaxy diversification. our result shows that mergers participate in a branching type of evolution, but do not seem to play the role of an evolutionary clock. </content></document><document><year>2006</year><authors>Anil Chaturvedi   | J  Douglas Carroll  </authors><title>cluscale ("clustering and multidimensional scal[e]ing"): a three-way hybrid model incorporating overlapping clustering and multidimensional scaling structure </title><content>abstract;;traditional techniques of perceptual mapping hypothesize that stimuli are differentiated in a common perceptual space of quantitative attributes. this paper enhances traditional perceptual mapping techniques such as multidimensional scaling (mds) which assume only continuously valued dimensions by presenting a model and methodology called cluscale for capturing stimulus differentiation due to perceptions that are qualitative, in addition to quantitative or continuously varying perceptual attributes or dimensions. it provides models and ols parameter estimation procedures for both a two-way and a three-way version of this general model. since the two-way version of the model and method has already been discussed by chaturvedi and carroll (2000), and a stochastic variant discussed by navarro and lee (2003), we shall deal in this paper almost entirely with the three-way version of this model. we recommend the use of the three-way approach over the two-way approach, since the three-way approach both accounts for and takes advantage of the heterogeneity in subjects&amp;#8217; perceptions of stimuli to provide maximal information; i.e., it explicitly deals with individual differences among subjects. </content></document><document><year>2006</year><authors>Wojtek J  Krzanowski  | Trevor C  Bailey | Derek Partridge | Jonathan E  Fieldsend | Richard M  Everson  | Vitaly Schetinin </authors><title>confidence in classification: a bayesian approach </title><content>abstract;;bayesian classification is currently of considerable interest. it provides a strategy for eliminating the uncertainty associated with a particular choice of classifiermodel parameters, and is the optimal decision-theoretic choice under certain circumstances when there is no single &amp;#8220;true&amp;#8221; classifier for a given data set. modern computing capabilities can easily support the markov chain monte carlo sampling that is necessary to carry out the calculations involved, but the information available in these samples is not at present being fully utilised. we show how it can be allied to known results concerning the &amp;#8220;reject option&amp;#8221; in order to produce an assessment of the confidence that can be ascribed to particular classifications, and how these confidence measures can be used to compare the performances of classifiers. incorporating these confidence measures can alter the apparent ranking of classifiers as given by straightforward success or error rates. several possible methods for obtaining confidence assessments are described, and compared on a range of data sets using the bayesian probabilistic nearest-neighbour classifier. </content></document><document><year>2006</year><authors>Weiliang Qiu   | Harry Joe </authors><title>generation of random clusters with specified degree of separation </title><content>abstract;;we propose a random cluster generation algorithm that has the desired features: (1) the population degree of separation between clusters and the nearest neighboring clusters can be set to a specified value, based on a separation index; (2) no constraint is imposed on the isolation among clusters in each dimension; (3) the covariance matrices correspond to different shapes, diameters and orientations; (4) the full cluster structures generally could not be detected simply from pair-wise scatterplots of variables; (5) noisy variables and outliers can be imposed to make the cluster structures harder to be recovered. this algorithm is an improvement on the method used in milligan (1985). </content></document><document><year>2006</year><authors>Irene Charon  | Lucile Denoeud  | Alain Guenoche   | Olivier Hudry  </authors><title>maximum transfer distance between partitions </title><content>abstract;;in this paper, we study a distance defined over the partitions of a finite set. given two partitions p and q, this distance is defined as the minimum number of transfers of an element from one class to another, required to transform p into q. we recall the algorithm to evaluate this distance and we give some formulae for the maximum distance value between two partitions having exactly or at most p and q classes, for given p and q. </content></document><document><year>2006</year><authors>Douglas Steinley   | Robert Henson </authors><title>oclus: an analytic method for generating clusters with known overlap </title><content>abstract;;the primary method for validating cluster analysis techniques is throughmonte carlo simulations that rely on generating data with known cluster structure (e.g., milligan 1996). this paper defines two kinds of data generation mechanisms with cluster overlap, marginal and joint; current cluster generation methods are framed within these definitions. an algorithm generating overlapping clusters based on shared densities from several different multivariate distributions is proposed and shown to lead to an easily understandable notion of cluster overlap. besides outlining the advantages of generating clusters within this framework, a discussion is given of how the proposed data generation technique can be used to augment research into current classification techniques such as finite mixture modeling, classification algorithm robustness, and latent profile analysis. </content></document><document><year>2006</year><authors>Daniela G  CalГІ  </authors><title>on a transvariation based measure of group separability </title><content>abstract;;in this paper, the potentialities of transvariation (gini, 1959) in measuring the separation between two groups of multivariate observations are explored. with this aim, a modified version of gini&amp;#8217;s notion of multidimensional transvariation is proposed. according to gini (1959), two groups g1 and g2 are said to transvary on the k-dimensional variable x = (x1,...,xh,...,xk) if there exists at least one pair of units, belonging to different groups, such that for h = 1,...,k the sign of the difference between their xh values is opposite to that of m1h &amp;#8722;m2h, where m1h and m2h are the corresponding group mean values of xh. we introduce a modification that allows us to derive a measure of group separation, which can be profitably used in discriminating between two groups. the performance of the measure is tested through simulation experiments. the results show that the proposed measure is not sensitive to distributional assumptions and highlight its robustness against outliers. </content></document><document><year>2006</year><authors>Seong Keon Lee  </authors><title>on classification and regression trees for multiple responses and its application </title><content>abstract;;in many application fields, multivariate approaches that simultaneously consider the correlation between responses are needed. the tree method can be extended to multivariate responses, such as repeated measure and longitudinal data, by modifying the split function so as to accommodate multiple responses. recently, researchers have constructed some decision trees for multiple continuous longitudinal response and multiple binary responses using mahalanobis distance and a generalized entropy index. however, these methods have limitations according to the type of response, that is, those that are only continuous or binary. in this paper, we will modify the tree for univariate response procedure and suggest a new tree-based method that can analyze any type of multiple responses by using gee (generalized estimating equations) techniques. to compare the performance of trees, simulation studies on selection probability of true split variable will be shown. finally, applications using epileptic seizure data and www data are introduced. </content></document><document><year>2006</year><authors>Ahmed N  Albatineh  | Magdalena Niewiadomska-Bugaj   | Daniel Mihalko  </authors><title>on similarity indices and correction for chance agreement </title><content>abstract;;similarity indices can be used to compare partitions (clusterings) of a data set. many such indices were introduced in the literature over the years. we are showing that out of 28 indices we were able to track, there are 22 different ones. even though their values differ for the same clusterings compared, after correcting for agreement attributed to chance only, their values become similar and some of them even become equivalent. consequently, the problem of choice of the index to be used for comparing different clusterings becomes less important. </content></document><document><year>2006</year><authors>Rahul Shah   | Martin Farach-Colton  </authors><title>on the complexity of ordinal clustering </title><content>abstract;;given a set of pairwise distances on a set of n points, constructing an edgeweighted tree whose leaves are these n points such that the tree distances would mimic the original distances under some criteria is a fundamental problem. one such criterion is to preserve the ordinal relation between the pairwise distances. the ordinal relation can be of the form of total order on the distances or it can be some partial order specified on the pairwise distances. we show that the problem of finding a weighted tree, if it exists, which would preserve the total order on pairwise distances is np-hard. we also show the np-hardness of the problem of finding a weighted tree which would preserve a particular kind of partial order called a triangle order, one of the most fundamental partial orders considered in computational biology. </content></document><document><year>2006</year><authors>Michael J  Brusco  </authors><title>on the performance of simulated annealing for large-scale l2 unidimensional scaling </title><content>abstract;;in this research note, i present a modified version of g. de soete, l. hubert, and p. arabie&amp;#8217;s (1988) simulated annealing approach for the problem of l2 unidimensional scaling via maximization of the defays criterion. the modifications include efficient storage and computation methods that facilitate rapid evaluation of trial solutions. the results of two experimental studies indicate that the enhanced simulated annealing algorithm is competitive with a. murillo, j.f. vera, and w.j. heiser&amp;#8217;s (2005) recently published pertsaus2 procedure in terms of solution quality and computation time. both fortran and matlab versions of this modified simulated annealing implementation are available from the author. </content></document><document><year>2006</year><authors>Ulas Akkucuk   | J  Douglas Carroll  </authors><title>paramap vs. isomap: a comparison of two nonlinear mapping algorithms </title><content>abstract;;dimensionality reduction techniques are used for representing higher dimensional data by a more parsimonious and meaningful lower dimensional structure. in this paper we will study two such approaches, namely carroll&amp;#8217;s parametric mapping (abbreviated paramap) (shepard and carroll, 1966) and tenenbaum&amp;#8217;s isometric mapping (abbreviated isomap) (tenenbaum, de silva, and langford, 2000). the former relies on iterative minimization of a cost function while the latter applies classical mds after a preprocessing step involving the use of a shortest path algorithm to define approximate geodesic distances. we will develop a measure of congruence based on preservation of local structure between the input data and the mapped low dimensional embedding, and compare the different approaches on various sets of data, including points located on the surface of a sphere, some data called the "swiss roll data", and truncated spheres. </content></document><document><year>2006</year><authors>Jerome H  Friedman  </authors><title>recent advances in predictive (machine) learning </title><content>abstract;;prediction involves estimating the unknown value of an attribute of a system under study given the values of other measured attributes. in prediction (machine) learning the prediction rule is derived from data consisting of previously solved cases. most methods for predictive learning were originated many years ago at the dawn of the computer age. recently two new techniques have emerged that have revitalized the field. these are support vector machines and boosted decision trees. this paper provides an introduction to these two new methods tracing their respective ancestral roots to standard kernel methods and ordinary decision trees. </content></document><document><year>2006</year><authors>Michel van de Velden   | Henk A L  Kiers  </authors><title>rotation in correspondence analysis </title><content>abstract;;in correspondence analysis rows and columns of a nonnegative data matrix are depicted as points in a, usually, two-dimensional plot. although such a two-dimensional plot often provides a reasonable approximation, the situation can occur that an approximation of higher dimensionality is required. this is especially the case when the data matrix is large. in such instances it may become difficult to interpret the solution. similar to what is done in principal component analysis and factor analysis the correspondence analysis solution can be rotated to increase the interpretability. however, due to the various scaling options encountered in correspondence analysis, there are several alternative options for rotating the solutions. in this paper we consider two options for rotation in correspondence analysis. an example is provided so that the benefits of rotation become apparent. </content></document><document><year>2006</year><authors>Jon R  Kettenring  </authors><title>the practice of cluster analysis </title><content>abstract;;cluster analysis is one of the main methodologies for analyzing multivariate data. its use is widespread and growing rapidly. the goal of this article is to document this growth, characterize current usage, illustrate the breadth of applications via examples, highlight both good and risky practices, and suggest some research priorities. </content></document><document><year>2007</year><authors>K  C  Klauer  | J  D  Carroll </authors><title>a comparison of two approaches to fitting directed graphs to nonsymmetric proximity measures </title><content>abstract;;two algorithms for fitting directed graphs to nonsymmetric proximity data are compared. the first approach, termed mapnet, is a direct extension of a mathematical programming procedure for fitting undirected graphs to symmetric proximity data presented by klauer and carroll (1989). for a user-specified number of links, the algorithm seeks to provide the connected network that gives the least-squares approximation of the proximity data with the specified number of links, allowing for linear transformations of the data. the mathematical programming approach is compared to the netscal method for fitting directed graphs (hutchinson 1989), using the monte carlo methods and data sets employed by hutchinson. </content></document><document><year>2007</year><authors>Geert De Soete  | Wayne S  DeSarbo </authors><title>a latent class probit model for analyzing pick any/n data </title><content>abstract;;a latent class probit model is developed in which it is assumed that the binary data of a particular subject follow a finite mixture of multivariate bermoulli distributions. an em algorithm for fitting the model is described and a monte carlo procedure for testing the number of latent classes that is required for adequately describing the data is discussed. in the final section, an application of the latent class probit model to some intended purchase data for residential telecommunication devices is reported. </content></document><document><year>2007</year><authors>Wayne S  DeSarbo |  | Venkatram Ramaswamy  | Peter Lenk </authors><title>a latent class procedure for the structural analysis of two-way compositional data </title><content>abstract;;this paper develops a new procedure for simultaneously performing multidimensional scaling and cluster analysis on two-way compositional data of proportions. the objective of the proposed procedure is to delineate patterns of variability in compositions across subjects by simultaneously clustering subjects into latent classes or groups and estimating a joint space of stimulus coordinates and class-specific vectors in a multidimensional space. we use a conditional mixture, maximum likelihood framework with an e-m algorithm for parameter estimation. the proposed procedure is illustrated using a compositional data set reflecting proportions of viewing time across television networks for an area sample of households. </content></document><document><year>2007</year><authors>Geert De Soete  | Suzanne Winsberg </authors><title>a latent class vector model for preference ratings </title><content>abstract;;a latent class formulation of the well-known vector model for preference data is presented. assuming preference ratings as input data, the model simultaneously clusters the subjects into a small number of homogeneous groups (or latent classes) and constructs a joint geometric representation of the choice objects and the latent classes according to a vector model. the distributional assumptions on which the latent class approach is based are analogous to the distributional assumptions that are consistent with the common practice of fitting the vector model to preference data by least squares methods. an em algorithm for fitting the latent class vector model is described as well as a procedure for selecting the appropriate number of classes and the appropriate number of dimensions. some illustrative applications of the latent class vector model are presented and some possible extensions are discussed. </content></document><document><year>2007</year><authors>D  Leuschner </authors><title>a mathematical model for classification and identification </title><content>abstract;;a unified model for classification and identification is presented by means of the theory of mathematical structures. the methodologies for classification and identification differ. for classification, an interchange scalar mechanism (iscl) is proposed which improves the capacity of classifications irrespective of character weighting, the number of characters used, and the form of the clustering algorithm. it modifies a distance between two otus by considering their distances to their nearest neighbors. formulas are developed for reliability, velocity, and capability of taxonomic keys. </content></document><document><year>2007</year><authors>Geert De Soete | J  Douglas Carroll  | Anil D  Chaturvedi </authors><title>a modified candecomp method for fitting the extended indscal model </title><content>abstract;;a modified candecomp algorithm is presented for fitting the metric version of the extended indscal model to three-way proximity data. the extended indscal model assumes, in addition to the common dimensions, a unique dimension for each object. the modified candecomp algorithm fits the extended indscal model in a dimension-wise fashion and ensures that the subject weights for the common and the unique dimensions are nonnegative. a monte carlo study is reported to illustrate that the method is fairly insensitive to the choice of the initial parameter estimates. a second monte carlo study shows that the method is able to recover an underlying extended indscal structure if present in the data. finally, the method is applied for illustrative purposes to some empirical data on pain relievers. in the final section, some other possible uses of the new method are discussed. </content></document><document><year>2007</year><authors>G  M  Fitzmaurice | W  J  Krzanowski  | D  J  H|  </authors><title>a monte carlo study of the 632 bootstrap estimator of error rate </title><content>abstract;;efron (1983) proposed the 632 bootstrap error rate estimator, and demonstrated its good performance in simulations. however, further recent studies have suggested that it only performs well for a restricted range of true error rates. we conduced an intensive, simulation study of the 632 estimator to investigate this hypothesis in detail. there was no evidence to support the contention, although the estimator's performance did vary with the true error rate. we also investigated some more general aspects of error rate studies. error rate is bounded by 0 and 1, so that comparisons based on an untransformed scale may be inappropriate. we therefore explored the consequences of stretching the error rate scale. furthermore, the results of such studies are typically generated as mixture distributions, because the performance results are averages over the true error rate values arising from underlying distributions which have a fixed optimal error rate. we discovered, rather surprisingly, that this has little effect if the conclusions are based on mean squared error. </content></document><document><year>2007</year><authors>Werner Vach |   | Paul O  Degens |  </authors><title>a new approach to isotonic agglomerative hierarchical clustering </title><content>abstract;;hierarchical clustering methods must be isotonic for the construction of ultrametric. we present a general strategy to widen the class of isotonic methods implemented by agglomerative algorithms. at each step of the agglomeration we allow one of several admissible pairs to be chosen. then under mild assumptions an appropriate definition of admissibility guarantees isotony. moreover we consider the use of the new methods to compute locally optimal ultrametrics. two examples demonstrate the ability to define new agglomerative methods superior to their traditional competitors. </content></document><document><year>2007</year><authors>Diane E  Duffy  | adolfo J  Quiroz </authors><title>a permutation-based algorithm for block clustering </title><content>abstract;;hartigan (1972) discusses the direct clustering of a matrix of data into homogeneous blocks. he introduces a stepwise divisive method for block clustering within a certain class of block structures which induce clustering trees for both row and column margins. while this class of structures is appealing, the stopping criterion for his method, which is based on asymptotic theory and the assumption that the individual elements of the data matrix are normally distributed, is quite restrictive. in this paper we propose a permutation-based algorithm for block clustering within the same class of block structures. by using permutation arguments to decide where to split and when to stop, our algorithm becomes applicable in a wide variety of cases, including matrices of categorical data and matrices of small-to-moderate size. in addition, our algorithm offers considerable flexibility in how block homogeneity is defined. the algorithm is studied in a series of simulation experiments on matrices of known structure, and illustrated in examples drawn from the fields of taxonomy, political science, and data architecture. </content></document><document><year>2007</year><authors>Robert B  Schneider  </authors><title>a uniform approach to multidimensional scaling </title><content>abstract;;we present a method and an algorithm that puts interval and ordinal multidimensional scaling at two ends of a continuum. theory and simulation show that the method compares favorably with classical scaling methods. a parameter is identified that produces scaling that combines benefits of interval, and ordinal scaling. </content></document><document><year>2007</year><authors>Pierre Hansen   | Sylvain Perron  </authors><title>algorithms for &amp;#8467;1-embeddability and related problems </title><content>abstract;;assouad has shown that a real-valued distance d = (dij)1 &amp;#8804; i &amp;lt; j &amp;#8804; n is isometrically embeddable in &amp;#8467;1space if and only if it belongs to the cut cone on n points. determining if this condition holds is np-complete. we use assouad's result in a constructive column generation algorithm for &amp;#8467;1-embeddability. the subproblem is an unconstrained 0-1 quadratic program, solved by tabu search and variable neighborhood search heuristics as well as by an exact enumerative algorithm. computational results are reported. several ways to approximate a distance which is not &amp;#8467;1-embeddable by another one which is are also studied. </content></document><document><year>2007</year><authors>H  Messatfa </authors><title>an algorithm to maximize the agreement between partitions </title><content>abstract;;given the marginal description of two partitionsc andy of the same set, an index of agreement between the two partitions is given by the number of pairs appearing together in an equivalence class in both partitions. letc be fixed andy an unknown partition represented by its marginal description. we consider the following problem: finding the distribution of objects (conditioned by the marginal description ofy) which maximizes the agreement betweenc andy. we discuss some approaches that have proposed, and we obtain a heuristic procedure from the solution of a linear transportation problem. </content></document><document><year>2007</year><authors>Thomas Eckes  | Peter Orlik </authors><title>an error variance approach to two-mode hierarchical clustering </title><content>abstract;;a new agglomerative method is proposed for the simultaneous hierarchical clustering of row and column elements of a two-mode data matrix. the procedure yields a nested sequence of partitions of the union of two sets of entities (modes). a two-mode cluster is defined as the union of subsets of the respective modes. at each step of the agglomerative process, the algorithm merges those clusters whose fusion results in the smallest possible increase in an internal heterogeneity measure. this measure takes into account both the variance within the respective cluster and its centroid effect defined as the squared deviation of its mean from the maximum entry in the input matrix. the procedure optionally yields an overlapping cluster solution by assigning further row and/or column elements to clusters existing at a preselected hierarchical level. applications to real data sets drawn from consumer research concerning brand-switching behavior and from personality research concerning the interaction of behaviors and situations demonstrate the efficacy of the method at revealing the underlying two-mode similarity structure. </content></document><document><year>2007</year><authors>Neal L  Oden  | Robert R  Sokal  </authors><title>an investigation of three-matrix permutation tests </title><content>abstract;;several methods have recently been introduced for investigating relations between three interpoint proximity matricesa, b, c, each of which furnishes a different type of distance between the same objects. smouse, long, and sokal (1986) investigate the partial correlation betweena andb conditional onc. dow and cheverud (1985) ask whethercorr (a, c), equalscorr (b, c). manly (1986) investigates regression-like models for predicting one matrix as a function of others. we have investigated rejection rates of these methods when their null hypotheses are true, but data are spatially autocorrelated (sa). that is,a, andb are distance matrices from independent realizations of the same sa generating process, andc is a matrix of geographic connections. </content></document><document><year>2007</year><authors>Akinobu Takeuchi  | Takayuki Saito   | Hiroshi Yadohisa  </authors><title>asymmetric agglomerative hierarchical clustering algorithms and their evaluations </title><content>abstract;;this paper presents asymmetric agglomerative hierarchical clustering algorithms in an extensive view point. first, we develop a new updating formula for these algorithms, proposing a general framework to incorporate many algorithms. next we propose measures to evaluate the fit of asymmetric clustering results to data. then we demonstrate numerical examples with real data, using the new updating formula and the indices of fit. discussing empirical findings, through the demonstrative examples, we show new insights into the asymmetric clustering. </content></document><document><year>2007</year><authors>Chris Fraley   | Adrian E  Raftery  </authors><title>bayesian regularization for normal mixture estimation and model-based clustering </title><content>abstract;;normal mixture models are widely used for statistical modeling of data, including cluster analysis. however maximum likelihood estimation (mle) for normal mixtures using the em algorithm may fail as the result of singularities or degeneracies. to avoid this, we propose replacing the mle by a maximum a posteriori (map) estimator, also found by the em algorithm. for choosing the number of components and the model parameterization, we propose a modified version of bic, where the likelihood is evaluated at the map instead of the mle. we use a highly dispersed proper conjugate prior, containing a small fraction of one observation's worth of information. the resulting method avoids degeneracies and singularities, but when these are not present it gives similar results to the standard method using mle, em and bic. </content></document><document><year>2007</year><authors>Robert R  Sokal | Junhyong Kim  | F  James Rohlt </authors><title>character and otu stability in five taxonomic groups </title><content>abstract;;the character and otu stability of classifications based on upgma clustering and maximum parsimony (mp) trees were compared for 5 datasets (families of angiosperms, families of orthopteroid insects, species of the fish genusictalurus, genera of the salamander family salamandridae, and genera of the frog family myobatrachidae). stability was investigated by taking different sized random subsamples of otus or characters, computing upgma clusters and an mp tree, and then comparing the resulting trees with those based on the entire dataset. agreement was measured by two consensus indices, that of colless, computed from strict consensus trees, and stinebrickner's 0.5-consensus index. tests of character stability generally showed a monotone decrease in agreement with the standard as smaller sets of characters are considered. the relative success of the two methods depended upon the dataset. tests of otu stability showed a monotone decrease in agreement for upgma as smaller sets of otus are considered. but for mp, agreement decreased and then increased again on the same scale. the apparent superiority of upgma relative to mp with respect to otu stability depended upon the dataset. considerations other than stability, such as computer efficiency or accuracy, will also determine the method of choice for classifications. </content></document><document><year>2007</year><authors>Saul G  de Amorim | Jean-Pierre BarthГ©lemy  | Celso C  Ribeiro </authors><title>clustering and clique partitioning: simulated annealing and tabu search approaches </title><content>abstract;;we study the application of simulated annealing and tabu search to the solution of the clique partitioning problem. we illustrate the effecveness of these techniques by computational results associated not only with randomly generated problems, but also with real-life problems arising from applications concerning the optimal aggregation of binary relations into an equivalence relation. the need for these approaches is emphasized by the example of a special class of instances of the clique partitioning problem for which the most commonly used heuristics perform arbitrarily badly, while tabu search systematically obtains the optimal solution. </content></document><document><year>2007</year><authors>Gilles Celeux  | GГ©rard Govaert </authors><title>clustering criteria for discrete data and latent class models </title><content>abstract;;we show that a well-known clustering criterion for discrete data, the information criterion, is closely related to the classification maximum likelihood criterion for the latent class model. this relation can be derived from the bryant-windham construction. emphasis is placed on binary clustering criteria which are analyzed under the maximum likelihood approach for different multivariate bernoulli mixtures. this alternative form of criterion reveals non-apparent aspects of clustering techniques. all the criteria discussed can be optimized with the alternating optimization algorithm. some illustrative applications are included. </content></document><document><year>2007</year><authors>Jos M  F  ten Berge | Henk A  L  Kiers  | Wim P  Krijnen </authors><title>computational solutions for the problem of negative saliences and nonsymmetry in indscal </title><content>abstract;;carroll and chang have derived the symmetric candecomp model from the indscal model, to fit symmetric matrices of approximate scalar products in the least squares sense. typically, the candecomp algorithm is used to estimate the parameters. in the present paper it is shown that negative weights may occur with candecomp. this phenomenon can be suppressed by updating the weights by the nonnegative least squares algorithm. a potential drawback of the resulting procedure is that it may produce two different versions of the stimulus space matrix. to obviate this possibility, a symmetry preserving algorithm is offered, which can be monitored to produce non-negative weights as well. </content></document><document><year>2007</year><authors>N  Sriram   | Scott Lewis</authors><title>constructing optimal ultrametrics </title><content>abstract;;clique optimization (clopt) is a family of graph clustering procedures that construct parsimonious ultrametrics by executing a sequence of divisive and agglomerative operations. every clopt procedure is associated with a distinct graph-partitioning heuristic. seven hcs methods, a mathematical programming algorithm, and two clopt heuristics were evaluated on simulated data. these data were obtained by distorting ultrametric partitions and hierarchies. in general, internally optimal models yielded externally optimal models. by recovering near-optimal solutions more consistently, clopt2 emerged as the most robust technique. </content></document><document><year>2007</year><authors>Herbert K H  Lee  </authors><title>default priors for neural network classification </title><content>abstract;;feedforward neural networks are a popular tool for classification, offering a method for fully flexible modeling. this paper looks at the underlying probability model, so as to understand statistically what is going on in order to facilitate an intelligent choice of prior for a fully bayesian analysis. the parameters turn out to be difficult or impossible to interpret, and yet a coherent prior requires a quantification of this inherent uncertainty. several approaches are discussed, including flat priors, jeffreys priors and reference priors. </content></document><document><year>2007</year><authors>A  Ferligoj  | V  Batagelj </authors><title>direct multicriteria clustering algorithms </title><content>abstract;;in a multicriteria clustering problem, optimization over more than one criterion is required. the problem can be treated in different ways: by reduction to a clustering problem with the single criterion obtained as a combination of the given criteria; by constrained clustering algorithms where a selected critetion is considered as the clustering criterion and all others determine the constraints; or by direct algorithms. in this paper two types of direct algorithms for solving multicriteria clustering problem are proposed: the modified relocation algorithm, and the modified agglomerative algorithm. different elaborations of these two types of algorithms are discussed and compared. finally, two applications of the proposed algorithms are presented. </content></document><document><year>2007</year><authors>A  GuГ©noche | P  Hansen  | B  Jaumard </authors><title>efficient algorithms for divisive hierarchical clustering with the diameter criterion </title><content>abstract;;divisive hierarchical clustering algorithms with the diameter criterion proceed by recursively selecting the cluster with largest diameter and partitioning it into two clusters whose largest diameter is smallest possible. we provide two such algorithms with complexitieso( n 2) ando(n 2logn) respectively, where denotes the maximum number of clusters in a partition andn the number of entities to be clustered. the former algorithm, an efficient implementation of an algorithm of hubert, allows to find all partitions into at most clusters and is ino(n 2) for fixed . moreover, if in each partitioning the size of the largest cluster is bounded byp times the number of entities in the set to be partitioned, with 1/2&amp;lt;=p&amp;lt;1, it provides a complete hierarchy of partitionso(n 2 logn) time. the latter algorithm, a refinement of an algorithm of rao allows to build a complete hierarchy of partitions ino(n 2 logn) time without any restriction. comparative computational experiments with both algorithms and with an agglomerative hierarchical algorithm of benzг©cri are reported. </content></document><document><year>2007</year><authors>Alex|er V  Genkin  | Ilya B  Muchnik </authors><title>fixed points approach to clustering </title><content>abstract;;assume that a dissimilarity measure between elements and subsets of the set being clustered is given. we define the transformation of the set of subsets under which each subset is transformed into the set of all elements whose dissimilarity to it is not greater than a given threshold. then a cluster is defined as a fixed point of this transformation. three well-known clustering strategies are considered from this point of view: hierarchical clustering, graph-theoretic methods, and conceptual clustering. for hierarchical clustering generalizations are obtained that allow for overlapping clusters and/or clusters not forming a cover. three properties of dissimilarity are introduced which guarantee the existence of fixed points for each threshold. we develop the relation to the theory of quasi-concave set functions, to help give an additional interpretation of clusters. </content></document><document><year>2007</year><authors>Nicolas Molinari |   </authors><title>free knot splines for supervised classification </title><content>abstract;;data in many different fields come to practitioners through a process naturally described as functional. we propose a classification procedure of oxidation curves. our algorithm is based on two stages: fitting the functional data by linear splines with free knots and classifying the estimated knots which estimate useful oxidation parameters. a real data set on 57 oxidation curves is used to illustrate our approach. </content></document><document><year>2007</year><authors>Abba M  Krieger  | Paul E  Green </authors><title>generalized measures of association for ranked data with an application to prediction accuracy </title><content>abstract;;a common practice in cross validation research in the behavioral sciences is to employ either the product moment correlation or a simple tabulation of first-choice &amp;#8220;hits&amp;#8221; for measuring the accuracy with which various preference models predict subjects&amp;#8217; responses to a holdout sample of choice objects. we propose a nonparametric approach for summarizing the accuracy of predicted rankings across a set of holdout-sample options. the methods that we develop contain a novel way to deal with ties and an approach to the different weighting of rank positions. </content></document><document><year>2007</year><authors>Michel Wedel </authors><title>glimmix: software for estimating mixtures and mixtures of generalized linear models </title><content>;;</content></document><document><year>2007</year><authors>J  Fern|o Vera  | Willem J  Heiser   | Alex Murillo  </authors><title>global optimization in any minkowski metric: a permutation-translation simulated annealing algorithm for multidimensional scaling </title><content>abstract;;it is well known that considering a non-euclidean minkowski metric in multidimensional scaling, either for the distance model or for the loss function, increases the computational problem of local minima considerably. in this paper, we propose an algorithm in which both the loss function and the composition rule can be considered in any minkowski metric, using a multivariate randomly alternating simulated annealing procedure with permutation and translation phases. the algorithm has been implemented in fortran and tested over classical and simulated data matrices with sizes up to 200 objects. a study has been carried out with some of the common loss functions to determine the most suitable values for the main parameters. the experimental results confirm the theoretical expectation that simulated annealing is a suitable strategy to deal by itself with the optimization problems in multidimensional scaling, in particular for city-block, euclidean and infinity metrics. </content></document><document><year>2007</year><authors>Claudio Cifarelli | Mario R  Guarracino | Onur Seref  | Salvatore Cuciniello  | Panos M  Pardalos </authors><title>incremental classification with generalized eigenvalues </title><content>abstract;;supervised learning techniques are widely accepted methods to analyze data for scientific and real world problems. most of these problems require fast and continuous acquisition of data, which are to be used in training the learning system. therefore, maintaining such systems updated may become cumbersome. various techniques have been devised in the field of machine learning to solve this problem. in this study, we propose an algorithm to reduce the training data to a substantially small subset of the original training data to train a generalized eigenvalue classifier. the proposed method provides a constructive way to understand the influence of new training data on an existing classification function. we show through numerical experiments that this technique prevents the overfitting problem of the earlier generalized eigenvalue classifiers, while promising a comparable performance in classification with respect to the state-of-the-art classification methods. </content></document><document><year>2007</year><authors>Douglas Steinley   | Michael J  Brusco  </authors><title>initializing k-means batch clustering: a critical evaluation of several techniques </title><content>abstract;;k-means clustering is arguably the most popular technique for partitioning data. unfortunately, k-means suffers from the well-known problem of locally optimal solutions. furthermore, the final partition is dependent upon the initial configuration, making the choice of starting partitions all the more important. this paper evaluates 12 procedures proposed in the literature and provides recommendations for best practices. </content></document><document><year>2007</year><authors>Peter G  Bryant </authors><title>large-sample results for optimization-based clustering methods </title><content>abstract;;many common (nonhierarchical) clustering and classification methods are optimization-based methods, in the sense described by windham (1987) in this journal. this paper gives some large sample properties for estimates derived by such methods. under appropriate conditions, such estimates converge with probability one to a limit, and are asymptotically normally distributed around that limiting value. the conditions are satisfied by most of the common examples of optimization-based methods. </content></document><document><year>2007</year><authors>Lawrence Hubert | Phipps Arabie  | Matthew Hesson-Mcinnis </authors><title>multidimensional scaling in the city-block metric: a combinatorial approach </title><content>abstract;;we present an approach, independent of the common gradient-based necessary conditions for obtaining a (locally) optimal solution, to multidimensional scaling using the city-block distance function, and implementable in either a metric or nonmetric context. the difficulties encountered in relying on a gradient-based strategy are first reviewed: the general weakness in indicating a good solution that is implied by the satisfaction of the necessary condition of a zero gradient, and the possibility of actual nonconvergence of the associated optimization strategy. to avoid the dependence on gradients for guiding the optimization technique, an alternative iterative procedure is proposed that incorporates (a) combinatorial optimization to construct good object orders along the chosen number of dimensions and (b) nonnegative least-squares to re-estimate the coordinates for the objects based on the object orders. the re-estimated coordinates are used to improve upon the given object orders, which may in turn lead to better coordinates, and so on until convergence of the entire process occurs to a (locally) optimal solution. the approach is illustrated through several data sets on the perception of similarity of rectangles and compared to the results obtained with a gradient-based method. </content></document><document><year>2007</year><authors>Jacques Benasseni  | Mohammed Bennani Dosse   | Serge Joly  </authors><title>on a general transformation making a dissimilarity matrix euclidean </title><content>abstract;;when a dissimilarity matrix cannot be represented in a euclidean space, it is possible to make it euclidean by means of suitable transformations of the original dissimilarity values. in this paper we discuss some interesting properties of a class of transformations based on adding a specific squared euclidean distance to the initial dissimilarity. </content></document><document><year>2007</year><authors>Wieslaw Szczesny </authors><title>on the performance of a discriminant function </title><content>abstract;;in two-class discriminant problems, objects are allocated to one of the two classes by means of threshold rules based on discriminant functions. in this paper we propose to examine the quality of a discriminant functiong in terms of its performance curve. this curve is the plot of the two misclassification probabilities as the thresholdt assumes various real values. the role of such performance curves in evaluating and ordering discriminant functions and solving discriminant problems is presented. in particular, it is shown that: (i) the convexity of such a curve is a sufficient condition for optimal use of the information contained in the data reduced byg, and (ii)g with non-convex performance curve should be corrected by an explicitly obtained transformation. </content></document><document><year>2007</year><authors>Peter Verboon  | Willem J  Heiser </authors><title>resistant orthogonal procrustes analysis </title><content>abstract;;in this paper two alternative loss criteria for the least squares procrustes problem are studied. these alternative criteria are based on the huber function and on the more radical biweight function, which are designed to be resistant to outliers. using iterative majorization it is shown how a convergent reweighted least squares algorithm can be developed. in asimulation study it turns out that the proposed methods perform well over a specific range of contamination. when a uniform dilation factor is included, mixed results are obtained. the methods also yield a set of weights that can be used for diagnostic purposes. </content></document><document><year>2007</year><authors>Chih-Chien Yang   | Chih-Chiang Yang  </authors><title>separating latent classes by information criteria </title><content>abstract;;this study evaluates performance of information criteria used to separate latent classes. in the evaluations, various numbers of latent classes, sample sizes, parameter structures and latent-class complexities were designed to simulate datasets. the average accuracy rates of information criteria in selecting the designed numbers of latent classes were the core results in this experiment. the study revealed that widely used information criteria, e.g., aic, bic, caic, could perform poorly under some circumstances. by including a sample size adjustment (rissanen, 1978), the unsatis-factory performances could be improved considerably. the sample size adjustment provides a plausible solution for separating latent classes. guidelines are provided to help achieve optimum use of the model fit indices. </content></document><document><year>2007</year><authors>Michael A  Steel | Michael D  Hendy  | David Penny </authors><title>significance of the length of the shortest tree </title><content>abstract;;the distribution of lengths of phylogenetic trees under the taxonomic principle of parsimony is compared with the distribution obtained by randomizing the characters of the sequence data. this comparison allows us to define a measure of the extent to which sequence data contain significant hierarchical information. we show how to calculate this measure exactly for up to 10 taxa, and provide a good approximation for larger sets of taxa. the measure is applied to test sequences on 10 and 15 taxa. </content></document><document><year>2007</year><authors>Maurizio Vichi  | Roberto Rocci   | Henk A L  Kiers  </authors><title>simultaneous component and clustering models for three-way data: within and between approaches </title><content>abstract;;in this paper two techniques for units clustering and factorial dimensionality reduction of variables and occasions of a three-mode data set are discussed. these techniques can be seen as the simultaneous version of two procedures based on the sequential application of k-means and tucker2 algorithms and vice versa. the two techniques, t3clus and 3fk-means, have been compared theoretically and empirically by a simulation study. in the latter, it has been noted that neither t3clus nor 3fk-means outperforms the other in every case. from these results rises the idea to combine the two techniques in a unique general model, named ct3clus, having t3clus and 3fk-means as special cases. a simulation study follows to show the effectiveness of the proposal. </content></document><document><year>2007</year><authors>Piet Brouwer  | Pieter M  Kroonenberg  </authors><title>some notes on the diagonalization of the extended three-mode core matrix </title><content>abstract;;we extend previous results of kroonenberg and de leeuw (1980) and kroonenberg (1983, ch. 5) on transformations of the extended core matrix of the tucker2 model (kroonenberg and de leeuw 1980). in particular, it is shown that non-singular transformations to diagonalize the core matrix will lead to parafac solutions (harshman 1970; harshman and lundy 1984), if such solutions exist. </content></document><document><year>2007</year><authors>Michael D  Hendy   | David Penny  </authors><title>spectral analysis of phylogenetic data </title><content>abstract;;the spectral analysis of sequence and distance data is a new approach to phylogenetic analysis. for two-state character sequences, the character values at a given site split the set of taxa into two subsets, a bipartition of the taxa set. the vector which counts the relative numbers of each of these bipartitions over all sites is called a sequence spectrum. applying a transformation called a hadamard conjugation, the sequence spectrum is transformed to the conjugate spectrum. this conjugation corrects for unobserved changes in the data, independently from the choice of phylogenetic tree. for any given phylogenetic tree with edge weights (probabilities of state change), we define a corresponding tree spectrum. the selection of a weighted phylogenetic tree from the given sequence data is made by matching the conjugate spectrum with a tree spectrum. we develop an optimality selection procedure using a least squares best fit, to find the phylogenetic tree whose tree spectrum most closely matches the conjugate spectrum. an inferred sequence spectrum can be derived from the selected tree spectrum using the inverse hadamard conjugation to allow a comparison with the original sequence spectrum. a possible adaptation for the analysis of four-state character sequences with unequal frequencies is considered. a corresponding spectral analysis for distance data is also introduced. these analyses are illustrated with biological examples for both distance and sequence data. spectral analysis using the fast hadamard transform allows optimal trees to be found for at least 20 taxa and perhaps for up to 30 taxa. </content></document><document><year>2007</year><authors>Eric W  Holman  </authors><title>statistical properties of large published classifications </title><content>abstract;;large published classifications typically consist of sets (called taxa) hierarchically arranged according to taxonomic rank. a statistical survey of 23 such classification reveals the following distinctive properties. the pattern of mandatory and optional taxonomic ranks is similar to a guttman scale. mean taxon size (defined as the number of next-lower-rank taxa per higher-rank taxon) is a u-shaped function of mandatory rank, and averages about seven across ranks with no significant differences between classifications. the variability of taxon size is a decreasing function of mandatory rank. the generality of these properties across classifications suggests that they are determined by the psychology of the classification process. in contrast, there are significant differences between classifications in the variability of taxon size and in the prevalence of optional ranks, both of which are greater in biological than in nonbiological classifications. these differences may reflect the nature of the materials classified. </content></document><document><year>2007</year><authors>Michael Steel </authors><title>the complexity of reconstructing trees from qualitative characters and subtrees </title><content>abstract;;in taxonomy and other branches of classification it is useful to know when tree-like classifications on overlapping sets of labels can be consistently combined into a parent tree. this paper considers the computation complexity of this problem. recognizing when a consistent parent tree exists is shown to be intractable (np-complete) for sets of unrooted trees, even when each tree in the set classifies just four labels. consequently determining the compatibility of qualitative characters and partial binary characters is, in general, also np-complete. however for sets of rooted trees an algorithm is described which constructs the &amp;#8220;strict consensus tree&amp;#8221; of all consistent parent trees (when they exist) in polynomial time. the related question of recognizing when a set of subtrees uniquely defines a parent tree is also considered, and a simple necessary and sufficient condition is described for rooted trees. </content></document><document><year>2007</year><authors>FranГ§ois-Joseph Lapointe  | Pierre Legendre </authors><title>the generation of random ultrametric matrices representing dendrograms </title><content>abstract;;many methods and algorithms to generate random trees of many kinds have been proposed in the literature. no procedure exists however for the generation of dendrograms with randomized fusion levels. randomized dendrograms can be obtained by randomizing the associated cophenetic matrix. two algorithms are described. the first one generates completely random dendrograms, i.e., trees with a random topology, random fusion level values, and random assignment of the labels. the second algorithm uses a double-permutation procedure to randomize a given dendrogram; it proceeds by randomization of the fixed fusion levels, instead of using random fusion level values. a proof is presented that the double-permutation procedure is a uniform random generation algorithmsensu furnas (1984), and a complete example is given. </content></document><document><year>2007</year><authors>Fionn Murtagh  </authors><title>the haar wavelet transform of a dendrogram </title><content>abstract;;we describe a new wavelet transform, for use on hierarchies or binary rooted trees. the theoretical framework of this approach to data analysis is described. case studies are used to further exemplify this approach. a first set of application studies deals with data array smoothing, or filtering. a second set of application studies relates to hierarchical tree condensation. finally, a third study explores the wavelet decomposition, and the reproducibility of data sets such as text, including a new perspective on the generation or computability of such data objects. </content></document><document><year>2007</year><authors>W  J  Krzanowski  </authors><title>the location model for mixtures of categorical and continuous variables </title><content>abstract;;recent research into graphical association models has focussed interest on the conditional gaussian distribution for analyzing mixtures of categorical and continuous variables. a special case of such models, utilizing the homogeneous conditional gaussian distribution, has in fact been known since 1961 as the location model, and for the past 30 years has provided a basis for the multivariate analysis of mixed categorical and continuous variables. extensive development of this model took place throughout the 1970&amp;#8217;s and 1980&amp;#8217;s in the context of discrimination and classification, and comprehensive methodology is now available for such analysis of mixed variables. this paper surveys these developments and summarizes current capabilities in the area. topics include distances between groups, discriminant analysis, error rates and their estimation, model and feature selection, and the handling of missing data. </content></document><document><year>2007</year><authors>Alain Hertz   | Sacha Varone  </authors><title>the metric bridge partition problem: partitioning of a metric space into two subspaces linked by an edge in any optimal realization </title><content>abstract;;let g = (v,e,w) be a graph with vertex and edge sets v and e, respectively, and w:e &amp;#8594; r + a function which assigns a positive weight or length to each edge of g. g is called a realization of a finite metric space (m,d), with m = { 1,...,n} if and only if { 1,...,n} &amp;#10949; v and d(i,j) is equal to the length of the shortest chain linking i and j in g &amp;#8704; i,j = 1,...,n. a realization g of (m,d), is said optimal if the sum of its weights is minimal among all the realizations of (m,d). consider a partition of m into two nonempty subsets k and l, and let e be an edge in a realization g of (m,d); we say that e is a bridge linking k with l if e belongs to all chains in g linking a vertex of k with a vertex of l. the metric bridge partition problem is to determine if the elements of a finite metric space (m,d) can be partitioned into two nonempty subsets k and l such that all optimal realizations of (m,d) contain a bridge linking k with l. we prove in this paper that this problem is polynomially solvable. we also describe an algorithm that constructs an optimal realization of (m,d) from optimal realizations of (k,d|k) and (l,d|l). </content></document><document><year>2007</year><authors>J  A  Hartigan  | Surya Mohanty </authors><title>the runt test for multimodality </title><content>abstract;;single linkage clusters on a set of points are the maximal connected sets in a graph constructed by connecting all points closer than a given threshold distance. the complete set of single linkage clusters is obtained from all the graphs constructed using different threshold distances. the set of clusters forms a hierarchical tree, in which each non-singleton cluster divides into two or more subclusters; the runt size for each single linkage cluster is the number of points in its smallest subcluster. the maximum runt size over all single linkage clusters is our proposed test statistic for assessing multimodality. we give significance levels of the test for two null hypotheses, and consider its power against some bimodal alternatives. </content></document><document><year>2003</year><authors>John C  Gower  | Mark de Rooij </authors><title>a comparison of the multidimensional scaling of triadic and dyadic distances </title><content>;;</content></document><document><year>2003</year><authors>Carey E  Priebe | David J  Marchette | Jason G  DeVinney  | Diego A  Socolinsky </authors><title>classification using class cover catch digraphs </title><content>class cover catch digraphs;; based on proximity between training observations. performance comparisons are presented on synthetic and real examples versus k-nearest neighbors, fisher's linear discriminant and support vector machines. we demonstrate that the proposed semiparametric classifier has performance approaching that of the optimal parametric classifier in cases for which the optimal is available for comparison. </content></document><document><year>2003</year><authors>Thaddeus Tarpey  | Kimberly K  J  Kinateder </authors><title>clustering functional data </title><content>;;</content></document><document><year>2003</year><authors>Michael P  Windham </authors><title>concavity in data analysis </title><content>m;;-estimators, and building clustering objective functions. finally, using the common thread of concavity, all three will be combined to build a comprehensive, flexible procedure for robust cluster analysis. </content></document><document><year>2003</year><authors>Werner Stuetzle </authors><title>estimating the cluster tree of a density by analyzing the minimal spanning tree of a sample </title><content>runt pruning;;, a new clustering method that attempts to find modes of a density by analyzing the minimal spanning tree of a sample. the method exploits the connection between the minimal spanning tree and nearest neighbor density (e.g. normal mixture) or about the geometric shapes of the clusters, and is computationally feasible for large data sets. </content></document><document><year>2003</year><authors>H  Bensmail  | J  J  Meulman </authors><title>model-based clustering with noise: bayesian inference and estimation </title><content>;; this paper proposes a new way of overcoming the existing limitations. it generalizes the model used in the previous approaches by introducing a more comprehensive portfolio of covariance matrix structures. further, this paper proposes a bayesian solution in the presence of the noise in clustering problems. the performace of the proposed method is first studied by simulation; the procedure is also applied to the analysis of data concerning species of butterflies and diabetes patients. </content></document><document><year>2002</year><authors>Stanley L  Sclove </authors><title>assessing accuracy and precision of a medical lab machine by means of cluster analysis </title><content>;;</content></document><document><year>2002</year><authors>Michel Meulders | Paul De Boeck | Peter Kuppens  | Iven  </authors><title>constrained latent class analysis of three-way three-mode data </title><content>;;</content></document><document><year>2002</year><authors>Mark de Rooij </authors><title>distance models for three-way tables and three-way association </title><content>p;; similarity function, the l p -transform and the minkowski-p distance. for triadic distance models defined by the l p -transform we will prove that they do not model three-way association. moreover, triadic distance models defined by the l p -transform are restricted multiple dyadic distances, where each dyadic distance is defined for a two-way margin of the three-way table. distance models for three-way two-mode data, called three-way distance models, do succeed in modeling three-way association. </content></document><document><year>2002</year><authors>Christian Hennig </authors><title>fixed point clusters for linear regression: computation and comparison </title><content>;; in this paper an algorithm is developed, which aims to find all fpcs of a dataset corresponding to well separated linear regression subpopulations. its ability to find such subpopulations under the occurence of outliers is compared to methods based on ml-estimation of mixture models by means of a simulation study. furthermore, fpc analysis is applied to a real dataset. </content></document><document><year>2002</year><authors>Michael D  Lee </authors><title>generating additive clustering models with minimal stochastic complexity </title><content>;;</content></document><document><year>2002</year><authors>Michael J  Brusco </authors><title>integer programming methods for seriation and unidemensional scaling of proximity matrices: a review and some extensions </title><content>l;; 1-norm are also presented. i conclude that the computational scaling problems depends largely on the criterion of interest, with unidimensional scaling problems depends largely on the criterion of interest, with unidimensional scaling in the l 1-norm being especially challenging. </content></document><document><year>2002</year><authors>L  J  Hubert | P  Arabie  | J  J  Meulman </authors><title>linear unidimensional scaling in the l 2 -norm: basic optimization methods using matlab </title><content>l2 ;;-norm: (1) dynamic programming; (2) an iterative quadratic assignment improvement heuristic; (3) the guttman update strategy as modified by pliner's technique of smoothing; (4) a nonlinear programming reformulation by lau, leung, and tse. the methods are all implemented through (freely downloadable) matlab m-files; their use is illustrated by a common data set carried throughout. for the computationally intensive dynamic programming formulation that can a globally optimal solution, several possible computational improvements are discussed and evaluated using (a) a transformation of a given m-function with the matlab compiler into c code and compiling the latter; (b) rewriting an m-function and a mandatory matlab gateway directly in fortran and compiling into a matlab callable file; (c) comparisons of the acceleration of raw m-files implemented under the most recent release of matlab version 6.5 (and compared to the absence of such acceleration under the previous matlab version 6.1). finally, and in contrast to the combinatorial optimization task of identifying a best unidimensional scaling for a given proximity matrix, an approach is given for the confirmatory fitting of a given unidimensional scaling based only on a fixed object ordering, and to nonmetric unidensional scaling that incorporates an additional optimal monotonic transformation of the proximities. </content></document><document><year>2002</year><authors>Kohei Adachi </authors><title>optimal quantification of a longitudinal indicator matrix: homogeneity and smoothness analysis </title><content>nj;; by k that represents n individuals' choices among k categories over j time points. the row and column scores of this univariate data matrix cannot be chosen uniquely by any standard optimal scaling technique. to approach this difficulty, we present a regularized method, in which the scores of individuals over time points (i.e. row scores) are represented using natural cubic splines. the loss of their smoothness is combined with the loss of homeogeneity underlying the standard technique to form a penalized loss function which is minimized under a normalization constraint. a graphical representation of the resulting scores allows us easily to grasp the longitudinal changes in individuals. simulation analysis is performed to evaluate how well the method recovers true scores, and real data are analyzed for illustration. </content></document><document><year>2002</year><authors>Eric W  Holman </authors><title>the relation between folk and scientific classification of plants and animals </title><content>;;</content></document><document><year>2002</year><authors>Richard Desper </authors><title>tree fitting: topological recognition from ordinary least-squares edge length estimates </title><content>;;</content></document><document><year>2002</year><authors>William D  Shannon | Maciej Faifer | Michael A  Province  | D  C  Rao </authors><title>tree-based models for fiting stratified linear regression models </title><content>;;</content></document><document><year>2002</year><authors>Andreas Buja  | Deborah F  Swayne </authors><title>visualization methodology for multidimensional scaling </title><content>;; these uncertainties will be addressed by the following interactive techniques: (a) algorithm animation, random restarts, and manual editing of configurations, (b) interactive control over parameters that determine the criterion and its minimization, (c) diagnostics for pinning down artifactual point configurations, and (d) restricting mds to subsets of objects and subsets of pairs of objects. </content></document><document><year>2000</year><authors>Trevor F  Cox  | Michael A  A  Cox </authors><title>a general weighted two-way dissimilarity coefficient </title><content>;;</content></document><document><year>2000</year><authors> </authors><title>announcement </title><content>;;</content></document><document><year>2000</year><authors>P  Legendre </authors><title>biological applications of reticulation analysis </title><content>;;</content></document><document><year>2000</year><authors>J  A  Hartigan </authors><title>bloc voting in the united states senate </title><content>blocs;; and legislative measures are partitioned into types so that, as nearly as possible, votes by each bloc for each type of measure are either all yeas or all nays. a probability model is given for the partitions into blocs and types, and for the pattern of yeas and nays given the partitions. the alternating randomized combination algorithm is presented for searching for high probability partition pairs. the probability of each bloc and type in the final optimal partition pair is estimated by markov chain monte carlo. the final partition identifies 18 blocs of senators, and 14 types of legislative measures. the blocs and types are delineated in a table reporting all decisive votes in the 103rd congress. the blocs are characterized by the types of measures in which they vote against the majority party. </content></document><document><year>2000</year><authors>E A  Maharaj </authors><title>cluster of time series </title><content>p-value;; of the test that is applied to every pair of given time series. </content></document><document><year>2000</year><authors>G W  Milligan </authors><title>construction and assessment of classification rules, by d.j. hand </title><content>;;</content></document><document><year>2000</year><authors>Z Taran </authors><title>corrigendum to jain and dubes (1988) </title><content>;;</content></document><document><year>2000</year><authors> </authors><title>csna-2000 program </title><content>;;</content></document><document><year>2000</year><authors>Olivier Gascuel </authors><title>data model and classification by trees: the minimum variance reduction (mvr) method </title><content>o;;(n 4), where n is the number of objects. we describe the application of the mvr method to two data models: the weighted least-squares (wls) model (v is diagonal), where the mvr method can be reduced to an o(n 3) time complexity; a model arising from the study of biological sequences, which involves a complex non-diagonal v matrix that is estimated from the dissimilarity matrix &amp;#916;. for both models, we provide simulation results that show a significant error reduction in the reconstruction of t, relative to classical agglomerative algorithms. </content></document><document><year>2000</year><authors>R F  Potthoff | K G  Manton  | M A  Woodbury </authors><title>dirichlet generalizations of latent-class models </title><content>;;</content></document><document><year>2000</year><authors>F -J Lapointe </authors><title>how to account for reticulation events in phylogenetic analysis: a comparison of distance-based methods </title><content>;;</content></document><document><year>2000</year><authors>C  Hennig </authors><title>identifiablity of models for clusterwise linear regression </title><content>;; the model choice and the interpretation of the parameters are discussed as well as the use of the identifiability concept for fixed partition models. the concept is generalized to "partial identifiability". </content></document><document><year>2000</year><authors> </authors><title>index to volume 17 </title><content>;;</content></document><document><year>2000</year><authors>T J  Smith </authors><title>l 1 optimization under linear inequality constraints </title><content>1;; optimization under linear inequality constraints based upon iteratively reweighted iterative projection (or irip). irip is compared to a linear programming (lp) strategy for l1 minimization (spг¤th 1987, chapter 5.3) using the ultrametric condition as an exemlar class of constraints to be fitted. coded for general constraints, the lp approach proves to be faster. both methods, however, suffer from a serious limitation in being unable to process reasonably-sized data sets because of storage requirements for the constraints. when the simplicity of vector projections is used to allow irip to be coded for specific (in this case, ultrametric) constraints, we obtain a fast and efficient algorithm capable of handling large data sets. it is also possible to extend irip to operate as a heuristic search strategy that simultaneously identifies both a reasonable set of constraints to impose and the optimally-estimated parameters satisfying these constraints. a few noteworthy characteristics of l1 optimal ultrametrics are discussed, including other strategies for reformulating the ultrametric optimization problem. </content></document><document><year>2000</year><authors>M  Wedel  | T H A  Bijmolt </authors><title>mixed tree and spacial representations of dissimilarity judgments </title><content>;;</content></document><document><year>2000</year><authors>F J  Rohfl </authors><title>phylogenetic models and reticulations </title><content>;;</content></document><document><year>2000</year><authors>P Legendre </authors><title>reticulate evolution:from bacteria to philosopher </title><content>;;</content></document><document><year>2000</year><authors>P H A  Sneath </authors><title>reticulate evolution in bacteria and other organisms: how can we study it? </title><content>;;</content></document><document><year>2000</year><authors>P E  Smouse </authors><title>reticulation inside the species boundary </title><content>gene trees;; and species trees. we construct different lineage histories for different genes, in spite of the fact that intragenic recombination ensures that building a gene tree can become an exercise in averaging over disparate (and reticulating) segmental phylogenies. combining data across disparate gene trees leads to an average species tree, but whether that represents anything real is dubious. another ploy is to study mitochondrial and/or chloroplast genomes, confidently asserted to be inherited in strictly lineal fashion, without recombination. evidence is mounting, however, that even these organellar elements have recombination and that their phylogenies are reticulate. given the generally reticulate process of evolution at the subspecific level, we should model the collection of relationships more as a redundant and multiply connected network than as a strictly radiating phylogeny. </content></document><document><year>2000</year><authors> </authors><title>reviewers </title><content>;;</content></document><document><year>2000</year><authors>Yu  S  Kharin  | E  E  Zhuk </authors><title>robust classification of multinomial observations with possible outliers </title><content>;;</content></document><document><year>2000</year><authors>JГЎnos Podani </authors><title>simulation of random dendrograms and comparison tests: some comments </title><content>quasi;;-ultrametrics because they do not satisfy the identity axiom. the fifth descriptor considered is path difference which is not recommended for comparisons except for unrooted trees. correlations among dendrogram descriptors are evaluated through simulation experiments, and it is shown that the significance of dendrogram comparisons is greatly influenced by the choice of the descriptor. the paper emphasizes that choice of the underlying tree distribution to be used as a reference in testing significance of a dendrogram comparison measure should be consistent with the descriptor incorporated by that measure. </content></document><document><year>2000</year><authors>Patrick Doreian | Vladimir Batagelj  | Anuska Ferligoj </authors><title>symmetric-acyclic decompositions of networks </title><content>;;</content></document><document><year>2000</year><authors>Phipps Arabie</authors><title>tribute to lynn bilger </title><content>;;</content></document><document><year>2000</year><authors>M J  Brusco  | S  Stahl</authors><title>using quadratic assignment methods to generate initial permutations for least-squares unidimensional scaling of symmetric proximity matrices </title><content>;;</content></document><document><year>1998</year><authors>Michael W  Trosset </authors><title>a new formulation of the nonmetric strain problem in multidimensional scaling </title><content>abstract;; a natural extension of classical metric multidimensional scaling is proposed. the result is a new formulation of nonmetric multidimensional scaling in which the strain criterion is minimized subject to order constraints on the disparity variables. innovative features of the new formulation include: the parametrization of the p-dimensional distance matrices by the positive semidefinite matrices of rank &amp;#8804;p; optimization of the (squared) disparity variables, rather than the configuration coordinate variables; and a new nondegeneracy constraint, which restricts the set of (squared) disparities rather than the set of distances. solutions are obtained using an easily implemented gradient projection method for numerical optimization. the method is applied to two published data sets. </content></document><document><year>1998</year><authors>Kin-nam Lau | Pui Lam Leung  | Ka-kit Tse </authors><title>a nonlinear programming approach to metric unidimensional scaling </title><content>abstract;; classical unidimensional scaling provides a difficult combinatorial task. a procedure formulated as a nonlinear programming (nlp) model is proposed to solve this problem. the new method can be implemented with standard mathematical programming software. unlike the traditional procedures that minimize either the sum of squared error (l 2 norm) or the sum pf absolute error (l 1 norm), the proposed method can minimize the error based on any l p norm for 1 &amp;#8804;p &amp;lt; &amp;#8734;. extensions of the nlp formulation to address a multidimensional scaling problem under the city-block model are also discussed. </content></document><document><year>1998</year><authors>Marek Ancukiewicz </authors><title>an unsupervised and nonparametric classification procedure based on mixtures with known weights </title><content>abstract;; i consider a new problem of classification into n(n &amp;#8805; 2) disjoint classes based on features of unclassified data. it is assumed that the data are grouped into m(m &amp;#8805; n) disjoint sets and within each set the distribution of features is a mixture of distributions corresponding to particular classes. moreover, the mixing proportions should be known and form a matrix of rank n. the idea of solution is, first, to estimate feature densities in all the groups, then to solve the linear system for component densities. the proposed classification method is asymptotically optimal, provided a consistent method of density estimation is used. for illustration, the method is applied to determining perfusion status in myocardial infarction patients, using creatine kinase measurements. </content></document><document><year>1998</year><authors>R W  Payne </authors><title>construction of efficient identification schemes using batches of discrete-valued tests </title><content>abstract;; well established methods are available for identifying a specimen from a known set of taxa by applying either a single set of tests, or a hierarchical sequence of single tests. these are relevant respectively when the cost of the tests or the time required for identification is most important. often, however, a mixed strategy is required which aims to reduce the cost of identification while avoiding taking too much time. methods are derived for constructing efficient identification schemes which involve the sequential use of batches of tests. also, the special case is considered where an initial batch of tests is used, followed by a second batch whose composition depends on the results observed for the initial batch. </content></document><document><year>1998</year><authors>Bernard Van Cutsem  | Bernard Ycart </authors><title>indexed dendrograms on random dissimilarities </title><content>abstract;; this paper studies the random indexed dendograms produced by agglomerative hierarchical algorithms under the non-classifiability hypothesis of independent identically distributed (i.i.d.) dissimilarities. new tests for classifiability are deduced. the corresponding test statistics are random variables attached to the indexed dendrograms, such as the indices, the survival time of singletons, the value of the ultrametric between two given points, or the size of classes in the different levels of the dendogram. for an indexed dendogram produced by the single link method on i.i.d. dissimilarities, the distribution of these random variables is computed, thus leading to explicit tests. for the case of the average and complete link methods, some asymptotic results are presented. the proofs rely essentially on the theory of random graphs. </content></document><document><year>1998</year><authors>Henk A L  Kiers </authors><title>joint orthomax rotation of the core and component matrices resulting from three-mode principal components analysis </title><content>abstract;; the analysis of a three-way data set using three-mode principal components analysis yields component matrices for all three modes of the data, and a three-way array called the core, which relates the components for the different modes to each other. to exploit rotational freedom in the model, one may rotate the core array (over all three modes) to an optimally simple form, for instance by three-mode orthomax rotation. however, such a rotation of the core may inadvertently detract from the simplicity of the component matrices. one remedy is to rotate the core only over those modes in which no simple solution for the component matrices is desired or available, but this approach may in turn reduce the simplicity of the core to an unacceptable extent. in the present paper, a general approach is developed, in which a criterion is optimized that not only takes into account the simplicity of the core, but also, to any desired degree, the simplicity of the component matrices. this method (in contrast to methods for either core or component matrix rotation) can be used to find solutions in which the core and the component matrices are all reasonably simple. </content></document><document><year>1998</year><authors>David Banks  | G M  Constantine </authors><title>metric models for random graphs </title><content>abstract;; many problems entail the analysis of data that are independent and identically distributed random graphs. useful inference requires flexible probability models for such random graphs; these models should have interpretable location and scale parameters, and support the establishment of confidence regions, maximum likelihood estimates, goodness-of-fit tests, bayesian inference, and an appropriate analogue of linear model theory. banks and carley (1994) develop a simple probability model and sketch some analyses; this paper extends that work so that analysts are able to choose models that reflect application-specific metrics on the set of graphs. the strategy applies to graphs, directed graphs, hypergraphs, and trees, and often extends to objects in countable metric spaces. </content></document><document><year>1998</year><authors>Pierre Hansen | Brigitte Jaumard  | Nenad Mladenovic </authors><title>minimum sum of squares clustering in a low dimensional space </title><content>abstract;; clustering with a criterion which minimizes the sum of squared distances to cluster centroids is usually done in a heuristic way. an exact polynomial algorithm, with a complexity in o(n p+1 logn), is proposed for minimum sum of squares hierarchical divisive clustering of points in a p-dimensional space with small p. empirical complexity is one order of magnitude lower. data sets with n = 20000 for p = 2, n = 1000 for p = 3, and n = 200 for p = 4 are clustered in a reasonable computing time. </content></document><document><year>1998</year><authors>Michel Wedel | Frenkel ter Hofstede  | Jan-Benedict E M  Steenkamp </authors><title>mixture model analysis of complex samples </title><content>abstract;; we investigate the effects of a complex sampling design on the estimation of mixture models. an approximate or pseudo likelihood approach is proposed to obtain consistent estimates of class-specific parameters when the sample arises from such a complex design. the effects of ignoring the sample design are demonstrated empirically in the context of an international value segmentation study in which a multinomial mixture model is applied to identify segment-level value rankings. the analysis reveals that ignoring the sample design results in both an incorrect number of segments as identified by information criteria and biased estimates of segment-level parameters. </content></document><document><year>1998</year><authors>A D  Gordon  | M  Vichi </authors><title>partitions of partitions </title><content>abstract;; the paper presents methodology for analyzing a set of partitions of the same set of objects, by dividing them into classes of partitions that are similar to one another. two different definitions are given for the consensus partition which summarizes each class of partitions. the classes are obtained using either constrained or unconstrained clustering algorithms. two applications of the methodology are described. </content></document><document><year>1998</year><authors>Thaddeus Tarpey </authors><title>self-consistent patterns for symmetric multivariate distributions </title><content>abstract;; the set of k points that optimally represent a distribution in terms of mean squared error have been called principal points (flury 1990). principal points are a special case of self-consistent points. any given set of k distinct points in r p induce a partition of r p into voronoi regions or domains of attraction according to minimal distance. a set of k points are called self-consistent for a distribution if each point equals the conditional mean of the distribution over its respective voronoi region. for symmetric multivariate distributions, sets of self-consistent points typically form symmetric patterns. this paper investigates the optimality of different symmetric patterns of self-consistent points for symmetric multivariate distributions and in particular for the bivariate normal distribution. these results are applied to the problem of estimating principal points. </content></document><document><year>1998</year><authors>W J  Krzanowski </authors><title>subspace projection for multivariate selection problems </title><content>abstract;; a new set of derived variables is proposed for exhibiting grouped multivariate data in a small number of dimensions, in such a way as to highlight `extremeness' of one or more groups relative to the rest of the data. such display can provide a useful exploratory tool in multivariate ranking and selection problems. we explore four possible measures of `extremeness', and suggest which one is best for practical application. we show that the technique can be used to derive either orthogonal or uncorrelated dimensions for any type of input data, and we give an illustrative example of its use. </content></document><document><year>1998</year><authors>Fionn Murtagh </authors><title>wedding the wavelet transform and multivariate data analysis </title><content>abstract;; we discuss the use of orthogonal wavelet transforms in preprocessing multivariate data for subsequent analysis, e.g., by clustering the dimensionality reduction. wavelet transforms allow us to introduce multiresolution approximation, and multiscale nonparametric regression or smoothing, in a natural and integrated way into the data analysis. as will be explained in the first part of the paper, this approach is of greatest interest for multivariate data analysis when we use (i) datasets with ordered variables, e.g., time series, and (ii) object dimensionalities which are not too small, e.g., 16 and upwards. in the second part of the paper, a different type of wavelet decomposition is used. applications illustrate the powerfulness of this new perspective on data analysis. </content></document><document><year>2005</year><authors>F  B  Baulieu </authors><title>a classification of presence/absence based dissimilarity coefficients</title><content>abstract;;several desirable order properties for dissimilarity coefficients based on presence/absence of attributes are given and several popular dissimilarity coefficients are examined with respect to these properties. a characterization for rational functions with linear numerator and linear denominator satisfying all of the desirable properties is given.</content></document><document><year>2005</year><authors>W  J  Krzanowski </authors><title>a comparison between two distance-based discriminant principles</title><content>abstract;;a distance-based classification procedure suggested by matusita (1956) has long been available as an alternative to the usual bayes decision rule. unsatisfactory features of both approaches when applied to multinomial data led goldstein and dillon (1978) to propose a new distance-based principle for classification. we subject the goldstein/dillon principle to some theoretical scrutiny by deriving the population classification rules appropriate not only to multinomial data but also to multivariate normal and mixed multinomial/multinormal data. these rules demonstrate equivalence of the goldstein/dillon and matusita approaches for the first two data types, and similar equivalence is conjectured (but not explicitly obtained) for the mixed data case. implications for sample-based rules are noted.</content></document><document><year>2005</year><authors>Edward K  Brown |   | William H  E  Day |  </authors><title>a computationally efficient approximation to the nearest neighbor interchange metric</title><content>abstract;;the nearest neighbor interchange (nni) metric is a distance measure providing a quantitative measure of dissimilarity between two unrooted binary trees with labeled leaves. the metric has a transparent definition in terms of a simple transformation of binary trees, but its use in nontrivial problems is usually prevented by the absence of a computationally efficient algorithm. since recent attempts to discover such an algorithm continue to be unsuccessful, we address the complementary problem of designing an approximation to the nni metric. such an approximation should be well-defined, efficient to compute, comprehensible to users, relevant to applications, and a close fit to the nni metric; the challenge, of course, is to compromise these objectives in such a way that the final design is acceptable to users with practical and theoretical orientations. we describe an approximation algorithm that appears to satisfy adequately these objectives. the algorithm requires o(n) space to compute dissimilarity between binary trees withn labeled leaves; it requires o(n logn) time for rooted trees and o(n2 logn) time for unrooted trees. to help the user interpret the dissimilarity measures based on this algorithm, we describe empirical distributions of dissimilarities between pairs of randomly selected trees for both rooted and unrooted cases.</content></document><document><year>2005</year><authors>Henk A  L  Kiers  | Yoshio Takane </authors><title>a generalization of gipscal for the analysis of nonsymmetric data</title><content>abstract;;graphical representation of nonsymmetric relationships data has usually proceeded via separate displays for the symmetric and the skew-symmetric parts of a data matrix. dedicom avoids splitting the data into symmetric and skewsymmetric parts, but lacks a graphical representation of the results. chino's gipscal combines features of both models, but may have a poor goodness-of-fit compared to dedicom. we simplify and generalize chino's method in such a way that it fits the data better. we develop an alternating least squares algorithm for the resulting method, called generalized gipscal, and adjust it to handle gipscal as well. in addition, we show that generalized gipscal is a constrained variant of dedicom and derive necessary and sufficient conditions for equivalence of the two models. because these conditions are rather mild, we expect that in many practical cases dedicom and generalized gipscal are (nearly) equivalent, and hence that the graphical representation from generalized gipscal can be used to display the dedicom results graphically. such a representation is given for an illustration. finally, we show generalized gipscal to be a generalization of another method for joint representation of the symmetric and skew-symmetric parts of a data matrix.</content></document><document><year>2005</year><authors>Stephen L  Bieber </authors><title>a hierarchical approach to multigroup factorial invariance</title><content>abstract;;a procedure is presented which permits the analysis of factor analytic problems in which several groups exist. the analysis incorporates a hierarchical scheme of searching for factorial invariance and is an extension of meredith's (1964) method one procedure. by overlaying a contextual frame of reference on a traditional factor analysis solution, it is possible to use this technique to examine structural similarity and dissimilarity between groups. the procedure is exhibited in an example and in addition a comparison is made to discriminant analysis.</content></document><document><year>2005</year><authors>a hierarchical methodology for class detection problems with skewed Priors</authors><title>abstract;;we describe a novel extension to the class-cover-catch-digraph (cccd)classifier, specifically tuned to detection problems. these are two-class classificationproblems where the natural priors on the classes are skewed by several orders of magnitude.the emphasis of the proposed techniques is in computationally efficient classificationfor real-time applications. our principal contribution consists of two boosted classi-fiers built upon the cccd structure, one in the form of a sequential decision process andthe other in the form of a tree. both of these classifiers achieve performances comparableto that of the original cccd classifiers, but at drastically reduced computational expense.an analysis of classification performance and computational cost is performed using datafrom a face detection application. comparisons are provided with support vector machines(svm) and reduced svms. these comparisons show that while some svms mayachieve higher classification performance, their computational burden can be so high as tomake them unusable in real-time applications. on the other hand, the proposed classifierscombine high detection performance with extremely fast classification.</title><content/></document></documents>