<?xml version="1.0" encoding="UTF-8" standalone="no"?><documents><document><year>2004</year><authors>A. A. Gusev1| N. A. Chekanov2| V. A. Rostovtsev1| S. I. Vinitsky1  | Y. Uwano3</authors><title>A Comparison of Algorithms for the Normalization and Quantization of Polynomial Hamiltonians</title><content>Algorithms and programs for the normalization of polynomial Hamiltonians of classical mechanics by the Birkhoff&amp;#x2013;Gustavson and Deprit&amp;#x2013;Hori, as well as quasi-classical quantization procedures for normal forms, are compared. The algorithms and programs are represented in a universal pseudocode and implemented in the computer algebra systems REDUCE, MAPLE, and MATHEMATICA. Examples that illustrate the operation of these algorithms and programs for polynomial Hamiltonians of atomic systems in external electromagnetic fields are considered.</content></document><document><year>2004</year><authors>D. A. Volkov1 </authors><title>A Concept of a Universal Server for the Client&amp;#x2013;Server Architecture</title><content>Without Abstract</content></document><document><year>2004</year><authors>G. V. Borisenko1 | A. M. Denisov1  | A. S. Krylov1 </authors><title>A Diffusion Filtering Method for Image Processing</title><content>A new diffusion method for image filtering based on incorporating an integral of image intensity over a point neighborhood into the diffusion coefficient is suggested. The efficiency of the method is illustrated on a number of test images.</content></document><document><year>2004</year><authors>A. M. Frolov1 </authors><title>A Hybrid Approach to Enhancing the Reliability of Software</title><content>Two approaches to enhancing the reliability and security of software&amp;#x2014;static analysis of the source code and dynamic protection&amp;#x2014;are compared. Advantages and disadvantages of these approaches are discussed. A hybrid approach to enhancing the reliability of software is suggested that combines advantages of both methods and smoothes over their drawbacks. A classification of dynamic protection systems is presented in terms of the time of their operation, abstraction level at which modifications are introduced and the protection code operates, and principles of protection. A pragmatic approach to the development and evolution of an algorithm for finding errors of a certain class in the source code that result in reducing the reliability or security of the system is described. The algorithm calculates an approximation of the exact solution (the set of dangerous fragments), and every next version of the algorithm improves the approximation to the exact solution. At each stage, the hybrid algorithm is used: when the static analysis cannot decide whether there are errors or not, the task of preventing the effects of possible errors is entrusted to the dynamic protection system. The iterative improvement of the algorithm has two purposes: to reduce the number of false alerts and to reduce the workload on the dynamic protection system. Application of the approach to a class of errors reducing the security of software is considered.</content></document><document><year>2004</year><authors>S. V. Bakhanovich1  | N. A. Likhoded1 </authors><title>A Method for Parallelizing Algorithms by Vector Scheduling Functions</title><content>A technique for parallelizing multidimensional algorithms with uniform dependencies designed for the implementation on parallel architectures of smaller dimensionalities is suggested. The technique is based on multidimensional separate scheduling of the basic operations of the algorithm. A procedure for the construction of a scheduling (parallelizing) function on the basis of theoretical results is suggested.</content></document><document><year>2004</year><authors>V. V. Mazalov1  | D. N. Zhuravlev1 </authors><title>A Method of Cumulative Sums in the Problem of Detection of Traffic Changes in Computer Networks</title><content>The problem of tastest finding the moments when the exponential parameter of the Pareto distribution is changed is solved by applying the method of cumulative sums. Analytical expressions for basic characteristics of the method&amp;#x2014;the average time of delay of the determination of the change-point and the average time between two incorrect determinations&amp;#x2014;are derived. An algorithm of detection of variations in the traffic in a computer network is developed.</content></document><document><year>2004</year><authors>V. V. Kornyak1 </authors><title>A Method of Splitting Cochain Complexes for Computing Cohomology: Lie Algebra of Hamiltonian Vector Fields H(2|0)</title><content>Computation of homology or cohomology is inherently a problem of high combinatorial complexity. Recently, we have proposed a new algorithm for computing cohomology of Lie (super)algebras. This algorithm is based on splitting a complete cochain complex into minimal subcomplexes. The algorithm is implemented in C as a program LieCohomology. This paper presents results of computation of cohomology in a trivial module for a Lie algebra of Hamiltonian vector fields H(2|0). We demonstrate that the new approach is much more efficient than the traditional one. In particular, we have revealed some new cohomology classes for the H(2|0) algebra and the related Lie algebra of the Poisson vector fields Po(2|0).</content></document><document><year>2004</year><authors>V. V. Kornyak1 </authors><title>A Method of Splitting Cochain Complexes to Compute Cohomologies of Lie (Super)algebras</title><content>A new algorithmic approach for computing cohomologies of Lie (super)algebras is described. This approach is based on splitting a complete cochain complex into minimal (in some noninvariant sense) subcomplexes; this makes the computations much more efficient due to the fact that the proposed splitting allows the cochain complex spaces (which, normally, have very large dimensions) to be decomposed into much smaller subspaces. The algorithms in a pseudocode are presented. The approach is illustrated by comprehensive examples.</content></document><document><year>2004</year><authors>V. V. Lipaev1</authors><title>A Methodology of Verification and Testing of Large Software Systems</title><content>Without Abstract</content></document><document><year>2004</year><authors>V. V. Prokhorov1  | D. V. Smirnov1 </authors><title>A Model of Estimation and Optimization of Expenditures in Multilevel Fuzzy Environments</title><content>A model for estimation and optimization of expenditures in complex, multilevel, multilanguage, fuzzy environments based of expert assessments is described. The model makes it possible to choose an optimal set of resources required for solving the problem. Aspects of probability-theoretic interpretation of the approach under uncertain resources are considered. The approach is extended to the fuzzy case. An illustrative example is considered.</content></document><document><year>2004</year><authors>V. V. Kornyak1 </authors><title>A Modular Algorithm for Computing Cohomologies of Lie Algebras and Superalgebras</title><content>The paper describes an improved algorithm for computing cohomologies of Lie (super)algebras. The original algorithm developed earlier by the author of this paper is based on the decomposition of the entire cochain complex into minimal subcomplexes. The suggested improvement consists in the replacement of the arithmetic of rational or integer numbers by a more efficient arithmetic of modular fields and the use of the relationship dim Hk(p)  dimHk() between the dimensions of cohomologies over an arbitrary modular field p = /p and the filed of rational numbers . This inequality allows us to rapidly find subcomplexes for which dimHk(p) &amp;gt; 0 (the number of such subcomplexes is usually not great) using computations over an arbitrary p and, then, carry out all required computations over  in these subcomplexes.</content></document><document><year>2004</year><authors>R. I. Podlovchenko1  | V. E. Khachatryan2 </authors><title>A New Approach to Solving Equivalence Problem</title><content>An application of a new method for the equivalence recognition in a computation model whose objects are labeled directed graphs is illustrated by the example of multitape automata. The paper is focused on general ideas of the method discussed. An algorithm that recognizes equivalence of multitape automata with disjoint loops is described in detail.</content></document><document><year>2004</year><authors>N. V. Sveshnikova1 | D. V. Yurin2 </authors><title>A Priori and A Posteriori Error Estimates in Recovery of 3D Scenes by Factorization Algorithms</title><content>Many various algorithms for recovering three-dimensional scenes from a set of digital images have currently been developed. For certain scenes and shooting conditions, some algorithms give nice results, whereas others produce unacceptable results. In this paper, for a group of algorithms based on the matrix factorization, criteria are derived that make it possible, (a) by known statistical characteristics of the scene and shooting conditions, to predict whether a given algorithm can be used in the given case and, if it can, to determine the expected accuracy, (b) when recovering an unknown scene, to compute not only the desired results but also their accuracy (authenticity). A modification of the algorithm based on the adaptive selection of the approximation is suggested. Experimental verification of the criteria and estimates obtained showed their high efficiency and reliability.</content></document><document><year>2004</year><authors>A. P. Shibanov1 </authors><title>A Software Implementation Technique for Simulation of Ethernet Local Area Networks</title><content>A software system designed for simulating Ethernet, Fast Ethernet, and Gigabit Ethernet local area networks (LAN) is described. Implementation-specific features of programs simulating the operation of switch-based full-duplex and half-duplex networks are considered. A subsystem for simulating the stochastic behavior of programs based on full-duplex LAN protocols is described.</content></document><document><year>2004</year><authors>A. A. Gusev1 | V. N. Samoilov1 | V. A. Rostovtsev1  | S. I. Vinitsky1 </authors><title>Algebraic Perturbation Theory for Hydrogen Atom in Weak Electric Fields</title><content>An algorithm for symbolic calculation of eigenvalues and eigenfunctions of a hydrogen atom in weak electric fields is suggested. A perturbation theory scheme is constructed that is based on an irreducible infinite-dimensional representation of algebra so(4, 2) of the group of dynamical symmetry for the hydrogen atom [1]. The scheme implementation does not rely on the assumption that the independent variables of the perturbation operator can be separated, and fractional powers of parabolic quantum numbers are not used in the recurrent relations determining the operation of algebra generators on the corresponding basis of the irreducible representation [2]. A seventh-order correction to the energy spectrum of the hydrogen atom in a uniform electric field is given. The algorithm suggested is implemented in REDUCE 3.6 [4].</content></document><document><year>2004</year><authors>A. V. Zamulin1 </authors><title>Algebraic Semantics of an Imperative Programming Language</title><content>Without Abstract</content></document><document><year>2004</year><authors>L. V. Gorodnyaya1 | D. V. Irtegov1 | N. N. Nepeivoda1 | I. V. Pottosin1  | T. G. Churina1 </authors><title>All-Siberian Open Olympiad in Programming (Novosibirsk State University)</title><content>Without Abstract</content></document><document><year>2004</year><authors>A. V. Zamulin1 </authors><title>An Abstract Compiler Model as a Result of the Algebraic Semantics of a Programming Language</title><content>Without Abstract</content></document><document><year>2004</year><authors>M. V. Sosnin1</authors><title>An Algorithm for Nonparametric Decomposition of Differential Polynomials</title><content>Last decades, one of the most important problems of symbolic computations (see [7]) is the development of algorithms for solving algebraic and differential equations, in particular, those for factoring linear ordinary differential operators (LODO) [1&amp;#x2013;4]. In this paper, the problems of LODO factorization and decomposition of ordinary polynomials [5, 6] are generalized: an algorithm is proposed for decomposition of differential polynomials that allows one to find a particular solution to a complex algebraic differential equation (an example is provided in the end of the paper).</content></document><document><year>2004</year><authors>A. Zamulin1 </authors><title>An ASM-based Formal Model of a Java Program</title><content>Without Abstract</content></document><document><year>2004</year><authors>B. Kh. Barladian1 | A. G. Voloboi1 | V. A. Galaktionov1  | E. A. Kopylov1 </authors><title>An Effective Tone Mapping Operator for High Dynamic Range Images</title><content>Tone mapping operators are used to compress a large range of pixel luminances into a smaller range, which can be displayed on a monitor screen. In this paper, an effective and easy-to-use tone mapping operator based on the latest ideas developed in this field is presented. The parameter estimation process relies on the sampling method. Special attention is given to the robustness of the algorithm for the parameter estimation. The suggested tone mapping operator ensures good quality of images and almost does not require manual parameter tuning.</content></document><document><year>2004</year><authors>A. Ya. Kalinov1  | I. N. Ledovskikh1 </authors><title>An Extension of Fortran for High Performance Parallel Computing</title><content>The mpF programming language, which is an extension of Fortran 90 for parallel systems with distributed memory, is described. This language was developed using the expertise obtained in the application and evolution of the mpC programming language. mpF is based on the explicit parallelism approach and is an attempt to find a compromise between the efficiency and expressive power on the one hand and the convenience of use on the other hand. Basic concepts of the language are outlined. The efficiency of programs written in mpF and in C with the calls of MPI functions is compared.</content></document><document><year>2004</year><authors>J.-C. Royer1 </authors><title>An Operational Approach to the Semantics of Classes: Application to Type Checking</title><content>This paper presents a simple and natural semantics for object-oriented languages with classes and multiple inheritance. The model, called the Formal Class model, is an intermediate level between the algebraic specification of data type, and the implementation within an object-oriented language. Our model is equipped with an operational semantics based on conditional term rewriting. One important characteristic is the use of conditional selectors. It allows one to define a type with a flat or an ordered design. In this context, we define a safe and simple type system with single dispatch and simply covariant methods. This type system is extended to some practical aspects, such as abstract classes, abstract methods, protected methods, and super methods. We describe and compare flat and ordered designs and prove that the latter is finer than the former one. We also look at multicovariant methods and show ways to fix type-checking problems using single dispatch. We describe the least pessimistic solution. Lastly, we discuss the extension of our type checking to multiple dispatch and side effects. This paper synthesizes several practical results, their proofs, and algorithms.</content></document><document><year>2004</year><authors>D. L. Uvarov1</authors><title>An Optimal Algorithm for Purging Regular Schemes</title><content>A joint application of four optimizing transformations for purging imperative programs&amp;#x2014;elimination of useless statements, unwinding of degenerate loops, removal from loops, and removal from branch statements&amp;#x2014;is considered. A model of regular schemes is introduced in terms of which the transformations and their context conditions are formulated. In the class of regular schemes, a subclass of irredundant schemes, which correspond to program fragments without redundant calculations, is separated. For the irredundant schemes, the context conditions of the transformations for removal from loops and branch statements are formulated, which are simpler than the standard context conditions. Algorithms for the elimination of useless statements, unwinding of degenerate loops, and removal from loops and hammocks are described. The correctness of the algorithms constructed is noted, and estimates of the time and memory required for their operation are given. The algorithms are shown to be optimal in terms of the number of the transformations used: the algorithms of elimination of useless statements and unwinding of degenerate loops are optimal in the whole class of regular schemes, and the algorithm of removal from loops and hammocks is optimal in the class of irredundant schemes without degenerate subloops. The practical implementation of the algorithms constructed is described.</content></document><document><year>2004</year><authors>G. Shukovich1 </authors><title>Application of Genetic Algorithms and Systems of Generating Graphs for Creation of Modular Neural Networks</title><content>There are many methods based on joint use of genetic algorithms and neural networks. In the majority of these methods, the architecture of the network and/or its weights are coded into chromosomes directly, which results in a huge number of chromosomes and increases their dimensions. From this point of view, methods based on coding rules that generate networks are highly promising. In this paper, a method of creation of architectures of modular neural networks based on the use of grammatical systems for fractal generation is considered. Genetic algorithms are used as an optimizer of the neural architectures obtained.</content></document><document><year>2004</year><authors>F. Clauss1| 2  | I. Yu. Chupaeva3 </authors><title>Application of Symbolic Approach to the Bernstein Expansion for Program Analysis and Optimization</title><content>Mathematical packages for static analysis of programs have recently been developed. Although these packages are widely used, they have a number of limitations. In particular, they do not support multivariate polynomials with integer coefficients, which are often met in programs and used for the analysis of systems. Some methods to overcome this difficulty have already been suggested, but, unfortunately, they can be applied to only a subclass of such expressions. In this paper, we suggest a more general approach based on the Bernstein expansion, which facilitates the analysis of integer multivariate polynomials.</content></document><document><year>2004</year><authors>V. V. Kislenkov1 </authors><title>Approaches to Expedite Function Computation on Dense Grids</title><content>The problem of function computation on dense grids is considered. Two approaches to expedite such computations are described: the use of base points and the adjustment of the computational method to certain interval of argument values. Implementations of the suggested algorithms can be integrated into modern computer algebra systems. Results of experiments on the Pentium II architecture are presented.</content></document><document><year>2004</year><authors>P. Bellini1 | M. Buonopane1  | P. Nesi1 </authors><title>Assessment of a Flexible Architecture for Distributed Control*</title><content>Production pipelines of manufactory industries present several machines and robots in which the movements of interpolated axes are managed by computerized numerical controls (CNCs). These are typically synchronized with several other simpler actuators along the pipeline of production. CNCs have to be flexible, easily expandable, and reusable, when pipelines of production are frequently reconfigured to realize different arranged pipelines with different technical requirements. In this paper, the assessment of a flexible CNC for such reconfigurable pipelines is presented. The analysis has been focused on defining objective metrics that can be applied for assessing performance and feasibility of distributed controls for pipelines. The method proposed has been applied on the distributed control architecture defined in the MUPAAC ESPRIT HPCN (Multi Processor Architecture for Automatic Control, High Performance Computer Networking of the European Commission). MUPAAC architecture and prototype has been assessed in order to identify the critical configurations and the limits of the architecture.</content></document><document><year>2004</year><authors>D. Yu. Buryak1 | Yu. V. Vizil'ter2 </authors><title>Automated Construction of Identification Procedures for Objects Belonging to Several Classes</title><content>Automated approaches to the choice and tuning of image analysis algorithms for solving a particular problem are considered. A new automated method for the construction of near-optimal object identification procedures is described. The objects to be identified can belong to several classes. The identification is based on reference images of those objects and uses a learning sample of images. The construction of the desired procedure assumes that it is selected from a set of procedures detecting the given object. This set is formed by the reference image of the object and uses algorithms of certain predefined types. The selection procedure is based on a genetic algorithm described in the paper.</content></document><document><year>2004</year><authors>A. S. Kossatchev1| P. Kutter2  | M. A. Posypkin1</authors><title>Automated Generation of Strictly Conforming Tests Based on Formal Specification of Dynamic Semantics of the Programming Language</title><content>A technique for an automated test generation for compilers, which is based on formal specifications of the programming language, is suggested. The technique makes it possible to generate tests correct from the dynamic semantics standpoint that do not depend on specific features (undefined or implementation-specific) of the semantics (the so-called strictly conforming tests). The application of the suggested technique to generating tests for C compilers is discussed in detail. For this purpose, a subset of C is defined the semantics of which, first, does not depend on the above-mentioned specific features and, second, possesses properties of type soundness and determinism, which guarantee the correct test execution for any implementation satisfying the C standard.</content></document><document><year>2004</year><authors>S. K. Chernonozhkin1 </authors><title>Automated Test Generation and Static Analysis</title><content>The study and development of techniques for automated generation of useful tests, the development of a system that implements those techniques, and the development of methods for the analysis of programs designed for solving this problem are based on the earlier works of the author of the present paper, the works by B. Korel, and on the desire to understand if the approaches suggested can be used to develop real-world software. The first problem is as follows: determine, which information on the program must be collected to automatically generate a set of tests, and develop a component for collecting this information. The emphasis was made on collecting this information statically using a powerful flow analyzer developed in a laboratory of the Institute of Information Systems. Another problem consists in developing a prototype system for trying both well-known and new test generation methods suggested by the author. As a result, path-oriented and objective-oriented methods of test generation and the chaining approach (which turned out to be the most interesting one) are considered. This approach uses the concept of influence of an input variable on an operator along a certain program execution path and is based on dynamic analysis. The concept of influence can be extended for the case of all paths; then, such influences can be detected statically. In this paper, the influence along any path is rigorously defined and its constructive flow reformulation is given. On the basis of this reformulation, a language processor is developed that performs a static analysis of dependencies and calculates, for every statement of the program, the set of input variables that influence it.</content></document><document><year>2004</year><authors>S. V. Coox1 </authors><title>Axiomatization of the Evolution of XML Database Schema</title><content>Database schema consists of constructs that model relationships between its entities. Changes made to the schema with time are called the schema evolution. An axiomatic model of the XML database schema is suggested that automatically maintains its integrity when basic changes are made to the schema. A classification of changes is described.</content></document><document><year>2004</year><authors>D. E. Khmelnov1 </authors><title>Basis Selection in Solving Linear Functional Equations</title><content>Search for polynomial and series solutions of linear functional (differential, difference, and q-difference) equations can be based on solving induced recurrences for coefficients of formal series in certain bases. It is shown in the paper that, for every operator type, different bases can be selected, with some of them being more preferable from the practical standpoint.</content></document><document><year>2004</year><authors>A. G. Voloboi1 | V. A. Galaktionov1 | K. A. Dmitriev1  | E. A. Kopylov1 </authors><title>Bidirectional Ray Tracing for the Integration of Illumination by the Quasi-Monte Carlo Method</title><content>Algorithms used to generate physically accurate images are usually based on the Monte Carlo methods for the forward and backward ray tracing. These methods are used to numerically solve the light energy transport equation (the rendering equation). Stochastic methods are used because the integration is performed in a high-dimensional space, and the convergence rate of the Monte Carlo methods is independent of the dimension. Nevertheless, modern studies are focused on quasi-random samples that depend on the dimension of the integration space and make it possible to achieve, under certain conditions, a high rate of convergence, which is necessary for interactive applications. In this paper, an approach to the development of an algorithm for the bidirectional ray tracing is suggested that reduces the overheads of the quasi-Monte Carlo integration caused by the high effective dimension and discontinuity of the integrand in the rendering equation. The pseudorandom and quasi-random integration methods are compared using the rendering equations that have analytical solutions.</content></document><document><year>2004</year><authors>L. G. Novak1  | S. D. Kuznetsov1 </authors><title>Canonical Forms of XML Schemas</title><content>This paper studies certain transformations of XML schemas, which are widely used in algorithms of the XML data management. In view of the fact that properties and functional characteristics of the XML documents considerably differ from those of data of other type, the solutions of a number of typical data management problems (such as the XML data validation, schema inference, and data translation to/from other models) for them are more complicated. The general idea of our approach to solving these problems is to transform the original structure (i.e., structural schema constraints) into another structure without loss of information about properties of the original data that are important for applications. The suggested technique has been successfully used in various algorithms for solving problems of this kind. In this paper, a systematic approach to solving these problems is discussed. Methods for reducing the XML schemas to several canonical forms are presented, and algorithms of solving the management problems for data satisfying schemas represented in the canonical forms are examined.</content></document><document><year>2004</year><authors>V. L. Arlazarov1| A. S. Loginov2  | O. A. Slavin1</authors><title>Characteristics of Optical Text Recognition Programs</title><content>Characteristics of optical recognition programs are described from the standpoint of typical recognition program modules. Not only quality criteria for the separate character recognition but also parameters of other important stages of document input, such as character boundary segmentation, binarization, page segmentation, and storing results, are discussed in detail. The set of characteristics presented can be used for the optimization of both separate recognition stages and the whole process of document input.</content></document><document><year>2004</year><authors>A. I. Ovchinnikov1 </authors><title>Characterizable Radical Differential Ideals and Some Properties of Characteristic Sets</title><content>In this paper, the characterizability of radical differential ideals is discussed and the characterizability criterion for them is proved. This criterion is based on the known algorithm for decomposing a radical differential ideal into characterizable components. The inclusion problem is also considered, in the light of which the algorithm for minimal characteristic decomposition of principal ideals is discussed. This algorithm is improved by using the proven characterizability criterion. Differential and algebraic properties of autoreduced sets are discussed, and the structure of differential chains and characteristic sets of radical differential ideals is revealed. The corresponding algorithms are constructed and discussed.</content></document><document><year>2004</year><authors>A. Ya. Kalinov1| A. L. Lastovetsky1| I. N. Ledovskikh1 | M. A. Posypkin1</authors><title>Compilation of Vector Statements of C[] Language for Architectures with Multilevel Memory Hierarchy</title><content>In the paper, the use of tiling for compilation of reduction statements in the C[] language is considered. A class of statements is distinguished for which the tiling transformation is proven to be correct and a scheme of their transformation to a sequence of reduction statements of a wide class is given. On the basis of a cache interference model, formulas are obtained that make it possible to accurately compute tiling parameters. It is shown that the code for reduction statements generated by the C[] compiler is comparable with (and, often, even better than) specially designed subroutines in terms of the efficiency.</content></document><document><year>2004</year><authors>V. E. Khachatryan1 </authors><title>Complete System of Equivalent Transformations for Multitape Automata</title><content>A classical model of computations&amp;#x2014;multitape automata&amp;#x2014;is considered. For any n, n  2, a system of equivalent transformations that is complete in the set of all n-tape automata is constructed.</content></document><document><year>2004</year><authors>N. A. Anisimov1 | E. A. Golenkov1  | D. I. Kharitonov1 </authors><title>Compositional Petri Net Approach to the Development of Concurrent and Distributed Systems</title><content>In the paper, a formal model based on Petri nets is proposed in the context of a compositional approach to the development and analysis of complex concurrent and distributed systems. Mutlilabels of Petri nets are introduced allowing labeling a transition not only with a single symbol, but also with a multiset of symbols. Operations on multilabeled Petri nets&amp;#x2014;parallel composition and restriction&amp;#x2014;are defined. A definition of a Petri net entity is given based on the notion of multilabels. A Petri net entity is a Petri net with a set of multilabels, where each multilabel is regarded as an access point of the entity. The operation of entity composition is introduced. Equivalence of entities is defined based on bisimulation equivalence of Petri nets. It is shown that the equivalence relation is congruent with respect to entity composition. It is also demonstrated that the composition operation is commutative and associative.</content></document><document><year>2004</year><authors>V. V. Kornyak1 </authors><title>Computation of Cohomologies of Lie Superalgebras: Algorithm and Implementation</title><content>In this work, an algorithm and its implementation in C for computing cohomologies of Lie algebras and superalgebras are presented. Using the program developed, we computed certain cohomologies of the Poisson and Hamiltonian vector fields and of their analogs based on the odd Poisson bracket (antibracket).</content></document><document><year>2004</year><authors>Yu. A. Blinkov1 </authors><title>Computation of Janet Bases for Toric Ideals</title><content>An algorithm for computation of Janet bases for toric ideals, which is based on the structure of the Janet tree, is suggested. The algorithm can be applied, in particular, to solving integer programming problems with the use of algorithmic ideas by Conti and Traverso.</content></document><document><year>2004</year><authors>M. V. Kondratieva1  | V. A. Mityunin1 </authors><title>Computation of the Differential Dimension Polynomial When Changing Generators in the Dirac Equations</title><content>Without Abstract</content></document><document><year>2004</year><authors>S. L. Skorokhodov1 </authors><title>Computer Algebra and Computing Special Functions</title><content>Examples of using symbolic transformations for computing special functions are given. These transformations considerably improve stability and efficiency of precise computation in a number of difficult problems. The first example deals with the computation of the Riemann zeta function (s). A technique for the elimination of false poles of this function on the critical line s = 1/2 + it is suggested. The second example concerns the computation of the generalized hypergeometric function pFp&amp;#x2013; 1. A method of analytic continuation to the neighborhood of the singular point z = 1 is developed.</content></document><document><year>2004</year><authors>O. S. Paramonova1  | A. W. Niukkanen2 </authors><title>Computer-Aided Analysis of Transformation Formulas for Appel and Horn Functions</title><content>Simultaneous use of general and special linear transformations allows 36 transformations for the Appel function F4 to be obtained. This result is important because F4 is widely used in physics and mathematics. The transformations express F4 in terms of the Appel functions F1, F2, and F3; the Horn function H2; and non-Hornian series G, K, and . Until now, it was not possible to obtain linear multiplets having such a large dimensionality. A program based on Maple V4 was developed for formula generation. Details of program operation and possible applications of the results obtained are discussed.</content></document><document><year>2004</year><authors>N. V. Bocharov1 </authors><title>Concurrent Programming Technologies and Techniques</title><content>Intensive use of computer experiments in modern science introduces qualitative changes into experimental resources. This implies the change in techniques used to solve relevant problems. An analysis of technological chains (from the problem statement to its solution) shows that often a particular problem can be solved in a variety of ways with the use of modern multiprocessor computers, which are also called supercomputers. The multiplicity of approaches to solving a problem requires that researches possess certain skills in using supercomputers. It is difficult for novice users of multiprocessor computers to find bearings when developing software for solving applied problems. The practice shows that main difficulties reveal themselves when it is required to develop portable and efficient parallel software. This is because tools that facilitate the development and provide full access to debugging information have yet to be elaborated. Actually, the problem is in the absence of standards for development and debugging tools for supercomputers, which is explained by the fact that computer science is yet young. For the same reason, no logically complete basic texts for concurrent programming courses for novices are available. On the basis of Russian-language literature, an attempt is made at setting up beacons that mark certain common and promising technologies in using supercomputers. The emphasis is made on problems encountered by programmers when solving applied problems with the use of supercomputers. The development of multiprocessor computers is closely related to concurrent programming technologies, both universal and oriented to specific supercomputer architectures. By programming technology, i.e., by memory management, we mean the use of tools designed for managing a particular computer system. It should be noted that when developing software for supercomputers (both management software and programs for solving applied problems), one must pay special attention to programming technique, i.e., to designing the logical architecture of a program. This implies the development and extending parallelizing algorithms, which enhances the efficiency of execution on multiprocessor computers. This review was compiled on the basis of publications in Russian journals and in the Russian Internet zone.</content></document><document><year>2004</year><authors>A. S. Okhotin1 </authors><title>Conjunctive Grammars and Systems of Language Equations</title><content>This paper studies systems of language equations that are resolved with respect to variables and contain the operations of concatenation, union and intersection. Every system of this kind is proved to have a least fixed point, and the equivalence of these systems to conjunctive grammars is established. This allows us to obtain an algebraic characterization of the language family generated by conjunctive grammars.</content></document><document><year>2004</year><authors>M. Yu. Okhtilev1 </authors><title>Construction of Programs for Real-Time Processing and Analysis of Measuring Information</title><content>Models for formalization of knowledge on subject domain and relevant programs for real-time processing and analysis of measuring information are considered. The concept of state of computational process is defined, and its adequacy to the state of the corresponding object being assessed is justified with the use of topological structures.</content></document><document><year>2004</year><authors>N. M. Ershov1 </authors><title>Construction of the Algorithm Graph by Autotracing Method</title><content>An autotracing approach to the problem of the algorithm graph construction based on the possibility of overloading operators in the C++ language is suggested. The basic idea of the approach is to replace the standard double type by a special class number, which supports basic operations on numbers (arithmetic, input/output) and constructs the graph in a background mode. A class graph is responsible for general control of the graph construction process. Classes vector and matrix are introduced to support the construction of the graph for vector and matrix operations. The library of classes developed is a powerful and flexible tool for analysis of the algorithm graphs.</content></document><document><year>2004</year><authors>V. V. Panyukov1 </authors><title>Construction of the Convex Hull of a Set for a Minimum Number of Iterations</title><content>An algorithm for constructing the convex hull of a finite set of points in a d-dimensional space for a minimum number of iterations is proposed.</content></document><document><year>2004</year><authors>Yu. M. Bayakovskii </authors><title>Convergence of Computer Graphics and Machine Vision (From the Editor of the Special Issue)</title><content>Without Abstract</content></document><document><year>2004</year><authors>Yu. G. Palii1 </authors><title>Correction of Numerical Integration as an Optimal Control Problem</title><content>The drift of numerical solution of a dynamical system off the integral and constraint surface is eliminated with the help of a gradient supplement to the equations of motion. This supplement makes the image point in the phase space to move along the normal to a given surface. The solution is compared with those obtained by integrating the generalized Hamilton&amp;#x2013;Dirac dynamics equations. The calculations were performed in Maple V R5 with the use of the standard subroutine dsolve/numeric for solving ordinary differential equations by the fourth-order Runge&amp;#x2013;Kutta method.</content></document><document><year>2004</year><authors>V. G. Zhislina1 | D. V. Ivanov2| V. F. Kuriakin1 | V. S. Lempitskii2| E. M. Martinova1 | K. V. Rodyushkin1 | T. V. Firsova1 | A. A. Khropov2 | A. V. Shokurov2</authors><title>Creating and Animating Personalized Head Models from Digital Photographs and Video</title><content>In this paper, a survey is given of the approaches, methods, and algorithms used for creating personalized three-dimensional models of human''s head from photographs or video. All stages of the model construction are considered in detail. These stages include image marking, camera registering, geometrical model adaptation, texture formation, and modeling of additional elements, such as eyes and hair. Some technologies of the animation of the models obtained, including that based on the MPEG-4 standard, are analyzed, and examples of the applications that use these technologies are given. In conclusion, some prospects of the developments in this field of the computer graphics are discussed.</content></document><document><year>2004</year><authors>V. M. Mikhelev1 </authors><title>Data Definition in the Programming Language MARKIZ</title><content>A way of data definition in an object-oriented programming language, which is designed mainly for constructing various language processors (including compilers, interpreters, and converters), is described. A special feature of the language is a nonconventional definition of the object type that can be used simultaneously as the description of a syntax class. Objects in a program are represented (denoted) as character strings that follow the grammatical rules given in the definitions of types. In the case of a compiler, for example, the object&amp;#x2013;program is represented by the source file itself. The availability of a constructor in the language makes it possible to generate objects while the program is running from components&amp;#x2013;subobjects given either by variable values or in the form of representations.</content></document><document><year>2004</year><authors>V. A. Galatenko1  | K. A. Kostyukhin1</authors><title>Debugging and Monitoring Distributed Heterogeneous Systems</title><content>Problems arising in debugging distributed heterogeneous systems are considered, and some methods for their solution are discussed. The paper is based on the experience obtained when developing debugging tools in the framework of studies conducted in the Institute of System Studies, Russian Academy of Sciences.</content></document><document><year>2004</year><authors>V. A. Krukov1  | R. V. Udovichenko1 </authors><title>Debugging DVM Programs</title><content>Facilities for debugging FORTRAN-DVM and C-DVM programs are described. The following approach is used to debug a DVM program. At the first stage, the program is debugged as an ordinary sequential program with the help of conventional debugging facilities. At the second stage, the program is executed on the same computer in a special mode of checking DVM directives. At the third stage, the program can be executed in a special mode when intermediate results of parallel execution are compared with reference results (e.g., those obtained during a sequential execution).</content></document><document><year>2004</year><authors>V. V. Toporkov1 </authors><title>Decidability of the Analysis Problem for Dataflow Models of Programs</title><content>In the paper, algorithmic decidability of the analysis problem for dataflow models of programs is studied. The solution of the problem is the least stable marking on upper semi-lattice of labels of arcs and vertices of the generalized dataflow graph of the program. The labels are allowed to be of arbitrary semantic nature. Whether the analysis problem is decidable depends on properties of the marking function that interprets the analysis scheme given by a system of functional equations.</content></document><document><year>2004</year><authors>G. A. Tarnavskii1  | S. I. Shpak1 </authors><title>Decomposition of Methods and Parallelization of Algorithms for Solving Aerodynamics and Physical Gas Dynamics Problems: Computer System Potok-3</title><content>This paper is aimed at developing modern computer technologies and methods of concurrent programming designed to improve the efficiency of solving fundamental scientific and applied problems of numerical simulation in aerodynamics and physical gas dynamics. Theoretical issues concerning the design of aircraft involving large amounts of computations are also examined. This paper is focused on theoretical issues of paralleling available methods and algorithms for solving complex integro-differential systems of equations. A number of paralleling methods are considered based on various types of decomposition of the original problem into several subproblems that can be solved concurrently (decomposition by physicomathematical processes of the technological chain of computations and by the corresponding processes that can be performed concurrently (horizontal paralleling), and decomposition by the computational geometric domains and by the corresponding processes that can be performed concurrently (vertical paralleling)). The efficiency of these methods is compared and the optimal paralleling method is found. The results of the theoretical study are used in developing the third-generation package of programs for solving aerodynamics and gas dynamics problems called Potok-3.</content></document><document><year>2004</year><authors>Li Chunlin1| 2 | Lu Zhengding1 | Li Layuan2</authors><title>Design and Implementation of a Hybrid Agent Platform</title><content>This paper presents IMAP, a hybrid agent platform composed of several cooperating intelligent agents and mobile agents. IMAP is implemented in Java and Prolog. Java is used to implement the framework of the system, and in particular for supporting the communication between agents and mobility of agent, while Prolog is used to implement both adduction and derivation mechanisms. IMAP intends to independently employ the underlying derivation/adduction and mobility mechanism. In IMAP, intelligent agent and mobile agent can not only fully exploit individual virtue, but also cooperate to perform a task under a uniform platform. Intelligent agents in IMAP are equipped with hypothetical reasoning capabilities, performed by means of adduction: if the knowledge available to an agent is insufficient to solve a query, the agent could adduce new hypotheses. Each intelligent agent can accept queries from mobile agents by means of the interface module, each query is passed to the reasoning module of intelligent agent which performs a derivation and adduction in order to get an answer for mobile agent. IMAP also provides mobile agents a flexible and efficient coordination mechanism and a reliable migration mechanism, and supports persistence of agent state and agent security. Mobile agent's coordination mechanism exploits the advantages of the XML language and Linda-like coordination. This programmable Linda-like coordination mechanism suits the mobility and openness of the Internet application, XML standard for Internet data representation may guarantee a high-degree of interoperability between heterogeneous environments. The design and implementation key technologies of IMAP are described in this paper. An Internet based auction application example shows the suitability and the effectiveness of the IMAP, and its performance evaluation is also made. Finally, some conclusions and remarks are given.</content></document><document><year>2004</year><authors>A. V. Niukkanen1  | P. A. Niukkanen2</authors><title>Diagram Technique for Hypergeometric Series of Several Variables</title><content>A convenient graphical algorithm for searching and constructing explicit analytical representations of all hypergeometric series belonging to any given class is proposed. The algorithm is based on a set of rules that define a one-to-one correspondence between analytic representations of series and diagrams. The algorithm can be easily implemented in the form of a computer program.</content></document><document><year>2004</year><authors>M. R. Kogalovsky1 </authors><title>Digital Libraries: Ongoing Development (From the Editor of the Special Issue)</title><content>Digital Libraries Initiative declared in the USA in the autumn of 1993 aroused interest to information systems of this class in many countries all over the world. Today, numerous research teams are involved in activities related to such systems. A significant number of digital libraries for diverse purposes are already in operation, and various research prototypes have been created. This subject has been discussed at international conferences dedicated specifically to digital libraries and conferences on fundamental directions of information system technologies, such as database technologies, Web technologies, textual search, data mining, and knowledge discovery. Programming and Computer Software already addressed the problems arising in relation to digital libraries. This issue of the journal further explores the subject.</content></document><document><year>2004</year><authors>N. A. Likhoded1 </authors><title>Distribution of Operations and Data Arrays over Processors</title><content>For algorithms described by loop nests, a method of construction of affine mappings of operations and data arrays onto virtual processors is suggested. Only local communications between the processors are required; in particular, there may be no communications at all. The method makes it possible to find many heuristic solutions, allows for dependence on outer loop indices, and can be used for automated parallelizing sequential programs.</content></document><document><year>2004</year><authors>N. I. V'yukova1 | V. A. Galatenko1 | S. V. Samborskii1  | S. M. Shumakov1 </authors><title>Effective Code Generation for Processor Architectures with Explicit Parallelism</title><content>In the paper, code generation problems specific for processor architectures with explicit parallelism are discussed, and methods for solving them are suggested. The basic method discussed is a postprocessor implemented on the level of assembler instructions.</content></document><document><year>2004</year><authors>S. V. Agoshkov1 | P. A. Dmitriev2 </authors><title>Electronic Publication Maintenance Systems</title><content>A review of technologies designed to maintain dedicated information systems called electronic publications is given. Requirements upon the software implementing these technologies is formulated and approaches to the development of such software are proposed and discussed.</content></document><document><year>2004</year><authors>A. G. Tormasov1 | M. A. Khasin1  | Yu. I. Pakhomov1 </authors><title>Ensuring Fault-Tolerance in Distributed Media</title><content>A method for ensuring system fault-tolerance and guaranteed data access based on a model of distributed data storage with controlled redundancy is considered. A data file is represented as a set of nparts, each of size 1/kof the source file, so that the source file can be generated from any kparts (kn). The cardinality of the set may vary by constructing new (or by deleting the existing) parts, i.e., without modifying the existing parts, so that the source file can still be generated from any kparts. The file partitioning and assembly algorithms are based on the theory of finite Galois fields GF. A file is represented as a sequence of k-dimensional vectors over a GF. Every fragment is a sequence of projections of these vectors onto a k-dimensional vector (chosen for the given fragment) over the GF. In the paper, several implementations of the model are presented. For each of these implementations, the results of performance on the Celeron-450 processor are obtained and analyzed to determine their range of application.</content></document><document><year>2004</year><authors>R. I. Podlovchenko1 </authors><title>Equivalent Transformations in the Model of Programs with Commuting and Monotone Operators</title><content>The fundamental problem in the theory of algebraic program models is considered. It consists in constructing a system of equivalent transformations of program schemes that is complete in the model. It is solved for a model different from those considered in earlier studies.</content></document><document><year>2004</year><authors>R. I. Podlovchenko1 </authors><title>Equivalent Transformations of Program Schemes for Entangling Programs</title><content>By entangling program, we mean its equivalent transformation that complicates understanding the program's logic. Conventionally, equivalent transformations of programs are designed on the basis of their schemes. The problem of constructing schemes that can be used for designing equivalent transformations is discussed. A general approach to solving this problem is presented. An example of its application to ALGOL-like programs without procedures is described in the case when program schemes are constructed from the program's algebraic models.</content></document><document><year>2004</year><authors>M. Yu. Loenko1 </authors><title>Evaluating Elementary Functions with Guaranteed Precision</title><content>Because of changes in the computer markets, the problem of efficient evaluation of elementary functions (which seemed to be already solved) becomes important again. In this paper, after a brief review of current approaches to this problem, algorithms for finding guaranteed bounds for values of elementary functions are suggested. The evaluation time is reduced through increasing the amount of memory used.</content></document><document><year>2004</year><authors>I. E. Kuralenok1  | I. S. Nekrestyanov1 </authors><title>Evaluation of Text Retrieval Systems</title><content>Evaluation is one of the main driving forces in studies and developments related to text retrieval. It is a basic tool for the comparison of efficiencies of alternative approaches. In this paper, the state of the art in the field of evaluation of text retrieval systems is surveyed. Two basic&amp;#x2014;system-oriented and user-oriented&amp;#x2014; paradigms, which are commonly accepted in this field, are often considered as incompatible. In this survey, both paradigms are considered in the context of a unique framework based on attributes affecting the innovation distribution and adaptation. A detailed discussion of the evaluation of text retrieval systems is based on the consideration of required components of the evaluation process for an arbitrary system. Methodological problems related to the verification of the results obtained are also discussed.</content></document><document><year>2004</year><authors>Evgenii Andreevich Zhogolev</authors><title/></document><document><year>2009</year><authors>D. V. Levshin1  | A. S. Markov1 </authors><title>Algorithms for integrating PostgreSQL with the semantic web      </title><content>This paper addresses the integration of the PostgreSQL database management system (DBMS) with the Semantic Web. Integration         algorithms based on the use of the DBMS capabilities that do not introduce changes in SQL are proposed. An integration based         on one of the algorithms supporting main formats of the Semantic Web is presented. The proposed algorithms can be implemented         in different DBMSs supporting triggers (or rules), table functions, and indexing.      </content></document><document><year>2009</year><authors>E. V. Kuzmin1 | V. A. Sokolov1  | D. Ju. Chalyy1 </authors><title>Application of the trace assertion method to the specification, design, and verification of automaton programs      </title><content>The paper considers the application of the trace assertion method [1] for specification and verification of automaton programs         [2&amp;#8211;4]. The trace assertion method allows the programmer to define an externally visible behavior of an automaton program in         a rigorous way, without considering details of its implementation. The method is employed at the requirements specification         stage of the system development. The paper introduces techniques for defining semantics of some elements of an automaton program,         especially those involved in interactions with the control system. A formal approach to defining states of automaton programs         is described. Results of studies related to the verification of specification requirements for automaton programs are also         presented.      </content></document><document><year>2009</year><authors>E. N. Dolgova1  | A. V. Chernov2 </authors><title>Automatic reconstruction of data types in the decompilation problem      </title><content>An algorithm for the automatic reconstruction of data types from the assembler code produced by a C compiler is described.         The types of the variables that are placed on the stack and in the static memory are reconstructed using an iterative algorithm         that uses a lattice over the properties of the data types. The derived data types are reconstructed by constructing the set         of possible offsets of the elements of these types (fields in the case of structures and array elements in the case of arrays).         This algorithm is used in the tool for decompiling assembler codes into C that is currently developed by the authors.      </content></document><document><year>2009</year><authors>S. G. Groshev1 </authors><title>Bug localization by constructing reduced traces      </title><content>A method, based on the existing UniTESK test, which finds a bug in a system under test, is proposed to construct the minimal         test that finds the same bug. This test can be used to localize this bug in the source code of the system. Two strategies         for constructing such a test are considered, a comparative analysis of their advantages and disadvantages is performed, and         the optimal strategy is proposed. A mathematical justification of the proposed method is given. An algorithm implementing         this method is described, and its correctness is proved. An implementation of the proposed method for the CTESK testing tool         is described.      </content></document><document><year>2009</year><authors>N. S. Vassilieva1 </authors><title>Content-based image retrieval methods      </title><content>Creation of a content-based image retrieval system implies solving a number of difficult problems, including analysis of low-level         image features and construction of feature vectors, multidimensional indexing, design of user interface, and data visualization.         Quality of a retrieval system depends, first of all, on the feature vectors used, which describe image content. The paper         presents a survey of common feature extraction and representation techniques and metrics of the corresponding feature spaces.         Color, texture, and shape features are considered. A detailed classification of the currently known features&amp;#8217; representations         is given. Experimental results on efficiency comparison of various methods for representing and comparing image content as         applied to the retrieval and classification tasks are presented.      </content></document><document><year>2009</year><authors>A. V. Purgin1 </authors><title>Distributive lattices of right divisors of linear ordinary differential operators      </title><content>In the paper, combinatorial issues of the factorization of linear ordinary differential operators are studied. It is proved         that any finite distributive lattice is that of right divisors of some d&amp;#8217;Alembert linear ordinary differential operator with         the coefficients belonging to the differential field C(x) of rational functions.      </content></document><document><year>2009</year><authors>N. N. Vasiliev1 | D. A. Pavlov2 </authors><title>Enumeration of finite monomial orderings and combinatorics of universal Grbner bases      </title><content>The goal of this work is to analyze various classes of finite and total monomial orderings. The concept of monomial ordering         plays the key role in the theory of Grbner bases: every basis is determined by a certain ordering. At the same time, in order         to define a Grbner basis, it is not necessary to know ordering of all monomials. Instead, it is sufficient to know only a         finite interval of the given ordering. We consider combinatorics of finite monomial orderings and its relationship with cells         of a universal Grbner basis. For every considered class of orderings (weakly admissible, convex, and admissible), an algorithm         for enumerating finite orderings is discussed and combinatorial integer sequences are obtained. An algorithm for computing         all minimal finite orderings for an arbitrary Grbner basis that completely determine this basis is presented. The paper presents         also an algorithm for computing an extended universal Grbner basis for an arbitrary zero-dimensional ideal.      </content></document><document><year>2009</year><authors>V. P. Ivannikov1 | A. I. Avetisyan1 | S. S. Gaissaryan1  | M. S. Akopyan1 </authors><title>Implementation of parallel programs interpreter in the development environment ParJava      </title><content>The implementation of the ParJava development environment is considered that enables one to develop parallel applications         in the modern programming language Java within the industrial standard MPI. The internal representation of the SPMD program         model is described, which is constructed so as to place as much of the interpretation work of a parallel Java program on JavaVM.         Features of the model generation and its preparation to the interpretation are described. The model generator transforms the         abstract syntax tree of each method of the program being simulated into a model of the control flow, forms a computation model         that will be executed on JavaVM, and forms a module for evaluating the execution times of the basic blocks. The interpretation         of the model executed on p nodes of a parallel computing system (cluster) is performed in p logical processes of which each         is executed in an individual thread. The interpretation of a logical process assumes that all its methods beginning from the         main method are interpreted. The interpretation of each method consists in executing the computation model of this method         on JavaVM. The order of interpretation of the method&amp;#8217;s basic blocks is determined by the system interpreter of the method&amp;#8217;s         model. The system makes it possible to reduce parts of the model and interpret the model by parts. Problems of the simulation         and interpretation of communication functions are discussed. The communication functions are described using nine basic exchange         operations. To evaluate the time needed to transfer data between processes, an empirical dependence between the amount of         the transferred data and the transfer time is used, which is obtained using tests. A short description of the ParJava graphical         interface is presented. Applications developed using the proposed implementation of the system are platform independent; and         the development, tuning, and maintenance overheads for those applications are considerably reduced. This is a contribution         to the development of high-productive parallel applications.      </content></document><document><year>2009</year><authors>P. P. Oleynik1 </authors><title>Implementation of the hierarchy of atomic literal types in an object system based of RDBMS      </title><content>Without Abstract</content></document><document><year>2009</year><authors/></document><document><year>2008</year><authors>G. V. Borisenko1| A. M. Denisov1 | A. S. Krylov1 </authors><title>A diffusion method for image filtering and sharpening      </title><content>Without Abstract</content></document><document><year>2008</year><authors>A. B. Galazin1 | E. V. Stupachenko1 | S. L. Shlykov1</authors><title>A software instruction prefetching method in architectures with static scheduling      </title><content>The performance of modern microprocessors considerably depends on the efficient workload of their execution units. The performance         in modern applications is considerably affected by instruction stalls. Until recently, the problem of instruction stalls was         mainly studied for superscalar microprocessors. A software instruction prefetching method for VLIW/EPIC architectures that         makes it possible to improve performance for a certain class of problems is described.      </content></document><document><year>2008</year><authors>E. A. Yusov1  | V. E. Turlapov1 </authors><title>Adaptive terrain triangulation using the representation of quad trees by vertex textures and wavelet estimation of vertex         significance      </title><content>A method of adaptive terrain triangulation is proposed that can be implemented in hardware. The method is based on an estimate         of the static error of a quad tree nodes using wavelet transforms and on the representation of the resulting quad tree by         a vertex texture. The proposed method has the following characteristic features: the adjacent nodes of the generated adapted         mesh can differ in any number of hierarchical levels; the triangulation process is not limited by the size of the decomposition         segments, which solves the problem of joining segments without inserting additional nodes; the multiscale terrain representation         used in the method makes it possible to store the levels of detail in the graphics processor memory as a multilevel vertex         texture; thus, the costliest part of the algorithm can be efficiently implemented using a vertex shader.                     When constructing the triangulation, the algorithm takes into account both local features of the terrain and the camera location;               also, it has a natural support of geomorphing.            </content></document><document><year>2008</year><authors>S. V. Gomanyuk1 </authors><title>An approach to creating development environments for a wide class of programming languages      </title><content>Creating an integrated development environment for a new programming language is a nontrivial and laborious task. Such universal         integration platforms as Eclipse, NetBeans, MS Visual Studio, and others partly facilitate it. The paper gives a comparative         analysis of the approaches to creating a development environment on the basis a universal integration platform and proposes         a new approach that eliminates the disadvantages while retaining the advantages of the existing approaches.      </content></document><document><year>2008</year><authors>V. A. Debelov1| 2 | G. G. Smirnova1| 2  | L. F. Vasilyeva1| 2 </authors><title>An extension of the light meshes method for three-dimensional scenes with semitransparent surfaces      </title><content>The light meshes method (a modification of the Whitted backwards recursive ray tracing) was justified and studied for scenes         consisting of opaque surfaces. Its main difference from the basic method is that the rendered image may include soft shadows         (i.e., point sources are simulated by area sources). This study makes a further step in the development of this method: it         is extended for rendering scenes containing semitransparent surfaces. A few computational schemes are considered and, for         each of them, the difference between the image calculated by the standard scheme and obtained by the application of the light         meshes method is shown.      </content></document><document><year>2008</year><authors>R. S. Zybin1 | V. V. Kuliamin1 | A. V. Ponomarenko1 | V. V. Rubanov1  | E. S. Chernov1 </authors><title>Automation of broad sanity test generation      </title><content>The technology for the broad generation of sanity tests for complex software developed in the Institute for System Programming         (Russian Academy of Sciences) is presented. This technology is called Azov; it is based on using a database containing structured         information about the interface operations of the system under test and on a procedure for enriching this information by refining         constraints imposed on parameter types and results of operations. Results of a practical application of this technology prove         its high efficiency in generating sanity tests for systems with a large number of functions.      </content></document><document><year>2008</year><authors>D. &amp;#350 tef&amp;#259 nescu1 </authors><title>Computation of dominant real roots of polynomials      </title><content>The computation of the dominant positive roots of univariate polynomials is a key step for real root isolation algorithms.         We propose a new device for computing dominant real roots and compare it with other methods. For roots surpassing unity, we         obtain better results than the classical estimates of Lagrange and Long-champ. We also discuss a new refined result on bounds         for positive roots that can be used for all polynomials with sign changes.      </content></document><document><year>2008</year><authors>A. A. Belevantsev1 | S. S. Gaisaryan1  | V. P. Ivannikov1 </authors><title>Construction of speculative optimization algorithms      </title><content>In modern processors, instructions to perform operations are often produced before it becomes known that this is required.         Such an expedient, which is called speculative execution, helps to reveal parallelism at the instruction level. In the EPIC         architectures, the speculative execution is completely controlled by the compiler, which makes it possible to avoid using         complex hardware mechanisms for supporting speculative instruction production. Moreover, the idea of the speculative execution         can be used by the compiler in machine-independent optimizations. The paper describes a scheme of construction of the speculative         optimization that is based on the selection of properties of the control flow and data flow that are important from the optimization         standpoint and on the estimation of the probabilities of their fulfillment. The probabilities found are used for searching         and constructing advantageous speculative and bookkeeping transformations. For optimizations that include only speculative         movements of instructions upwards along the control flow graph, on the basis of the suggested scheme, a method has been developed         that includes algorithms for finding probabilities of data and control dependences, for estimating benefit of speculative         movements, and for constructing a recovery code. On the basis of this method, an algorithm for the speculative scheduling         of instructions for the Intel Itanium architecture has been developed and implemented. Specific features of its implementation         and experimental results are described.      </content></document><document><year>2008</year><authors>A. A. Simanovsky1 </authors><title>Data schema evolution support in XML-relational database systems      </title><content>Many XML-relational systems, i.e., the systems that use an XML schema as an external schema and a relational schema as an         internal schema of the data application representation level, require modifications of the data schemas in the course of time.         Schema evolution is one of the ways to support schema modifications for the application at the DBMS level. A number of schema         evolution support systems for different data models have been suggested. Schema evolution can be applied to mapping-related         evolving schemas (such as schemas of XML-relational systems), the transformation problem for which is also known as schema         adaptation. In this paper, a survey of various approaches to solving the outlined problems is given.      </content></document><document><year>2008</year><authors>V. V. Kornyak1 </authors><title>Discrete dynamical systems with symmetries: Computer analysis      </title><content>Discrete dynamical systems and mesoscopic lattice models are considered from the standpoint of their symmetry groups. Universal         specific features of deterministic dynamical system behavior associated with nontrivial symmetries of these systems are specified.         Group nature of soliton-like moving structures of the &amp;#8220;spaceship&amp;#8221; type in cellular automata is revealed. Study of lattice         models is also considerably simplified when their symmetry groups are taken into account. A program in C for group analysis         of systems of both types is developed. The program, in particular, constructs and investigates phase portraits of discrete         dynamical systems modulo symmetry group and seeks dynamical systems possessing special features, such as, for example, reversibility.         For mesoscopic lattice models, the program computes microcanonical distributions and looks for phase transitions. Some computational         results and observations are presented.      </content></document><document><year>2008</year><authors>D. V. Koznov1  | K. Yu. Romanovsky1 </authors><title>DocLine: A method for software product lines documentation development      </title><content>The DocLine method designed for developing documentation for software product lines is presented. The method makes it possible         to reuse document fragments with adaptation to a particular usage context. The method provides the Documentation Reuse Language         (DRL) that has a graphical part (for designing the structure of documentation packages) and a text part (for implementing         the documentation). It also describes a process for developing documentation and a toolset architecture based on the DSM approach         and Eclipse GMF technology.      </content></document><document><year>2008</year><authors>D. A. Yanovich1 </authors><title>Efficiency estimate for distributed computation of Grbner bases and involutive bases      </title><content>Several years ago, we presented a program complex for parallel computation of Grbner bases that works on computers with shared-memory         architecture. Unfortunately, the number of the processors that we can use is small (from 2 to 16) because of hardware constraints.         This paper presents a program for distributed computation of bases that relies on the same principles but works in a network         consisting of heterogeneous machines. The effectiveness of such an approach is estimated from the standpoint of the processor         capacity usage and the required network bandwidth, and methods optimizing usage of these resources are specified.      </content></document><document><year>2008</year><authors>V. A. Nepomnyashchii1  | A. K. Petrenko2 </authors><title>From the editors of the special issue      </title><content>Without Abstract</content></document><document><year>2008</year><authors>N. V. Shilov1 | I. S. Anureev1  | E. V. Bodin1 </authors><title>Generation of correctness conditions for imperative programs      </title><content>Verification of imperative programs in the sense of Floyd-Hoare is an approach to proving correctness of programs annotated         by preconditions, postconditions, and loop invariants. It is based on generation of correctness conditions. In the structured         deterministic case, the problem of generation of correctness conditions seems trivial, since it is solved by a syntax-driven         algorithm, the complexity of which linearly depends on the number of control constructs. Vice versa, in the unstructured nondeterministic         case, it seems a priori clear that the complexity of generation of the correctness conditions exponentially depends on the         number of statements in the program. In the paper, an efficient and complete algorithm for the generation of the correctness         conditions is presented and justified. It can be used both in the structured deterministic and unstructured nondeterministic         cases. The algorithm complexity linearly depends on the number of control constructs and/or program statements.      </content></document><document><year>2008</year><authors>S. A. Abramov1| 2 | M. V. Kondrat&amp;#8217 eva1| 2 | V. N. Latyshev1| 2 | A. V. Mikhalev1| 2</authors><title>In memory of Engeny Vasil&amp;#8217;evich Pankratiev (December 29, 1944&amp;#8211;January 23, 2008)      </title><content>Without Abstract</content></document><document><year>2008</year><authors>S. P. Polyakov1 </authors><title>Indefinite summation of rational functions with additional minimization of the summable part      </title><content>An algorithm of indefinite summation of rational functions is proposed. For a given function f(x), it constructs a pair of rational functions g(x) and r(x) such that f(x) = g(x + 1) &amp;#8722; g(x) + r(x), where the degree of the denominator of r(x) is minimal, and, when this condition is satisfied, the degree of the denominator of g(x) is also minimal.      </content></document><document><year>2008</year><authors>A. B. Bugerya1 </authors><title>Interactive debugging of parallel programs: Distributed scheme of interacting components      </title><content>A general scheme of the organization of a distributed debugger of parallel programs. The experience of using this scheme for         developing a debugger of programs in NORMA and for developing a system for examining MPI programs is discussed.      </content></document><document><year>2008</year><authors>A. S. Semenov1  | P. A. Zyuzikov1 </authors><title>Involutive divisions and monomial orderings: Part II      </title><content>This paper is a sequel to the studies on classification properties of involutive divisions reported in [1]. An example is         given in which the minimal involutive basis of a particular monomial ideal for the &amp;#8220;Janet antipode&amp;#8221; &amp;lt;-division is neither         an involutive Janet basis nor a minimal basis for a Janet-like division for any of n! orderings of variables. This example disproves the hypothesis that the minimal involutive basis for continuous and constructive         divisions always coincides with the Janet basis for some ordering of variables.      </content></document><document><year>2008</year><authors>V. P. Gerdt1  | M. V. Zinin1 </authors><title>Involutive method for computing Grbner bases over                </title><content>In this paper, an involutive algorithm for computation of Grbner bases for polynomial ideals in a ring of polynomials in         many variables over the finite field  with the values of variables belonging of  is considered. The algorithm uses Janet division and is specialized for a graded reverse lexicographical order of monomials.         We compare efficiency of this algorithm and its implementation in C++ with that of the Buchberger algorithm, as well as with         the algorithms of computation of Grbner bases that are built in the computer algebra systems Singular and CoCoA and in the         FGb library for Maple. For the sake of comparison, we took widely used examples of computation of Grbner bases over &amp;#8474; and         adapted them for . Polynomial systems over  with the values of variables in  are of interest, in particular, for modeling quantum computation and a number of cryptanalysis problems.      </content></document><document><year>2008</year><authors>R. S. Samarev1 </authors><title>Method of adaptive controllable parallel execution of operations in object database management systems      </title><content>The design of parallel database management systems (DBMSs) normally implies using special-purpose multiprocessor computing         systems. Most often, a DBMS is supposed to work in an exclusive mode of operation. However, in the class of x86-based multiprocessor         computing systems designed for mass usage, the exclusive mode of DBMS operation with respect to other software is often not         secured. In addition, the legacy software for this class of computing systems is often not designed for mass parallel usage.         When the exclusive mode requirement is ignored and the resources of the computing system are not used in low-load DBMS regimes,         the efficiency of using resources of the computing system as a whole reduces. This paper considers a method of program organization         of controlled parallelism at the level of internal DBMS operations, allowing for their controlled execution based on the state         of the entire computing system. This method made it possible to significantly reduce the time of response for low densities         of query arrival in the ODB-Jupiter commercial object DBMS developed in the Inteltec Plus scientific manufacturing center.         The method of controlled parallel execution can be used in a wide class of program systems.      </content></document><document><year>2008</year><authors>R. I. Podlovchenko1 </authors><title>Minimization problem for schemes of program with commutative blocks      </title><content>Without Abstract</content></document><document><year>2008</year><authors>V. A. Nepomniaschy1| 2 | V. S. Argirov1| D. M. Beloglazov1| A. V. Bystrov1| 2| E. A. Chetvertakov1 | T. G. Churina1| 2</authors><title>Modeling and verification of the SDL-specified communication protocols using high-level Petri nets      </title><content>To simplify modeling and verification of communication protocols presented in the SDL language, the so-called hierarchical         typed timed Petri nets (HTT nets), which are substantial modifications of colored Petri nets, are introduced. A method of         translation of the SDL language into HTT nets is described. A program complex SPV (SDL Protocol Verifier), which includes         a translator from SDL into HTT nets and means for editing, simulation, visualization, and verification of these net models,         is presented. For the verification, a model checking method for properties presented by &amp;#956;-calculus formulas is used. Experiments         on application of the SPV complex for modeling and verifying two ring protocols (RE and ATMR protocols), an optimized version         of the sliding window protocol (i-protocol), and a dynamic version of the InRes protocol are described      </content></document><document><year>2008</year><authors>E. V. Kuzmin1  | V. A. Sokolov1 </authors><title>Modeling, specification, and verification of automaton programs      </title><content>Without Abstract</content></document><document><year>2008</year><authors>S. A. Abramov1  | A. A. Ryabenko1 </authors><title>On a computer algebra technology      </title><content>Modern computer algebra systems provide means for exact experimental calculations (including manipulations of formulas) that         enable one to obtain a solution of a problem under examination for certain not very large initial data. The results can provide         a basis for a conjecture concerning the general solution of the problem. A computer algebra system can also be helpful in         verifying the conjecture.      </content></document><document><year>2008</year><authors>T. Wolf1 </authors><title>On solving large systems of polynomial equations appearing in discrete differential geometry      </title><content>The paper describes methods for solving very large overdetermined algebraic polynomial systems on an example that appears         from a classification of all integrable 3-dimensional scalar discrete quasilinear equations Q         3=0 on an elementary cubic cell of the lattice &amp;#8484;3. The overdetermined polynomial algebraic system that has to be solved is far too large to be formulated. A &amp;#8220;probing&amp;#8221; technique,         which replaces independent variables by random integers or zero, allows to formulate subsets of this system.                     An automatic alteration of equation formulating steps and equation solving steps leads to an iteration process that solves               the computational problem.            </content></document><document><year>2008</year><authors>S. A. Abramov1  | M. Petkov&amp;#353 ek2 </authors><title>On the bottom summation      </title><content>We consider summation of consecutive values (&amp;#966;(v), &amp;#966;(v + 1), ..., &amp;#966;(w) of a meromorphic function &amp;#966;(z), where v, w &amp;#8712; &amp;#8484;. We assume that &amp;#966;(z) satisfies a linear difference equation L(y) = 0 with polynomial coefficients, and that a summing operator for L exists (such an operator can be found&amp;#8212;if it exists&amp;#8212;by the Accurate Summation algorithm, or, alternatively, by Gosper&amp;#8217;s algorithm         when ordL = 1). The notion of bottom summation which covers the case where &amp;#966;(z) has poles in &amp;#8484; is introduced.      </content></document><document><year>2008</year><authors>Yu. G. Palii1| 2  | A. M. Khvedelidze1| 3 </authors><title>On the homogeneous Grbner basis for tensors      </title><content>Algorithmic methods of commutative algebra based on the involutive and Grbner bases technique are efficient means for completion         of equations governing dynamical systems to involution. At the same time, when working with high-dimensional tensor quantities,         direct use of standard functions for calculating Grbner bases, which are built in computer algebra systems Maple and Mathematica, requires much memory. However, being multilinear forms, tensors admit special grading that makes it possible to classify         polynomials in terms of their degree of homogeneity. With regard to this feature, we propose to use a special homogeneous         Grbner basis, which allows us to avoid difficulties associated with large amount of computation. Such a basis is constructed         step by step, as the degree of the polynomial grows. As an example, an algorithm for constructing the homogeneous basis in         a finite-dimensional Hamiltonian system with many polynomial constraints (the so-called Yang-Mills mechanics) is presented.      </content></document><document><year>2008</year><authors>A. V. Inyukhin1 </authors><title>On the problem of increasing efficiency of Reed-Solomon-code-based algorithms for creating checkpoints for calculation applications      </title><content>An algorithm for constructing checksums based on the Reed-Solomon code is proposed. It makes it possible to increase the efficiency         of creating checkpoint files on local disk memory for parallel applications, as well as provide a series of other capabilities.         The paper also corrects a number of errors committed by other researchers of this domain.      </content></document><document><year>2008</year><authors>M. L. Gromov1 | N. V. Evtushenko1  | A. V. Kolomeets1 </authors><title>On the synthesis of adaptive tests for nondeterministic finite state machines      </title><content>The paper suggests a method for synthesis of adaptive tests with guaranteed coverage for checking functioning of discrete         systems whose behavior is described by nondeterministic finite state machines. In contrast to other known methods, we do not         represent the complete test as a tree but list test cases one by one and check functioning of the finite state machine on         each test case. The complete test detects all defective systems that are r-distinguishable from the reference system. Besides, the test detects other defective systems containing traces that are not         present in the specification; but detection of all such systems that are r-compatible with the specification is not guaranteed.      </content></document><document><year>2008</year><authors>D. B. Volegov1  | D. V. Yurin2 </authors><title>Preliminary coarse image registration by using straight lines found on them for constructing super resolution mosaics and         3D scene recovery      </title><content>An algorithm of coarse image registration of a 3D scene taken from different camera perspectives is proposed. The algorithm         uses information on geometrical parameters of straight lines found on the images and on distribution of color and/or brightness         around these lines. Colors are taken into account by using the fuzzy logic technique. The result of the algorithm operation         is a planar projective transformation (planar homography) matching approximately the images. In order to use the technique         in algorithms of 3D scene reconstruction, an estimate of size of the window used for searching correspondent points after         the coarse image registration is obtained.      </content></document><document><year>2008</year><authors>D. E. Khmelnov1 </authors><title>Search for Liouvillian solutions of linear recurrence equations in the MAPLE computer algebra system      </title><content>The paper considers implementation of the Singer-Hendriks algorithm in the MAPLE computer algebra system. The algorithm finds         Liouvillian solutions of linear recurrence equations with coefficients in the form of rational functions.      </content></document><document><year>2008</year><authors>V. L. Arlazarov1  | M. D. Kazanov2 </authors><title>Segmentation of small objects in color images      </title><content>A method for effective segmentation of small objects in color images is presented. It can be used jointly with region growing         algorithms. Segmentation of small objects in color images is a difficult problem because their boundaries are close to each         other. The proposed algorithm accurately determines the location of the boundary points of closely located small objects and         finds the skeletons (seed regions) of those objects. The method makes use of conditions obtained by analyzing the change of         color characteristics of the edge pixels along the direction that is orthogonal to the boundaries of adjacent objects. These         conditions are generalized for the case of the well-known class of color images having misregistration artifacts. If high-quality         seed regions are available, the final segmentation can be performed using one of the region growing methods. The segmentation         algorithm based on the proposed method was tested using a large number of color images, and it proved to be very efficient.      </content></document><document><year>2008</year><authors>I. B. Virbitskaite1| 2  | R. S. Dubtsov1 </authors><title>Semantic domains of timed event structures      </title><content>In the paper, timed extensions of various classes of event structures and marked Scott domains are studied, categories of         these models are constructed, and their properties are examined. In addition, based on category-theoretic methods, relationship         between the timed structures and marked Scott domains is established.      </content></document><document><year>2008</year><authors>V. A. Bobkov1 | Yu. S. Borisov1| A. V. Inzartsev1 | S. V. Mel&amp;#8217 man1</authors><title>Simulation program complex for studying motion control methods for autonomous underwater vehicles      </title><content>Development of a graphical simulation complex for studying motion control methods for autonomous underwater vehicles is discussed.         Its structure and functioning scheme are presented. An approach to solving navigation problem and to 3D reconstruction of         underwater environment from a given sequence of digital images is described. It is based on the use of an extended Kalman         filter and original algorithm of dense 3D recovery of the environment points. Results of computational experiments and estimates         of the efficiency of the approach are presented.      </content></document><document><year>2008</year><authors>Yu. A. Blinkov1  | V. P. Gerdt2 </authors><title>Specialized computer algebra system GINV      </title><content>Computer algebra system GINV (Grbner INVolutive) is presented. It is designed for studying and solving systems of algebraic,         differential, and difference equations of polynomial type by their completion to involution. The system is based on algorithms         for constructing involutive Janet and Janet-like bases for polynomial ideals and modules, as well as reduced Grbner bases,         developed by the authors. GINV consists of a library of C++ programs, which is a module of the Python language. It is available         at http://invo.jinr.ru/ginv/ and is distributed under the terms of the GPL v2.      </content></document><document><year>2008</year><authors>V. V. Toporkov1 </authors><title>Supporting schedules of resource co-allocation for distributed computing in scalable systems      </title><content>This paper proposes a model of scheduling and validates methods of resource co-allocation for distributed computations in         scalable systems. Solution of the problem of allocating heterogeneous computing resources for performing complex sets of tasks         (jobs) is related to the formation of strategies (families of admissible supporting schedules). The choice of a specific schedule         depends on the nature of events occurring in the distributed environment and related primarily to the load and accessibility         of computing nodes.      </content></document><document><year>2008</year><authors>O. G. Sharov1  | A. N. Afanasiev1</authors><title>Syntax error recovery in graphical languages      </title><content>The majority of analyzers in modern formal text languages are able to detect more than one error in one pass. Little attention         is devoted though to the problem of syntax error recovery in diagrams of graphical languages. In this paper, a method for         analysis of formal graphical languages with error recovery is suggested.      </content></document><document><year>2008</year><authors>B. A. Novikov1  | E. A. Gorshkova1</authors><title>Temporal databases: From theory to applications      </title><content>Problems concerning the date and time representation in databases are well studied in scientific literature. Temporal databases         are required in many applications including the conventional applications of DBMSs such as financial systems. However, commercial         systems and standards for the query language do not support temporal data features. A simple and efficient approach for implementing         temporal capabilities over conventional commercial DBMSs is proposed and various aspects of its practical applications are         described.      </content></document><document><year>2008</year><authors>V. E. Khachatryan1 </authors><title>The problem of equivalent transformations for homogeneous multitape automata      </title><content>A complete system of equivalent transformations is constructed for homogeneous multitape automata. Decidability of the equivalence         problem is established.      </content></document><document><year>2008</year><authors>S. A. Abramov1 | A. A. Bogolyubskaya2 | V. A. Rostovtsev2  | V. F. Edneral3 </authors><title>The research seminar on computer algebra in 2006&amp;#8211;2007      </title><content>An annual report on meetings of the scientific research seminar on computer algebra is presented.      </content></document><document><year>2008</year><authors>B. Kh. Barladyan1| A. G. Voloboi1 | K. A. Vostryakov1| V. A. Galaktionov1 | L. Z. Shapiro1</authors><title>The use of coherent ray tracing for physically accurate rendering      </title><content>As the power of modern microprocessors increases, the coherent ray tracing becomes increasingly popular in computer graphics         because the use of SIMD instructions considerably speeds up this operation. However, after speeding up ray tracing, it turns         out that other algorithms for physically accurate rendering, such as the calculation of illumination or application of texture,         etc., become a bottleneck in improving the performance. In this paper, a coherent physically accurate rendering algorithm         is proposed that makes use of SIMD instructions of modern processors at each stage of the image generation. Coherent algorithms         for the calculation of illumination and materials, for antialiasing, and for tone mapping are presented. The comparison of         the execution time of coherent and incoherent algorithms using benchmark scenes showed that the former are considerably faster.      </content></document><document><year>2008</year><authors>A. V. Demakov1 | S. V. Zelenov1  | S. A. Zelenova1 </authors><title>Using abstract models for the generation of test data with a complex structure      </title><content>An approach to the automatic generation of test data having a complex structure (such as XML documents, programs in various         programming languages, and the like) is presented. It is based on abstract models that represent various views of the structure         of the desired data. The approach enables one to generate small sets of test data for testing the functionality of the target         system. The use of abstract models makes configuration of the generation procedure easy and clear; it also facilitates the         maintenance and reuse of existing configurations of the test data generator. The approach was implemented in the test data         generator called Pinery, which was successfully used in a number of projects including testing commercial C/C++ compilers.      </content></document><document><year>2006</year><authors>A. V. Zamulin      </authors><title/></document><document><year>2007</year><authors>V. A. Vasenin1  | A. N. Vodomerov1 </authors><title>A formal model of a system for automated program parallelization      </title><content>In the paper, the T-system&amp;#8212;an approach to automated program parallelization that has several implementations&amp;#8212;is studied. In         the absence of formal justification, these implementations have a number of disadvantages, which results in incorrect operation         of programs. In the paper, a mathematical model of the T-system is constructed, and, in the framework of this model, correctness         of parallelization is proved. The model makes it possible to reveal a number of inaccuracies in the latest version of the         T-system OpenTS and suggest ways to eliminate them. The use of the formal model in the development of NewTS, a new version         of the T-system, is described.      </content></document><document><year>2007</year><authors>A. L. Lastovetsky1 | A. Ya. Kalinov1| I. N. Ledovskikh1| D. M. Arapov1 | M. A. Posypkin1</authors><title>A language and programming environment for high-performance parallel computing on heterogeneous networks      </title><content>An mpC language designed specifically for programming high-performance computations on heterogeneous networks is described.         An mpC program explicitly defines an abstract computing network and distributes data, computations, and communications over         it. At runtime, the mpC programming environment uses this information and that about the actual network to distribute the         processes over the actual network so as to execute the program in the most efficient way. Experience in using mpC for solving         problems on local networks consisting of heterogeneous workstations is discussed.      </content></document><document><year>2007</year><authors>N. A. Taranukha1  | Z. A. Izabekov1 </authors><title>A method for voxel visualization of 3D objects      </title><content>In the paper, a method for forming data structures for voxel description of volume objects is suggested. An approach for projecting         octant trees (octrees) is formulated and described. A method for visualization of volume data represented by a voxel octree         with removing invisible objects is suggested. We formulate a rule for the choice of transversal order for recursive structure         for forming an image with removing invisible parts, which makes it possible to reduce the time of priority calculations in         sorting voxels by the distance to the observer. Formation of topology of voxel projection images of three types and the corresponding         data structures are considered. A space of 3D object mappings represented by voxel octant trees is discussed.      </content></document><document><year>2007</year><authors>D. Yu. Gamayunov1  | R. L. Smelyanskii1 </authors><title>A model of the behavior of network objects in distributed computer systems      </title><content>A model designed for the analysis of intrusion detection methods is described. The model also helps validate such methods         and estimate their complexity. In terms of this model, a new intrusion detection method is proposed, its validity is proved,         and its computational complexity is evaluated. It differs from the available expert-based methods in that it does not impose         constraints on the behavior being detected and makes it possible to detect unknown or modified attacks.      </content></document><document><year>2007</year><authors>S. I. Vinitsky1 | V. P. Gerdt1| A. A. Gusev1| M. S. Kaschiev2| V. A. Rostovtsev1| V. N. Samoilov1| T. V. Tyupikova1 | O. Chuluunbaatar1</authors><title>A symbolic-numerical algorithm for the computation of matrix elements in the parametric eigenvalue problem      </title><content>A symbolic-numerical algorithm for the computation of the matrix elements in the parametric eigenvalue problem to a prescribed         accuracy is presented. A procedure for calculating the oblate angular spheroidal functions that depend on a parameter is discussed.         This procedure also yields the corresponding eigenvalues and the matrix elements (integrals of the eigenfunctions multiplied         by their derivatives with respect to the parameter). The efficiency of the algorithm is confirmed by the computation of the         eigenvalues, eigenfunctions, and the matrix elements and by the comparison with the known data and the asymptotic expansions         for small and large values of the parameter. The algorithm is implemented as a package of programs in Maple-Fortran and is         used for the reduction of a singular two-dimensional boundary value problem for the elliptic second-order partial differential         equation to a regular boundary value problem for a system of second-order ordinary differential equations using the Kantorovich         method.      </content></document><document><year>2007</year><authors>V. A. Semenov1 | P. B. Krylov1| S. V. Morozov1 | O. A. Tarlapan1</authors><title>An object-oriented architecture for applications of scientific visualization and mathematical modeling      </title><content>Issues of the general architecture design for integrated applications of mathematical modeling and scientific visualization         are considered. In line with the object-oriented methodologies of Bailin and Booch, a novel model for a visualization scene         is described. The scene is a composition of interrelated, typed scientific data and algorithms. A systematic approach to developing         applications based on the model is presented. Theoretical analysis is illustrated by various examples related to geometric         modeling, numerical solution of ordinary differential equations, visualization, and rendering.      </content></document><document><year>2007</year><authors>E. N. Bozhenkova1  | I. B. Virbitskaite1 </authors><title>Analysis of equivalence relations of event structures with continuous time      </title><content>Notions of testing and bisimulation equivalencies for concurrent nondeterministic processes in real (continuous) time are         introduced and analyzed. Processes are represented by timed event structures. Conditions under which the equivalencies defined         coincide are established, and algorithms for deciding equivalence are presented.      </content></document><document><year>2007</year><authors>A. V. Zamulin1 </authors><title>Andrei Ershov Fourth International Conference: Perspectives of Information Systems July 3&amp;#8211;6, 2001, Novosibirsk, Akademgorodok      </title><content>Without Abstract</content></document><document><year>2007</year><authors>I. B. Burdonov1 | A. S. Kossatchev1  | V. V. Kulyamin1 </authors><title>Application of finite automatons for program testing      </title><content>The application of the finite automaton theory to the problem of program testing is discussed. The problem is reduced to testing         a finite automaton. Testing of automatons using their state graphs, factor graphs, testing using factor graphs, and methods         for factor graphs construction are discussed.      </content></document><document><year>2007</year><authors>I. Kuralenok1  | I. Nekrest'yanov1 </authors><title>Automatic document classification based on latent semantic analysis      </title><content>In this paper, the problem of automatic document classification by a set of given topics is considered. The method proposed         is based on the use of the latent semantic analysis to retrieve semantic dependencies between words. The classification of         document is based on these dependencies. The results of experiments performed on the basis of the standard test data set TREC         (Text REtrieval Conference) confirm the attractiveness of this approach. The relatively low computational complexity of this         method at the classification stage makes it possible to be applied to the classification of document streams.      </content></document><document><year>2007</year><authors>A. V. Lapunov1  | V. A. Mityunin1</authors><title>Change of generators in differential modules      </title><content>Without Abstract</content></document><document><year>2007</year><authors>H. Le1 </authors><title>Communication-oriented representation of mathematical objects      </title><content>This paper presents two standards for communicating mathematical objects between computer programs, for representing these         objects on multimedia (i.e., the web) and our experimentation with those standards to develop input/output compliant processors         that can be used as basic components to build an effective World Wide Web computational server.      </content></document><document><year>2007</year><authors>R. I. Podlovchenko1 | V. E. Khachatryan2 | Yu. G. Chashin2</authors><title>Complete system of equivalent transformations for two-tape automata with disjoint loops      </title><content>Two-tape automata are considered such that their transition diagrams do not have intersecting loops. A system of equivalent         transformations is described for these automata, and its completeness with respect to the set of the transformations is proved.      </content></document><document><year>2007</year><authors>A. V. Zorin1| L. A. Sevastianov1  | N. P. Tretyakov1</authors><title>Computer modeling of hydrogen-like atoms in quantum mechanics with nonnegative distribution function      </title><content>An algorithm for describing operator structures and calculating energy levels for hydrogen-like atoms in the quantum mechanics         with nonnegative distribution function (Kuryshkin&amp;#8217;s quantum mechanics) is developed. The algorithm is implemented in Maple.         An original library of necessary functions and quantities (Coulomb wave functions, Sturm functions, their Fourier images and         kernels of integral transformations, Clebsch-Gordan coefficients, products of spherical harmonics, etc.) has been created.         In accordance with the quantization rules in Kuryshkin&amp;#8217;s quantum mechanics, operators of observable quantities are computed.         Based on the Hamiltonian obtained, energy levels of a hydrogen-like atom are calculated by the Ritz method (in the basis of         Sturm functions). Numerical values of model parameters are determined by comparing results obtained with experimental data         for hydrogen and alkali metals taken from the NIST Atomic Spectra Database Levels Data library.      </content></document><document><year>2007</year><authors>A. V. Zamulin1 </authors><title>Conference Report: Perspectives of Information Systems      </title><content>Without Abstract</content></document><document><year>2007</year><authors>E. A. Gorshkova1 | I. S. Nekrest'yanov1 | B. A. Novikov1  | E. Yu. Pavlova1 </authors><title>Consistency control for semistructured data      </title><content>Semistructured data models provide an important tool for studying methods for representing, searching, and processing heterogeneous         data in distributed systems with autonomous components (especially, on the WWW). However, the problem of data consistency         remains little investigated. In this paper, various approaches to this problem are discussed, and the usability of various         mechanisms suggested in the context of databases, including real-time databases, is analyzed. An approach based on the concept         of multilevel transactions is presented in detail. In the framework of this approach, commutativity predicates for basic operations         on semistructured data are constructed.      </content></document><document><year>2007</year><authors>E. V. Zima1  | A. M. Stewart2 </authors><title>Cunningham numbers in modular arithmetic      </title><content>The paper considers methods for modular arithmetic acceleration, based on a specific moduli selection method. Special attention         is paid to the moduli of the form 2n &amp;#8722; 1 and 2n + 1. Different schemes of choice of these types of moduli and algorithms for conversion of arbitrary precision integers into         the modular representation and back are considered. Results of experimental implementation of the described algorithms in         the GMP system are discussed.      </content></document><document><year>2007</year><authors>L. A. Kalinichenko1 | N. A. Skvortsov1 | D. O. Briukhov1 | D. V. Kravchenko1  | I. A. Chaban1 </authors><title>Designing personalized digital libraries over websites with semistructured data      </title><content>Issues concerning the design of personalized digital libraries over collections of semistructured data available on the Web         are considered. The approach suggested makes it possible to design libraries adjusted to the personal needs of information         users that place various requirements upon the contents and representation of information. The digital library is designed         as a composition of fragments of websites. In this paper, a method for the compositional design of information systems is         applied to semistructured data on the Web. This method was developed at the Institute for Problems of Informatics of the Russian         Academy of Sciences (IPI RAS) [2]. The design procedure is demonstrated by designing a library over two websites containing         data about registered patents.      </content></document><document><year>2007</year><authors>N. V. Pakulin1  | A. V. Khoroshilov1 </authors><title>Development of formal models and conformance testing for systems with asynchronous interfaces and telecommunications protocols      </title><content>There is a gap between the formal modeling and testing methods for modern protocols and asynchronous software systems: due         to high complexity of such systems, attempts to include formal models in testing procedures fail. In this paper, we propose         an approach to filling this gap based on a formalization of the behavior of systems with asynchronous interfaces using contract         specifications followed by the use of these specifications to design adaptive test suites. This approach was used for testing         various software systems including implementations of the IPv6 Internet protocols stack and implementations of the POSIX and         Linux Standard Base software interfaces.      </content></document><document><year>2007</year><authors>M. R. Kogalovsky1  | B. A. Novikov2 </authors><title>Digital libraries as a new class of information systems (from the editors of the special issue)      </title><content>In the paper, the origins of a new branch of information systems&amp;#8212;the so-called digital libraries&amp;#8212; is briefly discussed. Serious         study and development in this area only began in the early 1990s. Characteristics of digital library systems and the range         of related problems are examined. The papers of Russian authors published in this special issue are presented. These papers         are based on the materials reported at the first Russian national conference on digital libraries, held in October 1999.      </content></document><document><year>2007</year><authors>O. D. Golubitskii1 </authors><title>Distance calculation on strings      </title><content>A monoid of strings (words) over a finite alphabet is considered. The notion of distance on strings is important in the problem         of inductive learning related to artificial intelligence, in cryptography, and in some other fields of mathematics. The distance         is defined as a minimum length of the transformation path that transforms one string into another. One example is the Levenstein         distance, with the transformations being insertions, deletions, and substitutions of letters. A quadratic algorithm for calculating         this distance is known to exist. In this paper, a more general case&amp;#8212;insertion and deletion of words of arbitrary length&amp;#8212;is         considered. For this case, the problem of distance calculation turns out to be unsolvable. The basic results of this work         are the formulation of the condition of computability of distance and the algorithm for distance calculation, which is polynomial         in string length.      </content></document><document><year>2007</year><authors>L. M. Berkovich1 </authors><title>Exact linearization of nonlinear ordinary autonomous differential equations      </title><content>Many methods for finding exact solutions to nonlinear ordinary differential equations (ODE) are based on certain euristic         rules. The author suggested a newexact linearization method that provides an algorithmic procedure for constructing exact solutions for some important classes of ODEs [1].      </content></document><document><year>2007</year><authors>M. R. Kogalovsky1 | E. N. Efimova1| T. A. Rybina1 | V. B. Brakhin1</authors><title>Formal methods for verification of websites macrostructure integrity      </title><content>The problem of verifying macrostructure of websites where information resources are represented by means of HTML is studied.         The macrostructure of a website is understood as the structure of interrelations between its resources based on hyperlinks.         The approach presented involves inventorying information resources of the site, partial syntactic analysis of its HTML-files,         locating their hyperlinks, and, in so doing, reconstructing its macrostructure (the hyperlink graph of resources). The description         of the site's macrostructure is placed into a relational database and is analyzed by formal methods based on relational algebra         and graph theory in order to detect irrelevant (dangling) hyperlinks, resources to which no inner hyperlink points, as well         as hypertext pages unattainable from the homepage of the site. In the paper, the prospects of this approach are discussed         in relation to websites created with the help of XML technologies. A brief description of an implemented prototype of a verification         system for HTML sites is given.      </content></document><document><year>2007</year><authors>I. B. Bourdonov1 | A. S. Kossatchev1  | V. V. Kuliamin1 </authors><title>Formalization of test experiments      </title><content>Formal methods for testing conformance of the system under examination to its specification are examined. The operational         interaction semantics is specified by a special testing machine that formally determines the testing capabilities. A set of         theoretically powerful and practically important capabilities is distinguished that can be reduced to the observation of external         actions and refusals (the absence of external actions). The novelties are as follows. (1) Parameterization of the semantics         by the families of observable and not observable refusals, which makes it possible to take into account various constraints         on the (correct) interactions. (2) Destruction as a forbidden action, which is possible but should not be performed in the         case of a correct interaction. (3) Modeling of the divergence by the &amp;#916;-action, which also should be avoided in the case of         a correct interaction. On the basis of this semantics, the concept of safe testing, the implementation safety hypothesis,         and the safe conformance relation are proposed. The safe conformance relation corresponds to the principle of independent         observations: a behavior of an implementation is correct or incorrect independently of its other possible behaviors. For a         more narrow class of interactions, another version of the semantics based on the ready traces may be used along with the corresponding         conformance relation. Some propositions concerning the relationships between the conformance relations under various semantics         are formulated. The completion transformation that solves the problem of the conformance relation reflexivity and a monotone         transformation that solves the monotonicity problem (preservation of the conformance under composition) are defined.      </content></document><document><year>2007</year><authors>D. G. Shopyrin1  | A. A. Shalyto1</authors><title>Graphical inheritance notation for state-based classes      </title><content>State-based object-oriented programming combines basic advantages of object-oriented and automata-based programming technologies.         Its basic features are flexibility, extensibility, and powerful mechanism of description of complex behavior, which is based         on finite automata. The disadvantage of the state-based object-oriented programming is the lack of standard methods for designing         and implementing state-based classes. In this work, graphical notation for designing state-based classes, which combines capabilities         of the class diagrams of the object-oriented programming and behavior diagrams of the automata-based programming, is presented.         The proposed graphical notation makes it possible to generalize, decompose, structure, and incrementally extend logic of the         state-based classes by means of the inheritance.      </content></document><document><year>2007</year><authors>F. Ulmer1 </authors><title>How to solve linear differential equations: An outline      </title><content>There are several definitions of closed form solutions to linear differential equations. In this paper, we look for the so-called         Liouvillian solutions. Through examples, we give an overview of how the differential Galois theory leads to algorithms to         find the Liouvillian solutions. We will outline the general ideas and results, but will give examples instead of proofs.      </content></document><document><year>2007</year><authors>A. N. Terekhov1  | V. V. Sokolov1 </authors><title>Implementation of the conformation of MSC and SDL diagrams in the REAL technology      </title><content>Various methods of relating MSC and SDL diagrams are considered, including methods that allow one to automate manual conversion         from scenarios of the behavior of the entire system (HMSC/MSC) to behavior models of separate objects (SDL), methods for supporting         their conformity during the entire life cycle (concerted modification), and extensions of the MSC diagrams for real situations.         The existing algorithms are reviewed, their advantages and disadvantages are considered, and our own approaches eliminating         the disadvantages are proposed. The proposed algorithms are integrated into one complex.      </content></document><document><year>2007</year><authors>J. Torres1 | O. Martin1 | J. A. Troyano1  | M. Toro1 </authors><title>Implementing associations among classes in an environment of active databases      </title><content>The association is a native concept from relational databases, one that has been adapted to object oriented (OO) modelling.         It is an interesting operator used to describe links among objects of a system, commonly included in the most popular diagram-based         OO methodologies. However, those methodologies sometimes present a lack of formality that may undermine its use. In this paper         we formalize the semantics of associations. Firstly, we will describe an OO model based on different kinds of constraints.         Some of them will be especially useful for describing the semantics of associations. Finally, we will present some remarks         about implementation by means of triggers, a new feature incorporated in databases to specify an inner active behavior.      </content></document><document><year>2007</year><authors>D. E. Khmel&amp;#8217 nov1 </authors><title>Improved algorithms for solving difference andq-difference equations      </title><content>Improved algorithms for finding denominators of rational solutions of linear difference andq-difference equations with polynomial coefficients are proposed. The improved efficiency of these algorithms is achieved as         a result of a more efficient implementation of the Abramov algorithm (due to the use of the Man and Wright algorithm for calculating         the dispersion, which is extended for the case ofq-dispersion) and of the improvement of this algorithm by using an additional procedure for minimizing the degree of the denominator         (similar to the Migushov algorithm). The case of difference equations is analyzed in detail, whereasq-difference equations are considered by analogy with the first case. The algorithms described were implemented in Maple V.      </content></document><document><year>2007</year><authors>S. A. Abramov1  | S. P. Polyakov1 </authors><title>Improved universal denominators      </title><content>The paper presents an algorithm for improvement (degree reduction) of universal denominators, which are used, for example,         for constructing rational solutions of linear differential and difference systems with polynomial coefficients. A variant         of Zeilberger&amp;#8217;s algorithm is described; it uses construction of universal denominator instead of application of Gosper&amp;#8217;s algorithm.      </content></document><document><year>2007</year><authors>R. I. Podlovchenko1  | D. M. Rusakov1 </authors><title>Inclusion problem in algebraic models of programs with constants      </title><content>Without Abstract</content></document><document><year>2007</year><authors>A. N. Bezdushnyi1 | A. B. Zhizhchenko1 | M. V. Kulagin1  | V. A. Serebryakov1 </authors><title>Integrated information resource system of the Russian Academy of Sciences and a technology for developing digital libraries      </title><content>Problems of developing digital libraries are considered. An analysis of this class of distributed information systems is given.         The main effort is focused on the formalization of properties of the stored objects and operations, which makes it possible         to construct a formal model of digital libraries. This model can serve as a basis for designing development tools. Systems         based on this approach are called integrated information resource systems (IIRS). In particular, the information retrieval         system of the Russian Academy of Sciences (IIRS RAS) is based on these principles. The paper is organized as follows. First,         the aim of the paper is outlined. Then, the definition of a digital library is given (as it is understood by the authors),         basic concepts are discussed, and IIRS is considered as a digital library. The notion of the resource is introduced as the         basic object to be processed. Metadata and their role in the system of digital libraries are considered, as well as the role         of relationships and data organization. Then, the architecture and functional capabilities of IIRS are considered, and, in         particular, a metamodel of the system, data search, and the implementation of data distribution. The current implementation         of IIRS RAS is briefly outlined.      </content></document><document><year>2007</year><authors>Kh. D. Ikramov1  | N. V. Savel&amp;#8217 eva1</authors><title>Invariant subspaces of matrix algebras and MAPLE procedures detecting their existence      </title><content>Without Abstract</content></document><document><year>2007</year><authors>S. I. Serdyukova1 </authors><title>Inverse problem for the two-dimensional discrete Schrdinger equation in a square      </title><content>The potential of the two-dimensional discrete Schrdinger equation can be reconstructed from a part of its spectrum and prescribed         symmetry conditions of the basis eigenfunctions. The discrete potential along with the missing eigenvalues is found by solving         a polynomial system of equations, which is derived and solved using the REDUCE computer algebra system. To ensure the convergence         of the iterative process implemented in the Numeric package in REDUCE, proper initial data must be specified. The prescribed         eigenvalues are perturbed original eigenvalues corresponding to the zero discrete potential. The original eigenvalues provide         the natural initial data for the corresponding missing eigenvalues. In the case of a square, there are many multiple eigenvalues         among the original eigenvalues. The direct application of the variant of the Newton method implemented in the Numeric package         in REDUCE is impossible in the case of multiple initial data. A modification of the method proposed earlier for calculating         the discrete potential of the two-dimensional discrete Schrdinger equation in a square is illustrated by an example.      </content></document><document><year>2007</year><authors>A. V. Astrelin1 | O. D. Golubitsky1 | E. V. Pankratiev1</authors><title>Involutive bases of ideals in the ring of polynomials      </title><content>This paper continues the study of the relationship between Grbner bases and involutive bases of polynomial ideals started         in [1, 5]. Involutive bases are considered as Grbner bases with some fixed normal form algorithms. It is shown that once         the search order of critical pairs is coordinated, the sameS-elements and their reductions appear in the same order in the process of the construction of Grbner bases and involutive         bases.      </content></document><document><year>2007</year><authors>A. S. Semenov1  | P. A. Zyuzikov1 </authors><title>Involutive divisions and monomial orderings      </title><content>In the paper, two classes of involutive divisions related to admissible monomial orderings&amp;#8212;&amp;#8827;-divisions and &amp;#8826;-divisions&amp;#8212;are         considered. The latter may be viewed as an improvement of the class of induced divisions introduced in [1]. The continuity         and constructivity of the &amp;#8826;-divisions, as well as a number of additional properties of the &amp;#8827;-divisions, are proved. Taking         into account that the Janet division is a &amp;#8827;-division associated with the lexicographical order, its &amp;#8220;antipode&amp;#8221;&amp;#8212;a &amp;#8826;-division         associated with the same order&amp;#8212;is separated in the class of the &amp;#8826;-divisions.      </content></document><document><year>2007</year><authors>M. A. Osipov1 | O. L. Machul'sky2  | L. A. Kalinichenko3 </authors><title>Mapping the XML data model into the object model of the SYNTHESIS language      </title><content>In this paper, a mapping of the XML document structure into the canonical data model is studied [5]. The XML document structure         is specified by the Document Type Definition (DTD). DTD serves as a basis for a specification in the SYNTHESIS language; each         DTD element declaration is mapped into some data type of SYNTHESIS.      </content></document><document><year>2007</year><authors>F. A. Kolpakov1 | N. L. Podkolodnyi1| S. V. Lavryushev1| D. A. Grigorovich1| M. P. Ponomarenko1 | N. A. Kolchanov1</authors><title>Methods for integration of heterogeneous information resources in molecular biology in the digital library GeneExpress      </title><content>Difficulties in integrating information resources (IRs) in molecular biology are due to a complex hierarchical and/or network         organization of data, to their heterogeneity, complex interrelations, insufficient formalization, and to incompleteness. To         overcome these difficulties, a digital library called GeneExpress has been under development in the Institute of Cytology         and Genetics of the Siberian Division of Russian Academy of Sciences. This system, which belongs to a new class of information         systems, integrates a great number of data-bases and hundreds of computer programs designed for processing information on         the structure and functions of DNA, RNA, and proteins. The foundation of our approach is provided by hypertext integration,         integration on the basis of a unified object-oriented environment by mapping the data into a canonical model with the use         of specially designed mediators, and semantic data integration. A prototype of an implementation of this approach used in         the current version of GeneExpress is described.      </content></document><document><year>2007</year><authors>A. V. Babichev1  | V. G. Lebedev1 </authors><title>Model-100: Specification language for interacting processes      </title><content>Basic ideas and constructs of the Model-100 language designed for describing behavior of interacting processes are discussed.         Process interaction rules are specified by clauses of the form &amp;#8220;if &amp;#8230; then &amp;#8230;&amp;#8221; (Horn clauses). Structure of the interactions         is presented by a graph described by a rational term. Execution of one step of the program reduces to simultaneous application         of all rules to all nodes to which the rule can be applied (i.e., to all rational subterms with which the Horn clause can         be unified).      </content></document><document><year>2007</year><authors>O. S. Paramonova1  | A. V. Niukkanen2</authors><title>New algorithms for deriving reduction formulas for hypergeometric series of multiple variables      </title><content>A Maple-implementation of algorithms for the automatic derivation of hypergeometric series reduction formulas of the most         general form is considered. The list of elementary reductions is presented.      </content></document><document><year>2007</year><authors>A. V. Niukkanen1 </authors><title>New algorithms in the theory of hypergeometric series and Burchnall-Chaundy expansions      </title><content>It is shown that the Burchnall-Chaundy expansions, which are of fundamental importance in the theory of Appell's functions,         can easily be implemented and generalized by means of the operator factorization method, which provides a simple and universal         base, both for a new theory of hypergeometric series and for the development of effective new algorithms for computer-aided         symbolic transformations of these series. Five new generalized expansions are derived, including 44 Burchnall-Chaundy expansions,         as well as many new expansions, some of which are related to the Horn series.      </content></document><document><year>2007</year><authors>A. V. Demakov1 </authors><title>Object-oriented description of graph data structures      </title><content>A solution method for problems of processing graph data structures is presented. This method is based on the use of the specialized         language TreeDL and on its extendable compiler. The capabilities of the language and of the compiler exceed the existing solutions,         which makes the proposed method more efficient than its analogs.      </content></document><document><year>2007</year><authors>E. S. Shemyakova1  | F. Wincler1 </authors><title>Obstacles to factorization of partial differential operators into several factors      </title><content>In the paper, construction of algorithms for factoring linear partial differential operators is studied. New theoretical concepts&amp;#8212;obstacle         and ring of obstacles&amp;#8212;are introduced. These are invariants and posses other interesting properties. A theorem on unique factorization         extension starting from some moment, which is important from the standpoint of construction of such algorithms, is proved.         Obstacles in the case of the second and third degrees are found.      </content></document><document><year>2007</year><authors>R. I. Podlovchenko1 </authors><title>On a general solution to the problem of equivalent transformations of program schemes      </title><content>Schemes of programs without procedures are considered, and a rich family of scheme equivalences is studied. The structure         of equivalent schemes is analyzed in order to build transformation systems that are complete with respect to equivalences         from this family. The first result of the research is reported, which is that all equivalences from the family in question         are solvable.      </content></document><document><year>2007</year><authors>R. I. Podlovchenko1 </authors><title>On a general solution to the problem of equivalent transformations of program schemes (II)      </title><content>Schemes of programs without procedures are considered, and a rich family of scheme equivalences is studied. The known properties         of the structure of equivalent schemes make it possible to build, for each equivalence relation, an algorithm of polynomial         complexity recognizing the equivalence and a complete system of equivalent transformations of schemes.      </content></document><document><year>2007</year><authors>A. L. Gomozov1  | L. I. Stanevichene1</authors><title>On a generalization of regular expression      </title><content>CF expressions are defined. Using the concept of D-graphs, it is demonstrated that CF expressions define CF languages. A subclass         (equivalent to the class of regular expressions) of pseudo-coiterating CF expressions is defined.      </content></document><document><year>2007</year><authors>A. V. Klepinin1 </authors><title>On a universal model for the organization of database access      </title><content>Without Abstract</content></document><document><year>2007</year><authors>V. P. Gerdt1  | Yu. A. Blinkov2 </authors><title>On selection of nonmultiplicative prolongations in computation of Janet bases      </title><content>We consider three modifications of our basic involutive algorithm for computing polynomial Janet bases. These modifications,         which are related to degree-compatible monomial orders, yield specific selection strategies for nonmultiplicative prolongations.         Using a standard database of benchmarks designed for testing programs computing Grbner bases, we compare these algorithmic         modifications (in terms of their efficiency) with Faugre&amp;#8217;s F         4 algorithm, which is built in the Magma computer algebra system.      </content></document><document><year>2007</year><authors/></document><document><year>2005</year><authors>E. A. Gorshkova1| B. A. Novikov1| D. D. Belov2| V. S. Gurov3 | S. V. Spiridonov4 </authors><title>A UML-based modeling of web application controller</title><content>In this paper, the method suggested in [1] for designing web applications is extended through the modeling of logic of the web application controller. The UML diagram of the controller configuration is described in detail, and its use for the application development is explained.</content></document><document><year>2005</year><authors>E. A. Gorshkova1| B. A. Novikov1| D. D. Belov2| V. S. Gurov3 | S. V. Spiridonov4 </authors><title>A UML-based modeling of web application controller</title><content>In this paper, the method suggested in [1] for designing web applications is extended through the modeling of logic of the web application controller. The UML diagram of the controller configuration is described in detail, and its use for the application development is explained.</content></document><document><year>2005</year><authors>L. Ya. Savel'ev1 </authors><title>An Algorithm for Partitioning a Set into Simple Parts      </title><content>The paper describes a method for the structural analysis of abstract data and its applications. A finite set with two numberings,         two order relations, and one symmetry relation is considered. An algorithm is proposed for partitioning this set into simple         parts determined by compositions of given relations. Each simple part of the set is then partitioned into layers. This model         can also be used for analyzing different data admitting similar formalization. It can be used for analyzing structure of some         graphs (in particular, graphs describing molecular associations). The proposed algorithms are used for partitioning a complex         family into simple ones determined by family relationships and for determining family generations. The algorithms can be applied         to analyzing corporations with a family-like structure.      </content></document><document><year>2005</year><authors>V. A. Kostenko1  | E. S. Gur'yanov1</authors><title>An Algorithm for Scheduling Exchanges over a Bus with Centralized Control and an Analysis of Its Efficiency      </title><content>Without Abstract</content></document><document><year>2005</year><authors>A. Ya. Kalinov1 | K. A. Karganov1  | K. V. Khorenko1 </authors><title>An approach to the development of debuggers that use semantics of constructs of parallel programs</title><content>In the paper, a new approach to the development of interactive debuggers for parallel programs that use message-passing model is suggested. The basic idea of the approach is to design a debugger specific to a particular language or a parallel programming library and to use information about the semantics of constructs used in the parallel program for processing commands of the step-by-step execution and data representation. The development of the user interface and internal debugger structure, as well as their implementations in the debuggers for mpC programs and programs using the MPI library, are considered.</content></document><document><year>2005</year><authors>A. Ya. Kalinov1 | K. A. Karganov1  | K. V. Khorenko1 </authors><title>An approach to the development of debuggers that use semantics of constructs of parallel programs</title><content>In the paper, a new approach to the development of interactive debuggers for parallel programs that use message-passing model is suggested. The basic idea of the approach is to design a debugger specific to a particular language or a parallel programming library and to use information about the semantics of constructs used in the parallel program for processing commands of the step-by-step execution and data representation. The development of the user interface and internal debugger structure, as well as their implementations in the debuggers for mpC programs and programs using the MPI library, are considered.</content></document><document><year>2005</year><authors>I. V. Konnov1 | V. A. Zakharov1 </authors><title>An Approach to the Verification of Symmetric Parameterized Distributed Systems      </title><content>Without Abstract</content></document><document><year>2005</year><authors>S. D. Shtovba1 </authors><title>Ant Algorithms: Theory and Applications</title><content>This paper reviews the theory and applications of ant algorithms, new methods of discrete optimization based on the simulation of self-organized colony of biologic ants. The colony can be regarded as a multi-agent system where each agent is functioning independently by simple rules. Unlike the nearly primitive behavior of the agents, the behavior of the whole system happens to be amazingly reasonable. The ant algorithms have been extensively studied by European researchers from the mid-1990s. These algorithms have successfully been applied to solving many complex combinatorial optimization problems, such as the traveling salesman problem, the vehicle routing problem, the problem of graph coloring, the quadratic assignment problem, the problem of network-traffic optimization, the job-shop scheduling problem, etc. The ant algorithms are especially efficient for online optimization of processes in distributed nonstationary systems (for example, telecommunication network routing).</content></document><document><year>2005</year><authors>A. A. Ryabenko1  | S. L. Skorokhodov1 </authors><title>Asymptotics of sums of hypergeometric terms</title><content>Without Abstract</content></document><document><year>2005</year><authors>I. B. Bourdonov1</authors><title>Backtracking Problem in the Traversal of an Unknown Directed Graph by a Finite Robot</title><content>A covering path in a directed graph is a path passing through all vertices and arcs of the graph, with each arc being traversed only in the direction of its orientation. A covering path exists for any initial vertex only if the graph is strongly connected. The traversal of an unknown graph implies that the topology of the graph is not a priori known, and we learn it only in the course of traversing the graph. This is similar to the problem of traversing a maze by a robot in the case where the plan of the maze is not available. If the robot is a general-purpose computer without any limitations on the number of its states, then traversal algorithms with the estimate O(nm) are known, where n is the number of vertices and m is the number of arcs. If the number of states is finite, then this robot is a finite automaton. Such a robot is an analogue of the Turing machine, where the tape is replaced by a graph and the cells are assigned to the graph vertices and arcs. The selection of the arc that has not been traversed yet among those originating from the current vertex is determined by the order of the outgoing arcs, which is a priori specified for each vertex. The best known traversal algorithms for a finite robot are based on constructing the output directed spanning tree of the graph with the root at the initial vertex and traversing it with the aim to find all untraversed arcs. In doing so, we face the backtracking problem, which consists in searching for all vertices of the tree in the order inverse to their natural partial ordering, i.e., from the leaves to the root. Therefore, the upper estimate of the algorithms is different from the optimal estimate O(nm) by the number of steps required for the backtracking along the outgoing tree. The best known estimate O(nm + n2loglogn) has been suggested by the author in the previous paper [1]. In this paper, a finite robot is suggested that performs a backtracking with the estimate O(n2log*(n)). The function log* is defined as an integer solution of the inequality 1  log2log*(n) t = log &amp;ordm; log &amp;ordm; ... &amp;ordm; log (the superposition &amp;ordm; is applied t &amp;#x2013; 1 times) is the tth compositional degree of the logarithm. The estimate O(nm + n2log*(n)) for the covering path length is valid for any strongly connected graph for a certain (unfortunately, not arbitrary) order of the outgoing arcs. Interestingly, such an order of the arcs can be marked by symbols of the finite robot traversing the graph. Hence, there exists a robot that traverses the graph twice: first traversal with the estimate O(nm + n2loglogn) and the second traversal with the estimate O(nm + n2log*(n)).</content></document><document><year>2005</year><authors>V. V. Monakhov1 | A. V. Kozhedub1| P. A. Naumenko1| L. A. Evstigneev1| M. A. Krukelis1| D. V. Solodovnikov1 | I. B. Kernitskii1</authors><title>BARSIC: A Programming System for Physicists</title><content>The paper describes the BARSIC program complex developed by the authors. Its main features and benefits are considered from the viewpoint of the developer of applications for solving problems in physics.</content></document><document><year>2005</year><authors>M. V. Kondratieva1  | A. I. Ovchinnikov1 </authors><title>Characteristic sets for ordinary differential equations</title><content>In this paper, the problem of the construction of a characteristic set in the sense of Kolchin for a radical differential ideal is considered. Algorithms for constructing such sets in the ordinary case for arbitrary radical differential ideals, which are based on the estimate of the orders of their elements, are presented. These algorithms are applicable in the case of an orderly ranking on the set of the derivatives. Advantages of the regular and characteristic decompositions of radical differential ideals are discussed.</content></document><document><year>2005</year><authors>V. V. Kornyak1 </authors><title>Cohomologies of restricted Lie algebras of Hamiltonian vector fields: Computer analysis</title><content>Restricted algebras, or Lie p-algebras, of vector fields are finite-dimensional analogs of the corresponding classical algebras defined over fields of positive characteristic p. Our computations of p-algebras of Lie vector fields that preserve the symplectic structure (i.e., Hamiltonian and Poisson algebras) revealed important and interesting specific features of the structure of their cohomologies. Explanations of these specific features are presented.</content></document><document><year>2005</year><authors>A. V. Leonov1 | R. R. Khusnutdinov1</authors><title>Construction of an Optimal Relational Schema for Storing XML Documents in an RDBMS without Using DTD/XML Schema</title><content>The goal of this work is to construct an optimal relational schema for storing XML documents in a relational database (RDBMS) with the possibility of subsequently processing their elements without using information about the structure of these documents (such as DTD, XML Schema, and so on). A survey of the currently available methods for solving this problem is given, and the most promising among them from the standpoint of processing large arrays of documents are selected. Then, the methods selected are refined and modified, and, on the basis of these methods, a system for storing XML documents in an RDBMS is constructed. Finally, the performance of this system for each method considered is tested, and, by the results of these tests, an optimal relational schema is selected.</content></document><document><year>2005</year><authors>A. I. Bogolubsky1  | S. L. Skorokhodov2 </authors><title>Construction of generalized Gauss-Jacobi quadratures by means of computer algebra methods</title><content>Without Abstract</content></document><document><year>2005</year><authors>S. E. Bazhanov1 | V. P. Kutepov1  | D. A. Shestakov1</authors><title>Functional Parallel Typified Language and Its Implementation on Clusters      </title><content>In the paper, a functional parallel programming system implemented on clusters is discussed. It includes a language of compositional         functional parallel programming, program development tools, and tools for controlling parallel code execution on the clusters.      </content></document><document><year>2005</year><authors>S. V. Zelenov1  | S. A. Zelenova1</authors><title>Generation of Positive and Negative Tests for Parsers      </title><content>A methodology for automatic positive and negative test set generation for testing parsers is described. Coverage criteria         for such test sets based on the model approach to testing are proposed. Methods for the generation of test sets satisfying         these criteria are discussed. Results of the application of the proposed methodology for testing parsers for various languages         including C and Java are presented.      </content></document><document><year>2005</year><authors>A. Lukin1 | D. Kubasov1</authors><title>High-Quality Algorithm for Bayer Pattern Interpolation</title><content>In this paper, a brief survey of the algorithms for interpolating images represented in the form of the Bayer patterns is given, and a new interpolation algorithm considerably improving the image quality is suggested. The suggested algorithm is based on the Kimmel algorithm improved by introducing several modifications, such as a more accurate interpolation of the green color, adaptive control of the number of the iterations, and projection onto the input data.</content></document><document><year>2005</year><authors>B. Kh. Barladyan1| A. G. Voloboi1 | N. I. V'yukova2| V. A. Galaktionov1 | N. B. Deryabin1</authors><title>Illumination Modeling and Generation of Realistic Images Using Internet Technologies      </title><content>A technology for developing Internet applications involving computer graphics is presented. Such applications enable Internet         users create physically accurate models of global scene illumination and produce high-quality images; it also allows scene         editing. Based on this technology, software for creating active presentations or services accessed via the Internet was developed.         Architectural, technological, and software solutions that ensure effective modeling of illumination, produce realistic images,         and ensure a reasonable response time when working with Internet applications are considered.      </content></document><document><year>2005</year><authors>D. A. Lizorkin1  | K. Yu. Lisovsky2 </authors><title>Implementation of the XML linking language XLink by functional methods</title><content>This paper is devoted to the construction of processors of a language for describing links between resources in XML documents, which is based on the application of functional programming methods and representation of XML data as S-expressions. An implementation in the high-level functional programming language Scheme, the system SXLink compatible with the XLink specification of the W3 consortium, is considered. A survey and comparative analysis of the existing implementations of the XLink language are given. Typical difficulties associated with the implementation and use of the language are identified, and methods to overcome them are discussed. Examples of the application of the SXLink system to solving problems of processing links between resources in XML documents are considered. An SXLink application program interface based on the use of functions of the Scheme language as first-class objects is suggested. The application of this approach to constructing simple and powerful XLink processors is discussed.</content></document><document><year>2005</year><authors>D. A. Lizorkin1  | K. Yu. Lisovsky2 </authors><title>Implementation of the XML linking language XLink by functional methods</title><content>This paper is devoted to the construction of processors of a language for describing links between resources in XML documents, which is based on the application of functional programming methods and representation of XML data as S-expressions. An implementation in the high-level functional programming language Scheme, the system SXLink compatible with the XLink specification of the W3 consortium, is considered. A survey and comparative analysis of the existing implementations of the XLink language are given. Typical difficulties associated with the implementation and use of the language are identified, and methods to overcome them are discussed. Examples of the application of the SXLink system to solving problems of processing links between resources in XML documents are considered. An SXLink application program interface based on the use of functions of the Scheme language as first-class objects is suggested. The application of this approach to constructing simple and powerful XLink processors is discussed.</content></document><document><year>2005</year><authors>I. B. Virbitskaite1</authors><title>Information Announcement on Sixth International Andrei Ershov Memorial Conference &amp;#8220;Perspectives of System Informatics,&amp;#8221; 27&amp;#8211;30         June 2006, Novosibirsk, Akademgorodok, Russia      </title><content>Without Abstract</content></document><document><year>2005</year><authors>A. S. Semenov1 </authors><title>Involutive divisions: Slice and pair properties</title><content>Two classes of involutive divisions are considered: pairwise and sliced ones. Pairwise involutive divisions are convenient for the calculation of multiplicative and nonmultiplicative variables when new monomials are added. Directed sliced partitions are convenient for finding involutive divisors of an arbitrary monomial. It is proved that the only homothetic division that is simultaneously pairwise and directed sliced is the Janet involutive division. This shows that the Janet division is optimal for the calculation of multiplicative variables and for the fast search of a divisor.</content></document><document><year>2005</year><authors>V. V. Toporkov1  | A. S. Toporkova2 </authors><title>Measuring the Execution Time of Fragmented Programs</title><content>A technique for evaluating the execution time of program fragments on superscalar and explicitly parallel processors is described. Rules for the fragmentation and modification of the initial source code in a high-level language are proposed, and examples in C++ are considered. An implementation of the dynamic analysis of programs and the examination of its results with account for side effects caused by specific features of a processor architecture and operating system are considered.</content></document><document><year>2005</year><authors>N. A. Likhoded1 | S. V. Bakhanovich1  | A. V. Zherelo1 </authors><title>Obtaining Affine Transformations to Improve Locality of Loop Nests      </title><content>A new method for obtaining affine transformations of loops for the localization (fast reuse) of program data is proposed.         A technique of multidimensional scheduling is used with the following strategy of locality improvement: derive affine transformations         allowing one to quickly reuse as much data as possible; if the amount of localized data is insufficient, apply a blocking.         The method can easily be automated; the dependence on external parameters of the loops is explicitly taken into account.      </content></document><document><year>2005</year><authors>A. V. Mesyanzhin1 </authors><title>On a method for finding the roots of an ideal</title><content>Without Abstract</content></document><document><year>2005</year><authors>On the Jubilee of Nikolai Petrovich Brusentsov&amp;#x2019;s Birth</authors><title/></document></documents>