GUID:7185439F-0C3B-4BA4-9E3C-73D9561AD857
LCount:700
CCount:140
ClCount:7
ClNames: Classification; Computer simulation; Control systems; digital libraries; mathematical models; network protocols; pattern recognition;
L:1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 837 838 839 840 
C:697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 
ID:1
CLASS:1
Title: A two-stage fingerprint classification system
Abstract: In this paper we describe a fingerprint classification system based on a two-stage sequential architecture: an MKL-based classifier is first used to select the two-most-likely classes and then a second classifier (specifically trained to discriminate between the two classes) is then adopted for the final decision. The experimentation performed on NIST Special Database 4, which is one of the most important benchmarks in this area, shows that the new approach yields an error rate lower than previously published in the literature. In particular, the error rate is 4.8% and 3.7% for the five-class problem and four-class problem, respectively.
ID:2
CLASS:1
Title: Classification of heterogeneous gene expression data
Abstract: Recent advanced technologies in DNA microarray analysis are intensively applied in disease classification, especially for cancer classification. Most recent proposed gene expression classifiers can successfully classify testing samples obtained from the same microarray experiment as training samples with the assumption that the symmetric errors are constant among training and testing samples. However, the classification performance is degraded with heterogeneous testing samples obtained from different microarray experiments. In this paper, we propose the "impact factors" (IFs) to measure the variations between individual classes in training samples and heterogeneous testing samples, and integrate the IFs to classifiers for classification of heterogeneous samples. Two publicly available lung adenocarcinomas gene expression data sets are used in our experiments to demonstrate the effectiveness of the IFs. It shows that, with the integration of the IFs to the Golub and Slonim (GS) and k-nearest neighbors (kNN) classifiers, the classifiers can be further improved on the classification accuracy of heterogeneous samples. Even more, the classification accuracy of the integrated GS classifier is around 90%.
ID:3
CLASS:1
Title: Investigating regular sense extensions based on intersective Levin classes
Abstract: In this paper we specifically address questions of polysemy with respect to verbs, and how regular extensions of meaning can be achieved through the adjunction of particular syntactic phrases. We see verb classes as the key to making generalizations about regular extensions of meaning. Current approaches to English classification, Levin classes and WordNet, have limitations in their applicability that impede their utility as general classification schemes. We present a refinement of Levin classes, intersective sets, which are a more fine-grained classification and have more coherent sets of syntactic frames and associated semantic components. We have preliminary indications that the membership of our intersective sets will be more compatible with WordNet than the original Levin classes. We also have begun to examine related classes in Portuguese, and find that these verbs demonstrate similarly coherent syntactic and semantic properties.
ID:4
CLASS:1
Title: An efficient method for determining bilingual word classes
Abstract: In statistical natural language processing we always face the problem of sparse data. One way to reduce this problem is to group words into equivalence classes which is a standard method in statistical language modeling. In this paper we describe a method to determine bilingual word classes suitable for statistical machine translation. We develop an optimization criterion based on a maximum-likelihood approach and describe a clustering algorithm. We will show that the usage of the bilingual word classes we get can improve statistical machine translation.
ID:5
CLASS:1
Title: Whole-genome functional classification of genes by latent semantic analysis on microarray data
Abstract: Quantitative simultaneous monitoring of the expression levels of thousands of genes under various experimental conditions is now possible using microarray experiments. The resulting microarray data are very useful for elucidating the functional relationships among genes in the genomes. However, due to the experimental and biological nature of the data, wholegenome functional classification of genes on microarray data remains a challenging machine learning problem. In this paper, we introduce the application of latent semantic analysis (LSA) to microarray expression data for systematic, genome-wide functional classification of genes.In the LSA approach considered here, singular value decomposition is first applied as a dimensionreducing step on the gene expression data, followed by an unsupervised clustering procedure based on vector similarities in the truncated space. Functional classification is then conducted through calling by majority on each of the resulting gene clusters. Using this semi-supervised LSA approach on microarray data, we have performed systematic functional classification on the genes in the partially-annotated yeast genome, annotating more than 1,700 unknown genes into 40 distinct functional classes with promising results.
ID:6
CLASS:1
Title: An evolutionary optimization approach for 3D human head model classification
Abstract: Classification of 3-D head models based on their shape attributes for subsequent indexing and retrieval are important in many applications, as in the selection and generation of human characters in virtual scenes, and the composition of morphing sequences requiring a qualitatively similar target head model. Simple feature representations are more efficient but may not be adequate for distinguishing the subtly different head model classes. In view of these, we propose an optimization approach based on genetic algorithm (GA) where the original model representation is transformed in such a way that the classification rate is significantly enhanced while retaining the efficiency and simplicity of the original representation. Specifically, based on the Extended Gaussian Image (EGI) representation for 3-D models which summarizes the surface normal orientation statistics, we consider these orientations as a random variable, and proceed to search for an optimal transformation for this variable based on genetic optimization. The resulting transformed distribution for the random variable is then used as the modified classifier inputs. Experiments have shown that the optimized transformation results in a significant improvement in classification results for a large variety of class structures. More importantly, the transformation can be indirectly realized by bin removal and bin count merging in the original histogram, thus retaining the advantage of the original EGI representation.
ID:7
CLASS:1
Title: Automatic verb classification based on statistical distributions of argument structure
Abstract: Automatic acquisition of lexical knowledge is critical to a wide range of natural language processing tasks. Especially important is knowledge about verbs, which are the primary source of relational information in a sentence---the predicate-argument structure that relates an action or state to its participants (i.e., who did what to whom). In this work, we report on supervised learning experiments to automatically classify three major types of English verbs, based on their argument structure--specifically, the thematic roles they assign to participants. We use linguistically-motivated statistical indicators extracted from large annotated corpora to train the classifier, achieving 69.8% accuracy for a task whose baseline is 34%, and whose expert-based upper bound we calculate at 86.5%. A detailed analysis of the performance of the algorithm and of its errors confirms that the proposed features capture properties related to the argument structure of the verbs. Our results validate our hypotheses that knowledge about thematic relations is crucial for verb classification, and that it can be gleaned from a corpus by automatic means. We thus demonstrate an effective combination of deeper linguistic knowledge with the robustness and scalability of statistical techniques.
ID:8
CLASS:1
Title: Learning methods to combine linguistic indicators: improving aspectual classification and revealing linguistic insights
Abstract: Aspectual classification maps verbs to a small set of primitive categories in order to reason about time. This classification is necessary for interpreting temporal modifiers and assessing temporal relationships, and is therefore a required component for many natural language applications.A verb's aspectual category can be predicted by co-occurrence frequencies between the verb and certain linguistic modifiers. These frequency measures, called linguistic indicators, are chosen by linguistic insights. However, linguistic indicators used in isolation are predictively incomplete, and are therefore insufficient when used individually.In this article, we compare three supervised machine learning methods for combining multiple linguistic indicators for aspectual classification: decision trees, genetic programming, and logistic regression. A set of 14 indicators are combined for classification according to two aspectual distinctions. This approach improves the classification performance for both distinctions, as evaluated over unrestricted sets of verbs occurring across two corpora. This demonstrates the effectiveness of the linguistic indicators and provides a much-needed full-scale method for automatic aspectual classification. Moreover, the models resulting from learning reveal several linguistic insights that are relevant to aspectual classification. We also compare supervised learning methods with an unsupervised method for this task.
ID:9
CLASS:1
Title: A framework for the classification and the reclassification of electronic catalogs
Abstract: Electronic marketplaces are virtual communities where buyers may meet proposals of several suppliers and make the best choice. The exponential increment of the e-commerce amplifies the proliferation of different standards and joint initiatives for the classification of products and services. Therefore, B2B and B2C marketplaces have to classify products and goods according to different product classification standards. In this paper, we propose a framework to classify and reclassify electronic catalogs based on a semi-automatic methodology to define semantic mappings among different product classification standards and catalogs.
ID:10
CLASS:1
Title: Applying traits to the smalltalk collection classes
Abstract: Traits are a programming language technology that promote the reuse of methods between unrelated classes. This paper reports on a refactoring of the Smalltalk collections classes using traits. The original collection classes contained much duplication of code; traits let us remove all of it. We also found places where the protocols of the collections lacked uniformity; traits allowed us to correct these non-uniformities without code duplication.Traits also make it possible to reuse fragments of collection code outside of the existing hierarchy; for example, they make it easy to convert other collection-like things into true collections. Our refactoring reduced the number of methods in the collection classes by approximately 10 per cent. More importantly, understandability maintainability and reusability of the code were significantly improved.
ID:11
CLASS:1
Title: Automated categorization in the international patent classification
Abstract: A new reference collection of patent documents for training and testing automated categorization systems is established and described in detail. This collection is tailored for automating the attribution of international patent classification codes to patent applications and is made publicly available for future research work. We report the results of applying a variety of machine learning algorithms to the automated categorization of English-language patent documents. This procedure involves a complex hierarchical taxonomy, within which we classify documents into 114 classes and 451 subclasses. Several measures of categorization success are described and evaluated. We investigate how best to resolve the training problems related to the attribution of multiple classification codes to each patent document.
ID:12
CLASS:1
Title: A divisive information theoretic feature clustering algorithm for text classification
Abstract: High dimensionality of text can be a deterrent in applying complex learners such as Support Vector Machines to the task of text classification. Feature clustering is a powerful alternative to feature selection for reducing the dimensionality of text data. In this paper we propose a new information-theoretic divisive algorithm for feature/word clustering and apply it to text classification. Existing techniques for such "distributional clustering" of words are agglomerative in nature and result in (i) sub-optimal word clusters and (ii) high computational cost. In order to explicitly capture the optimality of word clusters in an information theoretic framework, we first derive a global criterion for feature clustering. We then present a fast, divisive algorithm that monotonically decreases this objective function value. We show that our algorithm minimizes the "within-cluster Jensen-Shannon divergence" while simultaneously maximizing the "between-cluster Jensen-Shannon divergence". In comparison to the previously proposed agglomerative strategies our divisive algorithm is much faster and achieves comparable or higher classification accuracies. We further show that feature clustering is an effective technique for building smaller class models in hierarchical classification. We present detailed experimental results using Naive Bayes and Support Vector Machines on the 20Newsgroups data set and a 3-level hierarchy of HTML documents collected from the Open Directory project (www.dmoz.org).
ID:13
CLASS:1
Title: Round robin classification
Abstract: In this paper, we discuss round robin classification (aka pairwise classification), a technique for handling multi-class problems with binary classifiers by learning one classifier for each pair of classes. We present an empirical evaluation of the method, implemented as a wrapper around the Ripper rule learning algorithm, on 20 multi-class datasets from the UCI database repository. Our results show that the technique is very likely to improve Ripper's classification accuracy without having a high risk of decreasing it. More importantly, we give a general theoretical analysis of the complexity of the approach and show that its run-time complexity is below that of the commonly used one-against-all technique. These theoretical results are not restricted to rule learning but are also of interest to other communities where pairwise classification has recently received some attention. Furthermore, we investigate its properties as a general ensemble technique and show that round robin classification with C5.0 may improve C5.0's performance on multi-class problems. However, this improvement does not reach the performance increase of boosting, and a combination of boosting and round robin classification does not produce any gain over conventional boosting. Finally, we show that the performance of round robin classification can be further improved by a straight-forward integration with bagging.
ID:14
CLASS:1
Title: Learning equivalence classes of bayesian-network structures
Abstract: Two Bayesian-network structures are said to be &lt;em&gt; equivalent&lt;/em&gt; if the set of distributions that can be represented with one of those structures is identical to the set of distributions that can be represented with the other. Many scoring criteria that are used to learn Bayesian-network structures from data are &lt;em&gt; score equivalent&lt;/em&gt;; that is, these criteria do not distinguish among networks that are equivalent. In this paper, we consider using a score equivalent criterion in conjunction with a heuristic search algorithm to perform model selection or model averaging. We argue that it is often appropriate to search among equivalence classes of network structures as opposed to the more common approach of searching among individual Bayesian-network structures. We describe a convenient graphical representation for an equivalence class of structures, and introduce a set of operators that can be applied to that representation by a search algorithm to move among equivalence classes. We show that our equivalence-class operators can be scored locally, and thus share the computational efficiency of traditional operators defined for individual structures. We show experimentally that a greedy model-selection algorithm using our representation yields slightly higher-scoring structures than the traditional approach without any additional time overhead, and we argue that more sophisticated search algorithms are likely to benefit much more.
ID:15
CLASS:1
Title: The computation and application of vector congruence classes
Abstract: In a similar fashion to the partitioning of the integers into residue classes, integer spaces (finitely generated free Z-modules) can be partitioned into complete or incomplete vector congruence classes. Complete vector congruence classes are computable by an application of the Smith normal form. The problem of computing efficiently incomplete vector congruence classes is discussed and a few methods are suggested. The application of complete and incomplete vector congruence classes is in performing set-theoretic operations on integer spaces. All set-theoretic operations can be performed on integer spaces which partition into complete vector congruence classes. Some set-theoretic operations can also be performed on integer spaces which partition into incomplete vector congruence classes, but not always in a satisfactory manner.
ID:16
CLASS:1
Title: Invited papers\&mdash;1: classification in information storage and retrieval
Abstract: WHEN I WAS ASKED to give a tutorial paper on information storage and retrieval, my first thought was to give a state-of-the-art survey of the field. But then it was evident that much of the paper would be a &ldquo;state-of-the 'state-of-the-art'&rdquo; survey since there have been several recent review papers1, 2, 3. Classification is a much used, and sometimes abused, concept not only in information storage and retrieval but in many other endeavors. Since this is the case, it seems appropriate to attempt a definitive review paper covering the concept which pervades almost all aspects of the field of information storage and retrieval.
ID:17
CLASS:1
Title: Classification of computable functions by primitive recursive classes
Abstract: A classification of all the computable functions is given in terms of subrecursive programming languages. These classes are those which also arise from the relation &ldquo;primitive recursive in.&rdquo; By distinguishing between honest and dishonest classes the classification is related to the computational complexity of the functions classified, and the classification has a wide degree of measure invariance. The structure of the honest and dishonest classes under inclusion is explored. It is shown that any countable partial ordering can be embedded in the honest or in the dishonest classes. The honest classes are dense in themselves, and the dishonest classes are dense in the honest classes. Every honest class is minimal over some dishonest class, but there is a dishonest class with no honest class minimal over it. Every honest class is the intersection (g.l.b.) of two incomparable honest classes, but there are incomparable pairs of honest classes with no g.l.b. It follows that the upper semi-lattice of the recursive degrees of primitive recursiveness is not a lattice. Finally, no r.e. increasing sequence of honest classes has a l.u.b.
ID:18
CLASS:1
Title: A case study in the use of defect classification in inspections
Abstract: In many software organizations, defects are classified very simply, using categories such as Minor, Major, Severe, Critical. Simple classifications of this kind are typically used to assign priorities in repairing defects. Deeper understanding of the effectiveness of software development methodologies and techniques requires more detailed classification of defects. A variety of classifications has been proposed.Although most detailied schemes have been developed for the purpose of analyzing software processes, defect classification schemes have the potential for more specific uses. These uses require the classification scheme to be tailored to provide relevant details. In this vein, a new scheme was developed to evaluate and compare the effectiveness of software inspection techniques. This paper describes this scheme and its use as a metric in two empirical studies. Its use was considered successful, but issues of validity and repeatability are discussed.
ID:19
CLASS:1
Title: Automated learning of model classifications
Abstract: This paper describes a new approach to automate the classification of solid models using machine learning techniques. Existing approaches, based on group technology, fixed matching algorithms or pre-defined feature sets, impose a priori categorization schemes on engineering data or require significant human labeling of design data. This paper describes a shape learning algorithm and a general technique for "teaching" the algorithm to identify new or hidden classifications that are relevant in many engineering applications. In this way, the core shape learning algorithm can be used to find a wide variety of model classifications based on user input and training data. This allows for great flexibility in search and data mining of engineering data.
ID:20
CLASS:1
Title: Web site mining: a new way to spot competitors, customers and suppliers in the world wide web
Abstract: When automatically extracting information from the world wide web, most established methods focus on spotting single HTML-documents. However, the problem of spotting complete web sites is not handled adequately yet, in spite of its importance for various applications. Therefore, this paper discusses the classification of complete web sites. First, we point out the main differences to page classification by discussing a very intuitive approach and its weaknesses. This approach treats a web site as one large HTML-document and applies the well-known methods for page classification. Next, we show how accuracy can be improved by employing a preprocessing step which assigns an occurring web page to its most likely topic. The determined topics now represent the information the web site contains and can be used to classify it more accurately. We accomplish this by following two directions. First, we apply well established classification algorithms to a feature space of occurring topics. The second direction treats a site as a tree of occurring topics and uses a Markov tree model for further classification. To improve the efficiency of this approach, we additionally introduce a powerful pruning method reducing the number of considered web pages. Our experiments show the superiority of the Markov tree approach regarding classification accuracy. In particular, we demonstrate that the use of our pruning method not only reduces the processing time, but also improves the classification accuracy.
ID:21
CLASS:1
Title: PEBL: positive example based learning for Web page classification using SVM
Abstract: Web page classification is one of the essential techniques for Web mining. Specifically, classifying Web pages of a user-interesting class is the first step of mining interesting information from the Web. However, constructing a classifier for an interesting class requires laborious pre-processing such as collecting positive and negative training examples. For instance, in order to construct a "homepage" classifier, one needs to collect a sample of homepages (positive examples) and a sample of non-homepages (negative examples). In particular, collecting negative training examples requires arduous work and special caution to avoid biasing them. We introduce in this paper the Positive Example Based Learning (PEBL) framework for Web page classification which eliminates the need for manually collecting negative training examples in pre-processing. We present an algorithm called Mapping-Convergence (M-C) that achieves classification accuracy (with positive and unlabeled data) as high as that of traditional SVM (with positive and negative data). Our experiments show that when the M-C algorithm uses the same amount of positive examples as that of traditional SVM, the M-C algorithm performs as well as traditional SVM.
ID:22
CLASS:1
Title: A refinement approach to handling model misfit in text categorization
Abstract: Text categorization or classification is the automated assigning of text documents to pre-defined classes based on their contents. This problem has been studied in information retrieval, machine learning and data mining. So far, many effective techniques have been proposed. However, most techniques are based on some underlying models and/or assumptions. When the data fits the model well, the classification accuracy will be high. However, when the data does not fit the model well, the classification accuracy can be very low. In this paper, we propose a refinement approach to dealing with this problem of model misfit. We show that we do not need to change the classification technique itself (or its underlying model) to make it more flexible. Instead, we propose to use successive refinements of classification on the training data to correct the model misfit. We apply the proposed technique to improve the classification performance of two simple and efficient text classifiers, the Rocchio classifier and the na&iuml;ve Bayesian classifier. These techniques are suitable for very large text collections because they allow the data to reside on disk and need only one scan of the data to build a text classifier. Extensive experiments on two benchmark document corpora show that the proposed technique is able to improve text categorization accuracy of the two techniques dramatically. In particular, our refined model is able to improve the na&iuml;ve Bayesian or Rocchio classifier's prediction performance by 45% on average.
ID:23
CLASS:1
Title: Enhanced word clustering for hierarchical text classification
Abstract: In this paper we propose a new information-theoretic divisive algorithm for word clustering applied to text classification. In previous work, such "distributional clustering" of features has been found to achieve improvements over feature selection in terms of classification accuracy, especially at lower number of features [2, 28]. However the existing clustering techniques are agglomerative in nature and result in (i) sub-optimal word clusters and (ii) high computational cost. In order to explicitly capture the optimality of word clusters in an information theoretic framework, we first derive a global criterion for feature clustering. We then present a fast, divisive algorithm that monotonically decreases this objective function value, thus converging to a local minimum. We show that our algorithm minimizes the "within-cluster Jensen-Shannon divergence" while simultaneously maximizing the "between-cluster Jensen-Shannon divergence". In comparison to the previously proposed agglomerative strategies our divisive algorithm achieves higher classification accuracy especially at lower number of features. We further show that feature clustering is an effective technique for building smaller class models in hierarchical classification. We present detailed experimental results using Naive Bayes and Support Vector Machines on the 20 Newsgroups data set and a 3-level hierarchy of HTML documents collected from Dmoz Open Directory.
ID:24
CLASS:1
Title: Integrating symbolic images into a multimedia database system using classification and abstraction approaches
Abstract: Symbolic images are composed of a finite set of symbols that have a semantic meaning. Examples of symbolic images include maps (where the semantic meaning of the symbols is given in the legend), engineering drawings, and floor plans. Two approaches for supporting queries on symbolic-image databases that are based on image content are studied. The classification approach preprocesses all symbolic images and attaches a semantic classification and an associated certainty factor to each object that it finds in the image. The abstraction approach describes each object in the symbolic image by using a vector consisting of the values of some of its features (e.g., shape, genus, etc.). The approaches differ in the way in which responses to queries are computed. In the classification approach, images are retrieved on the basis of whether or not they contain objects that have the same classification as the objects in the query. On the other hand, in the abstraction approach, retrieval is on the basis of similarity of feature vector values of these objects. Methods of integrating these two approaches into a relational multimedia database management system so that symbolic images can be stored and retrieved based on their content are described. Schema definitions and indices that support query specifications involving spatial as well as contextual constraints are presented. Spatial constraints may be based on both locational information (e.g., distance) and relational information (e.g., north of). Different strategies for image retrieval for a number of typical queries using these approaches are described. Estimated costs are derived for these strategies. Results are reported of a comparative study of the two approaches in terms of image insertion time, storage space, retrieval accuracy, and retrieval time.
ID:25
CLASS:1
Title: Scalable feature selection, classification and signature generation for organizing large text databases into hierarchical topic taxonomies
Abstract: We explore how to organize large text databases hierarchically by topic to aid better searching, browsing and filtering. Many corpora, such as internet directories, digital libraries, and patent databases are manually organized into topic hierarchies, also called taxonomies. Similar to indices for relational data, taxonomies make search and access more efficient. However, the exponential growth in the volume of on-line textual information makes it nearly impossible to maintain such taxonomic organization for large, fast-changing corpora by hand. We describe an automatic system that starts with a small sample of the corpus in which topics have been assigned by hand, and then updates the database with new documents as the corpus grows, assigning topics to these new documents with high speed and accuracy. To do this, we use techniques from statistical pattern recognition to efficiently separate the feature words, or discriminants, from thenoise words at each node of the taxonomy. Using these, we build a multilevel classifier. At each node, this classifier can ignore the large number of &ldquo;noise&rdquo; words in a document. Thus, the classifier has a small model size and is very fast. Owing to the use of context-sensitive features, the classifier is very accurate. As a by-product, we can compute for each document a set of terms that occur significantly more often in it than in the classes to which it belongs. We describe the design and implementation of our system, stressing how to exploit standard, efficient relational operations like sorts and joins. We report on experiences with the Reuters newswire benchmark, the US patent database, and web document samples from Yahoo!. We discuss applications where our system can improve searching and filtering capabilities.
ID:26
CLASS:1
Title: Partial information classes
Abstract: In this survey we present partial information classes, which have been studied under different names and in different contexts in the literature. They are defined in terms of partial information algorithms. Such algorithms take a word tuple as input and yield a small set of possibilities for its characteristic string as output. We define a unified framework for the study of partial information classes and show how previous notions fit into the framework. The framework allows us to study the relationship of a large variety of partial information classes in a uniform way. We survey how partial information classes are related to other complexity theoretic notions like advice classes, lowness, bi-immunity, NP-completeness, and decidability.
ID:27
CLASS:1
Title: QProber: A system for automatic classification of hidden-Web databases
Abstract: The contents of many valuable Web-accessible databases are only available through search interfaces and are hence invisible to traditional Web "crawlers." Recently, commercial Web sites have started to manually organize Web-accessible databases into Yahoo!-like hierarchical classification schemes. Here we introduce QProber, a modular system that automates this classification process by using a small number of query probes, generated by document classifiers. QProber can use a variety of types of classifiers to generate the probes. To classify a database, QProber does not retrieve or inspect any documents or pages from the database, but rather just exploits the number of matches that each query probe generates at the database in question. We have conducted an extensive experimental evaluation of QProber over collections of real documents, experimenting with different types of document classifiers and retrieval models. We have also tested our system with over one hundred Web-accessible databases. Our experiments show that our system has low overhead and achieves high classification accuracy across a variety of databases.
ID:28
CLASS:1
Title: A singer identification technique for content-based classification of MP3 music objects
Abstract: As there is a growing amount of MP3 music data available on the Internet today, the problems related to music classification and content-based music retrieval are getting more attention recently. In this paper, we propose an approach to automatically classify MP3 music objects according to their singers. First, the coefficients extracted from the output of the polyphase filters are used to compute the MP3 features for segmentation. Based on these features, an MP3 music object can be decomposed into a sequence of notes (or phonemes). Then for each MP3 phoneme in the training set, its MP3 feature is extracted and used to train an MP3 classifier which can identify the singer of an unknown MP3 music object. Experiments are performed and analyzed to show the effectiveness of the proposed method.
ID:29
CLASS:1
Title: Categorizing information objects from user access patterns
Abstract: Many web sites have dynamic information objects whose topics change over time. Classifying these objects automatically and promptly is a challenging and important problem for site masters. Traditional content-based and link structure based classification techniques have intrinsic limitations for this task. This paper proposes a framework to classify an object into an existing category structure by analyzing the users' traversals in the category structure. The key idea is to infer an object's topic from the predicted preferences of users when they access the object. We compare two approaches using this idea. One analyzes collective user behavior and the other each user's accesses. We present experimental results on actual data that demonstrate a much higher prediction accuracy and applicability with the latter approach. We also analyze the correlation between classification quality and various factors such as the number of users accessing the object. To our knowledge, this work is the first effort in combining object classification with user access prediction.
ID:30
CLASS:1
Title: Text genre classification with genre-revealing and subject-revealing features
Abstract: Subject or prepositional content has been the focus of most classification research. Genre or style, on the other hand, is a different and important property of text, and automatic text genre classification is becoming important for classification and retrieval purposes as well as for some natural language processing research. In this paper, we present a method for automatic genre classification that is based on statistically selected features obtained from both subject-classified and genre classified training data. The experimental results show that the proposed method outperforms a direct application of a statistical learner often used for subject classification. We also observe that the deviation formula and discrimination formula using document frequency ratios also work as expected. We conjecture that this dual feature set approach can be generalized to improve the performance of subject classification as well.
ID:31
CLASS:1
Title: Static load classification for improving the value predictability of data-cache misses
Abstract: While caches are effective at avoiding most main-memory accesses, the few remaining memory references are still expensive. Even one cache miss per one hundred accesses can double a program's execution time. To better tolerate the data-cache miss latency, architects have proposed various speculation mechanisms, including load-value prediction. A load-value predictor guesses the result of a load so that the dependent instructions can immediately proceed without having to wait for the memory access to complete. To use the prediction resources most effectively, speculation should be restricted to loads that are likely to miss in the cache and that are likely to be predicted correctly. Prior work has considered hardware- and profile-based methods to make these decisions. Our work focuses on making these decisions at compile time. We show that a simple compiler classification is effective at separating the loads that should be speculated from the loads that should not. We present results for a number of C and Java programs and demonstrate that our results are consistent across programming languages and across program inputs.
ID:32
CLASS:1
Title: Optimal classification and its consequences
Abstract: A particular classification and retrieval model are considered. A notion is introduced which indicates the extent to which retrieval performance may be improved by a suitable choice of classification within the model. A method for determining the optimal performance for the model is outlined together with an algorithm for constructing the classification which allows this limit to be attained. A treatment of the mathematical preliminaries for a particular class of match function is given. The relevance of the analysis in research on information retrieval systems is discussed.
ID:33
CLASS:1
Title: A categorization of classes based on the visualization of their internal structure: the class blueprint
Abstract: The reengineering and reverse engineering of software systems is gaining importance in software industry, because the accelerated turnover in software industry, because the accelerated turnover in software companies creates legacy systems in a shorter period of time. Especially understanding classes is a key activity in object-oriented programming, since classes represent the primary abstractions from which applications are built. The main problem of this task is to quickly grasp the purpose of a class and its inner structure. To help the reverse engineers in their first contact with a foreign system, we propose a categorization of classes based on the visualization of their internal structure. The contributions of this paper are a novel categorization of classes and a visualization of the which we call the class blueprint. We have validated the categorization on several case studies, two of which we present here.
ID:34
CLASS:1
Title: A robust audio classification and segmentation method
Abstract: In this paper, we present a robust algorithm for audio classification that is capable of segmenting and classifying an audio stream into speech, music, environment sound and silence. Audio classification is processed in two steps, which makes it suitable for different applications. The first step of the classification is speech and non-speech discrimination. In this step, a novel algorithm based on KNN and LSP VQ is presented. The second step further divides non-speech class into music, environment sounds and silence with a rule based classification scheme. Some new features such as the noise frame ratio and band periodicity are introduced and discussed in detail. Our experiments in the context of video structure parsing have shown the algorithms produce very satisfactory results.
ID:35
CLASS:1
Title: ACTION: automatic classification for full-text documents
Abstract: An important step in building up the document database of a full-text retrieval system is to classify each document under one or more classes according to the topical domains that the document discusses. This is commonly referred to as classification. Automatic classification attempts to replace human classifiers by using computers to automate this process. Automatic classification has two major components: (1) the classification scheme which defines the available classes under which a document can be classified and their inter-relationships; and (2) the classification algorithm which defines the rules and procedures for assigning one or more classes defined in the classification scheme to a document.In this paper, we present an automatic classification approach called ACTION. The design goal of ACTION is to achieve the appropriate balance between specificity and exhaustivity, which are important metrics for assessing an automatic classification approach. The key idea of ACTION is a scheme for measuring the significance of each keyword in a given document. The scheme not only takes into account the occurrence frequency of a keyword, but also the logical relationships between the available classes.
ID:36
CLASS:1
Title: Emancipating instances from the tyranny of classes in information modeling
Abstract: Database design commonly assumes, explicitly or implicitly, that instances must belong to classes. This can be termed the assumption of inherent classification. We argue that the extent and complexity of problems in schema integration, schema evolution, and interoperability are, to a large degree, consequences of inherent classification. Furthermore, we make the case that the assumption of inherent classification violates philosophical and cognitive guidelines on classification and is, therefore, inappropriate in view of the role of data modeling in representing knowledge about application domains.As an alternative, we propose a layered approach to modeling in which information about instances is separated from any particular classification. Two data     modeling layers are proposed: (1) an instance model consisting of an instance base (i.e., information about instances and properties) and operations to populate, use, and maintain it; and (2) a class model consisting of a class base (i.e., information about classes defined in terms of properties) and operations to populate, use, and maintain it. The two-layered model provides class independence. This is analogous to the arguments of data independence offered by the relational model in comparison to hierarchical and network models. We show that a two-layered approach yields several advantages. In particular, schema integration is shown to be partially an artifact of inherent classification that can be greatly simplified in designing a    database  based on a layered model; schema evolution is supported without the complexity of operations currently required by class-based models; and the difficulties associated with interoperability among heterogeneous databases are reduced because there is no need to agree on the semantics of classes among independent databases. We conclude by considering the adequacy of a two-layered approach, outlining possible implementation strategies, and drawing attention to some practical considerations.
ID:37
CLASS:1
Title: Explorative multilingual text retrieval based on fuzzy multilingual keyword classification
Abstract: This paper proposes an explorative approach to multilingual text retrieval (MLTR) based on fuzzy multilingual keyword classification. The approach applies fuzzy clustering to obtain a classification of multilingual keywords by concepts. A multilingual concept directory is developed by labeling each concept with native language of the target user and associating it with relevant multilingual documents. The directory works as a searching interface for document browsing. This explorative approach is particularly suitable for casual users to search with Asian languages by avoiding the trouble of query formulation and input in MLTR. For the general application of MLTR, an explorative interface is also advisable when the user has only a vague idea of the domain to be searched.
ID:38
CLASS:1
Title: MultiJava: modular open classes and symmetric multiple dispatch for Java
Abstract: We present MultiJava, a backward-compatible extension to Java supporting open classes and symmetric multiple dispatch. Open classes allow one to add to the set of methods that an existing class supports without creating distinct subclasses or editing existing code. Unlike the "Visitor" design pattern, open classes do not require advance planning, and open classes preserve the ability to add new subclasses modularly and safely. Multiple dispatch offers several well-known advantages over the single dispatching of conventional object-oriented languages, including a simple solution to some kinds of "binary method" problems. MultiJava's multiple dispatch retains Java's existing class-based encapsulation properties. We adapt previous theoretical work to allow compilation units to be statically typechecked modularly and safely, ruling out any link-time or run-time type errors. We also present a n compilation scheme that operates modularly and incurs performance overhead only where open classes or multiple dispatching are actually used.
ID:39
CLASS:1
Title: Classification schemes to aid in the analysis of real-time systems
Abstract: This paper presents three sets of classification schemes for processes, properties, and transitions that can be used to assist in the analysis of real-time systems.  These classification schemes are discussed in the context of ASTRAL, which is a formal specification language for real-time systems.  Eight testbed systems were specified in ASTRAL, and their proofs were performed to determine proof patterns that occur most often.  The specifications were then examined in an attempt to derive specific characteristics that could be used to statically identify each pattern within a specification.  Once the classifications were obtained, they were then used to provide systematic guidance for analyzing real-time systems by directing the prover to the proof techniques most applicable to each proof pattern.  This paper presents the set of classification schemes that were developed and discusses how they can be used to assist the proof process.
ID:40
CLASS:1
Title: A comparison of set-based and graph-based visualisations of overlapping classification hierarchies
Abstract: The visualisation of hierarchical information sets has been a staple of Information Visualisation since the field came into being in the early 1990's. However, at present, support for visualising the correlations between multiple, overlapping sets of hierarchical information has been lacking. This is despite the realisation that for certain tasks this information is as important as the information that forms the individual hierarchies. In response to this, we have produced two early visualisation prototypes, one based on a graph visualisation, and the other on a set-based metaphor, that endeavour to display such information in a readily perceived form to potential users. The science of botanical taxonomy is used as an example of a field where such a visualisation would be useful, and also as a resource for example information sets that the prototypes can act upon. Technical and perceptual issues involved in the design and implementation of both prototypes are discussed. Following this, informal user testing on both prototypes is described, which utilised user observation techniques to elicit qualitative feedback from the taxonomists. These findings are then used to emphasise the shortcomings and advantages of each prototype, and from these probable issues for future prototyping and development are drawn.
ID:41
CLASS:1
Title: Performance analysis of distributed applications using automatic classification of communication inefficiencies
Abstract: We present a technique for performance analysis that helps users understand the communication behavior of their message passing applications. Our method automatically classifies individual communication operations and it reveals the cause of communication inefficiencies in the application. This classification allows the developer to focus quickly on the culprits of truly inefficient behavior, rather than manually foraging through massive amounts of performance data. Specifically, we trace the message operations of MPI applications and then classify each individual communication event using decision tree classification, a supervised learning technique. We train our decision tree using microbenchmarks that demonstrate both efficient and inefficient communication. Since our technique adapts to the target system's configuration through these microbenchmarks, we can simultaneously automate the performance analysis process and improve classification accuracy. Our experiments on four applications demonstrate that our technique can improve the accuracy of performance analysis, and dramatically reduce the amount of data that users must encounter
ID:42
CLASS:1
Title: Tissue classification with gene expression profiles
Abstract: Constantly improving gene expression profiling technologies are expected to provide understanding and insight into cancer related cellular processes. Gene expression data is also expected to significantly and in the development of efficient cancer diagnosis and classification platforms. In this work we examine two sets of gene expression data measured across sets of tumor and normal clinical samples One set consists of 2,000 genes, measured in 62 epithelial colon samples [1]. The second consists of &ap; 100,000 clones, measured in 32 ovarian samples (unpublished, extension of data set described in [26]).
ID:43
CLASS:1
Title: Corrigenda: a hierarchy-aware approach to faceted classification of object-oriented components
Abstract: This article presents a hierarchy-aware classification schema for object-oriented code, where software components are classified according to their behavioral characteristics, such as provided services, employed algorithms, and needed data. In the case of reusable application frameworks, these characteristics are constructed from their model, i.e., from the description of the abstract classes specifying both the framework structure and purpose. In conventional object libraries, the characteristics are extracted semiautomatically from class interfaces. Characteristics are term pairs, weighted to represent "how well" they describe component behavior. The set of characteristics associated with a given component forms its software  descriptor. A descriptor base is presented where descriptors are organized on the basis of structured relationships, such as similarity and composition. The classification is supported by a thesaurus acting as a language-independent unified lexicon. The descriptor base is conceived for developers who, besides conventionally browsing the descriptors hierarchy, can query the system, specifying a set of desired functionalities and getting a ranked set of adaptable candidates. User feedback is taken into account in order to progressively ameliorate the quality of the descriptors according to the views of the user community. Feedback is made dependent of the user typology through a user profile. Experimental results in terms of recall and precision of the retrieval  mechanism against a sample code base are reported.
ID:44
CLASS:1
Title: Automatic Document Classification Part II . Additional Experiments
Abstract: This study reports the results of a series of experiments in the techniques of automatic document classification. Two different classification schedules are compared along with two methods of automatically classifying documents into categories. It is concluded that, while there is no significant difference in the predictive efficiency between the Bayesian and the Factor Score methods, automatic document classification is enhanced by the use of a factor-analytically-derived classification schedule. Approximately 55 percent of the document were automatically and correctly classified.
ID:45
CLASS:1
Title: Semantic analysis of virtual classes and nested classes
Abstract: Virtual classes and nested classes are distinguishing features of BETA. Nested classes originated from Simula, but until recently they have not been part of main stream object- oriented languages. C++ has a restricted form of nested classes and they were included in Java 1.1. Virtual classes is the BETA mechanism for expressing generic classes and virtual classes is an alternative to parameterized classes. There has recently been an increasing interest in virtual classes and a number of proposals for adding virtual classes to other languages, extending virtual classes, and unifying virtual classes and parameterized classes have been made. Although virtual classes and nested classes have been used in BETA for more than a decade, their implementation has not been published. The purpose of this paper is to contribute to the understanding of virtual classes and nested classes by presenting the central elements of the semantic analysis used in the Mj&oslash;lner BETA compiler.
ID:46
CLASS:1
Title: C++ classes for linking optimization with complex simulations
Abstract: The object-oriented programming paradigm can be used to overcome the incompatibilities between off-the-shelf optimization software and application software. The Hilbert Class Library (HCL) defines the fundamental mathematical objects arising in optimization problems, such as vectors, linear operators, and so forth, as C++ classes, making it possible to write optimization code in a natural fashion, while allowing application software such as simulators to use the most convenient data structures and programming style. In spite of the poor reputation C++ has for runtime performance, the use of mixed-language programming allows performance equal to that achieved by standard Fortran packages, as comparisons with the popular code LBFGS and ARPACK demonstrate.
ID:47
CLASS:1
Title: A hierarchy-aware approach to faceted classification of objected-oriented components
Abstract: This article presents a hierarchy-aware classification schema for obje ct-oriented code, where software components are classified according to their behavioral characteristics, such as provided services, employed algorithms, and needed data. In the case of reusable application frameworks, these characteristics are constructured from their model, i.e., from the description of the abstract classes specifying both the framework structure and purpose. In conventional object libraries, the characteristics are extracted semiautomatically from class interfaces. Characteristics are term pairs, weighted to represent &ldquo;how well&rdquo; they describe component behavior. The set of characteristics associated with a given component forms its  software descriptor. A descriptor base is presented where descriptors are organized on the basis of structured relationships, such as similarity and composition. The classification is supported by a thesaurus acting as a language-independent unified lexicon. The descriptor base is conceived for developers who, besides conventionally browsing the descriptors hierarchy, can query the system, specifying a set of desired functionalities and getting a ranked set of adaptable candidates. User feedback is taken into account in order to progressively ameliorate the quality of the descriptors according to the views of the user community. Feedback is made dependent of the user typology through a user profile. Experimental results in terms of recall and precision of  the retrieval mechanism against a sample code base are reported.
ID:48
CLASS:1
Title: Hierarchical classification as an aid to database and hit-list browsing
Abstract: A navigational aid for databases that relies on unsupervised hierarchical classification is presented. The approach to hierarchical classification, based on both functional and topological features, supports the creation of deep hierarchies in which succeeding levels represent increasing degrees of abstraction. This allows the user to quickly evaluate the result of a query and to locate interesting items and classes of items by performing a tree traversal rather than a sequential perusal of a hit list or a series of ad hoc query refinements. In very large databases where classical querying methods are increasingly inadequate such as chemical reaction databases, such a browsing method is required in order to manage the flood of information with which the user is confronted.
ID:49
CLASS:1
Title: A classification algorithm for supporting object-oriented views
Abstract: In recent years, object-oriented (OO) views have been recognized as a powerful mechanism for customizing the structural as well as behavioral aspects of interfaces to object-oriented databases (OODBs) for diverse users. In this context, classification is concerned with the integration of virtual classes derived using an OO query into one unifying schema. Existing approaches either require the user to explicitly specify the relationship between a virtual class and existing base classes, or they relate a virtual class directly with its source class(es) or with the root of the schema. In this paper, we propose a solution to this classification problem that accomplishes the following goals: (1) generate maximally informative, and thus comprehensible, schemas that explicitly model the subclass relationships between base and virtual classes, and (2) support efficient type resolution for shared property functions by supporting upwards inheritance for both base and virtual classes. Correctness and complexity of the classification algorithm are also discussed.
ID:50
CLASS:1
Title: Information extraction as a basis for high-precision text classification
Abstract: We describe an approach to text classification that represents a compromise between traditional word-based techniques and in-depth natural language processing. Our approach uses a natural language processing task called &ldquo;information extraction&rdquo; as a basis for high-precision text classification. We present three algorithms that use varying amounts of extracted information to classify texts. The relevancy signatures algorithm uses linguistic phrases; the augmented relevancy signatures algorithm uses phrases and local context; and the case-based text classification algorithm uses larger pieces of context. Relevant phrases and contexts are acquired automatically using a training corpus. We evaluate the algorithms on the basis  of two test sets from the MUC-4 corpus. All three algorithms achieved high precision on both test sets, with the augmented relevancy signatures algorithm and the case-based algorithm reaching 100% precision with over 60% recall on one set. Additionally, we compare the algorithms on a larger collection of 1700 texts and describe an automated method for empirically deriving appropriate threshold values. The results suggest that information extraction techniques can support high-precision text classification and, in general, that using more extracted information improves performance. As a practical matter, we also explain how the text classification system can be easily ported across  domains.
ID:51
CLASS:1
Title: Semantics of type classes revisited
Abstract: We present a new approach to the semantics of languages with ML-like polymorphic types and type classes. The goals of the new approach are simplicity and generality. Our typing rules are a relatively straightforward extension of the rules for translating core-ML to core-XML. The new features are an encoding of classes as recursive sets of types, and class-membership constraints on types. We show that the soundness of this type of system is independent of the fixedpoint operator used to interpret (recursive) classes, and thus there is no room to engineer a sound notion of well-typing based on other considerations such as decidability. These ideas are applied to investigate the appropriateness of Haskell-style type inference which uses backward chaining for inference of instance  relationships. Haskell's algorithm turns out to imply a least fixed point semantics for classes. We show that the Haskell approach is correct and complete for the special case of convergent classes. Although this includes all classes definable in Haskell, most proper extensions of Haskell allow classes that are not convergent, which helps explain the negative results for decidability of type inference for many extensions.
ID:52
CLASS:1
Title: Automatic document classification: natural language processing, statistical analysis, and expert system techniques used together
Abstract: In this paper we describe an automated method of classifying research project descriptions: a human expert classifies a sample set of projects into a set of disjoint and pre-defined classes, and then the computer learns from this sample how to classify new projects into these classes. Both textual and non-textual information associated with the projects are used in the learning and classification phases. Textual information is processed by two methods of analysis: a natural language analysis followed by a statistical analysis. Non-textual information is processed by a symbolic learning technique. We present the results of some experiments done on real data: two different classifications of our research projects.
ID:53
CLASS:1
Title: Notes and references on early automatic classification work
Abstract: This informal note was prompted by discussions and questions at the 1990 AAAI Spring Symposium on Text-Based Intelligent Systems (cf Jacobs 1990). There is a growing interest in access to, and the use of, large scale full-text databases for a variety of purposes, and in the application of classification methods to organise the mass of data involved (see e.g. Church and Hanks 1990). A good deal of work has been done in this field in the past, but it is little known, and some of the early research literature is not very accessible. Classification is an area in which it is easy to make plausible but mistaken assumptions, and as this certainly holds for classification in retrieval, there is a good deal that can be usefully learnt from past experience, most of which was hard won from careful thought and grinding experiment. This paper is intended as an introduction to this initial work on automatic classification, to help those now becoming interested in classification to avoid unnecessarily repeating heavy effort or, more especially, reinventing square wheels. It should also be noted that automatic classification and related (e.g. seriation) methods have been extensively developed for biological applications in particular, but have been more variously applied, and that much of this work may be relevant in the broad area of machine learning.It must be emphasised that as this paper is focussed on early work on automatic classification, particularly for information retrieval, and is designed primarily to lead into this research and its literature, it does not attempt a critical evaluation of the overall results established by now, or of the current state of the art. However it should be pointed out that in the retrieval context in general, as opposed to the wider one of classification as a whole, there has been comparatively little work since the seventies, largely for the reasons indicated in the paper. More recent work in any case refers heavily to earlier research, so this note can be taken as an entry point to the research of the last decade for which some references are given at the end of the note.
ID:54
CLASS:1
Title: Coarse-grained classification of web sites by their structural properties
Abstract: In this paper, we identify and analyze structural properties which reflect the functionality of a Web site. These structural properties consider the size, the organization, the composition of URLs, and the link structure of Web sites. Opposed to previous work, we perform a comprehensive measurement study to delve into the relation between the structure and the functionality of Web sites. Our study focuses on five of the most relevant functional classes, namely Academic, Blog, Corporate, Personal, and Shop. It is based upon more than 1,400 Web sites composed of 7 million crawled and 47 million known Web pages. We present a detailed statistical analysis which provides insight into how structural properties can be used to distinguish between Web sites from different functional classes. Building on these results, we introduce a content-independent approach for the automated coarse-grained classification of Web sites. A na&#239;ve Bayesian classifier with advanced density estimation yields a precision of 82% and recall of 80% for the classification of Web sites into the considered classes.
ID:55
CLASS:1
Title: Software extension and integration with type classes
Abstract: The abilities to extend a software module and to integrate a software module into an existing software system without changing existing source code are fundamental challenges in software engineering and programming-language design. We reconsider these challenges at the level of language expressiveness, by using the language concept of type classes, as it is available in the functional programming language Haskell. A detailed comparison with related work shows that type classes provide a powerful framework in which solutions to known software extension and integration problems can be provided. We also pinpoint several limitations of type classes in this context.
ID:56
CLASS:1
Title: Experiments on the Automatic Induction of German Semantic Verb Classes
Abstract: This article presents clustering experiments on German verbs: A statistical grammar model for German serves as the source for a distributional verb description at the lexical syntax-semantics interface, and the unsupervised clustering algorithm k-means uses the empirical verb properties to perform an automatic induction of verb classes. Various evaluation measures are applied to compare the clustering results to gold standard German semantic verb classes under different criteria. The primary goals of the experiments are (1) to empirically utilize and investigate the well-established relationship between verb meaning and verb behavior within a cluster analysis and (2) to investigate the required technical parameters of a cluster analysis with respect to this specific linguistic task. The clustering methodology is developed on a small-scale verb set and then applied to a larger-scale verb set including 883 German verbs.
ID:57
CLASS:1
Title: Meta-algorithmic systems for document classification
Abstract: To address cost and regulatory concerns, many businesses are converting paper-based elements of their workflows into fully electronic flows that use the content of the documents. Scanning the document contents into workflows, however, is a manual, error-prone, and costly process especially when the data extraction process requires high accuracy. These manual costs are a primary barrier to widespread adoption of distributed capture solutions for business critical workflows such as insurance claims, medical records, or loan applications. Software solutions using artificial intelligence and natural language processing techniques are emerging to address these needs, but each have their individual strengths and weaknesses, and none have demonstrated a high level of accuracy across the many unstructured document types included in these business critical workflows. This paper describes how to overcome many of these limitations by intelligently combining multiple approaches for document classification using meta-algorithmic design patterns. These patterns explore the error space in multiple engines, and provide improved and "emergent" results in comparison to voting schemes and to the output of any of the individual engines. This paper considers the results of the individual engines along with traditional combinatorial techniques such as voting, before describing prototype results for a variety of novel metaalgorithmic patterns that reduce individual document error rates by up to 13% and reduce system error rates by up to 38%.
ID:58
CLASS:1
Title: CLAIRE: A modular support vector image indexing and classification system
Abstract: Many users of image retrieval systems would prefer to express initial queries using keywords. However, manual keyword indexing is very time-consuming. Therefore, a content-based image retrieval system which can automatically assign keywords to images would be very attractive. Unfortunately, it has proved very challenging to build such systems, except where either the image domain is restricted or the keywords relate only to low-level concepts such as color. This article presents a novel image indexing and classification system, called CLAIRE (CLAssifying Images for REtrieval), composed of one image processing module and three modules of support vector machines for color, texture, and high-level concept classification for keyword assignment. The experimental prototype system described here assigns up to five keywords selected from a controlled vocabulary of 60 terms to each image. The system is trained offline by 1639 examples from the Corel stock photo library. For evaluation, five judges reviewed a sample of 800 unknown images to identify which automatically assigned keywords were actually relevant to the image. The system proved to have an 80&percnt; probability to assign at least one relevant keyword to an image.
ID:59
CLASS:1
Title: Query enrichment for web-query classification
Abstract: Web-search queries are typically short and ambiguous. To classify these queries into certain target categories is a difficult but important problem. In this article, we present a new technique called query enrichment, which takes a short query and maps it to intermediate objects. Based on the collected intermediate objects, the query is then mapped to target categories. To build the necessary mapping functions, we use an ensemble of search engines to produce an enrichment of the queries. Our technique was applied to the ACM Knowledge Discovery and Data Mining competition (ACM KDDCUP) in 2005, where we won the championship on all three evaluation metrics (precision, F1 measure, which combines precision and recall, and creativity, which is judged by the organizers) among a total of 33 teams worldwide. In this article, we show that, despite the difficulty of an abundance of ambiguous queries and lack of training data, our query-enrichment technique can solve the problem satisfactorily through a two-phase classification framework. We present a detailed description of our algorithm and experimental evaluation. Our best result for F1 and precision is 42.4&percnt; and 44.4&percnt;, respectively, which is 9.6&percnt; and 24.3&percnt; higher than those from the runner-ups, respectively.
ID:60
CLASS:1
Title: Perspectives to the classification of information interactions: the Cool and Belkin faceted classification scheme under scrutiny
Abstract: The faceted classification system of information interactions proposed by Cool and Belkin is discussed in the light of two case studies. The two examples use the classification scheme as a structural research instrument in two different phases of investigation: in framing the collection of data and in the analysis of already existing data. The discussion is focussed on usability and the issues related to the classification scheme. We conclude that the proposed scheme is a workable instrument for studying complex information interactions with different kinds of research designs. The either premisory or post-collection use of the classification scheme was recognised to have effects on the classification outcome. The principal issues of using the scheme seemed to relate to the frequent overlap of the facets and the tendency of the classifications to be highly dependent on the perspectives of the study.
ID:61
CLASS:1
Title: Towards genre classification for IR in the workplace
Abstract: Use of document genre in information retrieval systems has the potential to improve the task-appropriateness of results. However, genre classification remains a challenging problem. We describe a case study of genre classification in a software engineering workplace domain, which includes the development of a genre taxonomy and experiments in automatic genre classification using supervised machine learning. We present results based on evaluation using real-life enterprise data from this work domain.
ID:62
CLASS:1
Title: A preliminary performance comparison of five machine learning algorithms for practical IP traffic flow classification
Abstract: The identification of network applications through observation of associated packet traffic flows is vital to the areas of network management and surveillance. Currently popular methods such as port number and payload-based identification exhibit a number of shortfalls. An alternative is to use machine learning (ML) techniques and identify network applications based on per-flow statistics, derived from payload-independent features such as packet length and inter-arrival time distributions. The performance impact of feature set reduction, using Consistency-based and Correlation-based feature selection, is demonstrated on Na&#239;ve Bayes, C4.5, Bayesian Network and Na&#239;ve Bayes Tree algorithms. We then show that it is useful to differentiate algorithms based on computational performance rather than classification accuracy alone, as although classification accuracy between the algorithms is similar, computational performance can differ significantly.
ID:63
CLASS:1
Title: A reconstruction-based algorithm for classification rules hiding
Abstract: Data sharing between two organizations is common in many application areas e.g. business planing or marketing. Useful global patterns can be discovered from the integrated dataset. However, some sensitive patterns that should have been kept private could also be discovered. In general, disclosure of sensitive patterns could decrease the competitive ability of the data owner. Therefore, sensitive patterns should be hidden before data sharing starts. To address this problem, released datasets must be modified unavoidably. However, if the overall characteristics of the dataset can be maintained, the dataset is still usable perfectly. Therefore, not only the privacy should be concerned, but also the usability. In this paper, we propose a new algorithm to preserve the privacy of the classification rules by using reconstruction technique for categorical datasets. Firstly, all discovered classification rules in the released dataset are presented to the data owner to identify sensitive rules that should be hidden. Subsequently, remained non-sensitive rules along with extracted characteristics information of the dataset are used to build a decision tree. Finally, the new dataset which contains only non-sensitive classification rules is reconstructed from the tree. From empirical studies, our algorithm can preserve the privacy effectively. Additionally, the usability of the datasets can also be preserved.
ID:64
CLASS:1
Title: Acoustic environment classification
Abstract: The acoustic environment provides a rich source of information on the types of activity, communication modes, and people involved in many situations. It can be accurately classified using recordings from microphones commonly found in PDAs and other consumer devices. We describe a prototype HMM-based acoustic environment classifier incorporating an adaptive learning mechanism and a hierarchical classification model. Experimental results show that we can accurately classify a wide variety of everyday environments. We also show good results classifying single sounds, although classification accuracy is influenced by the granularity of the classification.
ID:65
CLASS:1
Title: A new ant colony algorithm for multi-label classification with applications in bioinfomatics
Abstract: The conventional classification task of data mining can be called single-label classification, since there is a single class attribute to be predicted. This paper addresses a more challenging version of the classification task, where there are two or more class attributes to be predicted. We propose a new ant colony algorithm for the multi-label classification task. The new algorithm, called MuLAM (Multi-Label Ant-Miner) is a major extension of Ant-Miner, the first ant colony algorithm for discovering classification rules. We report results comparing the performance of MuLAM with the performance of three other classification techniques, namely the very simple majority classifier, the original Ant-Miner algorithm and C5.0, a very popular rule induction algorithm. The experiments were performed using five bioinformatics datasets, involving the prediction of several kinds of protein function.
ID:66
CLASS:1
Title: Web ontology segmentation: analysis, classification and use
Abstract: Ontologies are at the heart of the semantic web. They define the concepts and relationships that make global interoperability possible. However, as these ontologies grow in size they become more and more difficult to create, use, understand, maintain, transform and classify. We present and evaluate several algorithms for extracting relevant segments out of large description logic ontologies for the purposes of increasing tractability for both humans and computers. The segments are not mere fragments, but stand alone as ontologies in their own right. This technique takes advantage of the detailed semantics captured within an OWL ontology to produce highly relevant segments. The research was evaluated using the GALEN ontology of medical terms and procedures.
ID:67
CLASS:1
Title: Classify By Representative Or Associations (CBROA): a hybrid approach for image classification
Abstract: Image classification has been an interesting research issue in multimedia content analysis due to the wide applications. In this paper, we observe that images can be classified (or annotated) in two ways: i) Classify by some main object, ii) Classify by multiple objects with their relations. These two types of images usually exist concurrently in real-life image databases. Although a number of image classification methods have been propose, they can only handle one certain type of images well and fail to deal with both types of images correctly at the same time. In this paper, we propose a hybrid image classification method, namely "CBROA" (Classify By Representative Or Associations), that can effectively classify both types of images at the same time. CBROA integrates the decision tree and association rules mining method in an adaptive manner with construction of a virtual semantic ontology. Experimental results show that CBROA outperforms other classification methods in terms of classification accuracy in classifying mixed types of images.
ID:68
CLASS:1
Title: Collaborative multi-strategy classification: application to per-pixel analysis of images
Abstract: This paper presents a new process of collaborative multi-step multi-strategy classification of complex data. Our goal is to be able to handle in the same system several instances of classifiers in order to make them collaborate. In this paper, we highlight how the classifiers collaborate. We present the implementation of our method dedicated to remote sensing images. Finally, we validate it with a pixel based classification application.
ID:69
CLASS:1
Title: A simple probabilistic approach to classification and routing
Abstract: Several classification and routing methods were implemented and compared. The experiments used FBIS documents from four categories, and the measures used were the tf.idf and Cosine similarity measures, and a maximum likelihood estimate based on assuming a Multinomial Distribution for the various topics (populations). In addition, the SMART program was run with 'lnc.ltc' weighting and compared to the others.Decisions for both our classification scheme (documents are put into any number of disjoint categories) and our routing scheme (documents are assigned a 'score' and ranked relative to each category) are based on the highest probability for correct classification or routing. All of the techniques described here are fully automatic, and use a training set of relevant documents to produce lists of distinguishing terms and weights. All methods (ours and the ones we compared to) gave excellent results for the classification task, while the one based on the Multinomial Distribution produced the best results on the routing task.
ID:70
CLASS:1
Title: Selecting text features for gene name classification: from documents to terms
Abstract: In this paper we discuss the performance of a text-based classification approach by comparing different types of features. We consider the automatic classification of gene names from the molecular biology literature, by using a support-vector machine method. Classification features range from words, lemmas and stems, to automatically extracted terms. Also, simple co-occurrences of genes within documents are considered. The preliminary experiments performed on a set of 3,000 S. cerevisiae gene names and 53,000 Medline abstracts have shown that using domain-specific terms can improve the performance compared to the standard bag-of-words approach, in particular for genes classified with higher confidence, and for under-represented classes.
ID:71
CLASS:1
Title: Using domain-specific verbs for term classification
Abstract: In this paper we present an approach to term classification based on verb complementation patterns. The complementation patterns have been automatically learnt by combining information found in a corpus and an ontology, both belonging to the biomedical domain. The learning process is unsupervised and has been implemented as an iterative reasoning procedure based on a partial order relation induced by the domain-specific ontology. First, term recognition was performed by both looking up the dictionary of terms listed in the ontology and applying the C/NC-value method. Subsequently, domain-specific verbs were automatically identified in the corpus. Finally, the classes of terms typically selected as arguments for the considered verbs were induced from the corpus and the ontology. This information was used to classify newly recognised terms. The precision of the classification method reached 64%.
ID:72
CLASS:1
Title: Survey and taxonomy of packet classification techniques
Abstract: Packet classification is an enabling function for a variety of Internet applications including quality of service, security, monitoring, and multimedia communications. In order to classify a packet as belonging to a particular flow or set of flows, network nodes must perform a search over a set of filters using multiple fields of the packet as the search key. In general, there have been two major threads of research addressing packet classification, algorithmic and architectural. A few pioneering groups of researchers posed the problem, provided complexity bounds, and offered a collection of algorithmic solutions. Subsequently, the design space has been vigorously explored by many offering new algorithms and improvements on existing algorithms. Given the inability of early algorithms to meet performance constraints imposed by high speed links, researchers in industry and academia devised architectural solutions to the problem. This thread of research produced the most widely-used packet classification device technology, Ternary Content Addressable Memory (TCAM). New architectural research combines intelligent algorithms and novel architectures to eliminate many of the unfavorable characteristics of current TCAMs. We observe that the community appears to be converging on a combined algorithmic and architectural approach to the problem. Using a taxonomy based on the high-level approach to the problem and a minimal set of running examples, we provide a survey of the seminal and recent solutions to the problem. It is our hope to foster a deeper understanding of the various packet classification techniques while providing a useful framework for discerning relationships and distinctions.
ID:73
CLASS:1
Title: Collective multi-label classification
Abstract: Common approaches to multi-label classification learn independent classifiers for each category, and employ ranking or thresholding schemes for classification. Because they do not exploit dependencies between labels, such techniques are only well-suited to problems in which categories are independent. However, in many domains labels are highly interdependent. This paper explores multi-label conditional random field (CRF)classification models that directly parameterize label co-occurrences in multi-label classification. Experiments show that the models outperform their single-label counterparts on standard text corpora. Even when multi-labels are sparse, the models improve subset classification error by as much as 40%.
ID:74
CLASS:1
Title: Lightweight detection and classification for wireless sensor networks in realistic environments
Abstract: A wide variety of sensors have been incorporated into a spectrum of wireless sensor network (WSN) platforms, providing flexible sensing capability over a large number of low-power and inexpensive nodes. Traditional signal processing algorithms, however, often prove too complex for energy-and-cost-effective WSN nodes. This study explores how to design efficient sensing and classification algorithms that achieve reliable sensing performance on energy-and-cost effective hardware without special powerful nodes in a continuously changing physical environment. We present the detection and classification system in a cutting-edge surveillance sensor network, which classifies vehicles, persons, and persons carrying ferrous objects, and tracks these targets with a maximum error in velocity of 15%. Considering the demanding requirements and strict resource constraints, we design a hierarchical classification architecture that naturally distributes sensing and computation tasks at different levels of the system. Such a distribution allows multiple sensors to collaborate on a sensor node, and the detection and classification results to be continuously refined at different levels of the WSN. This design enables reliable detection and classification without involving high-complexity computation, reduces network traffic, and emphasizes resilience and adaptation to the realistic environment. We evaluate the system with performance data collected from outdoor experiments and field assessments. Based on the experience acquired and lessons learned when developing this system, we abstract common issues and introduce several guidelines which can direct future development of detection and classification solutions based on WSNs.
ID:75
CLASS:1
Title: Learning to crawl: Comparing classification schemes
Abstract: Topical crawling is a young and creative area of research that holds the promise of benefiting from several sophisticated data mining techniques. The use of classification algorithms to guide topical crawlers has been sporadically suggested in the literature. No systematic study, however, has been done on their relative merits. Using the lessons learned from our previous crawler evaluation studies, we experiment with multiple versions of different classification schemes. The crawling process is modeled as a parallel best-first search over a graph defined by the Web. The classifiers provide heuristics to the crawler thus biasing it towards certain portions of the Web graph. Our results show that Naive Bayes is a weak choice for guiding a topical crawler when compared with Support Vector Machine or Neural Network. Further, the weak performance of Naive Bayes can be partly explained by extreme skewness of posterior probabilities generated by it. We also observe that despite similar performances, different topical crawlers cover subspaces on the Web with low overlap.
ID:76
CLASS:1
Title: Using a fuzzy classification query language for customer relationship management
Abstract: A key challenge for companies is to manage customer relationships as an asset. To create an effective toolkit for the analysis of customer relationships, a combination of relational databases and fuzzy logic is proposed. The fuzzy Classification Query Language allows marketers to improve customer equity, launch loyalty programs, automate mass customization, and refine marketing campaigns.
ID:77
CLASS:1
Title: BLINC: multilevel traffic classification in the dark
Abstract: We present a fundamentally different approach to classifying traffic flows according to the applications that generate them. In contrast to previous methods, our approach is based on observing and identifying patterns of host behavior at the transport layer. We analyze these patterns at three levels of increasing detail (i) the social, (ii) the functional and (iii) the application level. This multilevel approach of looking at traffic flow is probably the most important contribution of this paper. Furthermore, our approach has two important features. First, it operates in the dark, having (a) no access to packet payload, (b) no knowledge of port numbers and (c) no additional information other than what current flow collectors provide. These restrictions respect privacy, technological and practical constraints. Second, it can be tuned to balance the accuracy of the classification versus the number of successfully classified traffic flows. We demonstrate the effectiveness of our approach on three real traces. Our results show that we are able to classify 80%-90% of the traffic with more than 95% accuracy.
ID:78
CLASS:1
Title: On the collective classification of email "speech acts"
Abstract: We consider classification of email messages as to whether or not they contain certain "email acts", such as a request or a commitment. We show that exploiting the sequential correlation among email messages in the same thread can improve email-act classification. More specifically, we describe a new text-classification algorithm based on a dependency-network based collective classification method, in which the local classifiers are maximum entropy models based on words and certain relational features. We show that statistically significant improvements over a bag-of-words baseline classifier can be obtained for some, but not all, email-act classes. Performance improvements obtained by collective classification appears to be consistent across many email acts suggested by prior speech-act theory.
ID:79
CLASS:1
Title: Multi-dimensional text classification
Abstract: This paper proposes a multi-dimensional framework for classifying text documents. In this framework, the concept of multidimensional category model is introduced for representing classes. In contrast with traditional flat and hierarchical category models; the multi-dimensional category model classifies each text document in a collection using multiple predefined sets of categories, where each set corresponds to a dimension. Since a multi-dimensional model can be converted to flat and hierarchical models, three classification strategies are possible, i.e., classifying directly based on the multi-dimensional model and classifying with the equivalent flat or hierarchical models. The efficiency of these three classifications is investigated on two data sets. Using k-NN, na&iuml;ve Bayes and centroid-based classifiers, the experimental results show that the multi-dimensional-based and hierarchical-based classification performs better than the flat-based classifications.
ID:80
CLASS:1
Title: Attribute Clustering for Grouping, Selection, and Classification of Gene Expression Data
Abstract: This paper presents an attribute clustering method which is able to group genes based on their interdependence so as to mine meaningful patterns from the gene expression data. It can be used for gene grouping, selection, and classification. The partitioning of a relational table into attribute subgroups allows a small number of attributes within or across the groups to be selected for analysis. By clustering attributes, the search dimension of a data mining algorithm is reduced. The reduction of search dimension is especially important to data mining in gene expression data because such data typically consist of a huge number of genes (attributes) and a small number of gene expression profiles (tuples). Most data mining algorithms are typically developed and optimized to scale to the number of tuples instead of the number of attributes. The situation becomes even worse when the number of attributes overwhelms the number of tuples, in which case, the likelihood of reporting patterns that are actually irrelevant due to chances becomes rather high. It is for the aforementioned reasons that gene grouping and selection are important preprocessing steps for many data mining algorithms to be effective when applied to gene expression data. This paper defines the problem of attribute clustering and introduces a methodology to solving it. Our proposed method groups interdependent attributes into clusters by optimizing a criterion function derived from an information measure that reflects the interdependence between attributes. By applying our algorithm to gene expression data, meaningful clusters of genes are discovered. The grouping of genes based on attribute interdependence within group helps to capture different aspects of gene association patterns in each group. Significant genes selected from each group then contain useful information for gene expression classification and identification. To evaluate the performance of the proposed approach, we applied it to two well-known gene expression data sets and compared our results with those obtained by other methods. Our experiments show that the proposed method is able to find the meaningful clusters of genes. By selecting a subset of genes which have high multiple-interdependence with others within clusters, significant classification information can be obtained. Thus, a small pool of selected genes can be used to build classifiers with very high classification rate. From the pool, gene expressions of different categories can be identified.
ID:81
CLASS:1
Title: Joint Classification and Pairing of Human Chromosomes
Abstract: We reexamine the problems of computer-aided classification and pairing of human chromosomes, and propose to jointly optimize the solutions of these two related problems. The combined problem is formulated into one of optimal three-dimensional assignment with an objective function of maximum likelihood. This formulation poses two technical challenges: 1) estimation of the posterior probability that two chromosomes form a pair and the pair belongs to a class and 2) good heuristic algorithms to solve the three-dimensional assignment problem which is NP-hard. We present various techniques to solve these problems. We also generalize our algorithms to cases where the cell data are incomplete as often encountered in practice.
ID:82
CLASS:1
Title: Spatial contextual noise removal for post classification smoothing of remotely sensed images
Abstract: Extracting accurate land use and land cover information from remote sensing data is a challenging problem due to the gap between theoretically available information in remote sensing imagery and the limited classification ability based on spectral analysis. Traditional classification techniques based on spectral analysis of single pixel usually produce "noisy" results that contain many wrongly classified pixels. This paper presents a novel post classification method to detect the pixels that are wrongly classified and reassign them to correct fields in spatial context. The strategy is demonstrated through the classification of a benchmark digital aerial photograph. The experimental results show that the proposed approach can produce a more accurate classification than previous approaches.
ID:83
CLASS:1
Title: Automated text classification using a multi-agent framework
Abstract: Automatic text classification is an important operational problem in digital library practice. Most text classification efforts so far concentrated on developing centralized solutions. However, centralized classification approaches often are limited due to constraints on knowledge and computing resources. In addition, centralized approaches are more vulnerable to attacks or system failures and less robust in dealing with them. We present a de-centralized approach and system implementation (named MACCI) for text classification using a multi-agent framework. Experiments are conducted to compare our multi-agent approach with a centralized approach. The results show multi-agent classification can achieve promising classification results while maintaining its other advantages.
ID:84
CLASS:1
Title: Statistical Analysis of Some Multi-Category Large Margin Classification Methods
Abstract: The purpose of this paper is to investigate statistical properties of risk minimization based multi-category classification methods. These methods can be considered as natural extensions of binary large margin classification. We establish conditions that guarantee the consistency of classifiers obtained in the risk minimization framework with respect to the classification error. Examples are provided for four specific forms of the general formulation, which extend a number of known methods. Using these examples, we show that some risk minimization formulations can also be used to obtain conditional probability estimates for the underlying problem. Such conditional probability information can be useful for statistical inferencing tasks beyond classification.
ID:85
CLASS:1
Title: Using Uncorrelated Discriminant Analysis for Tissue Classification with Gene Expression Data
Abstract: The classification of tissue samples based on gene expression data is an important problem in medical diagnosis of diseases such as cancer. In gene expression data, the number of genes is usually very high (in the thousands) compared to the number of data samples (in the tens or low hundreds); that is, the data dimension is large compared to the number of data points (such data is said to be undersampled). To cope with performance and accuracy problems associated with high dimensionality, it is commonplace to apply a preprocessing step that transforms the data to a space of significantly lower dimension with limited loss of the information present in the original data. Linear Discriminant Analysis (LDA) is a well-known technique for dimension reduction and feature extraction, but it is not applicable for undersampled data due to singularity problems associated with the matrices in the underlying representation. This paper presents a dimension reduction and feature extraction scheme, called Uncorrelated Linear Discriminant Analysis (ULDA), for undersampled problems and illustrates its utility on gene expression data. ULDA employs the Generalized Singular Value Decomposition method to handle undersampled data and the features that it produces in the transformed space are uncorrelated, which makes it attractive for gene expression data. The properties of ULDA are established rigorously and extensive experimental results on gene expression data are presented to illustrate its effectiveness in classifying tissue samples. These results provide a comparative study of various state-of-the-art classification methods on well-known gene expression data sets.
ID:86
CLASS:1
Title: Essential classification rule sets
Abstract: Given a class model built from a dataset including labeled data, classification assigns a new data object to the appropriate class. In associative classification the class model (i.e., the classifier) is a set of association rules. Associative classification is a promising technique for the generation of highly accurate classifiers. In this article, we present a compact form which encodes without information loss the classification knowledge available in a classification rule set. This form includes the rules that are essential for classification purposes, and thus it can replace the complete rule set. The proposed form is particularly effective in dense datasets, where traditional extraction techniques may generate huge rule sets. The reduction in size of the rule set allows decreasing the complexity of both the rule generation step and the rule pruning step. Hence, classification rule extraction can be performed also with low support, in order to extract more, possibly useful, rules.
ID:87
CLASS:1
Title: Stylistic and lexical co-training for web block classification
Abstract: Many applications which use web data extract information from a limited number of regions on a web page. As such, web page division into blocks and the subsequent block classification have become a preprocessing step. We introduce PARCELS, an open-source, co-trained approach that performs classification based on separate stylistic and lexical views of the web page. Unlike previous work, PARCELS performs classification on fine-grained blocks. In addition to table-based layout, the system handles real-world pages which feature layout based on divisions and spans as well as stylistic inference for pages using cascaded style sheets. Our evaluation shows that the co-training process results in a reduction of 28.5% in error rate over a single-view classifier and that our approach is comparable to other state-of-the-art systems.
ID:88
CLASS:1
Title: Converting Java classes to use generics
Abstract: Generics offer significant software engineering benefits since they provide code reuse without compromising type safety. Thus generics will be added to the Java language in the next release. While this extension to Java will help programmers when they are writing new code, it will not help legacy code unless it is rewritten to use generics. In our experience, manually modifying existing programs to use generics is complex and can be error prone and labor intensive.
ID:89
CLASS:1
Title: Class-of-service mapping for QoS: a statistical signature-based approach to IP traffic classification
Abstract: The ability to provide different Quality of Service (QoS) guarantees to traffic from different applications is a highly desired feature for many IP network operators, particularly for enterprise networks. Although various mechanisms exist for providing QoS in the network, QoS is yet to be widely deployed. We believe that a key factor holding back widespread QoS adoption is the absence of suitable methodologies/processes for appropriately mapping the traffic from different applications to different QoS classes. This is a challenging task, because many enterprise network operators who are interested in QoS do not know all the applications running on their network, and furthermore, over recent years port-based application classification has become problematic. We argue that measurement based automated Class of Service (CoS) mapping is an important practical problem that needs to be studied.
ID:90
CLASS:1
Title: A pitfall and solution in multi-class feature selection for text classification
Abstract: Information Gain is a well-known and empirically proven method for high-dimensional feature selection. We found that it and other existing methods failed to produce good results on an industrial text classification problem. On investigating the root cause, we find that a large class of feature scoring methods suffers a pitfall: they can be blinded by a surplus of strongly predictive features for some classes, while largely ignoring features needed to discriminate difficult classes. In this paper we demonstrate this pitfall hurts performance even for a relatively uniform text classification task. Based on this understanding, we present solutions inspired by round-robin scheduling that avoid this pitfall, without resorting to costly wrapper methods. Empirical evaluation on 19 datasets shows substantial improvements.
ID:91
CLASS:1
Title: Web-page classification through summarization
Abstract: Web-page classification is much more difficult than pure-text classification due to a large variety of noisy information embedded in Web pages. In this paper, we propose a new Web-page classification algorithm based on Web summarization for improving the accuracy. We first give empirical evidence that ideal Web-page summaries generated by human editors can indeed improve the performance of Web-page classification algorithms. We then propose a new Web summarization-based classification algorithm and evaluate it along with several other state-of-the-art text summarization algorithms on the LookSmart Web directory. Experimental results show that our proposed summarization-based classification algorithm achieves an approximately 8.8% improvement as compared to pure-text-based classification algorithm. We further introduce an ensemble classifier using the improved summarization algorithm and show that it achieves about 12.9% improvement over pure-text based methods.
ID:92
CLASS:1
Title: Flow classification by histograms: or how to go on safari in the internet
Abstract: In order to control and manage highly aggregated Internet traffic flows efficiently, we need to be able to categorize flows into distinct classes and to be knowledgeable about the different behavior of flows belonging to these classes. In this paper we consider the problem of classifying BGP level prefix flows into a small set of homogeneous classes. We argue that using the entire distributional properties of flows can have significant benefits in terms of quality in the derived classification. We propose a method based on modeling flow histograms using Dirichlet Mixture Processes for random distributions. We present an inference procedure based on the Simulated Annealing Expectation Maximization algorithm that estimates all the model parameters as well as flow membership probabilities - the probability that a flow belongs to any given class. One of our key contributions is a new method for Internet flow classification. We show that our method is powerful in that it is capable of examining macroscopic flows while simultaneously making fine distinctions between different traffic classes. We demonstrate that our scheme can address issues with flows being close to class boundaries and the inherent dynamic behaviour of Internet flows.
ID:93
CLASS:1
Title: Significance of Gene Ranking for Classification of Microarray Samples
Abstract: Many methods for classification and gene selection with microarray data have been developed. These methods usually give a ranking of genes. Evaluating the statistical significance of the gene ranking is important for understanding the results and for further biological investigations, but this question has not been well addressed for machine learning methods in existing works. Here, we address this problem by formulating it in the framework of hypothesis testing and propose a solution based on resampling. The proposed r-test methods convert gene ranking results into position p-values to evaluate the significance of genes. The methods are tested on three real microarray data sets and three simulation data sets with support vector machines as the method of classification and gene selection. The obtained position p-values help to determine the number of genes to be selected and enable scientists to analyze selection results by sophisticated multivariate methods under the same statistical inference paradigm as for simple hypothesis testing methods.
ID:94
CLASS:1
Title: Using urls and table layout for web classification tasks
Abstract: We propose new features and algorithms for automating Web-page classification tasks such as content recommendation and ad blocking. We show that the automated classification of Web pages can be much improved if, instead of looking at their textual content, we consider each links's URL and the visual placement of those links on a referring page. These features are unusual: rather than being scalar measurements like word counts they are tree structured---describing the position of the item in a tree. We develop a model and algorithm for machine learning using such tree-structured features. We apply our methods in automated tools for recognizing and blocking Web advertisements and for recommending "interesting" news stories to a reader. Experiments show that our algorithms are both faster and more accurate than those based on the text content of Web documents.
ID:95
CLASS:1
Title: A novel feature selection method to improve classification of gene expression data
Abstract: This paper introduces a novel method for minimum number of gene (feature) selection for a classification problem based on gene expression data with an objective function to maximise the classification accuracy. The method uses a hybrid of Pearson correlation coefficient (PCC) and signal-to-noise ratio (SNR) methods combined with an evolving classification function (ECF). First, the correlation coefficients between genes in a set of thousands, is calculated. Genes, that are highly correlated across samples are considered either dependent or co-regulated and form a group (a cluster). Signal-to-noise ratio (SNR) method is applied to rank the correlated genes in this group according to their discriminative power towards the classes. Genes with the highest SNR are used in a preliminary feature set as representatives of each group.An incremental algorithm that consists of selecting a minimum number of genes (variables) from the preliminary feature set, starting from one gene, is then applied for building an optimum classification system. Only variables, that increase the classification rate in each of the validation iteration, are selected and added to the final feature set. The results show that the proposed hybrid PCC, SNR and ECF method improves the feature selection process in terms of number of variables required and also improves the classification rate. The classification accuracy of the ECF classifier is tested through the leave one out method for validation.
ID:96
CLASS:1
Title: SVM binary classifier ensembles for image classification
Abstract: We study how the SVM-based binary classifiers can be effectively combined to tackle the multi-class image classification problem. We study several ensemble schemes, including OPC (one per class), PWC (pairwise coupling), and ECOC (error-correction output coding), that aim to achieve good error correction capability through redundancy. To enhance these ensemble schemes' accuracy, we propose methods that on the one hand boost the margins (i.e., confidence) of the SVM-based binary classifiers, and, on the other hand, remove the noise of irrelevant classifiers from class prediction. From empirical study we show that our margin boosting and noise reduction methods lead to higher classification accuracy than ensemble schemes that are solely designed for maximum error correction capability.
ID:97
CLASS:1
Title: Support vector machine pairwise classifiers with error reduction for image classification
Abstract: In this paper we study how Support Vector Machines (SVMs) can be applied to image classification. To enhance classification accuracy, we normalize SVM pairwise classification results. From empirical study on a fifteen-category diversified image set, we show that combining pairwise SVMs and error reduction is an effective approach from image classification. This study is a critical step for our on-going effort on the development of a comprehensive approach, closely adapted to SVMs, to image classification.
ID:98
CLASS:1
Title: Hierarchical classification of Web content
Abstract: This paper explores the use of hierarchical structure for classifying a large, heterogeneous collection of web content. The hierarchical structure is initially used to train different second-level classifiers. In the hierarchical case, a model is learned to distinguish a second-level category from other categories within the same top level. In the flat non-hierarchical case, a model distinguishes a second-level category from all other second-level categories. Scoring rules can further take advantage of the hierarchy by considering only second-level categories that exceed a threshold at the top level.
ID:99
CLASS:1
Title: 3DString: a feature string kernel for 3D object classification on voxelized data
Abstract: Classification of 3D objects remains an important task in many areas of data management such as engineering, medicine or biology. As a common preprocessing step in current approaches to classification of voxelized 3D objects, voxel representations are transformed into a feature vector description.In this article, we introduce an approach of transforming 3D objects into feature strings which represent the distribution of voxels over the voxel grid. Attractively, this feature string extraction can be performed in linear runtime with respect to the number of voxels. We define a similarity measure on these feature strings that counts common k-mers in two input strings, which is referred to as the spectrum kernel in the field of kernel methods. We prove that on our feature strings, this similarity measure can be computed in time linear to the number of different characters in these strings. This linear runtime behavior makes our kernel attractive even for large datasets that occur in many application domains. Furthermore, we explain that our similarity measure induces a metric which allows to combine it with an M-tree for handling of large volumes of data. Classification experiments on two published benchmark datasets show that our novel approach is competitive with the best state-of-the-art methods for 3D object classification.
ID:100
CLASS:2
Title: Simulation for computer science majors: a preliminary report
Abstract: With the support of the NSF Grant listed below, the author is revising and restructuring an existing simulation course designed primarily for senior computer science majors by: 1) developing an integrated set of laboratory exercises based on computer science topics using commercially available software (GPSS/H); 2)incorporating these materials into a formal laboratory manual along with related computer science reference materials and instructions in the use of the software; 3) implementing a pilot course using this manual together with a single text in the theory of simulation; 4) preparing a syllabus and a detailed an notated course outline for the instructor, keyed to the manual and the text. The materials developed will be flexible and highly modular allowing their adoption or adaptation at other institutions.
ID:101
CLASS:2
Title: An appreciation of computer simulation
Abstract: Students learning computer simulation often are bewildered by the complexity of computer simulation models. To overcome this difficulty, we have used an exercise which requires modeling a simple system. The student constructs a model and performs hand simulation. Next, the student uses a program deck to perform computer simulation for the same problem. Finally, the student constructs an analytic model and compares the results of simulation runs with calculated results. Experience shows that this three-way exercise, involving hand simulation, computer simulation, and analytic model, gives the beginning student a feeling for and confidence in the validity of computer simulation.
ID:102
CLASS:2
Title: Computer simulations
Abstract: The use of computer simulations as instructional tools has grown considerably in recent years. With the growing availability of instructional-timesharing, expecially in elementary and secondary schools, the use of instructional computer simulations is likely to expand even more. This paper briefly explores the use of computer simulations as learning environments.
ID:103
CLASS:2
Title: A high level simulation model of a networked computer system
Abstract: The objective of this research was to design and develop a baseline planning tool for the OCLC networked computer system. This planning tool was necessitated by the dynamic, fast-growing on-line bibliographic needs of OCLC's remote library users. In this paper we show simulation to be the best research approach and justify the IPSS language as appropriate to this application. The resultant model of OCLC's networked computer system is highlighted. This tool was developed in a timely manner to meet the immediate goals of OCLC planners and provides a standard baseline model for future extensions.
ID:104
CLASS:2
Title: The simulation of computer systems in a university environment
Abstract: The spectrum of current work concerning the simulation of computer systems in a university environment ranges from simple interpreter-oriented simulation models for educational use through research into areas concerned with the development and refinement of techniques generalizing or simplifying the simulation process [37, 38]. When we speak of work related to the simulation of computer systems, we include the development and use of any software or technique which aids in the imitation of the stimulus-response relationship of any portion of a computer system. Thus, this survey paper discusses work concerned with the &ldquo;emulation&rdquo; of one machine (called a virtual machine) on another machine (called the real machine) as well as more conventional forms of simulation. These studies are prevalent in academia and are used for two distinct purposes: education and research. A topic of interest that frequently occurs in a research environment is the use of simulation models to create an environment in which some small portion of a total computer system can be tested. Popular examples of this area are job mix generators to test scheduling algorithm alternatives or reference stream generators to investigate paging algorithms. Included also in the area of environment creation are the software engineering systems, used to aid in the consistent design of computers, as may be best exemplified by Project LOGOS, [3, 28, 29]. These studies are of interest to our survey in that they liberally employ automated simulation during the design period. An area that has classically been popular in academic simulation studies is the creation and use of high level models for configuration studies, operating system tuning etc. This area represents the largest intersection of interest with investigators in government and industry. A final area of study included in this survey is the investigation to improve techniques for approaching the simulation problem, or the generalization of known techniques to develop some kind of theory or set of concepts for computer system simulation.
ID:105
CLASS:2
Title: An interim empirical evaluation of ECSS for computer system simulation development
Abstract: A recent experiment at Rand has provided quantitative data on the effect of using different languages for simulating computer systems. The experiment consisted of programming a small simulation of a hypothetical multiprogrammed computer in ECSS (the Extendable Computer System Simulator), a new experimental language specifically oriented toward simulating computer systems, and recording in detail the progress of program development. The purpose of the experiment was to determine to what extent the prototype version of ECSS could reduce the time and expense of such simulation projects. This paper reviews the major elements of ECSS, describes the experimental procedure, and outlines the key features of the ECSS program produced. The results of using ECSS are then compared to the results using FORTRAN and PL/I for the same task. A factor of three reduction in programming time and a factor of two reduction in machine time for model development using ECSS were obtained, but the number of statements required was not significantly reduced, more errors were made, and object program size was much larger for the ECSS version. Although suggestive, a number of experimental difficulties were found to limit the generality of the results. The paper concludes with a discussion of how these results have affected ECSS development, some suggestions for others attempting to evaluate languages for computer system simulation, and an assessment of the hazards and rewards of this empirical evaluation method.
ID:106
CLASS:2
Title: Computer simulation of computer system performance
Abstract: As the usage of some computer systems became more specialized and complicated, there became a need to study the performance of the software as well as the hardware. Thus, simulations were developed to assist in the design and in the improvement of the overall performance of these systems. The categories covered by such simulations ranged from batch processing direct couple systems to time-sharing systems to more specific systems such as those for message processing and switching. It is the intent of this paper to examine the circumstances which have led to the existing state of affairs and to illustrate the benefits which appropriate system performance simulations of some of the newer systems could bestow.
ID:107
CLASS:2
Title: An automated procedure for developing hybrid computer simulations of turbofan engines
Abstract: This paper offers a systematic, computer-aided, self-documenting methodology for developing hybrid computer simulations of turbofan engines. The methodology that is presented makes use of a host program that can run on a large digital computer and a machine-dependent target (hybrid) program. The host program performs all of the calculations and data manipulations that are needed to transform user-supplied engine design information to a form suitable for the hybrid computer. The host program also trims the self-contained engine model to match specified design point information. A test case is described and comparisons between hybrid simulation and specified engine performance data are presented.
ID:108
CLASS:2
Title: Computer simulation\&mdash;discussion of the technique and comparison of languages
Abstract: The purpose of this paper is to present a comparison of some computer simulation languages and of some of the packages by which each is implemented. Some considerations involved in comparing software packages for digital computers are discussed in Part I. The issue is obvious: users of digital computers must choose from available languages or write their own. Substantial costs can occur, particularly in training, implementation and computer time if an inappropriate language is chosen. More and more computer simulation languages are being developed: comparisons and evaluations of existing languages are useful for designers and implementers as well as users.The second part is devoted to computer simulation and simulation languages. The computational characteristics of simulation are discussed with special attention being paid to a distinction between continuous and discrete change models. Part III presents a detailed comparison of six simulation languages and packages: SIMSCRIPT, CLP, CSL, GASP, GPSS and SOL. The characteristics of each are summarized in a series of tables. The implications of this analysis for designers of languages, for users, and for implementers are developed.The conclusion of the paper is that the packages now available for computer simulation offer features which none of the more general-purpose packages do and that analysis of strengths and weaknesses of each suggests ways in which both current and future simulation languages and packages can be improved.
ID:109
CLASS:2
Title: Performance and dependability evaluation of scalable massively parallel computer systems with conjoint simulation
Abstract: Computer systems are becoming more and more a part of our daily life;  business and industry rely on their service, and the health of human beings depends on their correct functioning. Computer systems used for critical tasks have to be carefully designed and tested during the early design stage, the prototype phase, and their operational life. Methods and tools are required to support and facilitate this vital task. In this article, we tackle the issue of system-level performance and dependability analysis of fault-tolerant scalable computer systems. A modeling methodology called &ldquo;Conjoint Simulation&rdquo; is presented, which is based on the parti tioning of the system model and the combination of several modeling techniques. Object-oriented model construction and process-based simulation are applied for architecture and workload modeling, and timed Petri nets are  the core modeling technique representing the failure scenarios and repair policies. Splitting the overall model and exploiting appropriate modeling techniques ease the development, maintenance, and extensibility of large-scale and complex simulation models. Furthermore, techniques are provided for hierarchical model construction, object-oriented workload modeling, and simulated error injection in order to perform combined performance and dependability analysis.
ID:110
CLASS:2
Title: Computer system modelling and simulation
Abstract: To evaluate the suitability and limitations of software for computer systems modelling, a basic comprehension of the structure of such tools must be provided. A brief discussion of conceptual requirements for the description of discrete models, and computer system models in particular, is followed by a survey of commercially available computer simulation packages. Special and general purpose discrete event simulation and general purpose programming languages are also analysed for their suitability for this class of applications. The survey closes with some recommendations and guidelines for selection and application of computer system simulation tools.To aid the analyst contemplating a computer system modelling project, a brief list of relevant addresses and annotated references is also included.
ID:111
CLASS:2
Title: Simulation of computer systems: looking back
Abstract: The past two decades have seen a phenomenal growth in the area of computer systems simulation. As hardware and software systems increase in size, cost and complexity, accurate and timely models become even more vital to the decision maker. Significant research contributions have been made in simulation languages and models in an effort to meet the needs of society. This panel discussion will focus upon the area of computer systems simulation to assess the current state of the art, to learn from past successes and failures, and to predict how we can better model computer systems in the future.
ID:112
CLASS:2
Title: Simulation via implementation with applications in computer communication
Abstract: The traditional approach to performing discrete digital simulation has been one of developing a mathematical or statistical model to represent a process, programming this model on a large scale computer, and then executing the model to obtain performance results. In this study, the authors have developed a simulation of a computer communication network by simulating the users in a central computer and implementing the remainder of the network in actual network processors. This allows for authentic measurements on physical computers and reduces costs since one buys reusable computers instead of buying computer time.
ID:113
CLASS:2
Title: Technical note: a hierarchical computer architecture design and simulation environment
Abstract: A hierarchical computer architecture design and simulation environment (HASE) has been developed at the University of Edinburgh. HASE allows rapid development and exploration of computer architectures at multiple levels of abstraction, encompassing both hardware and software. It has five modes of operation (Design, Model Validation, Build Simulation, Simulate System, and Experiment) which formalize the design cycle and allow a proper separation of concerns among the different phases of simulation activity. The software of HASE itself includes a project data storage facility, a discrete-event simulation engine, graphical display/ editing mechanisms, a visualization mechanism, and tools for setting up experiments and gathering results. HASE has been used in a number of research and  student projects and these exemplify many of the interesting features of HASE and their relation to designing, simulating and evaluating scalable systems. They include the modeling of scalable implementations of the hierarchical PRAM model of parallel computation on a 2-D mesh, the evaluation of the performance of multiprocessor interconnection networks, and a model of the Stanford DASH architecture.
ID:114
CLASS:2
Title: Protein Explorer: A Petaflops Special-Purpose Computer System for Molecular Dynamics Simulations
Abstract: We are developing the 'Protein Explorer' system, a petaflops special-purpose computer system for molecular dynamics simulations. The Protein Explorer is a PC cluster equipped with special-purpose engines that calculate nonbonded interactions between atoms, which is the most time-consuming part of the simulations. A dedicated LSI 'MDGRAPE-3 chip' performs these force calculations at a speed of 165 gigaflops or higher. The system will have 6,144 MDGRAPE-3 chips to achieve a nominal peak performance of one petaflop. The system will be completed in 2006. In this paper, we describe the project plans and the architecture of the Protein Explorer.
ID:115
CLASS:2
Title: Speeding up computer system simulations using hierarchical modeling
Abstract: Hierarchical modeling has been applied with great success in analyzing queueing network models of computer systems, where a direct solution is not possible. A primary example is a memory-constrained timesharing (MCT) system. In a typical two-level model, the analysis of the higher level model is carried out using performance parameters, which are obtained by analyzing the lower-level model. The higher-level model can be usually represented by a multi-dimensional Markov Chain (MC), which is generally very expensive to solve due to the large number of its states. Also the transition probabilities among the states of the MC cannot be obtained or are difficult to obtain in most cases (e.g., models for concurrency control performance). Approximate (iterative) solution methods have been adopted to alleviate the cost of solving linear equations, but the accuracy of such solutions is less predictable than decomposition. In this paper, we discuss the use of simulation for solving the higher level model. This method termed hierarchical simulation is applied to the solution of MCT systems. The accuracy of this technique is checked against direct simulation results for a set of test cases reported in the literature. We then compare the cost of hierarchical simulation against that of direct simulation and comment on its applicability.
ID:116
CLASS:2
Title: Computer system simulation of an on-line interactive command and control system
Abstract: A computer simulation model was used as an analysis &ldquo;tool&rdquo; for computer system design trade-offs for an on-line interactive command and control system preliminary design study project. Three basic hardware configurations were modelled at the hardware interrupt/byte flow level: a. A Centralized Dual Multiprocessor b. Dual Computers c. A Distributed System of Central and Remote Computers The software of the system was modelled in several modules: a. The Operating System Routines b. The Data Base Management Routines c. Interactive File Maintenance and Query Routines d. Object-Coded Functional Applications Programs e. Support and Control Software Each module consists of parametric descriptions for each corresponding loadable software module (e.g., load module size, re-enterability) and procedural descriptions (e.g., read/write statements, processing statements, calls to system macros and other subroutines). The simulation is conducted in two modes: A fast-forward mode to load-up the system, and an observation mode to collect detailed data. A history tape of the environmental stimuli (interactive operator loads) on the system, produced by a separate &ldquo;loading model&rdquo;, enters tasks into the system. The system model is implemented on the IBM 360, Model 65 Computer using a high level computer systems simulation language. The technique developed was so successful that it is now being actively used as a design tool and system performance evaluator, providing a means to minimize the technical risk in the development of all of Litton DSD's major software projects.
ID:117
CLASS:2
Title: Applications of computer simulation in health care
Abstract: Several hundred computer simulation models have been developed in the last 15 years to solve problems in the nation's health care delivery system. These models are categorized and reviewed according to 21 areas of application, along with discussion of general model characteristics. Charts showing trends in health care simulation modeling are given, followed by discussion of problems in model implementation and directions for future research.
ID:118
CLASS:2
Title: Quasi-real simulation as a tool for the implementation of modular computer systems
Abstract:  As a result of the appearance of microprocessors, one of the important trends in actual computer architecture is the breakage of computer systems into special function processors. Accordingly, new methods and tools are developed to design and realize these systems.  Quasi-real simulation appears as a design tool insuring the cooperation between a simulated part of a system and its wired parts, in such a manner that its constructor may have an idea of the quasi-real machine during all the steps of its realization.
ID:119
CLASS:2
Title: Simulation of computers: A tutorial introduction
Abstract: It is only in the last six to eight years that serious, widespread application of the process of simulation has been applied to the performance analysis of computers. Although digital simulation itself is approximately thirty years old, it wasn't until 1966-67 that serious efforts were made to apply this process to a broad array of applications in computer analysis. The reasons for this are not clear. Possibly it was because the techniques of modeling computers had not sufficiently matured for this sophisticated use. Possibly it was because practitioners of simulation and modeling were not well enough versed in the design and operation of computers. Modelers are not necessarily computer technologists, as opposed to computer users. Likely the combination of both reasons served to create the situation which is the contextual background for the elements of this discussion which deals with three subjects: 1) the tools and techniques of computer simulation 2) the areas of activity to which these techniques have been found useful 3) some problems that have occurred due to the immaturity of the process itself
ID:120
CLASS:2
Title: A methodology for simulating computer systems
Abstract: Simulation languages, while providing the modeler with the essential tools for model development, do not provide well defined philosophies for modeling specific classes of systems. Although some languages strongly suggest a particular modeling approach, deriving from a particular world view, a methodology must be developed by the practitioner. A methodology for developing simulation models of computer systems is discussed. In all computer systems there are universal processes which may be broken down into various hardware and software steps. Standard model elements which simulate universal communication and input/output processes are explained. Other software to support model development and end user model execution is also presented. The methodology presented here has proven to reduce model implementation time, produce more reliable models, and relax modeler training requirements.
ID:121
CLASS:2
Title: CSP II\&mdash;a universal computer architecture simulation system for performance evaluation
Abstract: CSP II is a system through which computers can be quickly and flexibly simulated at the functional level, combining the accuracy of a detailed simulation with the simplicity of a high-level simulation. The simulation experiences which motivated the authors' design of CSP II are described, as are the objectives that CSP II was designed to achieve. Strongest of the latter are the capabilities to vary the workload, instruction set, architecture, and timing without recoding the simulation program. Since simulation languages and systems typically offer complete timing flexibility and some flexibility in specifying architecture and workload, emphasis is placed on how CSP II's table-driven approach achieves this total flexibility without significant inefficiency. The array of statistics-gathering mechanisms built into CSP II is described, from a detailed scoreboard of processor state changes to lumped parameters describing computer performance within a simulation run. The great emphasis placed on workload specification capability by the CSP II design is discussed, concluding with the description of the routines written to support workload specification, measurement, and generation. The advantages of the CSP II approach to workload specification are noted, including the ability to generate a workload synthetically. The use of a single workload specification to compare two or more computers, possibly with different instruction sets, is described-a unique capability of the CSP II system.
ID:122
CLASS:2
Title: A computer simulation facility for packet communication architecture
Abstract: Several proposals for computer data processing and memory systems that exploit the inherent parallelism in programs expressed in data flow form have been advanced recently. These systems have packet communication architecture&mdash;each system consists of many units that interact only through the transmission of information packets through channels that link pairs of units. A simulation facility for evaluating the programmability and potential performance of these proposed data processing and memory systems has been designed. The facility uses microprocessor modules to emulate the behavior of system units or groups of units. By conducting a simulation in accurate scale time a precise extrapolation of performance of a proposed system may be obtained. The user of the facility will specify the system to be simulated in an architecture description language. A host computer translates the system description modules into microprocessor programs and controls the loading and monitors the operation of the microprocessors. Application of the facility is illustrated by consideration of a simple data flow processor.
ID:123
CLASS:2
Title: A simulation model of the MICRONET computer system during join processing
Abstract: The MICRONET computer system was specifically designed for processing distributed relational databases. This paper describes a simulation study of the queueing and resource utilization of this system during processing of a relational join operation. Problems associated with representing a computer network in a simulation model are presented. In our model, one set of simulation facilities can represent any node of interest in the network. The processing at each node involves competition for resources by the data bus and the join algorithm. This was represented by processes which were synchronized by Wait Event and Post Event primitives. An algorithm for interrupting a non-shareable resource (e.g. the cpu) was also developed. Results for various system loadings and database sizes are presented.
ID:124
CLASS:2
Title: The design of a multi-microprocessor based simulation computer - II
Abstract: This paper presents further results in development of a discrete event simulation computer based on a network of micro processors. The network is being designed by identifying simulation tasks which may be performed in parallel with other computation required by the simulation, and then assigning those subtasks to attached processing elements in the network. The tasks of priority queue processing and state accounting are considered in this paper. A three attached processor simulation computer has been designed, using two processors for the event set and the third for state statistics accumulation. In a simulation model of this system, a forty to fifty percent reduction in the execution of a benchmark simulation program is easily achieved. (The benchmark program itself uses an adaptive scheduling algorithm). Further observations and suggestions for future research are presented.
ID:125
CLASS:2
Title: Curriculum for simulation education: integration of computer simulation and visualization research into undergraduate degree programs
Abstract: Faculty from several departments in the College of Natural Sciences and Mathematics at IUP have engaged in interdisciplinary projects involving the simulation and visualization of neural networks and material science research. The existing Computer Science degree programs at IUP, however, contain no courses in computer simulation. It has been felt by all the researchers involved in the projects that a degree program focusing on computer simulation is needed to, among its other missions, cultivate students with sufficient knowledge and skills to participate in the projects. This paper starts with an analysis of the knowledge and skills required of the students, followed by identification of existing and new courses that may be taken to acquire the knowledge and skills. The paper concludes with a proposal to establish a degree program in computer simulation and visualization, and an approach in integrating the research projects with the proposed degree program.
ID:126
CLASS:2
Title: A flow oriented computer system simulation language
Abstract: This paper describes a language expressly designed for the simulation of operating system software. A carefully selected portion of the modeling machinery has been incorporated into the language so that the user need only be concerned with the operating system logic in constructing the modeling program. The modeling statements, as input to the assembly portion of the package result in the generation of a series of tables and pseudo code segments which are acted upon interpretatively during the simulation phase. A general description of system features together with a sample model program are presented in the body of the paper. The system described is written mainly in Fortran in a highly modular fashion so that certain extensions and/or changes to the language are easily implemented. The foundation for the effort is simply that simulation of proposed equipment configurations and/or operating system logic can and should be done prior to the installation and/or coding of the actual hardware software complex. Existing simulation languages are not always convenient to the task. Special languages which are natural and convenient to use in describing operating systems can make the prospect of simulation more attractive and useful.
ID:127
CLASS:2
Title: Validation criteria for computer system simulations
Abstract: Validation of computer system simulation models is a common concern of both the programmer/analyst and the decision maker. This paper addresses the question of what are the major characteristics of the empirical aspects of validation and how one might carry out such a validation process for complex computer system models. Validation is described in terms of verification of the authenticity of the random number and random variate generators and of the independent variables established for the model, a proper choice of dependent (response) variables to observe in both the simulation model and the actual system itself (i.e., two sets of data), a choice of statistical tests for comparing their distributional properties, and the ability to predict system performance based on future changes in the actual system configuration. The concepts of validation are clarified through the example of an actual detailed model constructed for the input/output subsystem for a Burroughs B6700 computer. A validation process is proposed which specifies data that should be collected from the simulation model, which relates experiences with obtaining the coordinate live test data from the actual system under consideration, and finally shows how statistical tests can be applied to verify or reject the hypothesis that both sets of data result from the same population. Empirical data is presented to aid in the understanding of the concepts.
ID:128
CLASS:2
Title: A structural approach to simulation in support of computer system design
Abstract: This paper describes the various features of a new approach to supporting computer system design by simulating the computer system as it progresses through levels of increasingly detailed design These features include model specifications, use of structured programming, choice of simulation system or language, organization of simulation effort and personnel, the &ldquo;chief modeler&rdquo; concept, the model development process, modeler/designer information flow and interfaces, and the modeling of workload. An analysis is made of relative life cycle cost between the structured approach to simulation and the traditional approach of supporting a computer design effort.
ID:129
CLASS:2
Title: Computer graphics in support of Space Shuttle simulation
Abstract: Electronic scene generation plays an important role in simulation of the Space Shuttle at the Johnson Space Center in Houston, Texas. Simulators for astronaut training, system integration and engineering development utilize both a moving camera/map board system as well as computer generated images. Launch, on-orbit, payload handling and landing tasks are simulated with shaded computer graphics to provide realtime visual feedback. An overview of these simulators is presented.
ID:130
CLASS:2
Title: The use of micro level simulation in the design of a computer supervisory system
Abstract: This paper describes the use of simulation, at the instruction level, in the design of the supervisory software of a multi-computer system. The computer system included a supervisory computer, satellite mini computers, secondary data storage devices, and terminals with probabilistic data demands. The model development criteria was to consider every instance of conflict in resource allocation and to simulate its resolution. The computer system was primarily concerned with supplying data to the terminal devices. The criteria used to evaluate alternative supervisory software centered on the system's ability to provide adequate data communications. Using the model to test alternatives, system improvements in the order of 10-1 were obtained, primarily through software. The paper consists of a brief description of the operating environment, the computer hardware and software specifications, the modeling process and simulation, the alternatives tested and results and the benefits derived through the use of simulation.
ID:131
CLASS:2
Title: Factor screening methods in computer simulation experiments
Abstract: The use of a computer simulation model may be viewed as an experiment in which a set of k controllable factors are varied according to an experimental design, and the effect of these factors on the output observed. Usually not all k factors will be active, and considerable efficiency in the use of the model will result if the subset of active factors can be identified. Factor screening methods are useful in identifying the set of active factors. This paper discusses experimental design methods useful for factor screening in computer simulation. The general strategy recommended is group screening methods combined with 2k&minus;p fractional factorial designs. Some variance reduction considerations are also discussed.
ID:132
CLASS:2
Title: A local computer network simulation
Abstract: Computer Networks are an important part of our society and they are quickly becoming an integral part of computer science basic curriculum. This paper describes the development of a computer simulation model for a local computer network and its use as a viable tool in computer science education.
ID:133
CLASS:2
Title: Simulation of a computer with variable hardware and variable instruction set
Abstract: Parallel processing systems are used today in many applications such as in vision, robotics, real-time processes etc. It is therefore important to develop simulators to aid automated design of parallel-processing systems. This Paper discusses development of a Meta-simulator for simulating and analyzing such systems. This could form a part of a general multi-processor system CAD package. The statistical results derived using the simulator can be used to generate Reduced Instruction Set Computing (RISC) elements providing reduced hardware complexity and improved overall system performance. Two methods of implementation - namely using, Instruction Set Processing Specification, ISPS and High Level Language, C are reviewed and compared. Evaluation of candidate architectures requires use of high level and assembly languages for writing benchmark programs for the simulator. We therefore discuss the notion of Meta-Assembler and Meta-Compiler also.
ID:134
CLASS:2
Title: Closing the gap between simulation \&amp; combat computer systems
Abstract: As simulations have evolved, interoperability between them has emerged as a fundamental technique for increasing their applicability and minimizing the cost of development and maintenance. From totally independent systems, through manual interfaces, automated interfaces, messaging standards, control standards, and architectural standards - the field has been transformed from a set of independent programs into a loose confederation working together to maximize each others contributions. The next step in this evolution is the inclusion of real-world combat computers in the simulation federations, particularly command and control computers. This paper will define the steps that must be taken to support this integration with a large number of simulation systems. It will explore interoperability projects that are taking place within the simulation and C41 system communities, describing architectures such as the simulation High Level Architecture, the Modular Reconfigurable C41 Interface, the Defense Information Infrastructure Common Operating Environment, and the Joint Military Command and Information System. Interoperability methods for the generic integration of systems built to a common architecture will be proposed and some argument given to its viability.
ID:135
CLASS:2
Title: Gordon Bell finalists II---A 55 TFLOPS simulation of amyloid-forming peptides from yeast prion Sup35 with the special-purpose computer system MDGRAPE-3
Abstract: We have achieved a sustained performance of 55 TFLOPS for molecular dynamics simulations of the amyloid fibril formation of peptides from the yeast Sup35 in an aqueous solution. For performing the calculations, we used the MDGRAPE-3 system---a special-purpose computer system for molecular dynamics simulations. Its nominal peak performance was 415 TFLOPS for Coulomb force calculations; this is the highest-ever performance reported for classical molecular dynamics simulations. Amyloid fibril formation is known to be related to the occurrence of severe diseases such as Alzheimer's, Parkinson's, and Creutzfeldt-Jakob diseases. The Sup35 protein is a "yeast prion protein," which forms mini-crystals due to aggregation; it forms an effective platform for studying the formation process of amyloid fibrils. In these simulations, we first elucidate that the amyloid-forming peptides GNNQQNY aggregate at a higher frequency than non-amyloid-forming peptides SQNGNQQRG; further, the GNNQQNY peptides tend to form parallel two-stranded &szlig;-sheets that would grow into a cross-&szlig; amyloid nucleus. The results are consistent with those obtained experimentally. Furthermore, we could observe an early elongation of the amyloid nucleus. This result is expected to contribute toward a deeper understanding of the amyloid growth mechanism.
ID:136
CLASS:2
Title: A computer simulation approach to elevator system design
Abstract: Computer simulation methods enable the architech to accurately analyze the performance of specified elevator systems, thus facilitating more careful evaluation of alternative system designs than previously achievable. Simulation improves analysis because it involves replication of real-time elevator performance and does not rely on the rules of thumb and statistical assumptions incorporated into traditional analytical methods. The development of a computer simulation program for elevators requires caution to ascertain that the assumptions incorporated into the program are satisfactory and that the resulting program performs reliably and accurately. An acceptable simulation program, such as the one presented in this paper, facilitates a variety of research efforts encompassing sky lobby and express car layout strategies, dynamic peak control procedures, and cost/benefit studies of system design goals.
ID:137
CLASS:2
Title: COBOL simulation: random number generation for binary and decimal computers
Abstract: Although the Common Business Oriented Language was originally designed for use in business data processing, the language is now being employed as a simulation language under certain limiting conditions. Factors influencing the application of the language to simulation studies include its popularity, its self-documenting characteristic, its "believability," and its efficiency in programming the triangular distribution.A necessary requisite in any simulation study is the programming of random number generators to simulate the random occurrence of various events. Several methods of generating random numbers are available, but the technique most frequently used is the power residue method. Since most simulation studies are programmed with FORTRAN (a general purpose language), simulation languages (SIMSCRIPT, GPSS, GASP, etc.), or machine languages, little attention has been devoted to programming the power residue method of random number generation with COBOL.A procedure is presented which describes and discusses COBOL programming of random number generation for the binary computer and the decimal computer utilizing the power residue method. Program excerpts are provided to illustrate the procedure, and comparative differences in COBOL programming for the two computer types are noted. Conditions most favorable to COBOL programming of simulation studies are also discussed, as well as the conditions under which COBOL programming is not recommended.
ID:138
CLASS:2
Title: Optimizing bit-time computer simulation
Abstract: A major component of a bit-time computer simulation program is the Boolean compiler. The compiler accepts the Boolean functions representing the simulated computer's digital circuits, and generates corresponding sets of machine instructions which are subsequently executed on the &ldquo;host&rdquo; computer. Techniques are discussed for increasing the sophistication of the Boolean compiler so as to optimize bit-time computer simulation. The techniques are applicable to any general-purpose computer.
ID:139
CLASS:2
Title: A simulation approach to the design of dynamic feedback scheduling algorithms for time-shared computer systems
Abstract: The goal of a scheduling algorithm for a time-shared computer system is to provide acceptable request response time and resource utilization through effective resource allocation. In order to do this, it is necessary for the algorithm to be capable of adjusting itself to handle the various situations, precipitated by the set of active user requests and the computing system's status, which may occur. An effort is now underway to design the structural framework of a scheduling algorithm which will dynamically formulate its resource allocation policies and adjust its policy formulation depending on the success or failure of those policies. Once designed, the framework will then be used to construct the scheduling algorithm for a given time-shared computer system. The approach chosen for determining the practicability of the algorithm design is the inclusion of the algorithm in the simulation of a swapping time-shared computer system model. The simulation contains four basic activities: processor, input/output, swapper, each of which contains a resource allocation policy for determining a priority ordering among those requests which have asked for the respective resource, and the user activity. User activities follow one of a number of simulated scripts which may be composed of several types of requests. Each request is given behavioral traits dependent on its type. While the complete algorithm is not yet implemented within the simulation, preliminary results suggest that some improvement in response time may be possible.
ID:140
CLASS:2
Title: Explanation systems for computer simulations
Abstract: Explanation systems supply information that clarifies the structure and problem domain of a computer program for the user. We begin our paper by describing the early explanation systems, which were built for expert system programs, and by reviewing some of the subsequent developments in artificial intelligence that relate to this area. The results of our research are consistent with some of the recent developments in artificial intelligence; we have found that there are a variety of kinds of information that are useful to naive users of computer programs. We have been particularly interested in writing programs that can supply such information to naive users of numerical computer simulations. We describe an implemented explanation system, NATURALIST, which explains the structure and domain of a simulation for inventory control. Our experience with the NATURALIST program suggests that explanation facilities may be valuable additions to numerical computer simulations.
ID:141
CLASS:2
Title: Simulation structure for the development of Texas Instruments' Advanced Scientific Computer
Abstract: During development of a large-scale computer system, design decisions must be based on more than intuition and past experience. As development continues past the design phase, it is necessary to provide tools to verify that a system or subsystem is doing what it was designed to do from both functional and performance standpoints. Furthermore, it is necessary to have some means of evaluating the effects of proposed changes to an operational system. One valuable tool in satisfying these requirements is simulation. In developing the Advanced Scientific Computer (ASC) system, Texas Instruments relied, in part, upon an extensive simulation capability. This paper describes the various simulators, how they were used in the development and checkout of the ASC, and how they are now being used to assist in &ldquo;tuning&rdquo; the system, and to evaluate potential configurations. The simulators described include: &bull; An operating system simulator which models the operating system program executing in the Peripheral Processing (PP) unit of the ASC. &bull; A Fuctional Unit Simulator (FUS) which models the various functional units of the ASC. This simulator is of special interest because of the variety of techniques it employs and the number of functions it serves. &bull; A Memory Subsystem Simulator which models the affects of multiple device (CP, PP, DISC, etc.) access to Central Memory. An Instruction Level Simulator (ILS) which is a classical interpretive simulator for use in program check out.
ID:142
CLASS:2
Title: An extensive logic simulation method of very large scale computer design
Abstract: The paper describes one of the methods to evaluate the design verification progress of logic simulation. In the development of the very large scale general purpose computer HITACHI M-680H/682H, the function test programs designed for the products have been directly used to verify the design in simulation. Test programs establish the definite goal and enable to extensively verify the design. The simulation techniques, which carry out at high speed the very large design described in different levels of abstraction, have developed for this purpose. The method has detected 30% of design errors of M-68X and effectively reduced its development time.
ID:143
CLASS:2
Title: Simulation of computer systems using automatically generated load descriptions
Abstract: A complete description of a computer system must include three groups of components: 1. The hardware components 2. The software components (the operating system), and 3. The load components (the stream of tasks to be processed). When computer systems are simulated all of these components are found as features of the simulations. The hardware normally appears as a collection of tables and associated operational data. The operating system appears both as tables and as scheduling or assignment algorithms. The load is represented either as a sequence of requests for service (use of system resources) or as a set of functions which can generate such a sequence of requests. In many applications, the description of the load turns out to be the most difficult task. This paper discusses some techniques and procedures which have been used to automatically generate the required load descriptions. The emphasis is on a request sequence generator which uses data found in a system event trace. One such technique, called trace-driven modeling, has been implemented at the Purdue University Computing Center. This implementation is discussed and its usefulness and accuracy are illustrated with actual data.
ID:144
CLASS:2
Title: The design of a multi-microprocessor based simulation computer - I
Abstract: A discrete event simulation computer based on a network of microprocessors is being developed at Florida International University. This paper contains a description of the simulation models used thus far in the development process and results obtained from them. A system using a PDP-11 as the principal processor and a Motorola M68000 as an event set processor has been implemented. Results from the performance of this system are presented, and plans for further development are discussed.
ID:145
CLASS:2
Title: Reasoning in time and space: issues in interfacing a graphic computer simulation with an expert system for an intelligent simulation training system
Abstract: Computer simulation and expert systems technologies have the same goal: the study of intractable, complex systems for which standard algorithmic methods of study are inadequate. An expert system can be interfaced with a graphic computer simulation to reason about physical systems. Such an expert system needs the ability to reason qualitatively about simulation objects. This reasoning includes temporal, spatial, and causal (cause and effect) reasoning. This paper describes an expert-system/graphic-computer-simulation interface for an Intelligent Simulation Training System (ISTS) which is currently under development. Important design considerations include the reasoning tasks involved, mechanisms for reasoning about physical systems, and machine perception of simulation data for use by the expert system. It is necessary to carefully design the interface between a graphic computer simulation and an expert system in order to realize automated, intelligent training related to physical systems.
ID:146
CLASS:2
Title: Foundations of multi-paradigm modeling and simulation: computer automated multi-paradigm modelling: meta-modelling and graph transformation
Abstract: We present Computer Automated Multi-Paradigm Modelling (CAMPaM) (Mosterman and Vangheluwe 2002) for Model-Driven Development based on Meta-Modelling and Graph Transformation. The syntax of a class of models of interest is graphically meta-modelled in an appropriate formalism such as Entity-Relationship Diagrams. From this description of abstract syntax, augmented with concrete (visual) syntax information, an interactive, visual modelling environment is automatically generated. As the abstract syntax of models, irrespective of the formalism they are described in, is graph-like, graph rewriting can be used to perform model transformation. Graph Grammar models thus allow for model transformation specification. The Graph Grammar formalism can be meta-modelled in its own right and hence a visual environment for manipulating transformation models can also be automatically generated. Graph rewriting provides a rigourous basis for specifying and analyzing model transformations such as simplification, simulation, and code generation. In this article, we introduce AToM&#60;sup>3&#60;/sup>, A Tool for Multi-formalism and Meta-Modelling. We present the meta-modelling and graph transformation concepts through a simple reactive system example: a Timed Automata model of a traffic light. Meta-modelling Timed Automata, generating the visual modelling environment, and modelling transformations as graph grammers, as well as executing them, are all performed in the AToM&#60;sup>3&#60;/sup> environment. The model transformations include simulation, transformation into Timed Transition Petri Nets, and code generation.
ID:147
CLASS:2
Title: Dynamic simulation model for planning physical distribution systems: Discussion of the computer model
Abstract: The general class of problem considered in this paper is that of long-range planning of physical distribution systems. The physical distribution activity includes design and administration of systems to control raw material and finished goods flow from manufacturing source to point of consumption.2 From an analytical viewpoint, a physical distribution system consists of several interactive activity centers or subsystems among which tradeoffs in cost and service exist. These subsystems are often referred to as the components of a physical distribution system. In this research the classification of components includes: facility network, inventory allocations, communications, transportation, and unitization. With the exception of unitization, these components and the relative range of system design alternatives are familiar to the reader. Unitization, in a broad sense, involves material handling, packaging, and containerization.
ID:148
CLASS:2
Title: Evaluating computer systems simulation models
Abstract: The need to validate and evaluate the running of simulators of computer systems is considered. The paper describes the systematic construction of a simulator to minimise logical and modelling errors and discusses three alternative ways of validating and evaluating the correctness and accuracy of such simulators. The advantages and disadvantages of the method are outlined.
ID:149
CLASS:2
Title: An 8.61 Tflop/s molecular dynamics simulation for NaCl with a special-purpose computer: MDM
Abstract: We performed molecular dynamics (MD) simulation of 33 million pairs of NaCl ions with the Ewald summation and obtained a calculation speed of 8.61 Tflop/s. In this calculation we used a special-purpose computer, MDM, which we have developed for the calculations of the Coulomb and van der Waals forces. The MDM enabled us to perform large scale MD simulations without truncating the Coulomb force. It is composed of MDGRAPE-2, WINE-2 and a host computer. MDGRAPE-2 accelerates the calculation for real-space part of the Coulomb and van der Waals forces. WINE-2 accelerates the calculation for wavenumber-space part of the Coulomb force. The host computer performs other calculations. With the completed MDM system we performed an MD simulation similar to what was the basis of our SC2000 submission for a Gordon Bell prize. With this large scale MD simulation, we can dramatically decrease the fluctuation of the temperature less than 0.1 Kelvin.
ID:150
CLASS:2
Title: Computer graphics in medicine: from visualization to surgery simulation
Abstract: Medicine is an extremely challenging field of research, which has been -- more than any other discipline -- of fundamental importance in human existence. The variety and inherent complexity of unsolved problems has made it a major driving force for many natural and engineering sciences. Hence, from the early days of computer graphics the medical field has been one of most important application areas with an enduring provision of exciting research challenges. Conversely, individual graphics tools and methods have become increasingly irreplaceable in modern medicine, where medical imaging systems are only one prominent example.The purpose of the following article is twofold: Without claiming completeness, the first part gives a brief retrospective of the fruitful relationship between computer graphics and individual subareas of the medical field. We start with early imaging and 3D visualization and move via interactive, collaborative data analysis to the emerging field of surgery simulation. The second part of the paper presents a more detailed view on the interdisciplinary field of virtual and simulated surgery which encompasses knowledge from medicine, computer graphics, computer vision, mechanics, material sciences, robotics and numeric analysis The author describes the leading role of graphics and VR as core technologies and summarizes his personal vision of current and future research problems, which have to be pursued for realizing our vision of fully interactive and immersive surgery simulation.
ID:151
CLASS:2
Title: Confidence intervals for queueing simulations of computer systems
Abstract: Simulation models of computer systems may be formulated as queueing networks. Several methods for confidence interval estimation for queueing simulations are dicussed. Empirical studies of these methods are presented.
ID:152
CLASS:2
Title: Computer simulation of the zinc-chloride battery
Abstract: The zinc-chloride battery is being developed by Energy Development Associates for utility load-leveling applications. The many simultaneous and interacting processes occurring within the battery make predicting its behavior difficult without a computer simulation model. Such a simulation has been developed to an accuracy of 295%. In this paper, the methodology used to develop the computer model is discussed; sample computer outputs are shown; and the model predictions are verified with operational data from a battery.
ID:153
CLASS:2
Title: A computer organization course project: simulation of a modern traffic signal system
Abstract: This paper describes a simulation project concerning a modern traffic signal control system that was carried out by students in a computer organization course and in a subsequent independent research course. The overall project required both hardware realization and software development for simulating the traffic flow using assembly language. The features of this control system, the project scope, a prototype implementation - both hardware and software - and the educational value of such a project are presented.
ID:154
CLASS:2
Title: Use of performance analysis statistics in computer system simulation
Abstract: A general purpose job stream simulation model has been developed for routine use in evaluating hardware configurations and performance tuning a large scale multiprocessor computing system operating in a multiprogramming mode. The model is designed to simulate a variable workload of jobs statistically generated from attributes of the actual workload for any time period. Major functional modules include job-step generation, job classing, scheduling and step initiation, core allocation, cpu operation, and I/O activity. Hardware attributes (such as, available core and number of DASD control units), operating considerations (such as, number and priority class structure of initiators), and workload characteristics can readily be varied at model initialization time.
ID:155
CLASS:2
Title: Computer simulation of bacterial survival data from a complex dilution experiment
Abstract: A computer simulation is provided to generate bacterial survival data using the Weibull model (the exponential being an option). The simulation provides data when serial dilution is used before or after exposure to a bactericide allows for incubation as well. The simulation should be useful in all sterilization studies - whether of medical services, food, pharmaceuticals, or space vehicles. The algorithm, upon which the simulation is based, adheres faithfully to the probabilistic description of the experiment. The simulation should also be useful to both statisticians and microbiologists.
ID:156
CLASS:2
Title: A simulation model of a multi-computer system solving a combinatorial problem
Abstract: This paper describes a simulation of a multi-computer system used to solve computationally intensive combinatorial problems. The model is traced from its conception through to the initial experiments conducted using it and their results. Included are descriptions of the combinatorial problems being solved, the language selection process, the simulated multi-computer system, and the model validation performed.
ID:157
CLASS:2
Title: The design of a multi-microprocessor based simulation computer - III
Abstract: A continuing research project at Florida International University in the development of a discrete event simulation computer based on a tightly coupled network of high performance, (relatively) low cost microprocessors. The basic design approach involves identifying specific sets of related tasks within a simulation program, and assigning these tasks to ancillary processors. In this paper, the state of the system with respect to the task of Event Set Manipulation is reviewed. A new event set algorithm, the Merged Adaptive List algorithm is presented; using this algorithm permits one event set processor to perform computations previously requiring three; its performance is contrasted with that of the Linear and Adaptive Linked List algorithms.
ID:158
CLASS:2
Title: Design of SEMA: A software system for computer-aided modelling and simulation of sequential machines
Abstract: SEMA (SEquential MAchines) is a theory-based comprehensive computer-aided modelling and model processing system. The modelling methodologies of the current version of SEMA are finite-state machines (Moore and Meally) and Markov chains. In this paper, modelling features, computer-aided modelling facilities, and the highlights of some other features of the SEMA system are discussed.
ID:159
CLASS:2
Title: Simulation of a computer system with single and dual density discs
Abstract: The question of replacing a single density, two-channel, two-controller disc system with a less costly, plug compatible, dual density, single channel, single controller system having the same capacity is considered. A simulation model is designed to examine the effect of such a replacement on average transaction time, that is the time between issuing an I/O request and completion of the request. Although such a replacement results in an increase in transaction time, this increase may be tolerable if disc utilization is low. The effects of a special software change and of logical disc balancing are also investigated.
ID:160
CLASS:2
Title: Validation and use of computer system simulation for a dual IBM 370/165 system
Abstract: This paper describes an application of computer system simulation used to evaluate the impact of implementing the &ldquo;SET UP&rdquo; features in LASP on a dual IBM 370/165 system. The system supports a scheduled workload. The use of SET UP requires change in the resource demand of the input job streams such that all job steps within a job assume the memory and tape unit resource profile of the largest step in the job. The SET UP feature was considered by some to provide more consistent schedule performance in the existing tape-oriented installation. Simulation was used as the evaluation method because it offered reduced cost compared to physical testing and eliminated the hazards of testing in a production environment. Simulation job streams were generated from the system log (SMF) by an extract program to produce simulation job streams consisting of 3365 events representing the heaviest production day. The job streams were then simulated for the hardware/software configurations of their respective computers and the results validated by comparison of the simulated schedules and resource demands with actual schedule and resource usage data. After validation, the job streams were modified to represent the SET UP case with expanded tape and memory requirements and were introduced into the validated system simulation models. The additional resources required to support SET UP were determined from analysis of the simulation results and an implementation decision was made.
ID:161
CLASS:2
Title: Introducing computer concepts by simulating a simple computer
Abstract: The simulated computer consists of (1) main memory, (2) a register known as the accumulator, (3) a central processing unit (CPU), and (4) an instruction counter. This computer recognizes 8 op codes (Halt, Load, Store, Add, Subtract, Read, Write, and Branch On Zero). The computer is simulated by creating a program in Pascal or C++. This program simulates the execution of programs written by students, such as adding two numbers and printing their sum. Student programs are written in machine language and executed by the simulated computer. Students can write programs in assembly language, compile them by hand, and then test them by running them on the simulated computer. This example has been helpful in teaching students what a computer is and what computers can do.
ID:162
CLASS:2
Title: Simulation of computer program distribution
Abstract: A computer program library is essentially a &ldquo;job shop&rdquo; which accepts and processes requests for computer programs. Such processing usually results in an initial delivery of the program package to the requestor, followed later by deliveries of maintenance packages to him. Packages usually consist of documentation and machine readable material (cards, tapes, disks, etc.).The latter is prepared on data processing equipment installed in the shop. Simulation of this preparation process has proved to be a useful tool in the short and long range planning of the shop's facilities. The GPSS/360 model constructed simulates both the management's supervisory decision process as well as the resulting activity of machine readable material preparation. It produces a suggested equipment installation schedule, accompanied by statistics on equipment utilization, service times, costs, etc. based on that schedule.
ID:163
CLASS:2
Title: Animated graphics and computer simulation
Abstract: This paper discusses the role of animated graphics in computer simulation. Its focus is on low-cost software and hardware, in contrast to the expensive programs and equipment usually available commercially. We see that animated graphics can enhance model development as well as provide a better understanding of the basic mechanisms underlying the system under study.
ID:164
CLASS:2
Title: The use of computer simulation in health care facility design
Abstract: In this paper a decision-making tool for managers of hospitals and health care facilities, the management sciences technique of computer simulation modeling, is introduced. Its benefits as a planning and evaluative tool for hospital managers is illustrated by explaining a successful modeling application, a computer simulation model of physical therapy, developed at the Rehabilitation Institute of Chicago. With the physical therapy simulation as an example, the advantages of computer simulation modeling for containing costs and improving resource utilization and quality care are illustrated. This paper is based on research supported, in part, by Demonstration Grant No. 12-P-55189/5-01, from the Social and Rehabilitation Service, U.S. Department of Health, Education, and Welfare, awarded to the Rehabilitation Institute of Chicago and HEW-SRS Medical Rehabilitation Research and Training Center Number Twenty.
ID:165
CLASS:2
Title: Simulation of the time-varying load on future remote-access immediate-response computer systems
Abstract: A GPSS/360 program has been developed to model the behavior of a remote-access immediate-response computer system serving many concurrent users. Inputs to the model include characteristics of the users, the application category, the communication equipment, and the computer system. The model uses this information to determine the time-varying load imposed on the system in giving each on-line user immediate response.
ID:166
CLASS:2
Title: Computer simulations of cardiac electrophysiology
Abstract: CardioWave is a modular system for simulating wavefront conduction in  the heart. These simulations may be used to investigate the factors that generate and sustain life-threatening arrhythmias such as ventricular fibrillation. The user selects a set of modules which most closely reflects the simulation they are interested in and the simulator is built automatically. Thus, we do not present one monolithic simulator, but rather a simulator-generator which allows the researcher to make the trade-offs ofcomplexity versus performance. The results presented here are from simulations run on an IBM SP parallel computer and a cluster of workstations. The performance numbers show excellent scalability up through 128 processors. With the larger memory of the parallel machines, we have been  able to perform highly realistic simulations of the human atria. These simulations include realistic, 3-D geometries with inhomogeneity and anisotropy as well as highly complex membrane dynamics.
ID:167
CLASS:2
Title: A simulation approach to the design of dynamic feedback scheduling algorithms for time-shared computer systems
Abstract: The goal of a scheduling algorithm for a time-shared computer system is to provide acceptable request response time and resource utilization through effective resource allocation. In order to do this, it is necessary for the algorithm to be capable of adjusting itself to handle the various situations, precipitated by the set of active user requests and the computing system's status, which may occur. An effort is now underway to design the structural framework of a scheduling algorithm which will dynamically formulate its resource allocation policies and adjust its policy formulation depending on the success or failure of those policies. Once designed, the framework will then be used to construct the scheduling algorithm for a given time-shared computer system.The approach chosen for determining the practicability of the algorithm design is the inclusion of the algorithm in the simulation of a swapping time-shared computer system model. The simulation contains four basic activities: processor, input/output, swapper, each of which contains a resource allocation policy for determining a priority ordering among those requests which have asked for the respective resource, and the user activity. User activities follow one of a number of simulated scripts which may be composed of several types of requests. Each request is given behavioral traits dependent on its type.While the complete algorithm is not yet implemented within the simulation, preliminary results suggest that some improvement in response time may be possible.
ID:168
CLASS:2
Title: Report on selected readings on digital computer simulation
Abstract: The title of this text immediately reveals who it is written for: architects who are interested in computer applications. The author is assuming that the general reader in the field of architecture has absolutely no background in the field of computing and the text is therefore written on a very low level of sophistication, at which the simplicity is exaggerated. Though the text as a whole is probably helpful for an uninformed reader to learn about applications of computers to architecture, a more sophisticated reader will find reading of all but a few sections a waste of time. For a person with specific interests in the field of architecture and computer applications, those few more successful parts are probably quite worth reading, if for nothing else, then just for exposure to what is actually being done in that area. Besides that, an uninformed reader may find it interesting to get exposure to British hardware and ALGOL-based programming practice, as well as British terminology.
ID:169
CLASS:2
Title: Computer-assisted modeling and simulation for time oriented systems
Abstract: Most simulation systems are able to cope with large 'white box' problems, but their application proves to be difficult in case of 'grey box' and 'black box' problems in the social sciences. Even recently developed interactive tools for simulation and structural modeling cannot manage large scale models without difficulties. A computer-aided method is missing for the modeling and simulation of large-scale real-world problems. At the Department of Medical Cybernetics of the University of Vienna Medical School simulation languages and 'modeling tools' are applied in different non-technical fields. First our experience with four systems (CSMP, QSIM3, SPIN, SISSY) is described. A methodological concept is presented for computer-assisted modeling and simulation of time oriented systems. It provides among other features: user defined types of structural elements and relations by means of a meta-definition language; relational networks for the structural representation; defined interfaces between structural representation and processes; support of top-down and bottom-up approaches by incorporation of ordering relationships within the model entities; communication, useability and documentation for the novice and advanced modeler. The aim of the proposed new system is to encourage experimental modeling and simulation of comlex real world problems and to gain an appropriate level of detail. The concepts for the realization are presented.
ID:170
CLASS:2
Title: Developments in computer simulation of gate level physical logic
Abstract: This paper discusses techniques developed for simulation of large physical logic systems at high speeds and with accurate timing.
ID:171
CLASS:2
Title: Dynamic simulation of a national resource sharing computer network
Abstract: A national computer network for research and educational institutions has frequently been proposed as a means for meeting selected computing needs in an effective manner. Although many technical problems remain, it is generally believed that the most difficult issues facing such a network revolve around economic, political, and organizational considerations. In order to investigate these issues, a model of a computer network was developed to test a variety of networking alternatives, and to evaluate the ways in which a network would impact its member institutions. This paper describes the use of the simulation model in a three day gaming exercise by sixteen institutional teams who made decisions about their likely participation in a network that &ldquo;progressed&rdquo; through several years of simulated time. Participants were able to interact dynamically with the decisions and actions of other participants, to deal with a variety of network issues, and to explore the relative advantages and disadvantages of various modes and levels of network participation. This project represented an unusual and different application of a simulation game in that it concentrated on the policy and behavioral aspects (i.e., people concerns) of what is usually considered to be a technical design problem. The players were real decision makers, playing themselves as they relate to their own institutions, rather than students. Consequently, it was possible to focus on learning about the implications of national networking, rather than merely demonstrate or teach known principles.
ID:172
CLASS:2
Title: Computer graphics for simulation problem-solving
Abstract: Interactive computer graphics was used while simulating a computer system. The graphics capabilities were extremely valuable for sifting through the large volume of simulation output in order to discover anomalous behavior characteristics. Hard copy options were available, and they were used extensively.
ID:173
CLASS:2
Title: Hardware simulation tools for computer design
Abstract: An objective during the latest offering of our institution's Computer Organization course was to improve student's awareness that a computer is merely an electronic device, and that a simple working example may be constructed by using knowledge they already possess. A hardware simulation tool was used to construct illustrative portions of computer circuits and a complete, functioning computer used during different types of student exercises and assignments. Anecdotal feedback and a post-use survey confirmed my expectation that the simulation would contribute toward student's understanding and confidence.
ID:174
CLASS:2
Title: Computer graphics visualization for acoustic simulation
Abstract: Computer simulations can be used to generate the spatial and temporal data describing the acoustical behavior of performance halls, but typically the analytical results are difficult to assimilate and compare. By using computer graphics to display the multi-dimensional data, substantially greater amounts of information than that conveyed by standard techniques can be communicated to the designer. This allows designs of different acoustical spaces to be tested, evaluated, and compared.An example comparing the acoustical behavior of three different concert halls demonstrates these techniques and allows for the simultaneous assimilation of much of the information necessary to evaluate the acoustical nature of a space. The use of three-dimensional images, color, animation and abstract representation allows for the comprehension of the complex results of a scientific simulation. Specifically, the simultaneous display of particular icons familiar to the discipline enabled the simultaneous presentation of up to twelve parameters.From a more general point of view, the procedures demonstrate how computer graphics can be utilized for the portrayal of multi-dimensional time dependent data. The visualization techniques are potentially useful for the display of three-dimensional vector fields in many scientific and design applications.
ID:175
CLASS:2
Title: Methods for analyzing data from computer simulation experiments
Abstract: This paper addresses itself to the problem of analyzing data generated by computer simulations of economic systems. We first turn to a hypothetical firm, whose operation is represented by a single-channel, multistation queueing model. The firm seeks to maximize total expected profit for the coming period by selecting one of five operating plans, where each plan incorporates a certain marketing strategy, an allocation of productive inputs, and a total cost.The results of the simulated activity under each plan are subjected to an F-test, two multiple comparison methods, and a multiple ranking method. We illustrate, compare, and evaluate these techniques. The paper adopts the position that the particular technique of analysis (possibly not any one of the above) chosen by the experimenter should be an expression of his experimental objective: The F-test tests the homogeneity of the plans; multiple comparison methods quantify their differences; and multiple ranking methods directly identify the one best plan or best plans.
ID:176
CLASS:2
Title: Hybrid simulation models of computer systems
Abstract: This paper describes the structure and operation of a hybrid simulation model in which both discrete-event simulation and analytic techniques are combined to produce efficient yet accurate system models. In an example based on a simple hypothetical computer system, discrete-event simulation is used to model the arrival and activation of jobs, and a central-server queueing network models the use of system processors. The accuracy and efficiency of the hybrid technique are demonstrated by comparing the result and computational costs of the hybrid model of the example with those of an equivalent simulation-only model.
ID:177
CLASS:2
Title: A simulation of dynamic task allocation in a distributed computer system
Abstract: Distributed processor systems are currently used for advanced, high-speed computation in application areas such as image processing, artificial intelligence, signal processing, and general data processing. The use of distributed and parallel processor computer systems today requires systems designers to partition an application into at least as many functions as there are processors. Spare processors must be allocated and function migration paths must be designed to allow fault tolerant reconfiguration. The parallel process/ parallel architecture control simulation (PPCS) models parallel task allocation on a distributed processor architecture. Parallel task allocation is a first step in designing a dynamic parallel processor operating system that automatically assigns and reassigns application tasks to processors. Advantages of this approach are: dynamic reconfigurability removing the need for spare processing power reserved for failures; the reduced need for fallback and recovery software for fault detection; more optimized partitioning of functions; and better load balancing over available processors. PPCS models various distributed processing configurations, task dependencies, and the scheduling of the tasks onto the processor architecture. The PPCS system implements fifteen different heuristic scheduling algorithms to map a set of tasks onto the processing nodes of a distributed computer. The simulation shows the feasibility of using fast algorithms to heuristically schedule a system of multiple processors allowing dynamic task allocation.
ID:178
CLASS:2
Title: MuSiC: an event-flow computer for fast simulation of digital systems
Abstract: The Munich Simulation Computer (MuSiC), a special-purpose, highly-parallel programmable machine, is an approach to transfer concepts (developed for data flow computers) to fast, mixed-design-level simulation of digital systems. To gain high performance, however, the operation principle is modified from data flow computation to event flow computation. This paper presents the event flow computation scheme and its implementation by the MUSIC organisation. Parameters, which influence performance, are discussed and it is shown that MuSiC can simulate more than 8 million gates and flipflops at a speed of up to some billion events per second.
ID:179
CLASS:2
Title: Simulation of facility designs on a micro-computer
Abstract: The design of a high technology production facility quite often hinges on the successful design of a material handling system to integrate the various automation centers. Traditionally, management has been reluctant to invest the capital necessary for high technology material handling equipment since they have no guarantee of the performance potential. Simulation of a proposed facility design, with a special emphasis on the material handling system is illustrated as a key method for evaluating the proposed design prior to the purchase of production process equipment.
ID:180
CLASS:2
Title: A computer center simulation project
Abstract: Today's computation centers are based on rapidly changing technologies of hardware and software systems. It is difficult, therefore, to base decisions on experience; in most instances, the benefits of comparable experience for a given problem situation are not available. In this paper, a mathematical model of the Lockheed Central Computer Center is formulated that describes the operation of a computation center in terms of information nets, decision processes, and control functions. Experiments performed with this model, the results of the experiments, and the application of the results are discussed.
ID:181
CLASS:2
Title: Functional distribution of the workload of a linked computer system and its simulation
Abstract: Consideration is given to a possible functional distribution of the workload over two linked computers with separate channel access to a large disc store, into the resource utilisation of the linked system achieved by simulation using a modified and re-entrant single processor simulator. Results suggest that the proposed distribution realises a high utilisation.
ID:182
CLASS:2
Title: A multinomial clustering model for fast simulation of computer architecture designs
Abstract: Computer architects utilize simulation tools to evaluate the merits of a new design feature. The time needed to adequately evaluate the tradeoffs associated with adding any new feature has become a critical issue. Recent work has found that by identifying execution phases present in common workloads used in simulation studies, we can apply clustering algorithms to significantly reduce the amount of time needed to complete the simulation. Our goal in this paper is to demonstrate the value of this approach when applied to the set of industry-standard benchmarks most commonly used in computer architecture studies. We also look to improve upon prior work by applying more appropriate clustering algorithms to identify phases, and to further reduce simulation time.We find that the phase clustering in computer architecture simulation has many similarities to text clustering. In prior work on clustering techniques to reduce simulation time, K-means clustering was used to identify representative program phases. In this paper we apply a mixture of multinomials to the clustering problem and show its advantages over using K-means on simulation data. We have implemented these two clustering algorithms and evaluate how well they can characterize program behavior. By adopting a mixture of multinomials model, we find that we can maintain simulation result fidelity, while greatly reducing overall simulation time. We report results for a range of applications taken from the SPEC2000 benchmark suite.
ID:183
CLASS:2
Title: Computer aided simulation for computer system studies
Abstract: This paper introduces a simulation system, CAPS, which interacts with an analyst via an on-line dialog and produces a simulation program that is logically consistent and executes on first submittal. CAPS is based upon the use of activity cycles for system decomposition. Activity cycles are discussed and the system demonstrated by the simulation of a computing system. The major advantages of CAPS are the speed with which models can be implemented and its ease of use which permits non-programmers to develop sophisticated models. For example, the demonstration model of an interactive computer system, from the start of the CAPS dialog to simulation output, was 23 minutes at a cost of &dollar;3.29.
ID:184
CLASS:2
Title: A computer simulation model for portfolio strategy formulation
Abstract: A working computer simulation model for formulating investment strategy for a portfolio of capital assets is presented. The use of modern capital market and portfolio theories in a flexible simulation network allows an investor to directly examine and compare the probable consequences of various static and dynamic investment and consumption policies and facilitates his decision-making process. Description of the model is illustrated by its application to the endowment portfolio of a university.
ID:185
CLASS:2
Title: Sizing and assessing computer design alternatives using simulation
Abstract: This paper describes the major phases of a computer system simulation study performed by the Federal Computer Performance Evaluation and Simulation Center for the Federal Aviation Administration. The Central Flow Control System, the system simulated, was in the preliminary design stage when the study was initiated. The study was undertaken to assess the performance of the proposed system, as well as the performance of system design alternatives. This study demonstrates the utility of using simulation during the early stages of a system's life cycle by providing designers insight into the system's performance and by identifying design alternatives that will improve performance. This paper contains descriptions of the system, the simulation process and objectives, the alternatives simulated, and the results and benefits derived through the use of simulation.
ID:186
CLASS:2
Title: Experiences and observations on teaching computer programming and simulation concepts to high school students
Abstract: This paper outlines the experience of the author in teaching computer programming and simulation concepts to thirty high school students as part of a National Science Foundation Summer Institute in probability and computing.2 It is hoped that the experience and observations reported in this paper might help others who might become involved in a similar course. There is certainly no doubt that students at this age level are capable of doing sophisticated work in computing. This program consisted only of high ability students; however, the author's experience with this program and another high school program with students with less ability indicates that students do not have to be of high ability in order to be attracted to and do well in computing. As is true of almost any area of study, what is particularly needed for success is motivation. Students with average or above average ability can do quite well in computing if they are motivated to do so.
ID:187
CLASS:2
Title: Simulation exercises for computer architecture education
Abstract: In a case studies approach to computer architecture education, there is a need for small-scale simulation exercises to illustrate significant concepts and to provide hands-on student experience with architectural tradeoffs. Two such exercises are discussed, and one is described in some detail. The exercises cover virtual memory and multiprogramming systems' architecture, and are suitable as projects students can do within a ten-week academic quarter. Some hindsight based on student reaction to these exercises is provided, together with estimated costs to the educator and students for exercise development and execution.
ID:188
CLASS:2
Title: Astrophysical N-body simulations on GRAPE-4 special-purpose computer
Abstract: We report on resent astrophysical N-body simulations performed on the GRAPE-4 (GRAvity PipE 4) system, a special-purpose computer for astrophysical N-body simulations. We first review the astrophysical motivation, the algorithm, the structure of the GRAPE system, and the actual performance. The GRAPE-4 system consists of 1692 pipeline processors. The peak speed of one pipeline processor is 523 Mflops and that of the total system is 884 Gflops. The performance obtained is 529 Gflops for the simulation of two massive black holes in the core of a galaxy with 700,000 stars.
ID:189
CLASS:2
Title: Planning of production and material flow systems by inter-interactive computer graphics simulation
Abstract: The INSIMAS (Interactive Simulation of Material Flow-Systems) simulation system is described. The systems-concept corresponds to the four planning steps design, analysis, simulation and evaluation. Each step is supported by interactive computer graphics procedures. The simulation run can be represented on a graphics screen by moving of objects (vehicles) through the simulated network. Main application areas of INSIMAS are automated material flow systems like AGVS and electric monorails. The modular architecture allows simple handling based on a network lay-out-plan, descriptions of systems load and dispatching and control strategies.
ID:190
CLASS:2
Title: Management of a large computer network simulation project
Abstract: As simulation technology matures, there is an increasing demand for the development of useful products within specified time and cost constraints. Hence, simulation studies must be managed and measured by the same criteria as other large projects. The project described in this paper, a behavioral study of a possible national computer network, requires the implementation of a large and complex simulation model. In order to manage better the many individuals and diverse groups contributing to the overall effort, many of the new advances in project management, software design, and programming technology have been adopted. The results of this effort tend to support the economies and efficiencies in programming, as well as improvements in reliability, usually claimed by advocates of these techniques. More significantly, these approaches make it possible to keep all participants active in overall project progress. They have also permitted a work segmentation that takes advantage of the variety of personnel available to the project.
ID:191
CLASS:2
Title: Computer system simulation with ASPOL
Abstract: ASPOL (A Simulation Process - Oriented Language) is a simulation language developed specifically for computer system simulation. Its process control and synchronization facilities derive from, and function similiarly to, those developed in the designs of computer operating systems. Consequently, ASPOL provides a natural vehicle for simulating such systems. Other important features of ASPOL include facilities for defining and operating on sets of entities, thus simplifying the modeling of parallel systems (multiprocessors, multiple disk drives, etc.), and macro facilities, which provide language extensibility. This paper describes the ASPOL simulation constructs&mdash;processes, events, facilities, and storages&mdash;and then illustrates their use in a simple model of a time-sharing system with a paged memory. The ASPOL macro facilities then are described in brief, and a simple example of how they may be used to construct a higher-level computer simulation language is given.
ID:192
CLASS:2
Title: A computer simulation model of driver-vehicle performance at intersections
Abstract: Problems of safety and efficiency in present day highway traffic systems are receiving considerable attention. Much of this attention is being focused upon the driving task. Driving an automobile encompasses extremely complex patterns of behavior involving sensory, perceptual, decision making and response processes. Current knowledge of the effects of the variables influencing this behavior, and of their interactions, is quite limited. For many aspects of the driving task the relevant variables have not even been identified. These considerations suggest at least two approaches to the study of the driving task. First, an analytical approach is required to help identify the variables involved in automobile driving. Second, experimental studies are needed to determine the effects of specific combinations of these variables.
ID:193
CLASS:2
Title: Computer simulation as a method for selecting nurse staffing levels in hospitals
Abstract: Efficient utilization of staff resources is perhaps the most critical issue facing nursing department administrators today, and has been a matter of concern to nursing service administrators since at least the early 1940's. This study used computer simulation to examine the effect on wage costs and staffing adequacy of varying nurse staffing levels. Three Psychiatric care units in a large VA hospital served as models for the simulation study. The staffing patterns tested were 40%, 50%, 60%, and 80% of maximum workload. Due to a quirk in rounding, the 40% and 50% staffing levels were exactly the same for these nursing units. The 80% staffing level produced direct wage costs 8% higher than the 50% level and 6.7% higher than the 60% level. It also produced 11.6% overstaffing as compared with 1.7% for the 60% staffing level and .2% for the 50% level. The 50% staffing level produced .9% understaffing as compared with .4% for the 60% level and .3% for the 80% level. It was concluded that both the 50% and 60% staffing levels performance was acceptable. Graphical representation of the data demonstrated that the optimal staffing level fell at approximately the 55% staffing level.
ID:194
CLASS:2
Title: The use of computer simulation to develop hospital systems
Abstract: The use of computer simulation in the development of hospital systems, which has a major effect on the cost and quality of operation, is presented. Discussion of results achieved in specific areas include: inpatient admissions scheduling and control systems, surgical scheduling systems, maximum average occupancy prediction models, and patient classification systems for predicting the size of nursing staffs. The paper concludes with a discussion of the general problems encountered with computer simulation.
ID:195
CLASS:2
Title: Interactive instruction simulation on and of the Datapoint 2200 computer
Abstract: An interactive simulation of the execution of mnemonically entered instructions for the Datapoint 2200 Computer has been developed which runs on this same machine. A representation of the registers, flip-flops, program counter, subroutine stack, and referenced memory cell is show on the display of the machine. Individual mnemonic instructions may be entered from the keyboard and are shown on the display in standard assembly source language except that instructions may not be labelled. Both the instructions and their operands are syntactically checked character-by-character as they are entered and all illegal entries are refused. The simulator displays the corresponding octal form of these instructions and modifies the representation of the state of the machine accordingly. Short programs of such instructions may be entered and normal sequential execution simulated, Experience indicates that such simulators can provide an easy means of learning the computer organization, mnemonic instructions, and program execution of a computer. They can be especially helpful in demonstrating the dynamics of recursive subroutine calls and push-down stacks.
ID:196
CLASS:2
Title: Graphical programming for simulation of computer systems
Abstract: This paper describes a graphically based programming system for simulation models of systems representable as generalized queueing network models. The model and program development system substantially enhances the capabilities of automating the development process of current graphically-oriented systems. The enhancement includes representations of virtual devices in the model formulation process and use of graphically specified programs as the user visible representation of an executable simulation model.
ID:197
CLASS:2
Title: The discrete event simulation computer - DESC
Abstract: Simulation of large models on digital computers is often limited by the high computational expenses. The Discrete Event Simulation Computer (DESC) reported here improves simulation performance through an exploitation of parallelism inherent in simulation, with regard to list processing, random number generation, statistical analysis and program control. The DESC consists of a set of nodes that communicate via FIFO-buffered channels (i.e. do not share memory among nodes). In order to achieve high system throughput dedicated hardware modules were developed; this includes new concepts for a list processor and a hardware random number generator for uniform deviates.The implementation of simulation languages such as SIMULA, SIMSCRIPT or GPSS is conceptually straightforward. We chose SIMULA as the frame language concept. Metrics applicable to simulation throughput and simulation costs are defined and compared with the CD CYBER 175.
ID:198
CLASS:2
Title: Computer simulation of road surface profiles for a four-wheeled vehicle
Abstract: A computer method for simulating road surface profiles is described. 'The technique involves the generation and subsequent modification of pseudorandom binary sequences. The statistical properties of the profiles are similar to those of typical road surfaces. The profiles are particularly suitable for use in computer simulations of four-wheeled vehicles.
ID:199
CLASS:3
Title: Directed stigmergy-based control for multi-robot systems
Abstract: Multi-robot systems are particularly useful in tasks that require searching large areas such as planetary science exploration, urban search and rescue, or landmine remediation. In order to overcome the inherent complexity of controlling multiple robots, the user must be able to give high-level, goal driven direction to the robot team. Since human robot interaction is a relatively new discipline, it is helpful to look to existing systems for concepts, analogies, or metaphors that might be utilized in building useful systems. Inspiration from natural decentralized systems guides the development of a computer simulation for stigmergy-based control of multi-robot system, and the interface with which an operator can interact and control mobile robots. In-depth description of the design process includes a description of a basic stigmergy-based control system and an innovative Directed Stigmergy control system that facilitates operator control of the robot team in an interesting and surprisingly effective way.
ID:200
CLASS:3
Title: Evaluation of an adaptive traffic control technique with underlying system changes
Abstract: A key problem in traffic engineering is the optimization of the flow of vehicles through a given road network. Improving the timing of the traffic signals at intersections in the network is generally the most powerful and cost-effective means of achieving this goal. Recent efforts have resulted in the development of a fundamentally different approach for optimal centralized signal timing control that eliminates the need for an open-loop model of the traffic network dynamics. The approach is based on a neural network (NN) serving as the basis for the control law, with the internal NN weight estimation occurring real-time in closed-loop mode via the simultaneous perturbation stochastic approximation (SPSA) algorithm. The paper investigates the application of such a non-network-model-based approach and illustrates the approach through a simulation on a nine-intersection, mid-Manhattan, New York network. The simulated traffic network contains varying short and long-term congestion behavior and short-term stochastic, nonlinear effects. The approach results in a net 10% reduction in vehicle wait time relative to the performance of the existing, in-place strategy.
ID:201
CLASS:3
Title: A static type system for JVM access control
Abstract: This article presents a static type system for the Java virtual machine (JVM) code that enforces an access control mechanism similar to that found in a Java implementation. In addition to verifying type consistency of a given JVM code, the type system statically verifies whether the code accesses only those resources that are granted by the prescribed access policy. The type system is proved to be sound with respect to an operational semantics that enforces access control dynamically, similar to Java stack inspection. This result ensures that &ldquo;well-typed code cannot violate access policy.&rdquo; The authors then develop a type inference algorithm and show that it is sound with respect to the type system. These results allow us to develop a static system for JVM access control, without resorting to costly runtime stack inspection.
ID:202
CLASS:3
Title: A distributed, operating system based, blackboard architecture for real-time control
Abstract: The design and implementation of a Distributed, Operating System based, Blackboard Architecture for Real-Time control (DOSBART) is described. DOSBART demonstrates the outstanding applicability of AI languages and blackboard techniques to the construction of versatile distributed real-time control frameworks. It provides a means to remotely and transparently execute operations on non-local objects, furnishing the ability to share data and blackboard structures transparently across a network of heterogeneous computers. It allows the simultaneous execution of all blackboard activities by utilizing the underlying operating system's multi-process functionality rather than its own scheduling mechanism. Architectural features are incorporated to deal with distributed real-time control issues such as interrupts, data dependencies, resource contention, activity control and I/O. Computation may occur in both process based and message based perspectives, and may be driven by a first order theorem prover that dynamically infers triggering events, by changes in demoned datums or by arbitrary predicates. The representational capabilities of the Common Lisp Object System (CLOS) were exploited to provide a rich set of base classes from which specific applications can be tailored. Lisp macro facilities support for multiple platforms.
ID:203
CLASS:3
Title: First experiences using XACML for access control in distributed systems
Abstract: Authorization systems today are increasingly complex. They span domains of administration, rely on many different authentication sources, and manage permissions that can be as complex as the system itself. Worse still, while there are many standards that define authentication mechanisms, the standards that address authorization are less well defined and tend to work only within homogeneous systems. This paper presents XACML, a standard access control language, as one component of a distributed and inter-operable authorization framework. Several emerging systems which incorporate XACML are discussed. These discussions illustrate how authorization can be deployed in distributed, decentralized systems. Finally, some new and future topics are presented to show where this work is heading and how it will help connect the general components of an authorization system.
ID:204
CLASS:3
Title: Overload management in sensor-actuator networks used for spatially-distributed control systems
Abstract: Overload management policies avoid network congestion by actively dropping packets. This paper studies the effect that such data dropouts have on the performance of spatially distributed control systems. We formally relate the spatially-distributed system's performance (as measured by the average output signal power) to the data dropout rate. This relationship is used to pose an optimization problem whose solution is a Markov chain characterizing a dropout process that maximizes control system performance subject to a specified lower bound on the dropout rate. We then use this Markov chain to formulate an overload management policy that enables nodes to enforce the "optimal" dropout process identified in our optimization problem. Simulation experiments are used to verify the paper's claims.
ID:205
CLASS:3
Title: Emulation as a design tool in the development of real-time control systems
Abstract: A major facility for manufacturing research is being established at the National Bureau of Standards. The Automated Manufacturing Research Facility (AMRF) will provide testbed where measurement research of computer integrated manufacturing systems can be performed. The control architecture of the facility is based on a sensory-interactive, modular, hierarchical, feedback system. Each module is represented as a finite state machine that interacts through a shared time-sliced common-memory where command, feedback and database information is stored. A hierarchical control system emulator (HCSE) has been developed that allows the system to be designed and tested before implementation on the actual hardware. The HCSE has been successfully used in the AMRF project as a design management tool, providing a complete specification of the control software. It is also used as a testing aid that allows a given module (i.e., a robot control system) to interact with emulated control modules substituting for unavailable AMRF hardware.
ID:206
CLASS:3
Title: Digital control simulation system
Abstract: Today there is widespread application of digital control circuitry in a wide range of products. This paper describes a simulation system in which the designer of these control circuits can interact with his design ideas before they are implemented in hardware. The Digitial Control Simulation System (DCSS) is a digital design description language with a set of programs to generate and execute a simulation program. The main use of this system (with an appropriate hardware interface) is the testing of, and possibly on-line simulation of, the control of a system being designed and constructed.
ID:207
CLASS:3
Title: Automating the design of microprocessor-based real time control systems
Abstract: Many facets of Computer Science and associated technologies may be profitably viewed as dedicated real time control activities. Production of systems to exercise such control has been difficult and costly. An abstract model of the process of producing these systems is presented. The model indicates three areas of the design problem amenable to automation: l) the selection and configuration of hardware; 2) the production of software, and 3) the selection of a monitor to maintain real time integrity of the entire system. The concept of hardware binding is introduced and it is shown that delaying the point in the design cycle where hardware is functionally bound allows a new approach to machine independence. Techniques which allow expression of repetitive control situations are described, as are methods for automatically selecting a time-wise correct monitor. A language bringing together these concepts is outlined and a system to automate the production of real time control systems is briefly described. The system is intended to produce a hardware configuration listing and software which together form a complete dedicated real time controller.
ID:208
CLASS:3
Title: On the use of GPSS to model hierarchical control systems in a manufacturing environment
Abstract: The concept of hierarchical, multilevel control systems is reviewed in the context of manufacturing systems, and the strata typically composing such control systems are discussed. The possibility of building simulation models of hierarchical systems, using FORTRAN routines to represent the higher-level strata, and GPSS to model the actual manufacturing steps themselves, is introduced. A hypothetical, nine-product toy-manufacturing system is described, and some of the specific features of a GPSS-FORTRAN package which successfully models this system in accord with hierarchical control principles are indicated. The relative ease of constructing the GPSS-FORTRAN model suggests that there may be substantial potential in this approach for assessing the properties of specific proposed hierarchical control systems. Such models can be used initially to investigate the relative goodness of various control algorithms which are candidates for use in these systems; then, after selection of a specific control algorithm or combination of algorithms, the models can be used further to test and evaluate the control software and data bases created to support the operation of such systems.
ID:209
CLASS:3
Title: Applications of digital processors to energy monitoring and control systems
Abstract: The crisis in cost and availability of energy has led to the development of digital monitoring and control systems which manage and reduce energy consumption in a wide range of facilities. Large energy management systems incorporate distributed processing architectures and a wide range of manual and automatic functions. Design and implementation of such systems poses serious problems of function and algorithm definition, data communications, and optimization of physically dispersed processor networks. This paper describes the application of a structured design methodology which addresses the problem of interdisciplinary communication in energy management system realization and greatly simplifies the development of the wide range of software required. Also considered are questions of proper data communication design for the unique environment encountered in such situations and optimum implementation of the distributed processing architecture for the functional priorities of the energy conservation application.
ID:210
CLASS:3
Title: Modeling and control of robotic mine haulage system
Abstract: Concepts borrowed from discrete and hybrid system simulation have been successfully applied in the design of a complex, distributed computer control system. The example presented is a rail haulage system for a horizontally cut coal mine. The system controls all train movements and haulage operations into and out of the mine. The control logic is embedded in the system software, distributed over three levels: 1. Central control (resident in a minicomputer) 2. Wayside control (five microcomputers in distinct mine sections) 3. Locomotive control (one microcomputer in each locomotive) The paper focuses on the wayside control. To accomplish the control objectives, the wayside software compares actual operation with the operation of a flexible reference model. That model gives the wayside control the ability to function like an intelligent robotic system.
ID:211
CLASS:3
Title: Cryptographic access control in a distributed file system
Abstract: Traditional access control mechanisms rely on a reference monitor to mediate access to protected resources. Reference monitors are inherently centralized and existing attempts to distribute the functionality of the reference monitor suffer from problems of scalability.Cryptographic access control is a new distributed access control paradigm designed for a global federation of information systems. It defines an implicit access control mechanism, which relies exclusively on cryptography to provide confidentiality and integrity of data managed by the system. It is particularly designed to operate in untrusted environments where the lack of global knowledge and control are defining characteristics.The proposed mechanism has been implemented in a distributed file system, which is presented in this paper along with a preliminary evaluation of the proposed mechanism.
ID:212
CLASS:3
Title: A utility-based power-control scheme in wireless cellular systems
Abstract: Distributed power-control algorithms for systems with hard signal-to-interference ratio (SIR) constraints may diverge when infeasibility arises. In this paper, we present a power-control framework called utility-based power control (UBPC) by reformulating the problem using a softened SIR requirement (utility) and adding a penalty on power consumption (cost). Under this framework, the goal is to maximize the net utility, defined as utility minus cost. Although UBPC is still noncooperative and distributed in nature, some degree of cooperation emerges: a user will automatically decrease its target SIR (and may even turn off transmission) when it senses that traffic congestion is building up. This framework enables us to improve system convergence and to satisfy heterogeneous service requirements (such as delay and bit error rate) for integrated networks with both voice users and data users. Fairness, adaptiveness, and a high degree of flexibility can be achieved by properly tuning parameters in UBPC.
ID:213
CLASS:3
Title: A knowledge-based water purification plant control system
Abstract: A knowledge-based control system has been developed and applied to a water purification plant. The objective of the system is to realize an intelligent supervisory control system that is based on the accumulated knowledge of experts. This control system employs a production system as an expert system. &ldquo;Knowledge&rdquo; required for operating the plant is represented by IF-THEN rules. In order for such an expert system to operate in real time, an on-line interface and environment are required.This paper describes the configuration of the knowledge-based water purification plant control system and results of numerical simulation and on-line operation.
ID:214
CLASS:3
Title: FlySPEC: a multi-user video camera system with hybrid human and automatic control
Abstract: FlySPEC is a video camera system designed for real-time remote operation. A hybrid design combines the high resolution of an optomechanical video camera with the wide field of view always available from a panoramic camera. The control system integrates requests from multiple users so that each controls a virtual camera. The control system seamlessly integrates manual and fully automatic control. It supports a range of options from untended automatic to full manual control. The system can also learn control strategies from user requests. Additionally, the panoramic view is always available for an intuitive interface, and objects are never out of view regardless of the zoom factor. We present the system architecture, an information-theoretic approach to combining panoramic and zoomed images to optimally satisfy user requests, and experimental results that show the FlySPEC system significantly assists users in a remote inspection tasks.
ID:215
CLASS:3
Title: Ensuring code safety without runtime checks for real-time control systems
Abstract: This paper considers the problem of providing safe programming support and enabling secure online software upgrades for control software in real-time control systems. In such systems, offline techniques for ensuring code safety are greatly preferable to online techniques. We propose a language called Control-C that is essentially a subset of C, but with key restrictions designed to ensure that memory safety of code can be verified entirely by static checking, under certain system assumptions. The language permits pointer-based data structures, restricted dynamic memory allocation, and restricted array operations, without requiring any runtime checks on memory operations and without garbage collection. The language restrictions have been chosen based on an understanding of both compiler technology and the needs of real-time control systems. The paper describes the language design and a compiler implementation for Control-C. We use control codes from three different experimental control systems to evaluate the suitability of the language for these codes, the effort required to port them to Control-C, and the effectiveness of the compiler in detecting a wide range of potential security violations for one of the systems.
ID:216
CLASS:3
Title: Software control systems for parallel simulation
Abstract: Parallel simulations using optimistic synchronization strategies such as Time Warp, operate with no regard to global synchronization since this results in greater parallelism and lower synchronization cost. However, like virtual memory, the parallel simulators may end up thrashing instead of performing useful work. The complication in using a Time Warp simulator is then to configure it suitably for good performance and avoid thrashing. Unfortunately, the optimal configuration is not generally static among different applications or even throughout an entire run of a single application. Thus, online feedback control systems are deployed to govern the adjustment of input parameters in our Time Warp simulation kernel. The design and implementation of effective feedback control systems can be difficult; the extra processing is pure overhead that must be absorbed by any performance gains delivered. The problem is further complicated when attempting to build a simulation kernel that is designed efficiently to operate with many different applications. In this paper, we introduce a control-centric architecture that is used to monitor and manage different parts of a Time Warp simulator. Specifically, we extend concepts from control theory such as adaptive control and stability, to better understand and design hierarchically-distributed run-time control systems for Time Warp based parallel simulation.
ID:217
CLASS:3
Title: ProCEED: an expert system for multivariate process control systems design
Abstract: Design and implementation of effective control systems is vital to the competitiveness of the process industry. Process control system design requires knowledge based systems which are capable of efficient numeric computing along with the symbolic reasoning. A brief survey presented in this paper shows that many industrial and academic research groups, are actively developing such knowledge based tools, in the U.S. and other countries.ProCEED, the expert system described in this paper has been developed on Digital's A.I. work-station and using Intellicorp's Knowledge Engineering Environment (KEE). This ideally combines the KEE and LISP based reasoning and Fortran based number crunching. The modular structure and the user interface permit easier integration of additional knowledge about existing systems, as well as incorporation of completely new controllers and processes.A controller design session begins with process modeling. Then the extent of interaction in the multivariable process is determined using a variety of techniques, including relative gain analysis and singular value decomposition, and conflicts among them are resolved. Based on the apparent interaction and controller implementation resources available to the user, multi-loop or completely multivariable forms of one or more control strategies, including proportional-integra-derivative mode control and simplified model predictive control, are chosen. The control systems are designed to achieve the specified performance criteria, utilizing the available numeric software in Fortran. The expert system presents the user with the design results and the simulation of the controlled system, in a graphical form.
ID:218
CLASS:3
Title: A simulation test-bed to evaluate multi-agent control of manufacturing systems
Abstract: Current research in the area of manufacturing planning and control has moved away from traditional centralized solutions towards distributed architectures that range from hierarchical to heterarchical. Between these two extremes of the control architecture spectrum lies the holonic manufacturing systems paradigm, where partial dynamic hierarchies of agents cooperate to meet global system objectives in the face of disturbances. This paper describes a simulation test bed for the evaluation of a distributed multi-agent control architecture for holonic manufacturing systems that integrates discrete-event simulation software into its design to allow the control architecture to be evaluated with a variety of emulated manufacturing systems.
ID:219
CLASS:3
Title: A fine-grained access control system for XML documents
Abstract: Web-based applications greatly increase information availability and ease of access, which is optimal for public information. The distribution and sharing of information via the Web that must be accessed in a selective way, such as electronic commerce transactions, require the definition and enforcement of security controls, ensuring that information will be accessible only to authorized entities. Different approaches have been proposed that address the problem of protecting information in a Web system. However, these approaches typically operate at the file-system level, independently of the data that have to be protected from unauthorized accesses. Part of this problem is due to the limitations of HTML, historically used to design Web documents. The extensible markup language (XML), a markup language promoted by the World Wide Web Consortium (W3C), is de facto the standard language for the exchange of information on the Internet and represents an important opportunity to provide fine-grained access control. We present an access control model to protect information distributed on the Web that, by exploiting XML's own capabilities, allows the definition and enforcement of access restrictions directly on the structure and content of the documents. We present a language for the specification of access restrictions, which uses standard notations and concepts, together with a description of a system architecture for access control enforcement based on existing technology. The result is a flexible and powerful security system offering a simple integration with current solutions.
ID:220
CLASS:3
Title: Enterprise resource planning (ERP) systems as a technology of power: empowerment or panoptic control?
Abstract: This paper explores ERP as an ambivalent technology of power. On the one hand, it may tighten management control by bringing a new level of panoptic visibility to organizational activities; on the other hand, the embedded business model within the ERP may drive empowerment of employees and greater control relaxation through the configuration of new process design. How will the implementation of an ERP system affect organizational control? Our This research seeks to understand how the different forces play out in the context of ERP implementation, and to explore the implications for traditional power distribution in organizations.This paper adopts a mixed qualitative-quantitative methodology in an intensive case study of a restructured hospital in Singapore. A survey of 260 users was administered, supplemented by approximately 27 hours of individual interviews with 23 people. Results reveal that although ERP as a technology can facilitate both empowerment and panoptic control, management has consciously resisted empowerment by working to re-institute the "loss of power" driven by power lost through the ERP implementation. On the other hand, the new panoptic visibility, though partially unintended, appears to have evolved naturally and was readily learnted and applied in the organization. This study is significant in exposing the likelihood of ERP implementation as a technology to that perpetuates management power. At least in the context of the hospital studied, it is yet another means of enlarging the management authority for "total control."
ID:221
CLASS:3
Title: The role-based access control system of a European bank: a case study and discussion
Abstract: Research in the area of role-based access control has made fast progress over the last few years. However, little has been done to identify and describe existing role-based access control systems within large organisations. This paper describes the access control system of a major European Bank. An overview of the systems structure, its administration and existing control principles constraining the administration is given. In addition, we provide an answer to a key question - the ratio of the number of roles to the system user population - which was raised in the recent RBAC2000 Workshop. Having described certain weaknesses of the Banks system, the case study is extended to a comparison between the system and the RBAC96 models. In particular the issues of inheritance and grouping are addressed.
ID:222
CLASS:3
Title: Human-Computer Interaction in the Control of Dynamic Systems
Abstract: Modes of human-computer interaction in the control of dynamicsystems are discussed, and the problem of allocating tasks betweenhuman and computer considered. Models of human performance in avariety of tasks associated with the control of dynamic systems arereviewed. These models are evaluated in the context of a designexample involving human-computer interaction in aircraftoperations. Other examples include power plants, chemical plants,and ships.
ID:223
CLASS:3
Title: Specification and dialogue control of visual interaction through visual rewriting systems
Abstract: Computers are increasingly being seen not only as computing tools but more so as communication tools, thus placing special emphasis on human-computer interaction (HCI). In this article, the focus is on visual HCI, where the messages exchanged between human and computer are images appearing on the computer screen, as usual in current popular user interfaces. We formalize interactive sessions of a human-computer dialogue as a structured set of legal visual sentences, i.e., as a visual language, and show how rewriting systems can be generalized to specify both the pictorial and the computational aspects of visual languages. To this end, Visual Conditional Attributed Rewriting (VCARW) systems are introduced, and use for specification of visual languages. These specifications are given as inputs to a procedure illustrated in the article as a system of algorithms, which automatically generates control mechanisms of the interaction, thus favoring the design of more reliable and usable systems.
ID:224
CLASS:3
Title: Designing specification languages for process control systems: lessons learned and steps to the future
Abstract: Previously, we defined a blackbox formal system modeling language called RSML (Requirements State Machine Language). The language was developed over several years while specifying the system requirements for a collision avoidance system for commercial passenger aircraft. During the language development, we received continual feedback and evaluation by FAA employees and industry representatives, which helped us to produce a specification language that is easily learned and used by application experts.Since the completion of the RSML project, we have continued our research on specification languages. This research is part of a larger effort to investigate the more general problem of providing tools to assist in developing embedded systems. Our latest experimental toolset is called SpecTRM (Specification Tools and Requirements Methodology), and the formal specification language is SpecTRM-RL (SpecTRM Requirements Language).This paper describes what we have learned from our use of RSML and how those lessons were applied to the design of SpecTRM-RL. We discuss our goals for SpecTRM-RL and the design features that support each of these goals.
ID:225
CLASS:3
Title: Control system development tools
Abstract: This paper provides a core of APL algorithms for control system development and demonstrates their use by solving a typical control problem. In doing so it outlines useful numerical techniques for simulating dynamic systems and for solving some of the central equations of control theory.Although some sections of the paper are addressed to APL2 users, the majority of the paper applies to APL. Moreover, by doing a little extra work to handle complex numbers and by installing a &ldquo;callable&rdquo; compiled eigenvalue-eigenvector routine, all of the material presented can be adapted to any APL system.While APL is a comfortable environment for control system development, APL2 contains two especially useful enhancements: 1) complex numbers included in a natural way, and 2) the function EIGEN.APL2's facility with complex numbers permits the direct and clear coding of frequency domain methods such as root locus, bode plots, and the generation of transfer functions. APL2's facility with complex numbers also makes it possible to include a native eigenvalue-eigenvector utility function, EIGEN. This function generates the eigenvalues and eigenvectors of general square matrices, which can then be used for root locus studies, for transforming system equations to canonical forms, and for efficiently solving the Riccati and Lyapunov equations.Non-EIGEN-based functions are also provided so that all APL users will find enough tools to model, simulate, analyze, and develop regulators, observers, and filters for linear dynamic systems.
ID:226
CLASS:3
Title: A control and management network for wireless ATM systems
Abstract: This paper describes the design of a control and management network (orderwire) for a mobile wireless Asynchronous Transfer Mode (ATM) network. This mobile wireless ATM network is part of the Rapidly Deployable Radio Network (RDRN). The orderwire system consists of a packet radio network which overlays the mobile wireless ATM network. Each network element in this network uses Global Positioning System (GPS) information to control a beamforming antenna subsystem which provides for spatial reuse. This paper also proposes a novel Virtual Network Configuration (VNC) algorithm for predictive network configuration. A mobile ATM Private Network--Network Interface (PNNI) based on VNC is also discussed. Finally, as a prelude to the system implementation, results of a Maisie simulation of the orderwire system are discussed.
ID:227
CLASS:3
Title: High-performance operating system primitives for robotics and real-time control systems
Abstract: To increase speed and reliability of operation, multiple computers are replacing uniprocessors and wired-logic controllers in modern robots and industrial control systems. However, performance increases are not attained by such hardware alone. The operating software controlling the robots or control systems must exploit the possible parallelism of various control tasks in order to perform the necessary computations within given real-time and reliability constraints. Such software consists of both control programs written by application programmers and operating system software offering means of task scheduling, intertask communication, and device control.The Generalized Executive for real-time Multiprocessor applications (GEM) is an operating system that addresses several requirements of operating software. First, when using GEM, programmers can select one of two different types of tasks differing in size, called processes and microprocesses. Second, the scheduling calls offered by GEM permit the implementation of several models of task interaction. Third, GEM supports multiple models of communication with a parameterized communication mechanism. Fourth, GEM is closely coupled to prototype real-time programming environments that provide programming support for the models of computation offered by the operating system. GEM is being used on a multiprocessor with robotics application software of substantial size and complexity.
ID:228
CLASS:3
Title: AVCS: the APL version control system
Abstract: This paper described AVCS, which is an APL-oriented version control system devised as a tool to track the history of software projects and to control concurrent access to project components. The basics of version control systems are explained, and specific aspects of applying a version control system methodology to project development in APL environments are considered. Particular attention is given to features which differentiate the approach accepted in AVCS from that of available version control and project management systems. Specification of AVCS's data maintenance, programming and user interface is presented to the extent required in order to explain how the system works. In conclusion, the possible application of AVCS to solving problems of porting APL projects across different  environments is outlined.
ID:229
CLASS:3
Title: Separating data and control transfer in distributed operating systems
Abstract: Advances in processor architecture and technology have resulted in workstations in the 100+ MIPS range. As well, newer local-area networks such as ATM promise a ten- to hundred-fold increase in throughput, much reduced latency, greater scalability, and greatly increased reliability, when compared to current LANs such as Ethernet.We believe that these new network and processor technologies will permit tighter coupling of distributed systems at the hardware level, and that distributed systems software should be designed to benefit from that tighter coupling. In this paper, we propose an alternative way of structuring distributed systems that takes advantage of a communication model based on remote network access (reads and writes) to protected memory segments.A key feature of the new structure, directly supported by the communication model, is the separation of data transfer and control transfer. This is in contrast to the structure of traditional distributed systems, which are typically organized using message passing or remote procedure call (RPC). In RPC-style systems, data and control are inextricably linked&mdash;all RPCs must transfer both data and control, even if the control transfer is unnecessary.We have implemented our model on DECstation hardware connected by an ATM network. We demonstrate how separating data transfer and control transfer can eliminate unnecessary control transfers and facilitate tighter coupling of the client and server. This has the potential to increase performance and reduce server load, which supports scaling in the face of an increasing number of clients. For example, for a small set of file server operations, our analysis shows a 50% decrease in server load when we switched from a communications mechanism requiring both control transfer and data transfer, to an alternative structure based on pure data transfer.
ID:230
CLASS:3
Title: Real time groupware as a distributed system: concurrency control and its effect on the interface
Abstract: This paper exposes the concurrency control problem in groupware when it is implemented as a distributed system. Traditional concurrency control methods cannot be applied directly to groupware because system interactions include people as well as computers. Methods, such as locking, serialization, and their degree of optimism, are shown to have quite different impacts on the interface and how operations are displayed and perceived by group members. The paper considers both human and technical considerations that designers should ponder before choosing a particular concurrency control method. It also reviews our work-in-progress designing and implementing a library of concurrency schemes in GROUPKIT, a groupware toolkit.
ID:231
CLASS:3
Title: Formal aspects of concurrency control in long-duration transaction systems using the NT/PV model
Abstract: In the typical database system, an execution is correct if it is equivalent to some serial execution. This criterion, called serializability, is unacceptable for new database applications which require long-duration transactions. We present a new transaction model which allows correctness criteria more suitable for these applications. This model combines three enhancements to the standard model: nested transactions, explicit predicates, and multiple versions. These features yield the name of the new model, nested transactions with predicates and versions, or NT/PV.The modular nature of the NT/PV model allows a straightforward representation of simple systems. It also provides a formal framework for describing complex interactions. The most complex interactions the model allows can be captured by a protocol which exploits all of the semantics available to the NT/PV model. An example of these interactions is shown in a CASE application. The example shows how a system based on the NT/PV model is superior to both standard database techniques and unrestricted systems in both correctness and performance.
ID:232
CLASS:3
Title: Empirical performance evaluation of concurrency and coherency control protocols for database sharing systems
Abstract: Database Sharing (DB-sharing) refers to a general approach for building a distributed high performance transaction system. The nodes of a DB-sharing system are locally coupled via a high-speed interconnect and share a common database at the disk level. This is also known as a &ldquo;shared disk&rdquo; approach. We compare database sharing with the database partitioning (shared nothing) approach and discuss the functional DBMS components that require new and coordinated solutions for DB-sharing. The performance of DB-sharing systems critically depends on the protocols used for concurrency and coherency control. The frequency of communication required for these functions has to be kept as low as possible in order to achieve high transation rates and short response times. A trace-driven simulation system for DB-sharing complexes has been developed that allows a realistic performance comparison of four different concurrency and coherency control protocols. We consider two locking and two optimistic schemes which operate either under central or distributed control. For coherency control, we investigate so-called on-request and broadcast invalidation schemes, and employ buffer-to-buffer communication to exchange modified pages directly between different nodes. The performance impact of random routing versus affinity-based load distribution and different communication costs is also examined. In addition, we analyze potential performance bottlenecks created by hot spot pages.
ID:233
CLASS:3
Title: An abstract model of rollback recovery control in distributed systems
Abstract: This paper develops an abstract model which presents a method of uniform description of different rollback recovery control algorithms for distributed systems. We first developed a general definition of the distributed rollback recovery control problem. The concept of a distributed recovery control system (DRC system), consisting of distributed recovery control units (DRC units), is proposed to model recovery with various control granularities. Then, we developed a graph model, called dependency graph, for distributed rollback recovery control algorithms. An atomic subgraph is defined as a subgraph induced by a set of nodes which has no outgoing arcs to other nodes in the graph. Committing and aborting atomic actions can be modeled as identifying atomic subgraphs. Next, we defined two kinds of dependency graphs: checkpoint graphs and unit graphs, based on the dependency relation defined by rollback propagation. We have shown that various types of distributed recovery control algorithms can be classified based on the identifications of atomic subgraphs in these two graphs. Therefore, using the model may allow us to describe existing algorithms in a uniform way and, more importantly, to find new algorithms.
ID:234
CLASS:3
Title: Control of large scale computing systems
Abstract: The rapidly increasing scale of computing systems means that it is vitally important to address the scaling challenges in the control of computing systems. We introduce a framework for describing the control problems for large scale computing systems that expand along two dimensions: the scale of the target system and the scale of the policy. Using this framework, we present control architectures that span a range from centralized schemes to distributed solutions. We further identify several research challenges related to issues such as target systems latencies and policy decomposition.
ID:235
CLASS:3
Title: TrustBAC: integrating trust relationships into the RBAC model for access control in open systems
Abstract: Conventional access control are suitable for regulating access to resources by known users.However,these models have often found to be inadequate for open and decentralized multi-centric systems where the user population is dynamic and the identity of all users are not known in advance.For such systems, credential based access control has been proposed. Credential based systems achieve access control by implementing a binary notion of trust.If a user is trusted by virtue of successful evaluation of its credentials it is allowed access, otherwise not. However,such credential based models have also been found to be lacking because of certain inherent drawbacks with the notion of credentials.In this work,we propose a trust based access control model called TrustBAC. It extends the conventional role based access control model with the notion of trust levels.Users are assigned to trust levels instead of roles based on a number of factors like user credentials,user behavior history,user recommendation etc. Trust levels are assigned to roles which are assigned to permissions as in role based access control.The TrustBAC model thus incorporates the advantages of both the role based access control model and credential based access control models.
ID:236
CLASS:3
Title: On classifying access control implementations for distributed systems
Abstract: This paper presents a classification of implementations of access control systems based on a lattice taxonomy where the axes are properties of the implementation. The current taxonomy has six axes representing:partitioning of control over sharing of access control credentials, distribution of the state relevant to access control decisions,.delity of policy enforcement, the identity resolution mechanism, local versus centralized decisions,and static or adaptive trust management.Analysis of implemented systems in terms of these properties sheds insight on tradeo .s between performance, scalability and potential vulnerability to specified attacks. The taxonomy reveals that distributed systems for several points on the lattice with interesting access control characteristics have not yet been implemented. The relationship of this classification to conventional classifications by type (for instance,role-based access control or mandatory access control) and mechanism (for instance,access control list or capabilities)is briefly discussed. Several implementations of access control are classi .ed by their values for these properties.The roles of access control in formulation and operation of distributed systems are discussed.
ID:237
CLASS:3
Title: Microprocessor systems and architectures for applications to the control and protection of electric power systems
Abstract: Some design concepts for microprocessor applications to the control and protection of electric power systems are presented. A formal design methodology is outlined. Present microprocessor applications to the control and protection of the electric power generation, transmission and distribution systems are summarized. These applications are generalized to provide a basis for identifying a set of "standardized application modules." A projection is made of probable future developments in microprocessor applications to the electric power industry. A probable development is believed to be the use of hierarchically structured networks of microprocessors to provide, through distributed processing, more cost-effective and reliable control and protection than is possible through centralized processing.
ID:238
CLASS:3
Title: Computer control systems in organizations
Abstract: The purpose of this paper is to present an overview of control systems in organizations, with the emphasis on computer control systems. Specifically, the paper will present a model of organizational control systems, discuss the responsibility for internal control systems, present a model of computer security and control points, and categorize the security and control points by specific internal control objectives.
ID:239
CLASS:3
Title: Triage: Performance differentiation for storage systems using adaptive control
Abstract: Ensuring performance isolation and differentiation among workloads that share a storage infrastructure is a basic requirement in consolidated data centers. Existing management tools rely on resource provisioning to meet performance goals; they require detailed knowledge of the system characteristics and the workloads. Provisioning is inherently slow to react to system and workload dynamics and, in the general case, it is not practical to provision for the worst case.We propose a software-only solution that ensures predictable performance for storage access. It is applicable to a wide range of storage systems and makes no assumptions about workload characteristics. We use an online feedback loop with an adaptive controller that throttles storage access requests to ensure that the available system throughput is shared among workloads according to their performance goals and their relative importance. The controller considers the system as a &ldquo;black box&rdquo; and adapts automatically to system and workload changes. The controller is distributed to ensure high availability under overload conditions, and it can be used for both block and file access protocols. The evaluation of Triage, our experimental prototype, demonstrates workload isolation and differentiation in an overloaded cluster file-system where workloads and system components are changing.
ID:240
CLASS:3
Title: A component-based development framework for supporting functional and non-functional analysis in control system design
Abstract: The use of component-based development (CBD) is growing in the software engineering community and it has been successfully applied in many engineering domains such as office applications and in web-based distributed applications. Recently, the need of CBD is growing also in other domains related to dependable and embedded systems, namely, in the control engineering domain. However, the widely used commercial component technologies are unable to provide solutions to the requirements of embedded systems as they require too much resources and they do not provide methods and tools for developing predictable and analyzable embedded systems. There is a need for new component-based technologies appropriate to development of embedded systems. In this paper we briefly present a component-based development framework called SAVEComp. SAVEComp is developed for safety-critical real-time systems. One of the main characteristics of SAVEComp is syntactic and semantic simplicity which enables a high analyzability of properties important for embedded systems. We discuss how SAVEComp is able to provide an efficient support for designing and implementing embedded control systems by mainly focusing on simplicity and analyzability of functional requirements and of real-time and dependability quality attributes. In particular we discuss the typical solutions of control systems in which feedback loops are used and which significantly complicate the design process. We provide a solution for increasing design abstraction level and still being able to reason about system properties using SAVEComp approach. Finally, we discuss an extension of SAVEComp with dynamic run-time property checking by utilizing run-time spare capacity that is normally induced by real-time analysis.
ID:241
CLASS:3
Title: Issues in performance certification for high-level automotive control software
Abstract: High-level supervisory control software for automotive applications (e.g., drive-by-wire) presents many challenges to making performance guarantees, which are a necessary part of the software's certification for deployment. The features of such systems demand that a compositional, or modular, approach to reasoning about performance be devised and applied. We discuss one such analytical approach as an alternative to simulation and testing.
ID:242
CLASS:3
Title: Hierarchical model-based autonomic control of software systems
Abstract: Various control algorithms are used in autonomic control to maintain Quality of Service (QoS) and Service Level Agreements (SLAs). Controllers are all based to some extent on models of the relationship between resources, QoS measures, and the workload imposed by the environment. This work discusses the range of algorithms with an emphasis on richer and more powerful models to describe non-linear performance relationships, and strong interactions among the system resources. A hierarchical framework is described which accommodates different scopes and timescales of control actions, and different control algorithms. The control algorithms and architectures can be considered in three stages: tuning, load balancing and provisioning. Different situations warrant different solutions, so this work shows how different control algorithms and architectures at the three stages can be combined to fit into different autonomic environments to meet QoS and SLAs across a large variety of workloads.
ID:243
CLASS:3
Title: Adaptive trust negotiation and access control
Abstract: Electronic transactions regularly occur between business partners in separate security domains. Trust negotiation is an approach that provides an open authentication and access-control environment for such transactions, but it is vulnerable to malicious attacks leading to denial of service or leakage of sensitive information. This paper introduces an Adaptive Trust Negotiation and Access Control (ATNAC) framework to solve these problems. The framework combines two existing systems, TrustBuilder and GAA-API, to create a system with more flexibility and responsiveness to attack than either system currently provides.
ID:244
CLASS:3
Title: A model of real time control system production
Abstract: Many facets of Computer Science and associated technologies may be profitably viewed as dedicated real time control activities. Production of systems to exercise such control has been difficult and costly. An abstract model of the process of producing these systems is presented. The model indicates three areas of the design problem amenable to automation: 1) the selection and configuration of hardware; 2) the production of software; and 3) the selection of a monitor to maintain real time integrity of the entire system. The concept of hardware binding is introduced and it is shown that delaying the point in the design cycle where hardware is functionally bound allows a new approach to machine independence.This paper comprises two chapters of a larger work which developes an implementation-independent application-specification language and techniques to automate control system design. Such an automation system is intended to produce a hardware configuration listing and software which together define a complete dedicated real time controller. Development of this system is based on the model presented here and is an on-going design automation project at Lawrence Livermore Laboratory.
ID:245
CLASS:3
Title: Access control in collaborative systems
Abstract: Balancing the competing goals of collaboration and security is a difficult, multidimensional problem. Collaborative systems often focus on building useful connections among people, tools, and information while security seeks to ensure the availability, confidentiality, and integrity of these same elements. In this article, we focus on one important dimension of this problem---access control. The article examines existing access control models as applied to collaboration, highlighting not only the benefits, but also the weaknesses of these models.
ID:246
CLASS:3
Title: Queueing properties of feedback flow control systems
Abstract: In this paper, we consider a network with both controllable and uncontrollable flows. Uncontrollable flows are typically generated from applications with stringent QoS requirements and are given high priority. On the other hand, controllable flows are typically generated by elastic applications and can adapt to the available link capacities in the network. We provide a general model of such a system and analyze its queueing behavior. Specially, we obtain a lower bound and an asymptotic upper bound for the tail of the workload distribution at each link in the network. These queueing results provide us with guidelines on how to design a feedback flow control system. Simulation results show that the lower bound and asymptotic upper bound are quite accurate and that our feedback control method can effectively control the queue length in the presence of both controllable and uncontrollable traffic. Finally, we describe a distributed strategy that uses the notion of Active Queue Management (AQM) for implementing our flow control solution.
ID:247
CLASS:3
Title: Optimal power and retransmission control policies for random access systems
Abstract: We consider in this study dynamic control policies for Slotted Aloha random access systems. New performance bounds are derived when random access is combined with power control for system optimization, and we establish the existence of optimal control approaches for such systems. We analyze throughput and delay when the number of backlogged users is known, where we can explicitly obtain optimal policies and analyze their corresponding performance using Markov Decision Process (MDP) theory with average cost criterion. For the realistic unknown-backlog case, we establish the existence of optimal backlog-minimizing policies for the same range of arrival rates as the ideal known-backlog case by using the theory of MDPs with Borel state space and unbounded costs. We also propose suboptimal control policies with performance close to the optimal without sacrificing stability. These policies perform substantially better than existing "Certainty Equivalence" controllers.
ID:248
CLASS:3
Title: Manufacturing analysis and control: behavior of an order release mechanism in a make-to-order manufacturing system with selected order acceptance
Abstract: The value of holding orders in a pre-shop pool, prior to their release to the factory floor, is a somewhat controversial topic. This is especially true for make-to-order manufacturing systems, where, if capacity is fixed and exogenous due dates are inflexible, having orders wait in a preshop pool may cause the overall due date performance of the system to deteriorate. In such circumstances, selective rejection of orders offers an alternative approach to dealing with surges in demand whilst maintaining acceptable due date performance. This paper reports on the behavior of such a make-to-order manufacturing system under a control policy involving both an order release component and an order acceptance/rejection component.
ID:249
CLASS:3
Title: Real-time control: the extended use of simulation in evaluating real-time control systems of AGVs and automated material handling systems
Abstract: Control systems for logistic and transport systems are among the most complex control systems in existence. Currently control systems are only fully tested at the shop floor after commissioning. This means a lot of costly failures occur at the startup stages of control systems. The goal of this paper is to describe the extended role that simulation can play in evaluating of fully automated logistic systems and their control systems before commissioning. We followed a three-step approach in evaluating both logistic and logistic control systems. A simulated control system was used to control simulated, emulated, and real prototypes of logistic resources. Three different simulation packages have been used; Simple++, AutoMod, Arena. The control system was implemented in all three simulation packages to control logistic resources at the Connekt TestSite. The TestSite is a special laboratory for testing new technologies in logistic automation.
ID:250
CLASS:3
Title: Optimal control of make-to-order manufacturing systems via selected order acceptance
Abstract: Capacity constrained make-to-order manufacturing systems with exogenously set due dates and heavy tardiness penalties can be effectively managed by selective acceptance of orders, especially when the system encounters heavy congestion. This is demonstrated using a popular order acceptance rule. How this rule can optimally control a manufacturing system under different environments and how the main performance measures of the manufacturing system are affected in doing so, are demonstrated and analyzed. The study is done on a simulated hypothetical manufacturing system used as a testbed.
ID:251
CLASS:3
Title: A static type system for JVM access control
Abstract: This paper presents a static type system for JAVA Virtual Machine (JVM) code that enforces an access control mechanism similar to the one found, for example, in a JAVA implementation. In addition to verifying type consistency of a given JVM code, the type system statically verifies that the code accesses only those resources that are granted by the prescribed access policy. The type system is proved to be sound with respect to an operational semantics that enforces access control dynamically, similarly to JAVA stack inspection. This result ensures that "well typed code cannot violate access policy." The paper then develops a type inference algorithm and shows that it is sound with respect to the type system and that it always infers a minimal set of access privileges. These results allows us to develop a static system for JVM access control without resorting to costly runtime stack inspection.
ID:252
CLASS:3
Title: A simulation model for evaluating control algorithms of an automated storage/retrieval system
Abstract: Automated Storage/Retrieval Systems (AS/RS's) automatically perform storage and retrieval functions in a manufacturing facility. They have assured themselves a place of value in the factory of the present, as well as in the factory of the future. This paper presents an evaluation of different control algorithms of a single-aisle single-stacker AS/RS, using computer simulation, in order to identify an optimum (or very efficient) control algorithm. Storage location assignment rules, zoning procedures, stacker movement, incoming and outgoing queue priority and sequencing rules were evaluated by grouping control variables and testing the significance of these variables on system performance. Some of the results of this simulation study confirmed some of the literature. Other results provided an interesting contrast for effects of alternate control variables on system performance. The study also provides some guidelines for designing an AS/RS control strategy.
ID:253
CLASS:3
Title: Novanet communications network for a control system
Abstract: Novanet is a control system oriented fiber optic local area network that was designed to meet the unique and often conflicting requirements of the Nova laser control system which will begin operation in 1984. The computers and data acquisition devices that form the distributed control system for a large laser fusion research facility need reliable, high speed communications. Both control/status messages and experimental data must be handled. A subset of NOVANET is currently operating on the two beam Novette laser system.
ID:254
CLASS:3
Title: Using discrete-event computer simulation to test control systems
Abstract: The material handling control system of an automated manufacturing facility is tested during the commissioning of the plant. This leads to protracted commissioning periods as well as the possibility of costly equipment damage. The testing is performed in a modular fashion so that complex interaction are often overlooked.It is suggested that simulation can play a valuable part in speeding up the commissioning stage of plant startup by interfacing the control system to a computer simulation of the factory. The control system receives information about the state of the manufacturing system from the simulation and the simulation receives information from the controller on what to do next. By developing a complete simulation model and running the simulation for long periods of simulated time, the control system can be tested rigorously prior to the plant startup.The emphasis of this paper is on some of the important practical concerns of linking a discrete-event simulation system to a controller. The impact this has on the simulation model will be discussed in conjunction with two small example problems. The examples will include some of the code used to connect the controller and the simulation.
ID:255
CLASS:3
Title: CANDIDE: a learning system for process control
Abstract: The aim of this paper is to present an application of artificial intelligence techniques to control. Their use at a high level, as supervisor tools is shortly described and we focuse the attention onto their use at low level, inside the control loops. We describe our approach using artificial intelligence machine learning to acquire knowledge concerning the controlled system, to modelise it and finally to control it. As an example, CANDIDE learns to drive a car. We explain all the learning steps and shows the obtained results.
ID:256
CLASS:3
Title: Intelligent module for planning/control of master-dependent systems
Abstract: An intelligent module is proposed in this paper which is capable of performing a joint recursive planning/control operation which propagates through the intelligent module at all planning/control levels simultaneously. Each of the actuators is equipped by an intelligent module, and all of these modules are working independently and concurrently. The model of the world is being constantly updated based upon vision and a multiplicity of other available sensors, and at various resolutions is submitted to each of the intelligent modules as applied to particular properties of the link being controlled by this module. Together these intelligent modules are working as a team of the actuators controllers, and all decisions are constantly negotiated among the members of the team. Each of the resolutional levels within the actuator intelligent modules is using the following set of planning/control tools: learning rule base, learning heuristic search, and situational decision generator which are first applied simultaneously, and then one of them takes over. A neural network is collecting information about the progress and the results of planning/control processes, and is modifying heuristics, as well as enriching the system of rules. The same neural network is used for supplying the provisional analytical model required for the lowest levels of execution control. Provisional analytical models are applied in a simple form which allows for simple real-time controller operation, and the parameters of this provisional model are constantly being updated by the neural network.
ID:257
CLASS:3
Title: The development of Prometheus: an expert system tool for preliminary design of spacecraft thermal control systems
Abstract: Spacecraft thermal control system design is a complex application of thermal engineering. This design process has a structure that is common for many experienced thermal control system engineers. Prometheus, an expert system design tool, was developed to guide the thermal engineer to an acceptable preliminary design for a spacecraft thermal control system. Its architecture reflects the common structure of the thermal control system preliminary design process. The scope is intially limited to single payloads internal to the spacecraft and adjacent to the thermal sink. This scope will be expanded in the second year of development to include other thermal control system design options.
ID:258
CLASS:3
Title: The design of a solid-state physical model of an automated system to be used as a test bed for control applications
Abstract: In order to develop, test, and validate control software for managing automated systems, laboratories have traditionally constructed experimental test beds using actual physical equipment (small scale). These experimental systems typically occupy a large amount of lab space, cost thousands of dollars to construct, and require considerable human expertise to operate. Using dedicated micro-controllers (programmable logic controllers), we have proposed the use of a solid-state physical model of an automated system which faithfully replicates the operating characteristics of an ensemble of physical equipment that would typically comprise an automated system. In this paper we present the design of a solid-state physical model of a Flexible Manufacturing System (FMS). Solid-state models have several unique advantages over the traditional models. First, they are inexpensive and can easily be replicated at other laboratories. Second, they can be easily reconfigured to consider alternative scenarios. Third, they can consider an emulated environment that is far more complex than those that are typically addressed by models using actual equipment. Finally, they are totally reliable and safe, and require minimal expertise to operate. This paper discusses the design and operational characteristics of the solid-state model along with its anticipated uses and current limitations.
ID:259
CLASS:3
Title: Documentation meets version control: an automated backup system for HTML-based help
Abstract: Software developers have used version control systems for years, to manage source code changes and to enable them to reproduce any given level of their software from the source code that created it. Most writing departments, however, tend to perform full-scale weekly backups at best, or tempt fate at worst. The two major reasons for this neglect of document version control are lack of adequate tools and the effort required by writers to deal with the inadequate tools presently available. This paper describes a tool I developed at IBM, the Automated Backup Manager (ABM), which attempts to connect the writer's documentation to a true source version control system, without reducing writer productivity.
ID:260
CLASS:3
Title: SPARSE\&mdash;an expert system for alarm processing and operator assistance in substations control centers
Abstract: In case of occurrence of an incident in an electrical network, several hundreds of messages per minute may be presented to Control Center operators. This makes very difficult the identification of the fault and to decide about the required actions in order to minimize the consequences of the incident and to restore the service.This paper describes an expert system named SPARSE that provides on-line assistance to the operators of Substation Control Centers (SCC) of the portuguese electrical transmission network. SPARSE performs intelligent alarm processing and provides advice regarding operator actions. This system has been developed by the Faculty of Engineering of University of Porto in a joint project with Electricidade de Portugal, EDP, S.A., the utility that deals with power generation, transmission and distribution in Portugal.
ID:261
CLASS:3
Title: A flexible interactive control structure for rule-based systems
Abstract: Flexibility in control mechanism will allow solutions of a much wider range of problems with the expert system technology than currently possible. In order to provide flexibility in control mechanism deviations from the standard fixed control (recognize-act cycle) should be allowed. As a first step toward achieving this we develop a flexible interactive backtracking strategy that can deviate significantly from the fixed control structure of rule-based systems. This paper describes a general purpose tool for developing expert systems called PRO2. PRO2 has an effective, intelligent and flexible backtracking control mechanism which makes the system more dependable and flexible. It has a reasonably efficient backtracking facility that is used when the user is not satisfied with the solution and requests for alternatives. Thus, the system provides a greater opportunity to find an acceptable solution if the user is not satisfied with the earlier solution provided. The system also provides an interactive conflict resolution facility.
ID:262
CLASS:3
Title: Perceptions of control during systems development: effects on job satisfaction of systems professionals
Abstract: While a great deal of organizational research has been devoted to the study of individual differences and task characteristics as the major determinants of job satisfaction, the role of organizational variables in explaining employee satisfaction has received little empirical attention. The present study argues that the extent to which employees perceive that their activities are controlled by managers, peers, or themselves may have significant effects upon their corresponding levels of job satisfaction. Based upon this rationale, this study investigated perceptions of different control approaches in relation to job satisfaction of 62 systems professionals of a local government organization. Bivariate analyses indicated that managerial control, team-member control, and self-control were highly correlated with general satisfaction. Additional analyses indicated that self-control had strong positive effects on both intrinsic and extrinsic satisfaction, while, managerial control had a strong positive effect on extrinsic satisfaction. Implications of the findings for the management of information systems personnel and future research are discussed.
ID:263
CLASS:3
Title: Modeling real-world control systems: beyond hybrid systems
Abstract: Hybrid system modeling refers to the construction of system models combining both continuous and discrete dynamics. These models can greatly reduce the complexity of a physical system model by abstracting some of the continuous dynamics of the system into discrete dynamics. Hybrid system models are also useful for describing the interaction between physical processes and computational processes, such as in a digital feedback control system. Unfortunately, hybrid system models poorly capture common software architecture design patterns, such as threads, mobile code, safety, and hardware interfaces. Dealing effectively with these practical software issues is crucial when designing real-world systems. This paper presents a model of a complex control system that combines continuous-state physical system models with rich discrete-state software models in a disciplined fashion. We show how expressive modeling using multiple semantics can be used to address the design difficulties in such a system.
ID:264
CLASS:3
Title: Applying the control adaptation method to a real-world system: hydropower system example
Abstract: This paper presents part of a project aimed at evaluating ecological interfaces in a real world complex system -a hydropower system. We investigate whether an advanced measurement method---here called the control adaptation method (CAM)---can be extended to evaluate how effectively a human operator is coupled to a complex process control environment. So far the CAM has been successfully applied to the simple, DURESS II microworld. In this paper we attempt to extend the CAM to a real-world complex control environment---a hydropower system operating in a deregulated electricity market. We encounter challenges in transferring the CAM to this more complex work domain. Nonetheless, we provide an approximation to the original methodology that should let us measure the effectiveness of ecological displays for hydropower systems. Our findings may generalise to the evaluation of ecological interfaces in other real-world systems.
ID:265
CLASS:3
Title: Separating control from structural knowledge in construction expert systems
Abstract: In most expert systems for constructional tasks the knowledge base consists of a set of facts or object definitions and a set of rules. These rules contain knowledge about correct or ideal solutions as well as knowledge on how to control the construction process. In this paper we present an approach that avoids this type of rules and thus the disadvantages caused by them.We propose a static knowledge base consisting of a set of object definitions interconnected by is-a and part-of links. This conceptual hierarchy declaratively defines a taxonomy of domain objects and the aggregation of components to composite objects. Thus, the conceptual hierarchy describes the set of all admissible solutions to a constructional problem. Interdependencies between objects are represented by constraints. A solution is a syntactically complete and correct partial instantiation of the conceptual hierarchy.No control knowledge is included in the conceptual hierarchy. Instead, the control mechanism will use it as a guideline. It is thus possible to determine in which respects a current partial solution is incomplete, simply by comparing it with the conceptual hierarchy syntactically. The most important advantage of this approach is the ability to represent control knowledge and structural knowledge separately.
ID:266
CLASS:3
Title: Plant control expert system coping with unforeseen events\&mdash;model based reasoning using fuzzy qualitative reasoning
Abstract: An ordinary expert system controls a plant according to heuristics. So, it fails to control the plant for lack of heuristics if unforeseen events occur as a result of abnormal situations. We propose a new framework of model-based reasoning that can dynamically generate the knowledge for plant control against unforeseen events. This proposed framework consists of three functions: (a) generation of the goal state after recovery from the unforeseen events; (b) generation of knowledge for plant control; (c) prediction of process trend curves and estimation of the generated knowledge. In the proposed framework, various kinds of models which correspond to the fundamental knowledge about plant control are used. We have implemented a thermal power plant control expert system on the basis of this proposed framework. This paper describes the model-based reasoning mechanism of the experimental plant control expert system to realize each of three functions. Especially as for (c), this paper explains qualitative reasoning mechanism using fuzzy logic.
ID:267
CLASS:3
Title: Experience gained from the American Airlines SABRE system control program
Abstract: Just over ten years ago, IBM and American Airlines undertook the development of a real-time airlines reservations system. At that time, there were several systems in use by the airlines to present &ldquo;yes-no&rdquo; information on seat availability and in some cases maintain seat inventory counts. None of these systems, however, performed the complete &ldquo;back-room&rdquo; job of filing records, sending communication messages, processing wait-lists, preparing boarding manifests, etc. Significant improvements in passenger service were expected if the many possible sources of error in these operations could be reduced. The effort included development of specialized pieces of equipment and of a control program to interface between the application programs and the hardware. This was at a time when operating systems were just beginning to come into use. This paper concentrates upon the control program architecture, setting forth the important lessons that were learned after the system became operational.
ID:268
CLASS:3
Title: A Simulation Support System Capable Of Control, Monitoring And Simulation Of Airborne Systems
Abstract: With increasing use of simulations as a means of demonstrating and verifying systems, more emphasis has been placed on simulation support systems capable of sustaining these demonstrations. This paper contains a discussion of a current Support System used in conjunction with the Digital Avionics Information System (DAIS) Program being conducted at the Air Force Avionics Laboratory, Wright-Patterson Air Force Base. Descriptions of Support Hardware Systems and Software Support and Analysis Programs are included in this document. The purpose of the Simulation Support System is to test and evaluate advanced avionic system and subsystem configurations. The support system provides a real-time simulation of a military aircraft performing an operational mission. The simulation generates interface signals between the aircraft sensor suite and the avionic system so that the avionics equipment is subjected to a data signal environment which is nearly identical to actual flight. In addition to the simulation of flight data, the support system has the capability to monitor, record and control the data from both the simulation and the actual flight hardware.
ID:269
CLASS:3
Title: HaWCoS: the "hands-free" wheelchair control system
Abstract: A system allowing to control an electrically powered wheelchair without using the hands is introduced. HaWCoS -- the "Hands-free" Wheelchair Control System -- relies upon muscle contractions as input signals. The working principle is as follows. The constant stream of EMG signals associated with any arbitrary muscle of the wheelchair driver is monitored and reduced to a stream of contraction events. The reduced stream affects an internal program state which is translated into appropriate commands understood by the wheelchair electronics. The feasibility of the proposed approach is illustrated by a prototypical implementation for a state-of-the-art wheelchair. Operating a HaWCoS-wheelchair requires extremely little effort, which makes the system suitable even for people suffering from very severe physical disabilities.
ID:270
CLASS:3
Title: Manufacturing controls: understanding the fundamentals of Kanban and CONWIP pull systems using simulation
Abstract: This paper presents an introductory overview and tutorial in simulation modeling and control of serial Kanban and CONWIP (CONstant Work In Process) pull systems using ARENA/SIMAN 3.5/4.0. Card level estimation is discussed for both types of pull systems, and a heuristic method to adjust card levels controlling system WIP (Work In Process) is provided. The objective is to present a tutorial for students and practicing engineers familiar with the basics of simulation, but unfamiliar with pull system fundamentals.
ID:271
CLASS:3
Title: Role-based access control in online authoring and publishing systems vs. document hierarchy
Abstract: How to structure diverse (documentation) information sources of an enterprise and how to arrange a workflow with access control are two important issues for online authoring and publishing systems. Aim of this paper is to describe a solution for both problems, which is based on department structure, subject areas, and roles in an enterprise. Our approach will be introduced by presenting the DAPHNE system. DAPHNE provides possibilities to support collaborative authoring on a document hierarchy that reflects the diverse branches of an enterprise's organization structure and allows diverse (documentation) information sources of an enterprise to be well structured. The role-based access control (RBAC) mechanism implemented within DAPHNE is supported by the document hierarchy as well.
ID:272
CLASS:3
Title: Analysis of different AGV control systems in an integrated IC manufacturing facility, using computer simulation
Abstract: In an integrated Manufacturing Facility, consisting of various individual manufacturing cells, an automated material handling system (AMHS) - such as an Automated Guided Vehicle System (AGVS) - servicing each of cells plays a major role. In order to understand, and choose, the correct type of AGV system, simulation techniques can be used very effectively. In this paper, two different AGV Control Systems have been analyzed with computer simulation models. These animated graphic models also include details of all the individual process steps from the Wafer Sort operation through the Test processes of an IC Manufacturing Facility at Intel. The simulation model is used to analyze the behavior of the AGVS, as measured by the average AGV utilizations, AGV congestion levels, average AGV response times, as well as process characteristics such as Throughput Time through the line, Work in Process levels and overall product throughput through the line. The model has been used to recommend the proper AGV control logic, as well as the number of vehicles required.
ID:273
CLASS:3
Title: Modal processes: towards enhanced retargetability through control composition of distributed embedded systems
Abstract: To explore different points in the design space of an embeddedsystem, it is important to be able to compose a designfrom reusable design components, and then map the resultingsystem description onto several possible target architectureswith different partitionings of functionality. Today's specificationmodels support composition styles that work well fordata communication but not for control communication betweenconcurrent processes to be mapped onto a distributedarchitecture. We propose a new retargetable system specificationmodel that combines the best properties of process-basedand hierarchical-FSM-based methods for modular compositionof data and control. The model lends itself to automatedsynthesis of the run-time system for coordinating tasks ondifferent processors in the system. The model and synthesismethod are illustrated with several examples of embeddedsystems.
ID:274
CLASS:3
Title: Control procedures for slotted Aloha systems that achieve stability
Abstract: A class of slotted ALOHA dynamic control strategies is considered. These strategies are simple to implement and can yield lossless and stable operation for arbitrarily large user populations with aggregate arrival rates below e-1 packets/slot. An ergodicity analysis is given that provides conditions on the system parameters, such that any specified set of control parameters that satisfies the given conditions is guaranteed to yield stable performance. The system state is modelled as a two-dimensional Markov chain that incorporates the backlog (the number of packets awaiting retransmission) and the estimate of the backlog. The geometrical concepts are illustrated by figures corresponding to an example case. Simulation results are presented that compare alternative control schemes.
ID:275
CLASS:3
Title: Simulation of manufacturing operations: optimum-seeking simulation in the design and control of manufacturing systems: experience with optquest for arena
Abstract: This paper presents some of my experience in applying a commercial &#60;i>optimum-seeking simulation&#60;/i> tool to manufacturing system design and control problems. After a brief introduction to both the general approach and to the specific tool being used, namely &#60;i>OptQuest for Arena&#60;/i>, the main body of the paper reports on the use of the tool in tackling two manufacturing system design and control problems, one very simple and one significantly more complex. The paper concludes with some material highlighting how easy the tool is to apply to this kind of problem and also presents some thoughts on how the tool might be enhanced to improve its value.
ID:276
CLASS:3
Title: A flexible client/server application for robotic control
Abstract: Flexibility is essential during the research, development and testing of multi-robot systems. This paper describes a flexible client/server application and presents examples of how this flexibility is being used. A software architecture is presented that allows multiple analysis tools the ability to control robotic platforms that have different hardware control systems but use similar locomotion control commands and feedback. Two different robotic platform specifications, one for a wheeled robot and one for a boat, are given along with a description of how both are controlled. An example of how both platforms are being used to conduct research is illustrated in order to show some of the advantages of having flexible robotic configuration and control. Various aspects of the application's evolution while supporting Unmanned Underwater Vessel (UUV) team research are presented along with a discussion of future work to be done.
ID:277
CLASS:3
Title: Simulation system for real-time planning, scheduling, and control
Abstract: This paper introduces a framework for on-line simulation systems in the operational planning, scheduling, and control of manufacturing systems. Five basic concepts for software design of an on-line simulation system are identified and an example simulator is illustrated.
ID:278
CLASS:3
Title: Control systems in robots
Abstract: A general framework is presented for treating the production of behavior in a system that interacts purposively with its environment. Such a system is viewed as having two parts: a body, which forms the interface with the outside world, and a control. Communications between these two parts constitute the moves in the system's game against the environment. The control embodies the rules that specify the system's set of tasks, as well as the strategy used in the reduced game that results from the use of the rules. Three classes of strategies are defined: local, problem-solving, and decision-making. Decision-making strategies, applied in the reduced game with the policy of maximizing utility, have desirable features. The simulation of PERCY, a nest-building insect, illustrates how such a strategy avoids difficulties that obstruct a problem-solving approach.
ID:279
CLASS:3
Title: A control strategy for small computer systems
Abstract: A general purpose hardware oriented control structure is presented. This outer control structure can be used to implement a variety of target languages. Further, the control structure can be adapted to a variety of Large Scale Integration components including general purpose ALU's microprogram storage medias and programmable logic arrays. The independence from specific components reduces the binding to specific component vendors and permits various versions with varying integration and performance levels to be constructed.
ID:280
CLASS:3
Title: Hierarchical scheduling in an intelligent environmental control system
Abstract: This paper describes design and implementation of the hierarchical scheduling subsystem and graphical user interface in an intelligent environmental control system. The hierarchical scheduling system is capble of managing all environmental events occuring in widely different time scales as specified by the user. We employ a knowledge representation scheme called system entity structure to specify the environmental schedules in a hierarchical fashion. A system entity structure called TAL (Timed Action Language) is developed. TAL organizes a family of all possible long-/mid-/short-term schedules from which a specific schedule can be pruned by the user through graphical interface.
ID:281
CLASS:3
Title: Network expert diagnostic system for real-time control
Abstract: Data communications networks are controlled by network management systems that are responsible for performance and fault management. This paper presents an expert system capable of performing fault and performance management through different levels of autonomous control. A blackboard architecture design provides for processing of multiple lines of machine reasoning and planning: the set of all unresolved events is used to generate hypotheses of network state through event correlation and ancillary network information; supporting network data provides evidence that supports or refutes the hypotheses; conclusions are drawn from the hypotheses; plans of corrective action are built, executed, and monitored to attempt improvement to a &ldquo;normal&rdquo; network state.
ID:282
CLASS:3
Title: A tool for simulation and fast prototyping of embedded control systems
Abstract: This paper presents a set of C++ libraries, called RTSIM, aimed at realizing a joint simulation of a continuous plant and of a real-time embedded controller. The libraries permit a separate specification of the functional behaviour of the controller and of the software platform to be used for its deployment. In particular, it is possible to provide an accurate modeling of the concurrent architecture of the control tasks and of the run-time support offered by the operating system for the real-time scheduling of the shared resources (CPU, memory buffers, network links). In this way, its is possible to compare different scheduling solutions by evaluating their simulated performance in the domain of the control application. Moreover, the tool can be utilized to tune up such design parameters as the activation frequencies of the tasks. The application of the tool is shown on a meaningful robotic case-study.
ID:283
CLASS:3
Title: Embedded Control Systems Development with Giotto
Abstract: Giotto is a principled, tool-supported design methodology for implementing embedded control systems on platforms of possibly distributed sensors, actuators, CPUs, and networks. Giotto is based on the principle that time-triggered task invocations plus time-triggered mode switches can form the abstract essence of programming real-time control systems. Giotto consists of a programming language with a formal semantics, and a retargetable compiler and runtime library. Giotto supports the automation of control system design by strictly separating platform-independent functionality and timing concerns from platform-dependent scheduling and communication issues. The time-triggered predictability of Giotto makes it particularly suitable for safety-critical applications with hard real-time constraints. We illustrate the platform-independence and time-triggered execution of Giotto by coordinating a heterogeneous flock of Intel x86 robots and Lego Mindstorms robots.
ID:284
CLASS:3
Title: Completeness in formal specification language design for process-control systems
Abstract: This paper examines the issue of completeness in specification language design.  In the mid-80s we identified a set of 26 formal criteria to identify missing, incorrect, and ambiguous requirements for process-control systems.  Experimental validation of the criteria on NASA and NASDA spacecraft systems have supported their usefulness in detecting commonly omitted but important information and engineers have been using them in checklist form on real systems.  At the same time, we have extended the criteria and now have over 60.  This paper shows how most of the criteria can be embedded in a formal specification language in ways that potentially allow automated checking or assist in manual reviews.
ID:285
CLASS:3
Title: Fault-tolerance in air traffic control systems
Abstract: The distributed real-time system services developed by Lockheed Martin's Air Traffic Management group serve the infrastructure for a number of air traffic control systems. Either completed development or under development are the US Federal Aviation Administration's Display System Replacement (DSR) system, the UK Civil Aviation Authority's New Enroute Center (NERC) system, and the Republic of China's Air Traffic Control Automated System (ATCAS). These systems are intended to replace present en route systems over the next decade. High availability of air traffic control services is an essential requirement of these systems. This article discusses the general approach to fault-tolerance adopted in this infrastructure, by reviewing some of the questions which were asked during the system  design, various alternative solutions considered, and the reasons for the design choices made. The aspects of this infrastructure chosen for the individual ATC systems mentioned above, along with the status of those systems, are presented in the Section 11 of the article.
ID:286
CLASS:3
Title: Real-time synchronization control in multimedia distributed systems
Abstract: Two basic synchronization problems are involved in the distributed multimedia systems. One of them is the simultaneous real-time data delivery. Simultaneous Real Time Data Delivery (SRTDD) refers to delivering multimedia data in different data streams belonging to the same time interval simultaneously. In this paper, an entire SRTDD control scheme for multimedia transmission is established. We propose a layered architecture which can be mapped to the OSI model to support the SRTDD control. The segment delivery protocols for real-time multimedia data streams are addressed. A practical segmentation method is also developed for real-time voice and video.
ID:287
CLASS:3
Title: Continuous TTCN-3: testing of embedded control systems
Abstract: The systematic testing approaches developed within the telecommunication domain for conformance and interoperability testing of communication protocols have been extended and broadened to allow the testing of local and distributed, reactive and proactive systems in further domains such as Internet, IT, control systems in automotive, railways, avionics and alike. With the application of these testing principles it became apparent that the testing of systems with continuous systems is different to that of discrete systems. Although every continuous signal can be discretized by sampling methods (and hence mapped to the discrete signal paradigm), abstraction and performance issues in this setting become critical. This paper revises the initial design of Continuous TTCN-3. It presents the concepts for specifying continuous and hybrid test behavior. The TTCN-3 extensions are demonstrated for a case study1.
ID:288
CLASS:3
Title: Improving the effectiveness of monitoring and control systems exploiting knowledge-based approaches
Abstract: This paper illustrates how the adoption of techniques typical of artificial intelligence (AI) could improve the performance of monitoring and control systems (MCSs). Traditional MCSs are designed according to a three-level architectural pattern in which intelligent devices are usually devoted to evaluate whether the data acquired by a set of sensors could be interpreted as anomalous or not. Possible mistakes in the evaluation process, due to faulty sensors or external factors, can cause the generation of undesirable false alarms. To solve this problem, the traditional three-tier architecture of MCSs has been extended with a fourth level, named the correlation level, where an intelligent module, usually a knowledge-based system, collects the local interpretations made by each evaluation device, building a global view of the monitored field. In this way, possible local mistakes are identified by the comparison with other local interpretations.
ID:289
CLASS:3
Title: Decentralized control of E'GV transportation systems
Abstract: Egemin N. V. is a Belgian manufacturer of Automatic Guided Vehicles -named E'GVs- and control software for automating logistics services in warehouses and manufactories using E'GVs. In a joint R&D project, Egemin and the AgentWise research group are developing an innovative version of the E'GVs control system aimed to cope with new and future system requirements such as flexibility and openness.In this project, we exploit principles and mechanisms known from situated multi-agent systems for modelling and implementing a decentralized control system. Instead of a centralistic approach, where one computer system is in charge of numerous complex and time-consuming tasks (such as routing, collision avoidance, deadlock avoidance, etc.), we aim to provide the E'GVs with a considerable amount of autonomy. This allows to obtain a system that is far more flexible than the current software - the E'GVs adapt themselves to the current situation in their direct vicinity, order assignment is dynamic, the system can cope with E'GVs leaving the system (e.g. for maintenance) or adding new E'GVs, and so on.In this paper, we describe the architecture that is employed for implementing the control of the E'GV system. The implementation of the control software seamlessly integrates with E'nsor, the low-level vehicle control system. We illustrate a concrete control scenario in which two E'GVs coordinate their behavior to avoid collisions.
ID:290
CLASS:3
Title: Synthesising verified access control systems in XACML
Abstract: The &#60;i>eXtensible Access Control Markup Language&#60;/i> (XACML) was proposed by the OASIS committee to be used as a standard language in e-business [6]. However, policy files written in XACML are hard to read and analyse directly. In this paper, we present a tool which generates verified XACML scripts from access control system descriptions in simple but expressive language proposed in [3], which admits algorithmic verification of access control systems against appropriately formalised policies. This allows the generation of XACML scripts for systems that can be formally verified to be implementing the relevant policies.
ID:291
CLASS:3
Title: Keyframe control of complex particle systems using the adjoint method
Abstract: Control of physical simulation has become a popular topic in the field of computer graphics. Keyframe control has been applied to simulations of rigid bodies, smoke, liquid, flocks, and finite element-based elastic bodies. In this paper, we create a framework for controlling systems of interacting particles -- paying special attention to simulations of cloth and flocking behavior. We introduce a novel integrator-swapping approximation in order to apply the adjoint method to linearized implicit schemes appropriate for cloth simulation. This allows the control of cloth while avoiding computationally infeasible derivative calculations. Meanwhile, flocking control using the adjoint method is significantly more efficient than currently-used methods for constraining group behaviors, allowing the controlled simulation of greater numbers of agents in fewer optimization iterations.
ID:292
CLASS:3
Title: A case study in access control requirements for a Health Information System
Abstract: We present a detailed examination of the access constraints for a small real-world Health Information System with the aim of achieving minimal access rights for each of the involved principals. We show that, even for such a relatively simple system, the resulting constraints are very complex and cannot be expressed easily or clearly using the static per-method access control lists generally supported by component-based software. We derive general requirements for the expressiveness of access constraints and propose criteria for a more suitable access control mechanism in the context of component-based systems. We describe a two-level mechanism which can fulfil these criteria.
ID:293
CLASS:3
Title: A detailed interactive simulation system for developing command and control systems
Abstract: The Dynamic Ground Target Simulation (DGTS) system is a real-time interactive simulation system which produces detailed scenarios of military unit activity. DGTS is composed of three subsystems: a Model Construction Subsystem, which uses a Pascal-based discrete event simulation language, a Data Preparation Subsystem, and a Scenario Generation Subsystem, which executes a model according to a specific set of orders and allows it to be interactively manipulated. DGTS has been used to generate scenarios of varying size and scope.
ID:294
CLASS:3
Title: Concurrency control in hierarchical multidatabase systems
Abstract: Over the past decade, significant research has been done towards developing transaction management algorithms for multidatabase systems. Most of this work assumes a monolithic architecture of the multidatabase system with a single software module that follows a single transaction management algorithm to ensure the consistency of data stored in the local databases. This monolithic architecture is not appropriate in a multidatabase environment where the system spans multiple different organizations that are distributed over various geographically distant locations. In this paper, we propose an alternative multidatabase transaction management architecture, where the system is hierarchical in nature. Hierarchical architecture has consequences on the design of transaction management algorithms. An implication of the architecture is that the transaction management algorithms followed by a multidatabase system must be composable&ndash; that is, it must be possible to incorporate individual multidatabase systems as elements in a larger multidatabase system. We present a hierarchical architecture for a multidatabase environment and develop techniques for concurrency control in such systems.
ID:295
CLASS:3
Title: A hierarchical access control model for video database systems
Abstract: Content-based video database access control is becoming very important, but it depends on the progresses of the following related research issues: (a) efficient video analysis for supporting semantic visual concept representation; (b) effective video database indexing structure; (c) the development of suitable video database models; and (d) the development of access control models tailored to the characteristics of video data. In this paper, we propose a novel approach to support multilevel access control in video databases. Our access control technique combines a video database indexing mechanism with a hierarchical organization of visual concepts (i.e., video database indexing units), so that different classes of users can access different video elements or even the same video element with different quality levels according to their permissions. These video elements, which, in our access control mechanism, are used for specifying the authorization objects, can be a semantic cluster, a subcluster, a video scene, a video shot, a video frame, or even a salient object (i.e., region of interest). In the paper, we first introduce our techniques for obtaining these multilevel video access units. We also propose a hierarchical video database indexing technique to support our multilevel video access control mechanism. Then, we present an innovative access control model which is able to support flexible multilevel access control to video elements. Moreover, the application of our multilevel video database modeling, representation, and indexing for MPEG-7 is discussed.
ID:296
CLASS:3
Title: Electronic monitoring and the redundancy of control systems: The role of the supervisor
Abstract: Despite an increasing amount of research on the concerns of lower level computer workers who perform clerical work using Video Display Terminals, there has been virtually no attention paid to the concerns and behaviors of their supervisors. Consequently, little is known about actual supervisory methods in settings with computerized performance monitoring systems.This paper reports on the results of a field study focusing on the supervisor's role in computerized and non-computerized data entry settings. Both supervisors and their employees comprised the research sample.In general, the results of this study do not support prior research regarding the differences in perception of closeness in supervision between VDT and non-VDT workers. Furthermore, the results suggest that the supervisors are largely under-utilizing the monitoring capabilities of the system. Implications for systems design are discussed.
ID:297
CLASS:3
Title: Distributed admission control for power-controlled cellular wireless systems
Abstract: It is well known that power control can help to improve spectrum utilization in cellular wireless systems. However, many existing distributed power control algorithms do not work well without an effective connection admission control (CAC) mechanism, because they could diverge and result in dropping existing calls when an infeasible call is admitted. In this work, based on a system parameter defined as the discriminant, we propose two distributed CAC algorithms for a power-controlled system. Under these CAC schemes, an infeasible call is rejected early, and incurs only a small disturbance to existing calls, while a feasible call is admitted and the system converges to the Pareto optimal power assignment. Simulation results demonstrate the performance of our algorithms.
ID:298
CLASS:3
Title: Two-level control of a real-time data acquisition and control system for studying the electrical activity of the heart
Abstract: A high speed data acquisition system for experiments investigating the electrical activity of the heart is discussed with emphasis on the method of specifying and controllinq the experiment in progress. Provision is made for control by the investigator during the experiment of such things as sampling rate, initiation and duration of sampling, control of temperature of tissue preparations, pacing rates of various stimuli, etc. For many experiments direct investigator control works well, but where sequences of control are complicated, or where changes in control must occur in real time (e.g. sampling duration changes within a single heart beat), or where sequences of pacing outputs must vary depending upon values of immediately preceding data, direct investigator control is not feasible. Our approach to this problem is to use a Master Program - a small separate module tailored to each particular experiment which can monitor the progress of the experiment and make control choices automatically - in effect, an automated operator, Master Programs are subroutines prepared independently from the data acquisition program and allow the investigator to continue to exert whatever control he desires while the Master Program is running. A Master Program and an associated set of system parameters are stored together in a "workspace" on auxiliary storage with other workspaces. Any workspace can be loaded, if required, during execution of the data acquisition program, quickly changing the experiment's environment. Master Programs operate as coroutines with the existing modules of the data acquisition program. A general description of the data acquisition system is given along with an example of a specific Master Program. The implementation method is briefly discussed.
ID:299
CLASS:4
Title: How geography professors select materials for classroom lectures: implications for the design of digital libraries
Abstract: A goal of the Alexandria Digital Earth Prototype (ADEPT) project is to make primary resources in geography useful for undergraduate instruction in ways that will promote inquiry learning. The ADEPT education and evaluation team interviewed professors about their use of geography information as they prepare for class lectures, as compared to their research activities. We found that professors desired the ability to search by concept (erosion, continental drift, etc ) as well as geographic location, and that personal research collections were an important source of instructional materials. Resources in geo-spatial digital libraries are typically described by location, but are rarely described by concept or educational application. This paper presents implications for the design of an educational digital library from our observations of the lecture preparation process. Findings include functionality requirements for digital libraries and implications for the notion of digital libraries as a shared information environment. The functional requirements include definitions and enhancements of searching capabilities, the ability to contribute and to share personal collections of resources, and the capability to manipulate data and images.
ID:300
CLASS:4
Title: Digital libraries and educational practice: a case for new models
Abstract: Educational digital libraries can benefit from theoretical and methodological approaches that enable lessons learned from design and evaluation projects performed in one particular setting to be applied to other settings within the library network. Three promising advances in design theory are reviewed - reference tasks, design experiments, and design genres. Each approach advocates the creation of 'intermediate' constructs as vehicles for knowledge building and knowledge sharing across design and research projects. One purpose of an intermediate construct is to formulate finer-grained models that describe and explain the relationship between key design features and the cognitive and social dimensions of the context of use. Three models are proposed and used as thought experiments to analyze the utility of these approaches to educational digital library design and evaluation: digital libraries as cognitive tools, component repositories, and knowledge networks.
ID:301
CLASS:4
Title: Streams, structures, spaces, scenarios, societies (5s): A formal model for digital libraries
Abstract: Digital libraries (DLs) are complex information systems and therefore demand formal foundations lest development efforts diverge and interoperability suffers. In this article, we propose the fundamental abstractions of Streams, Structures, Spaces, Scenarios, and Societies (5S), which allow us to define digital libraries rigorously and usefully. Streams are sequences of arbitrary items used to describe both static and dynamic (e.g., video) content. Structures can be viewed as labeled directed graphs, which impose organization. Spaces are sets with operations on those sets that obey certain constraints. Scenarios consist of sequences of events or actions that modify states of a computation in order to accomplish a functional requirement. Societies are sets of entities and activities and the relationships among them. Together these abstractions provide a formal foundation to define, relate, and unify concepts---among others, of digital objects, metadata, collections, and services---required to formalize and elucidate "digital libraries". The applicability, versatility, and unifying power of the 5S model are demonstrated through its use in three distinct applications: building and interpretation of a DL taxonomy, informal and formal analysis of case studies of digital libraries (NDLTD and OAI), and utilization as a formal basis for a DL description language.
ID:302
CLASS:4
Title: Integrating digital libraries into learning environments: the <i>LEBONED</i> approach
Abstract: This paper presents the project LEBONED that focuses on the integration of digital libraries and their contents into web-based learning environments. We describe in general how the architecture of a standard learning management system has to be modified to enable the integration of digital libraries. An important part of this modification is the LEBONED Metadata Architecture which depicts the handling of metadata and documents imported from digital libraries. The main components of this architecture and their interrelation are presented in detail. Afterwards we show a practical application of the concepts described before: The integration of the digital library eVerlage into the learning management system Blackboard.
ID:303
CLASS:4
Title: Creating virtual collections in digital libraries: benefits and implementation issues
Abstract: Digital libraries have the potential to not only duplicate many of the services provided by traditional libraries but to extend them. Basic finding aids such as search and browse are common in most of today's digital libraries. But just as a traditional library provides more than a card catalog and browseable shelves of books, an effective digital library should offer a wider range of services. Using the traditional library concept of special collections as a model, in this paper we propose that explicitly defining sub-collections in the digital library-virtual collections-can benefit both the library's users and contributors and increase its viability. We first introduce the concept of a virtual collection, outline the costs and benefits for defining such collections, and describe an implementation of collection-level metadata to create virtual collections for two different digital libraries. We conclude by discussing the implications of virtual collections for enhancing interoperability and sharing across digital libraries, such as those that are part of the National SMETE Digital Library.
ID:304
CLASS:4
Title: Use of multiple digital libraries: a case study
Abstract: The aim of the work reported here was to better understand the usabili ty issues raised when digital libraries are used in a natural setting. The method used was a protocol analysis of users working on a task of their own choosing to retrieve documents from publicly available digital libraries. Various classes of usability difficulties were found. Here, we focus on use in context - that is, usability concerns that arise from the fact that libraries are accessed in particular ways, under technically and organisationally imposed constraints, and that use of any particular resource is discretionary. The concepts from an Interaction Framework, which provides support for reasoning about patterns of interaction between users and systems, are applied to understand interaction issues.
ID:305
CLASS:4
Title: Creating digital libraries together\&mdash;collaboration, multimodality, and plurality
Abstract: Many have tried to answer the question of what a digital library is and how such libraries should be built. But, in a sense the question of how to construct digital libraries as well defined entities is misguided from the beginning. There are many approaches to building digital libraries [7, 18, 4] and each approach must be understood from within a context. Some contexts such as information retrieval and digitizing of existing materials have received much attention [12, 22, 18, 17], while other contexts have been more or less ignored [19]. One such context is that of networking from a higher level of abstraction [8, 11]. Since traditional libraries have long since existed in elaborate and large-scale physical networks it is only natural that we should see such structures mirrored in the world of digital abstract networks. The Universal Simulator [10] application builds on the idea that research in digital libraries need not necessarily focus on micro level infrastructures, but that we may also find interesting possibilities on the macro level of digital library infrastructures. Moreover, at such a macro level we may find important new ways of collaborating and building digital libraries in educational settings.
ID:306
CLASS:4
Title: Going digital: a look at assumptions underlying digital libraries
Abstract: What are digital libraries, how should they be designed, how will they be used, and what relationship will they bear to what we now call &ldquo;libraries&rdquo;? Although we cannot hope to answer all these crucial questions in this short article, we do hope to encourage, and in some small measure to shape, the dialog among computer scientists, librarians, and other interested parties out of which answers may arise. Our contribution here is to make explicit, and to question, certain assumptions that underlie current digital library efforts. We will argue that current efforts are limited by a largely unexamined and unintended allegiance to an idealized view of what libraries have been, rather than what they actually are or could be. Since these limits come from current ways of thinking about the problem, rather than being inherent in the technology or in social practice, expanding our conception of digital libraries should serve to expand the scope and the utility of development efforts.
ID:307
CLASS:4
Title: The roles of digital libraries in teaching and learning
Abstract: Libraries have long served crucial roles in learning. The first great library, in Alexandria 2,000 years ago, was really the first university. It consisted of a zoo and various cultural artifacts in addition to much of the ancient world's written knowledge and attracted scholars from around the Mediterranean, who lived and worked in a scholarly community for years at a time. Today, the rhetoric associated with the National/Global Information Infrastructure (N/GII) always includes examples of how the vast quantities of information that global networks provide (i.e., digital libraries) will be used in educational settings [16].
ID:308
CLASS:4
Title: Copyright and digital libraries
Abstract: This issue of Communications highlights some of the many projects underway for the creation or enhancement of digital libraries. At the moment, no one seems to think there will be only one gargantuan digital library to sate the public's appetite for information. Rather, the expectation is that there will be many digital libraries, most of which will have specialized collections and will be internetworked together in a way loosely resembling today's Internet. Most digital library project planners are aware there are intellectual property issues that must be resolved in order to successfully deploy their libraries. Some proposals for digital library projects express an intent to resolve intellectual property issues as part of the overall plan for the library, albeit without much specificity about how this would be achieved in their systems [2, 4].
ID:309
CLASS:4
Title: Social empowerment and exclusion: A case study on digital libraries
Abstract: This article reports on work studying how technology can empower or exclude its users due to interactions between social context, system design, and implementation. The analysis is based around the introduction and use of digital libraries in four different settings, three clinical and one academic. Across the four settings, in-depth interview and focus group data was collected from 144 users and analyzed with reference to &ldquo;communities of practice&rdquo;. The four settings represent three different approaches to digital library implementation: making digital library resources available from existing computer systems in people's offices and the library (a traditional approach); making computer systems, and hence digital libraries, available in shared spaces (in this case, hospital wards); and employing information intermediaries to work with staff and library resources. These different approaches engendered different perceptions of the technology. The traditional approach produced perceptions of technology as being irrelevant for current needs and community practices. Making technology available within shared physical space but with poor design, support, and implementation procedures was widely perceived as a threat to current organizational structures. In contrast, technology implemented within the community which could adapt and change practices according to individual and group needs, supported by an information intermediary, was seen as empowering to both the community and the individual. We relate the findings to a discussion of evolutionary and revolutionary approaches to design and to the concept of communities of practice.
ID:310
CLASS:4
Title: Digital libraries' support for the user's 'information journey'
Abstract: The temporal elements of users' information requirements are a continually confounding aspect of digital library design. No sooner have users' needs been identified and supported than they change. This paper evaluates the changing information requirements of users through their 'information journey' in two different domains (health and academia). In-depth analysis of findings from interviews, focus groups and observations of 150 users have identified three stages to this journey: information initiation, facilitation (or gathering) and interpretation. The study shows that, although digital libraries are supporting aspects of users' information facilitation, there are still requirements for them to better support users' overall information work in context. Users are poorly supported in the initiation phase, as they recognize their information needs, especially with regard to resource awareness; in this context, interactive press-alerts are discussed. Some users (especially clinicians and patients) also require support in the interpretation of information, both satisfying themselves that the information is trustworthy and understanding what it means for a particular individual.
ID:311
CLASS:4
Title: A generic alerting service for digital libraries
Abstract: Users of modern digital libraries (DLs) can keep themselves up-to-date by searching and browsing their favorite collections, or more conveniently by resorting to an alerting service. The alerting service notifies its clients about new or changed documents. Proprietary and mediating alerting services fail to fluidly integrate information from differing collections. This paper analyses the conceptual requirements of this much-sought after service for digital libraries. We demonstrate that the differing concepts of digital libraries and its underlying technical design has extensive influence (a) the expectations, needs and interests of users regarding an alerting service, and (b) on the technical possibilities of the implementation of the service. Our findings will show that the range of issues surrounding alerting services for digital libraries, their design and use is greater than one may anticipate. We also show that, conversely, the requirements for an alerting service have considerable impact on the concepts of DL design. Our findings should be of interest for librarians as well as system designers. We highlight and discuss the far-reaching implications for the design of, and interaction with, libraries. This paper discusses the lessons learned from building such a distributed alerting service. We present our prototype implementation as a proof-of-concept for an alerting service for open DL software.
ID:312
CLASS:4
Title: Universal access architecture for digital libraries
Abstract: In this paper we present a universal access architecture for digital libraries. Our architecture supports traditional fixed clients and mobile clients addressing the connection adaptation and limited resources challenges presented by mobile devices. We describe the requirements of universally available personal digital libraries and illustrate their applicability with a user scenario. These requirements are addressed by our universal access architecture, which targets to support multiple device access, including mobile devices. The main components of the architecture are the Client-Side Applications, the Data Server and the Mobile Communication Middleware (MCM). Our work has focused on the mobile connection support provided by the interaction of mobile clients with the MCM, obtaining a constant response rate in spite of variability of network conditions. The architecture of a mobile software client that benefits from these mechanisms is described and supplemented with implementation notes showing how-in spite of the limited computing resources of mobile devices-it can interact with a data server that has not been designed to support client mobility via adaptation techniques implemented in a middleware.
ID:313
CLASS:4
Title: You can lead a horse to water: teacher development and use of digital library resources
Abstract: This article presents findings from approximately 150 users who created instructional projects using educational digital library resources. One hundred of these users were teachers participating in professional development workshops on the topic of digital libraries. Our iterative approach to tool and workshop development and implementation was based on a framework that characterizes several input, output, and process variables affecting dissemination of such technologies in educational contexts. Data sources involved a mix of qualitative and quantitative methods, including electronic surveys, interviews, participant observations, and server log file and artifact analyses. These multiple and complementary levels of analyses reveal that despite teachers reporting great value in learning resources and educational digital libraries, significant and lasting impact on teaching practice remains difficult to obtain.
ID:314
CLASS:4
Title: Analytical usability evaluation for digital libraries: a case study
Abstract: There are two main kinds of approach to considering usability of any system: empirical and analytical. Empirical techniques involve testing systems with users, whereas analytical techniques involve usability personnel assessing systems using established theories and methods. We report here on a set of studies in which four different techniques were applied to various digital libraries, focusing on the strengths, limitations and scope of each approach. Two of the techniques, Heuristic Evaluation and Cognitive Walkthrough, were applied in text-book fashion, because there was no obvious way to contextualize them to the Digital Libraries (DL) domain. For the third, Claims Analysis, it was possible to develop a set of re-usable scenarios and personas that relate the approach specifically to DL development. The fourth technique, CASSM, relates explicitly to the DL domain by combining empirical data with an analytical approach. We have found that Heuristic Evaluation and Cognitive Walkthrough only address superficial aspects of interface design (but are good for that), whereas Claims Analysis and CASSM can help identify deeper conceptual difficulties (but demand greater skill of the analyst). However, none fit seamlessly with existing digital library development practices, highlighting an important area for further work to support improved usability.
ID:315
CLASS:4
Title: FRBR: enriching and integrating digital libraries
Abstract: FRBR (Functional Requirements for Bibliographic Records) is a promising framework for supporting rich indexation, and therefore rich interaction, in digital libraries. However, it is poorly reported in the digital library research literature and practical examples of its use are seldom discussed. In this paper, we introduce an implemented architecture for FRBR support that can supplement existing digital library systems. We also demonstrate the benefits gained by the user when FRBR data is used to enrich the user's interaction with the digital library.
ID:316
CLASS:4
Title: The Web-DL environment for building digital libraries from the Web
Abstract: The Web contains a huge volume of unstructured data, which is difficult to manage. In digital libraries, on the other hand, information is explicitly organized, described, and managed. Community-oriented services are built to attend specific information needs and tasks. In this paper, we describe an environment, Web-DL, that allows the construction of digital libraries from the Web. The Web-DL environment will allow us to collect data from the Web, standardize it, and publish it through a digital library system. It provides support to services and organizational structure normally available in digital libraries, but benefiting from the breadth of the Web contents. We experimented with applying the Web-DL environment to the Networked Digital Library of Theses and Dissertations (NDLTD), thus demonstrating that the rapid construction of DLs from the Web is possible. Also, Web-DL provides an alternative as a largescale solution for interoperability between independent digital libraries.
ID:317
CLASS:4
Title: Patron-augmented digital libraries
Abstract: Digital library research is mostly focused on the generation of large collections of multimedia resources and state-of-the-art tools for their indexing and retrieval. However, digital libraries should provide more than advanced collection maintenance and retrieval services since the ultimate goal of any (academic) library is to serve the scholarly needs of its users. This paper begins by presenting a case for digital scholarship in which patrons perform all scholarly work electronically. A proposal is then made for patron-augmented digital libraries (PADLs), a class of digital libraries that supports the digital scholarship of its patrons. Finally, a prototype PADL (called Synchrony) providing access to video segments and associated textual transcripts is described. Synchrony allows patrons to search the library for artifacts, create annotations/original compositions, integrate these artifacts to form synchronized mixed text and video presentations and, after suitable review, publish these presentations into the digital library if desired. A study to evaluate the PADL concept and the usability of Synchrony is also discussed. The study revealed that participants were able to use Synchrony for the authoring and publishing of presentations and that attitudes toward PADLs were generally positive.
ID:318
CLASS:4
Title: Digital libraries, value, and productivity
Abstract: A digital library is popularly viewed an electronic version of a public library. But replacing paper by electronic storage leads to three major differences: storage in digital form, direct communication to obtain material, and copying from a master version. These differences in turn lead to a plethora of further differences, so that eventually the digital library no longer mimics the traditional library. Furthermore, a library is only element in the process of creating, storing, culling, accessing, selecting, and distributing information to customers. While the technical focus of digital library research is on the central functions of storage and access, major changes will occur in the interaction within the new systems.
ID:319
CLASS:4
Title: Tacit user and developer frames in user-led collection development: the case of the digital water education library
Abstract: This paper discusses the impact that developers' and users' tacit understandings can have on digital library development. It draws on three years of ethnographic research with the Digital Water Education Library (DWEL) that focused on the observation, collection, and analysis of the project's face-to-face and electronic organizational communication. The DWEL project involved formal and informal educators in the development of its collection, and experienced problems at the start of the project with getting these educators to complete their cataloguing tasks. The research showed that despite having spent several days in face-to-face workshops, the project's PIs and the educators had different tacit understandings of what digital libraries were, that were impeding the project's organizational communication and workflow. I describe how these differences were identified and analyzed, and subsequently addressed and mediated through the design and development of online tools that acted as boundary objects between the PIs and the educators.
ID:320
CLASS:4
Title: What leads to acceptance of digital libraries?
Abstract: While millions of dollars have been spent building digital libraries, research indicates that millions of potential users may still be ignoring them.
ID:321
CLASS:4
Title: Understanding educator perceptions of "quality" in digital libraries
Abstract: The purpose of the study was to identify educators' expectations and requirements for the design of educational digital collections for classroom use. A series of five focus groups was conducted with practicing teachers, pre-service teachers, and science librarians, drawn from different educational contexts (i.e., K-5, 6--12, College). Participants' expect that the added value of educational digital collections is the provision of: (1) 'high quality' teaching and learning resources, and (2) additional contextual information beyond that in the resource. Key factors that influence educators' perceptions of quality were identified: scientific accuracy, bias, advertising, design and usability, and the potential for student distraction. The data showed that participants judged these criteria along a continuum of tolerance, combining consideration of several factors in their final judgements. Implications for collections accessioning policies, peer review, and digital library service design are discussed.
ID:322
CLASS:4
Title: Quality of service in multimedia digital libraries
Abstract: There is currently considerable interest in developing multimedia digital libraries. However, it has become clear that existing architectures for management systems do not support the particular requirements of continuous media types. This is particularly the case in the important area of quality of service support. In this correspondence, we discuss quality of service issues within digital libraries and present a reference architecture able to support some quality aspects.
ID:323
CLASS:4
Title: Curriculum development for digital libraries
Abstract: The Virginia Tech Department of Computer Science (VT CS) and the University of North Carolina at Chapel Hill School of Information and Library Science (UNC SILS) have launched a curriculum development project in the area of digital libraries. Educational resources will be developed based on the ACM/IEEE-CS Computing Curriculum 2001. Lesson plans and modules will be developed in a variety of areas (that cover the topics of papers and conference sessions in the field), evaluated by experts in those areas, and then pilot tested in CS and LIS courses. An analysis of papers on digital library-related topics from several corpora was performed, to identify the areas in which more and less work has already been performed on these topics; this analysis will guide the initial stages of this curriculum development.
ID:324
CLASS:4
Title: Probabilistic, object-oriented logics for annotation-based retrieval in digital libraries
Abstract: In this paper we introduce POLAR, a probabilistic object-oriented logical framework for annotation-based information retrieval. In POLAR, the knowledge about digital objects, annotations and their relationships in a digital library repository can be modelled considering certain characteristics of annotations and annotated objects. Insights about these characteristics are gained by an analysis of the annotation models behind existing systems and a discussion of an object-oriented, logical view on relevant objects in a digital library. Retrieval methods applied in a digital library should take annotations into account to satisfy users' information needs. POLAR thus supports a wide range of flexible and powerful annotation-based fact and content queries by making use of knowledge and relevance augmentation. An evaluation of our approach on email discussions shows performance improvements when annotation characteristics are considered.
ID:325
CLASS:4
Title: 5SL: a language for declarative specification and generation of digital libraries
Abstract: Digital libraries (DLs) are among the most complex kinds of information systems, due in part to their intrinsic multi disciplinary nature. Nowadays DLs are built within monolithic, tightly integrated, and generally inflexible systems -- or by assembling disparate components together in an ad-hoc way, with resulting problems in interoperability and adaptability. More importantly, conceptual modeling, requirements analysis, and software engineering approaches are rarely supported, making it extremely difficult to tailor DL content and behavior to the interests, needs, and preferences of particular communities. In this paper, we address these problems. In particular, we present 5SL, a declarative language for specifying and generating domain-specific digital libraries. 5SL is based on the 5S formal theory for digital libraries and enables high-level specification of DLs in five complementary dimensions, including: the kinds of multimedia information the DL supports (Stream Model); how that information is structured and organized (Structural Model); different logical and presentational properties and operations of DL components (Spatial Model); the behavior of the DL (Scenario Model); and the different societies of actors and managers of services that act together to carry out the DL behavior (Societal Model). The practical feasibility of the approach is demonstrated by the presentation of a 5SL digital library generator for the MARIAN digital library system.
ID:326
CLASS:4
Title: Metis: lightweight, flexible, and Web-based workflow services for digital libraries
Abstract: The Metis project is developing workflow technology designed for use in digital libraries by avoiding the assumptions made by traditional workflow systems. In particular, digital libraries have highly distributed sets of stake-holders who nevertheless must work together to perform shared activities. Hence, traditional assumptions that all members of a workflow belong to the same organization, work in the same fashion, or have access to similar computing platforms are invalid. The Metis approach makes use of event-based workflows to support the distributed nature of digital library workflow and employs techniques to make the resulting technology lightweight, flexible, and integrated with the Web. This paper describes the conceptual framework behind the Metis approach as well as a prototype which implements the framework. The prototype represents a "proof-of-concept" of the Metis framework and approach as we show how it can both model and execute a peer review workflow drawn from a "real-world" digital library. After describing related work, the paper concludes with a discussion of future research opportunities in the area of digital library workflow and outlines how Metis is being deployed to a small set of digital libraries for additional evaluation.
ID:327
CLASS:4
Title: CiteSeer-API: towards seamless resource location and interlinking for digital libraries
Abstract: We introduce CiteSeer-API, a public API to CiteSeer-like services. CiteSeer-API is SOAP/WSDL based and allows for easy programmatical access to all the specific functionalities offered by CiteSeer services, including full text search of documents and citations and citation-based document discovery. In order to enable operability and interlinking with arbitrary software agents and digital library systems, CiteSeer-API uses digital content signatures to create system-independent handles for the Document, Citation and Group resources of CiteSeer servers. We discuss specific functionalities of CiteSeer-API that take advantage of these handlers in order to enable seamless location of CiteSeer resources. Finally we argue that the digital signature scheme used by CiteSeer-API is well suited for the creation of machine-usable semantic descriptions of digital library services which is the key toward seamless discovery and integration of services such as CiteSeer-API. CiteSeer-API is currently showcased on CiteSeer.IST, the CiteSeer server of the School of Information Science and Technology at the Pennsylvania State University.
ID:328
CLASS:4
Title: Visual exploration of large collections in digital libraries
Abstract: Though conceptually very powerful, Visual Information Seeking (VIS) has been demonstrated with only relatively small collections of a few thousand items, which makes it possible to keep entire collections in main memory and perform recalculations and rendering in real time as the user manipulates sliders and filters in an interactive fashion. For vast digital libraries, collections may include hundreds of thousands, millions or even more items. We describe EVA2D, a visualization environment that implements and extends the notion of Visual Information Seeking (VIS) to facilitate the exploration of large collections comprised by digital libraries. This is accomplished by introducing four main features into EVA2D: pre-computation of graphical data, simultaneous bi-dimensional selection (direct zooming), precision filtering mechanisms, and quasi- immediate feedback.
ID:329
CLASS:4
Title: Supporting personal collections across digital libraries in spatial hypertext
Abstract: Creating, maintaining, or using a digital library requires the manipulation of digital documents. Information workspaces provide a visual representation allowing users to collect, organize, annotate, and author information. The Visual Knowledge Builder(VKB) helps users access, collect, annotate, and combine materials from digital libraries and other sources into a personal information workspace VKB has been enhanced to include direct search interfaces for NSDL and Google. Users create a visualization of search results while selecting and organizing materials for their current activity. Additionally, metadata applicators have been added to VKB. This interface allows the rapid addition of metadata to documents and aids the user in the extraction of existing metadata for application to other documents. A study was performed to compare the selection and organization of documents in VKB to the commonly used tools ofa Web browser and a word processor. This study shows the value of visual workspaces for such effort but points to the need for subdocument level objects, ephemeral visualizations, and support for moving from visual representations to metadata.
ID:330
CLASS:4
Title: Towards knowledge-based digital libraries
Abstract: From the standpoint of satisfying human's information needs, the current digital library (DL) systems suffer from the following two shortcomings: (i) inadequate high-level cognition support; (ii) inadequate knowledge sharing facilities. In this article, we introduce a two-layered digital library architecture to support different levels of human cognitive acts. The model moves beyond simple information searching and browsing across multiple repositories, to inquiry of knowledge about the contents of digital libraries. To address users' high- order cognitive requests, we propose an information space consisting of a knowledge subspace and a document subspace. We extend the traditional indexing and searching schema of digital libraries from keyword-based to knowledge-based by adding knowledge to the documents into the DL information space. The distinguished features of such enhanced DL systems in comparison with the traditional knowledge-based systems are also discussed.
ID:331
CLASS:4
Title: Moving digital libraries into the student learning space: The GetSmart experience
Abstract: The GetSmart system was built to support theoretically sound learning processes in a digital library environment by integrating course management, digital library, and concept mapping components to support a constructivist, six-step, information search process. In the fall of 2002 more than 100 students created 1400 concept maps as part of selected computing classes offered at the University of Arizona and Virginia Tech. Those students conducted searches, obtained course information, created concept maps, collaborated in acquiring knowledge, and presented their knowledge representations. This article connects the design elements of the GetSmart system to targeted concept-map-based learning processes, describes our system and research testbed, and analyzes our system usage logs. Results suggest that students did in fact use the tools in an integrated fashion, combining knowledge representation and search activities. After concept mapping was included in the curriculum, we observed improvement in students' online quiz scores. Further, we observed that students in groups collaboratively constructed concept maps with multiple group members viewing and updating map details.
ID:332
CLASS:4
Title: Panorama: extending digital libraries with topical crawlers
Abstract: A large amount of research, technical and professional documents are available today in digital formats Digital libraries are created to facilitate search and retrieval of information supplied by the documents. These libraries may span an entire area of interest (e.g., computer science) or be limited to documents within a small organization. While tools that index, classify, rank and retrieve documents from such libraries are important, it would be worthwhile to complement these tools with information available on the Web. We propose one such technique that uses a topical crawler driven by the information extracted from a research document. The goal of the crawler is to harvest a collection of Web pages that are focused on the topical subspaces associated with the given document. The collection created through Web crawling is further processed using lexical and linkage analysis. The entire process is automated and uses machine learning techniques to both guide the crawler as well as analyze the collection it fetches. A report is generated at the end that provides visual cues and information to the researcher.
ID:333
CLASS:4
Title: Evaluating digital libraries
Abstract: "So far, evaluation has not kept pace with efforts in digital libraries (or with digital libraries themselves), has not become part of their integral activity, and has not been even specified as to what it means, and how to do it." - [1]Conducting a comprehensive evaluation of a digital library requires a "triangulation" approach including multiple models, procedures, and tools. Carrying out valid evaluations of digital libraries in a timely and efficient manner is the focus of this tutorial. Why is evaluation of digital libraries so important? Each year sees the introduction of new digital libraries promoted as valuable resources for education and other needs. Yet systematic evaluation of the implementation and efficacy of these digital library systems is often lacking. This tutorial is specifically designed to establish evaluation as a key strategy throughout the design, development, and implementation of digital libraries. The tutorial focuses on a decision-oriented model for evaluating digital libraries using multiple methods such as: service evaluation, usability evaluation, information retrieval, biometrics evaluation, transaction log analysis survey methods, interviews and focus groups, observations, and experimental methods. Participants in this tutorial will learn how to implement models and procedures for evaluating digital libraries at all levels of education. The tutorial includes presentations with actual case studies that are focused on a variety of digital library evaluation strategies. Participants will also receive a copy of Evaluating Digital Libraries: A User-Friendly Guide.
ID:334
CLASS:4
Title: Assembling and enriching digital library collections
Abstract: People who create digital libraries need to gather together the raw material, add metadata as necessary, and design and build new collections. This paper sets out the requirements for these tasks and describes a new tool that supports them interactively, making it easy for users to create their own collections from electronic files of all types. The process involves selecting documents for inclusion, coming up with a suitable metadata set, assigning metadata to each document or group of documents, designing the form of the collection in terms of document formats, searchable indexes, and browsing facilities, building the necessary indexes and data structures, and putting the collection in place for others to use. Moreover, different situations require different workflows, and the system must be flexible enough to cope with these demands. Although the tool is specific to the Greenstone digital library software, the underlying ideas should prove useful in more general contexts.
ID:335
CLASS:4
Title: Annotating illuminated manuscripts: an effective tool for research and education
Abstract: The aim of this paper is to report the research results of an ongoing project that deals with the exploitation of a digital archive of drawings and illustrations of historic documents for research and educational purposes. According to the results on a study of user requirements, we have designed tools to provide researchers with innovative ways for accessing the digital manuscripts, sharing, and transferring knowledge in a collaborative environment. We have found that the results of scientific research on the relationships between images of manuscripts produced over the centuries can be rendered explicit by using annotations. For this purpose, a taxonomy for linking annotation is introduced, together with a conceptual schema which represents annotations and links them to digital objects.
ID:336
CLASS:4
Title: Enhancing digital libraries with TechLens+
Abstract: The number of research papers available is growing at a staggering rate. Researchers need tools to help them find the papers they should read among all the papers published each year. In this paper, we present and experiment with hybrid recommender algorithms that combine Collaborative Filtering and Content-based. Filtering to recommend research papers to users. Our hybrid algorithms combine the strengths of each filtering approach to address their individual weaknesses. We evaluated our algorithms through offline experiments on a database of 102, 000 research papers, and through an online experiment with 110 users. For both experiments we used a dataset created from the CiteSeer repository of computer science research papers. We developed separate English and Portuguese versions of the interface and specifically recruited American and Brazilian users to test for cross-cultural effects. Our results show that users value paper recommendations, that the hybrid algorithms can be successfully combined, that different algorithms are more suitable for recommending different kinds of papers, and that users with different levels of experience perceive recommendations differently These results can be applied to develop recommender systems for other types of digital libraries.
ID:337
CLASS:4
Title: Factors motivating use of digital libraries
Abstract: Knowledge about how users use digital libraries and their contents is inextricably tied to a library's ability to sustain itself, grow its services and meet the needs of its users. This paper reports on the preliminary results of a study of how science, technology, engineering and mathematics (STEM) instructors perceive and use digital libraries. Preliminary findings indicate that: they do not differentiate between digital libraries and other kinds of content that comes from the web, they seek content to supplement traditional teaching methods and their reliance on Google and personal networks impedes their ability to recall the primary sources of useful content.
ID:338
CLASS:4
Title: Directions for hypertext research: exploring the design space for interactive scholarly communication
Abstract: This paper is a "call to arms" for the community to take up Van Bush's original challenge of effecting a transformation of scholarly communications and record keeping. It argues for the necessity of an interactive scholarly communication research agenda by briefly reviewing the rapid development of alternative authoring and publishing models. Seven dimensions of interactive communication that delineate a design space for the area are described. Previous work and existing new media are used to initially populate the design space and show opportunities for new research directions. VKB spaces, Synchrony PADLs, and Walden's paths are used as foils for describing new media for interactive scholarly communication. This leads to a brief discussion of uncovered areas in the design space and open research questions. A community developed framework for future interactive scholarly communications would be a major contribution and is put forth as the overall goal.
ID:339
CLASS:4
Title: The ADEPT digital library architecture
Abstract: The Alexandria Digital Earth ProtoType (ADEPT) architecture is a framework for building distributed digital libraries of georeferenced information. An ADEPT system comprises one or more autonomous libraries, each of which provides a uniform interface to one or more collections, each of which manages metadata for one or more items. The primary standard on which the architecture is based is the ADEPT bucket framework, which defines uniform client-level metadata query services that are compatible with heterogeneous underlying collections. ADEPT functionality strikes a balance between the simplicity of Web document delivery and the richness of Z39.50. The current ADEPT implementation runs as servlet-based middleware and supports collections housed in arbitrary relational databases.
ID:340
CLASS:4
Title: Resolving the unencoded character problem for chinese digital libraries
Abstract: Constructing a Chinese digital library, especially for a historical article archiving, is often bothered by the small character sets supported by the current computer systems. This paper is aimed at resolving the unencoded character problem with a practical and composite approach for Chinese digital libraries. The proposed approach consists of the glyph expression model, the glyph structure database, and supporting tools. With this approach, the following problems can be resolved. First, the extensibility of Chinese characters can be preserved. Second, it would be as easy to generate, input, display, and search unencoded characters as existing ones. Third, it is compatible with existing encoding schemes that most computers use.This approach has been utilized by organizations and projects in various application domains including archeology, linguistics, ancient texts, calligraphy and paintings, and stone and bronze rubbings. For example, in Academia Sinica, a very large full-text database of ancient texts called Scripta Sinica has been created using this approach. The Union Catalog of National Digital Archives Project (NDAP) dealt with the unencoded characters encountered when merging the metadata of 12 different thematic domains from various organizations. Also, in Bronze Inscriptions Research Team (BIRT) of Academia Sinica, 3,459 Bronze Inscriptions were added, which is very helpful to the education and research in historic linguistics.
ID:341
CLASS:4
Title: G-Portal: a map-based digital library for distributed geospatial and georeferenced resources
Abstract: As the World Wide Web evolves into an immense information network, it is tempting to build new digital library services and expand existing digital library services to make use of web content. In this paper, we present the design and implementation of G-Portal, a web portal that aims to provide digital library services over geospatial and georeferenced content found on the World Wide Web. G-Portal adopts a map-based user interface to visualize and manipulate the distributed geospatial and georeferenced content. Annotation capabilities are supported, allowing users to contribute geospatial and georeferenced objects as well as their associated metadata. The other features included in G-Portal's design are query support, content classification, and content maintenance. This paper will mainly focus on the architecture design, visualization and annotation capabilities of G-Portal.
ID:342
CLASS:4
Title: Translating unknown cross-lingual queries in digital libraries using a web-based approach
Abstract: Users' cross-lingual queries to a digital library system might be short and not included in a common translation dictionary (unknown terms). In this paper, we investigate the feasibility of exploiting the Web as the corpus source to translate unknown query terms for cross-language information retrieval (CLIR) in digital libraries. We propose a Web-based term translation approach to determine effective translations for unknown query terms by mining bilingual search-result pages obtained from a real Web search engine. This approach can enhance the construction of a domain-specific bilingual lexicon and benefit CLIR services in a digital library that only has monolingual document collections Very promising results have been obtained in generating effective translation equivalents for many unknown terms, including proper nouns, technical terms and Web query terms.
ID:343
CLASS:4
Title: How fast is too fast?: evaluating fast forward surrogates for digital video
Abstract: To support effective browsing, interfaces to digital video libraries should include video surrogates (i.e., smaller objects that can stand in for the videos in the collection, analogous to abstracts standing in for documents). The current study investigated four variations (i.e., speeds) of one form of video surrogate: a fast forward created by selecting every Nth frame from the full video. In addition, it tested the validity of six measures of user performance when interacting with video surrogates. Forty-five study participants interacted with all four versions of the fast forward surrogate, and completed all six performance tasks with each. Surrogate speed affected performance on four of the measures: object recognition (graphical), action recognition, linguistic gist comprehension (full text), and visual gist comprehension. Based on these results, we recommend a fast forward default speed of 1:64 of the original video keyframes. In addition, users should control the choice of fast forward speed to adjust for content characteristics and personal preferences.
ID:344
CLASS:4
Title: Digital library services for authors of learning materials
Abstract: Digital libraries, particularly those designed to meet the needs of educators and students, focus their primary services on the needs of their end users [1]. In this paper, we introduce and discuss the types of services authors of the materials cataloged within this type of digital library expect, or may find useful. Results from a study of authors cataloged in NEEDS - a national engineering education digital library guide this discussion.
ID:345
CLASS:4
Title: Digital music libraries - research and development
Abstract: Digital music libraries provide enhanced access and functionality that  facilitates scholarly research and education.  This panel will present a report on the progress of several major research and development projects in digital music libraries.
ID:346
CLASS:4
Title: Dynamic digital libraries for children
Abstract: The majority of current digital libraries (DLs) are not designed forchildren. For DLs to be popular with children, they need to be fun, easy-to-use and empower them, whether as readers or authors. This paper describes a new childrens DL emphasizing its design and evaluation, working with the children (11-14 year olds) as design partners and testers. A truly participatory process was used, and observational study was used as a means of refinement to the initial design of the DL prototype. In contrast with current DLs, the childrens DL provides both a static as well as a dynamic environment to encourage active engagement of children in using it. Design, implementation and security issues are also raised.
ID:347
CLASS:4
Title: Clusters, meta-clusters, and digital libraries: digital libraries for scientific, engineering and medical applications
Abstract: We describe the architectural design and our early experience with scientific, engineering, and medical digital libraries that we have developed as part of the National Scalable Cluster Project (NSCP). Our goal is to develop an infrastructure for scalable, interactive digital libraries supporting high performance computing and high performance data management which interfaces to and interoperates with the World Wide Web (WWW).
ID:348
CLASS:4
Title: An authorization system for digital libraries
Abstract: Digital Libraries (DLs) introduce several challenging requirements with respect to the formulation, specification, and enforcement of adequate data protection policies. Unlike conventional database environments, a DL environment typically is characterized by a dynamic subject population, often making accesses from remote locations, and by an extraordinarily large amount of multimedia information, stored in a variety of formats. Moreover, in a DL environment, access policies are often specified based on subject qualifications and characteristics, rather than subject identity. Traditional authorization models are not adequate to meet access control requirements of DLs. In this paper, we present a Digital Library Authorization System (DLAS). DLAS employs a content-based authorization model, called a Digital Library Authorization Model (DLAM) which was proposed in previous work [1].
ID:349
CLASS:4
Title: A multi-view intelligent editor for digital video libraries
Abstract: Silver is an authoring tool that aims to allow novice users to edit di gital video. The goal is to make editing of digital video as easy as text editing. Silver provides multiple coordinated views, including project, source, outline, subject, storyboard, textual transcript and timeline views. Selections and edits in any view are synchronized with all other views. A variety of recognition algorithms are applied to the video and audio content and then are used to aid in the editing tasks. The Informedia Digital Library supplies the recognition algorithms and metadata used to support intelligent editing, and Informedia also provides search and a repository. The metadata includes shot boundaries and a time-synchronized transcript, which are used to support intelligent selection and intelligent cut/copy/paste.
ID:350
CLASS:4
Title: An ethnographic study of music information seeking: implications for the design of a music digital library
Abstract: At present, music digital library systems are being developed based on anecdotal evidence of user needs, intuitive feelings for user information seeking behavior, and a priori assumptions of typical usage scenarios. Emphasis has been placed on basic research into music document representation, efficient searching, and audio-based searching, rather than on exploring the music information needs or information behavior of a target user group. This paper focuses on eliciting the native music information strategies employed by people searching for popular music (that is, music sought for recreational or enjoyment purposes rather than to support a serious or scientific exploration of some aspect of music). To this end, we conducted an ethnographic study of the searching/browsing techniques employed by people in the researchers local communities, as they use two common sources of music: the public library and music stores. We argue that the insights provided by this type of study can inform the development of searching/browsing support for music digital libraries.
ID:351
CLASS:4
Title: Finding a catalog: generating analytical catalog records from well-structured digital texts
Abstract: One of the criticisms library users often make of catalogs is that they rarely include information below the bibliographic level. It is generally impossible to search a catalog for the titles and subjects of particular chapters or volumes. There has been no way to add this information to catalog records without exponentially increasing the workload of catalogers. At the same time, well-structured full-text XML transcriptions of printed works are becoming increasingly available. This paper describes how existing investments in full text digitization and structural markup combined with current named-entity extraction technology can efficiently generate the detailed level of catalog data that users want, at no significant additional cost. This system is demonstrated on an existing digital collection within the Perseus Digital Library.
ID:352
CLASS:4
Title: Integrating digital libraries and electronic publishing in the DART project
Abstract: The Digital Anthropology Resources for Teaching (DART) project integrates the content acquisition and cataloging initiatives of a federated digital repository with the development of scholarly publications and the creation of digital tools to facilitate classroom teaching. The project's technical architecture and unique publishing model create a teaching context where students move easily between primary and secondary source material and between authored environments and independent research, and raise specific issues with regard to metadata, object referral, rights, and exporting content. The model also addresses the loss of provenance and catalog information for digital objects embedded in "born-digital" publications. The DART project presents a practical methodology to combine repository and publication that is both exportable and discipline-neutral.
ID:353
CLASS:4
Title: The robustness of content-based search in hierarchical peer to peer networks
Abstract: Hierarchical &#60;i>peer to peer&#60;/i> networks with multiple directory services are an important architecture for large-scale file sharing due to their effectiveness and efficiency. Recent research argues that they are also an effective method of providing large-scale content-based federated search of text-based digital libraries. In both cases the directory services are critical resources that are subject to attack or failure, but the latter architecture may be particularly vulnerable because content is less likely to be replicated throughout the network.
ID:354
CLASS:4
Title: What's there and what's not?: focused crawling for missing documents in digital libraries
Abstract: Some large scale topical digital libraries, such as CiteSeer, harvest online academic documents by crawling open-access archives, university and author homepages, and authors' self-submissions. While these approaches have so far built reasonable size libraries, they can suffer from having only a portion of the documents from specific publishing venues. We propose to use alternative online resources and techniques that maximally exploit other resources to build the complete document collection of any given publication venue.We investigate the feasibility of using publication metadata to guide the crawler towards authors' homepages to harvest what is missing from a digital library collection. We collect a real-world dataset from two Computer Science publishing venues, involving a total of 593 unique authors over a time frame of 1998 to 2004. We then identify the missing papers that are not indexed by CiteSeer. Using a fully automatic heuristic-based system that has the capability of locating authors' homepages and then using focused crawling to download the desired papers, we demonstrate that it is practical to harvest using a focused crawler academic papers that are missing from our digital library. Our harvester achieves a performance with an average recall level of 0.82 overall and 0.75 for those missing documents. Evaluation of the crawler's performance based on the harvest rate shows definite advantages over other crawling approaches and consistently outperforms a defined baseline crawler on a number of measures.
ID:355
CLASS:4
Title: Building domain-specific web collections for scientific digital libraries: a meta-search enhanced focused crawling method
Abstract: Collecting domain-specific documents from the Web using focused crawlers has been considered one of the most important strategies to build digital libraries that serve the scientific community. However, because most focused crawlers use local search algorithms to traverse the Web space, they could be easily trapped within a limited sub-graph of the Web that surrounds the starting URLs and build domain-specific collections that are not comprehensive and diverse enough to scientists and researchers. In this study, we investigated the problems of traditional focused crawlers caused by local search algorithms and proposed a new crawling approach, meta-search enhanced focused crawling, to address the problems. We conducted two user evaluation experiments to examine the performance of our proposed approach and the results showed that our approach could build domain-specific collections with higher quality than traditional focused crawling techniques.
ID:356
CLASS:4
Title: Facilitating middle school students' sense making process in digital libraries
Abstract: Previous research on using digital libraries in science classrooms indicated that middle school students tend to passively find answers rather than actively make sense of information they find in digital libraries. In response to this challenge, we designed a scaffolded software tool, the Digital IdeaKeeper, to support middle school students in making sense of digital library resources during online inquiry. This study describes preliminary results from a study to see how middle school students use different IdeaKeeper features. Initial data analysis indicates that IdeaKeeper can facilitate online learners to engage in sense-making process in online inquiry.
ID:357
CLASS:4
Title: Extending the role of the digital library: computer support for creating articles
Abstract: A digital library, together with its users and its contents, does not exist in isolated splendour; nor in hypertext terms is it merely the intertextual relationships between its texts. There is a cycle of activities which provides the context for the library's existence, and which the library supports through its various roles of information access, discovery, storage, dissemination and preservation. This paper describes the role of digital library systems in the undertaking of science, and in particular in the context of the recent developments of the Grid for computer-supported scientific collaboration and Virtual Universities for computer-supported education. This paper focuses on a specific framework, the Dynamic Review Journal, which supports the development and dissemination of documents by assisting authors in collating and analysing experimental results, organising internal project discussions, and producing papers. By bridging the gap between the undertaking of experimental work and the dissemination of its results through electronic publication, this work addresses the cycle of activity in which a digital library rests.
ID:358
CLASS:4
Title: Indexing and searching tera-scale Grid-Based Digital Libraries
Abstract: The University of California, Berkeley and the University of Liverpool in conjunction with the San Diego Supercomputer Center are developing a framework for Grid-Based Digital Library systems and Information Retrieval Services (Cheshire3) that operates in both single-processor and distributed computing environments. In this paper we discuss some results of testing Grid-based parallel approaches in indexing and retrieval for a variety of information resources, ranging from small test collections like the TREC and INEX collections, to medium-scale metadata collections like Medline and a test version of University of California Online Union Catalog, MELVYL (with 15 million and 16.5 million records respectively) ranging up to large-scale collections like the US National Records and Archives Administration (NARA) Preservation Prototype. This paper examines our approaches to indexing and retrieving from these collections and the architecture of the system that supports them.
ID:359
CLASS:4
Title: Sharing encountered information: digital libraries get a social life
Abstract: As part of a more extensive study of reading-related practices, we have explored how people share information they encounter in their everyday reading as a complement to the more traditional digital library focus on sharing intentionally retrieved materials. In twenty contextual interviews in home and work place settings, we investigated how people encounter and save published material in the form of paper and electronic clippings. We found that sharing forms a significant use for encountered materials. Furthermore, the function of these clippings extends far beyond a simple exchange of content to inform the recipient; in fact, the content itself may have little immediate value to the recipient. We also found the practice to be ubiquitous: all of our participants had both shared clippings with others and received them themselves. Specifically, this paper reports on: (1) how sharing encountered items fits into the broader spectrum of clipping practices; (2) the function and value of the shared information; and (3) the social role of sharing the encountered information We conclude that from a technological standpoint, we should think beyond an email model for sharing encountered information and, from a social perspective, we should attend to how sharing this sort of material contributes to the strength of social ties outside of a traditional information needs framework.
ID:360
CLASS:4
Title: Digital libraries settling the score: 10 years hence and 10 before
Abstract: Six panelists and a moderator leverage knowledge of the first ten years of the digital libraries field, to suggest key future directions.
ID:361
CLASS:4
Title: 5SGraph demo: a graphical modeling tool for digital libraries
Abstract: The current demand from non-experts who wish to build digital libraries is strong worldwide. However, since DLs are complex systems, it usually takes a huge amount of effort and time to create and tailor a digital library to satisfy specific needs and requirements of target communities/societies. What is desired is a simplified modeling process and rapid generation of digital libraries. To enable this, digital libraries should be modeled with descriptive domain-specific languages [1]. In a domain-specific modeling language, the models are made up of elements representing concepts, rules, and terminology that are part of the domain world, as opposed to the code world or generic modeling languages (e.g., UML [2]). A visual modeling tool would be helpful to non-experts so they may model a digital library without knowing the theoretical foundations and the syntactical details of the descriptive language.In this demonstration, we present a domain-specific visual modeling tool, 5SGraph, aimed at modeling digital libraries. 5SGraph is based on a metamodel that describes DLs using the 5S theory [3]. The output from 5SGraph is a digital library model that is an instance of the metamodel, expressed in the 5S description language (5SL) [4].5SGraph presents the metamodel in a structured toolbox, and provides a top-down visual building environment for designers (see Figure 1). The visual proximity of the metamodel and instance model facilitates requirements gathering and simplifies the modeling process. Furthermore, 5SGraph maintains semantic constraints specified by the 5S metamodel and enforces these constraints over the instance model to ensure semantic consistency and correctness. 5SGraph enables component reuse to reduce the time and efforts of designers. 5SGraph also is designed to be flexible and extensible, able to accommodate and integrate several other complementary tools (e.g., to model scenarios or complex digital objects), reflecting the interdisciplinary nature of digital libraries. The tool has been tested with real users and several modeling tasks in a usability experiment [5] and its usefulness and learnability have been demonstrated.
ID:362
CLASS:4
Title: Digital libraries supporting digital government
Abstract: The needs of society have long been addressed through government resea rch support for new technologies-the Internet representing one example.  Today, under the rubric of digital government, federal agencies as well as state and local units of governments at all levels have begun to leverage the fruits of these research investments to better serve the needs of their constituencies.  Government agencies apply these technologies in a variety of settings including emergency response, health and safety regulation, financial management, data gathering, and hosts of information dissemination needs. In addition, governments are investigating ways to use technology to encourage citizen participation.  There is a growing digital government community of practice that strongly parallels the evolving digital library community.  These parallel developments are not surprising because libraries and governments share service missions for their overlapping constituencies.Governments at all levels create enormous volumes of information for use by citizens and have long depended on libraries to organize, disseminate, and preserve this public information.  There is an inextricable link between democratic government and libraries stemming from the 19th century creation of public libraries as democracys offer to citizens to learn, to grow, and to participate.  The idea of sharing knowledge to enable good citizenship engenders many cross-currents inherent in social-political policy, and today this idea is given new incarnation in the global Internet environment.  Digital library projects in national and local libraries were in many ways the precursors of digital government initiatives and it is particularly instructive to examine a selection of digital government projects through the lens of digital libraries.  This panel presents overviews of several digital government projects and initiatives that combine the technical and conceptual threads composing these mutuall
ID:363
CLASS:4
Title: How to avoid designing digital libraries: a scenario based approach
Abstract: Digital libraries are a rapidly evolving and diverse technology. From the history of technology, we know that there are no guarantees that "best" solutions prevail, even in the long-term (e.g., Basalla, 1988). The indeterminacies of technology evolution are probably increased when the pace of evolution is rapid and its scope and trajectory are uncertain. In such circumstances, we should avoid clinging to traditional niche concepts (which are necessarily, but often subtly, anchored in prior technology). We should instead attempt to manage and define new technology by analyzing and designing core user activities.
ID:364
CLASS:4
Title: From playful exhibits to LOM: lessons from building an exploratorium digital library
Abstract: The Exploratorium, an interactive hand-on science museum, is developing an online collection of science learning and teaching resources to better serve educators' needs for pedagogically-rich instructional resources via the Web. Several challenges arise when designing a digital library for formal K12 education audiences using the Learning Object Metadata standard. These problems are multiplied when attempting to catalog the wide variety of informal learning digital resources from the Exploratorium's ever growing website and exhibit-based resource collections. This paper shares key challenges and early solutions for the creation of an educational metadata scheme, new vocabularies, and strategies for retrofitting existing informal learning science resources into learning objects.
ID:365
CLASS:4
Title: Digital libraries: a brief introduction
Abstract: One advantage of reading the other domain columns before writing this one on digital libraries is seeing how interdependent all these different SIGGROUP threads really are. The rapid development of internetworking technology generally, and the World Wide Web specifically, simply magnifies these interdependencies. So while this column focuses on digital libraries, and not on cooperation, learning, work practices, or knowledge management, I feel that all these areas are mutually interdependent, and that advances in one will be felt in all. I expect that these domain columns will cross-reference each other.
ID:366
CLASS:4
Title: Partnership reviewing: a cooperative approach for peer review of complex educational resources
Abstract: Review of digital educational resources, such as course modules, simulations, and data analysis tools, can differ from review of scholarly articles, in the heterogeneity and complexity of the resources themselves. The Partnership Review Model, as demonstrated in two cases, appears to promote cooperative interactions between distributed resource reviewers, enabling reviewers to effectively divide up the task of reviewing complex resources with little explicit coordination. The shared structural outline of the resource made visible in the review environment enables participants to monitor other reviewers' actions and to thus target their efforts accordingly. This reviewing approach may be effective in educational digital libraries that depend on community volunteers for most of their reviewing.
ID:367
CLASS:4
Title: A study of user behavior in an immersive virtual environment for digital libraries
Abstract: In this paper we present a 2x3 factorial design study evaluating the   limits and differences on the behavior of 10 users when searching in a      virtual reality representation that mimics the arrangement of a traditional library. The focus of this study was the effect of clustering techniques    and query highlighting on search strategy users develop in the virtual      environment, and whether position or spatial arrangement influenced user    behavior. We found several particularities that can be attributed to the    differences in the VR environment.This study's results identify: 1) the    need of co-designing both spatial arrangement and interaction method; 2) adifficulty novice users faced when using clusters to identify commontopics; 3) the influence of position and distance on users' selection of collection items to inspect; and 4) that users did not search until found the best match, but only until they found a satisfactory match.
ID:368
CLASS:4
Title: Socially grounded engineering for digital libraries
Abstract: Our work embodies one approach to developing theories of use that can be embedded in programs and new ways of working. We argue that building digital libraries that work will require that systems design, development and deployment be grounded in use and done collaboratively with users, and we will describe our approach to accomplishing this as well as the issues and questions it raises.
ID:369
CLASS:4
Title: Customizing digital libraries for small screen devices
Abstract: In this paper we present a system that allows users to access digital libraries using small screen devices. Instead of providing users with a single hardcoded solution, we allow them to customize how the content is structured, formatted and viewed on the small display. The centre of our system is a tool that can be used to customize Greenstone Digital Library collections for small displays. To lower the entry level, this tool has been designed to provide an abstraction from Greenstone's low level architecture and other computing technologies, such as HTML and Java Script. We also place a strong emphasis on evaluation and incorporate users throughout the software development cycle. Lastly in the discussion, we speculate that by designing usable and customizable systems, there is the potential of breaking down the open source revenue model, which relies on providing services for systems that are hard to use and configure.
ID:370
CLASS:4
Title: Time as essence for photo browsing through personal digital libraries
Abstract: We developed two photo browsers for collections with thousands of time-stamped digital images. Modern digital cameras record photo shoot times, and semantically related photos tend to occur in bursts. Our browsers exploit the timing information to structure the collections and to automatically generate meaningful summaries. The browsers differ in how users navigate and view the structured collections. We conducted user studies to compare the two browsers and an un-summarized image browser. Our results show that exploiting the time dimension and appropriately summarizing collections can lead to significant improvements. For example, for one task category, one of our browsers enabled a 33% improvement in speed of finding given images compared to the commercial browser. Similarly, users were able to complete 29% more tasks when using this same browser.
ID:371
CLASS:4
Title: Workshop 1: visual interfaces to digital libraries - its past, present, and future
Abstract: The design of easy-to-use and informative visual interfaces to digital  libraries is an integral part to the advances of digital libraries. A wide range of approaches have been developed from a diverse spectrum of perspectives that focus on users and tasks to be supported, data to be modeled, and the efficiency of algorithms. Information visualization aims to exploit the human visual information processing system, especially with non-spatial data (such as documents and images typically found in digital libraries). Generally, information visualization examines semantic relationships intrinsic to an abstract information space and how they can be spatially navigated and memorized using similar cognitive processes to those that would apply during interactions with the real world. This workshop promotes the convergence of information visualization and digital libraries. It brings together researchers and practitioners in the areas of information visualization, digital libraries, human-computer interaction, library and information science, and computer science to identify the most important issues in the past and the present, and what should be done in the future.
ID:372
CLASS:4
Title: A new framework for building digital library collections
Abstract: This paper introduces a new framework for building digital library collections and contrasts it with existing systems. It describes a significant new step in the development of a widely-used open-source digital library system, Greenstone, which has evolved over many years. It is supported by a fresh implementation, which forced us to rethink the entire design rather than making incremental improvements. The redesign capitalizes on the best ideas from the existing system, which have been refined and developed to open new avenues through which digital librarians can tailor their collections. We demonstrate its flexibility by showing how digital library collections can be extended and altered to satisfy new requirements.
ID:373
CLASS:4
Title: The effectiveness of automatically structured queries in digital libraries
Abstract: Structured or fielded metadata is the basis for many digital library services, including searching and browsing. Yet, little is known about the impact of using structure on the effectiveness of such services. In this paper, we investigate a key research question: do structured queries improve effectiveness in DL searching? To answer this question, we empirically compared the use of unstructured queries to the use of structured queries. We then tested the capability of a simple Bayesian network system, built on top of a DL retrieval engine, to infer the best structured queries from the keywords entered by the user. Experiments performed with 20 subjects working with a DL containing a large collection of computer science literature clearly indicate that structured queries, either manually constructed or automatically generated, perform better than their unstructured counterparts, in the majority of cases. Also, automatic structuring of queries appears to be an effectiveand viable alternative to manual structuring that may significantly reduce the burden on users.
ID:374
CLASS:4
Title: Localizing experience of digital content via structural metadata
Abstract: With the increasing technical sophistication of both information consumers and providers, there is increasing demand for more meaningful experiences of digital information. We present a framework that separates digital object experience, or rendering, from digital object storage and manipulation, so the rendering can be tailored to particular communities of users. Our framework also accommodates extensible digital object behaviors and interoperability. The two key components of our approach are 1) exposing structural metadata associated with digital objects - metadata about labeled access points within a digital object and 2) information intermediaries called context brokers that match structural characteristics of digital objects with mechanisms that produce behaviors. These context brokers allow for localized rendering of digital information stored externally.
ID:375
CLASS:4
Title: A performance support systems approach to digital publishing in libraries
Abstract: Electronic performance support tools are used in many workplaces, but digital libraries have not evaluated their potential usefulness. In a pilot project, the Florida State University Libraries developed inexpensive performance support tools for three types of in-house digital publishing. This strategy improved productivity and quality control.
ID:376
CLASS:4
Title: If you build it, will they come?: lessons learned from the workshop on participant interaction in digital libraries
Abstract: A workshop in early February 2004, hosted by the Math Forum, brought together over thirty experts from the National Science Digital Library (NSDL) program and representatives from online communities to discuss and identify promising models of participant involvement for the NSDL and NSDL--funded projects [see pidlworkshop comm nsdl org]. The workshop leveraged the expertise of attendees to identify tools and reporting mechanisms, develop strategies and formulate recommendations that will help NSDL projects incorporate, support and grow the communities who use their digital libraries Workshop attendees also provided a rich set of examples of how users are currently involved in building and maintaining NSDL digital libraries and the potential impact of their involvement Participant involvement is a critical factor not only in developing educational digital libraries, but also in sustaining the resources, the technology and most importantly, the communities who use them Without converting casual or one--time users into recurring, involved participants, or even members of a community, educational digital libraries will simply be yet another example of, 'If you build it, will they come'.
ID:377
CLASS:4
Title: Digital trail libraries
Abstract: We propose the idea of an online, user submitted digital library of recreation trails. Digital libraries of trails offer advantages over paper guidebooks in that they are more accurate, dynamic and not limited to the experience of the author(s). The basic representation of a trail is a GPS track log, recorded as recreators travel on trails. As users complete trips, the GPS track logs of their trips are submitted to the central library voluntarily. A major problem is that track logs will overlap and intersect each other. We present a method for the combination of overlapping and intersecting GPS track logs to create a network of GPS trails. Each trail segment in the network can then be characterized by automatic and manual means, producing a digital library of trails. We also describe the TopoFusion system which creates, manages and visualizes GPS data, including GPS networks.
ID:378
CLASS:4
Title: Integrating automatic genre analysis into digital libraries
Abstract: With the number and types of documents in digital library systems incr easing, tools for automatically organizing and presenting the content have to be found. While many approaches focus on topic-based organization and structuring, hardly any system incorporates automatic structural analysis and representation. Yet, genre information (unconsciously) forms one of the most distinguishing features in conventional libraries and in information searches. In this paper we present an approach to automatically analyze the structure of documents and to integrate this information into an automatically created content-based organization. In the resulting visualization, documents on similar topics, yet representing different genres, are depicted as books in differing colors. This representation supports users intuitively in locating relevant information presented in a relevant form.
ID:379
CLASS:4
Title: A hypermedia approach to digital libraries: review of research issues
Abstract: Digital libraries can provide users with fast access to large, complex, richly connected, and cross-referenced bodies of information. They can be considered as applications based on the hypermedia paradigm. Hypermedia is hypertext with multimedia. The principle behind hypertext or hypermedia is nodes of information (concepts) associated through links (relationships). It is essentially non-linear organization and presentation of information. Nodes can contain text, graphics, animation, audio, video, and even other applications.
ID:380
CLASS:4
Title: Lightweight video service for multi-media digital libraries
Abstract: In this paper we present the design, architecture, implementation and performance of a digital library of video data. Our goal is to provide a lightweight video service for multimedia digital libraries built upon an ATM infrastructure, providing nonlinear editing and viewing of video. To accomplish this objective we have used a low overhead, high performance persistent object manager to manage the underlying video data.To test these ideas, we used the lightweight persistent object manager PTool, developed by the Laboratory for Advanced Computing at the University of Illinois at Chicago, to create persistent object stores of video data on a cluster of Unix workstations connected with an ATM switch. To improve performance, we striped the video data across the cluster.We verified that we were able to manage gigabytes of video data without performance degradation and that striping improved performance linearly up to the bandwidth of the equipment. We also compared the performance of ATM networked and ethernet networked clusters.Finally, we mention that viewing the video data as a persistent collection of objects (i.e. each frame of video as an object) provides attribute based retrieval of data, and hence allows for very simple editing, querying and retrieval of video data by attribute. It allows for the use of object associations to combine video, audio, text, etc.
ID:381
CLASS:4
Title: Visual interfaces to digital libraries
Abstract: Today's digital libraries (DLs) are content rich, multimedia, multilingual collections that are distributed and accessed worldwide. Designing useful interfaces to access, understand, and manage this knowledge has become an active and challenging field of study. Visual interfaces to DLs aim to shift the user's mental load from slow reading to faster perceptual processes such as visual pattern recognition. They draw on progress in the new field of Information Visualization.The workshop in 2002 continues the theme started at JCDL 2001. In addition, the growth of the field warrants new perspectives on some of the issues we have addressed last year.
ID:382
CLASS:4
Title: Usability for digital libraries
Abstract: As digital libraries are becoming increasingly available to, and used by, diverse user communities who do not have background or training in information sciences, the need to ensure that such libraries are usable and useful is becoming increasingly urgent. Usability issues can be tackled from various directions - technical, cognitive, social, design-oriented - and it is important to bring these different perspectives together, to share views, experiences and insights.
ID:383
CLASS:4
Title: Semantics and syntax of dublin core usage in open archives initiative data providers of cultural heritage materials
Abstract: This study analyzes metadata shared by cultural heritage institutions via the Open Archives Initiative Protocol for Metadata Harvesting. The syntax and semantics of metadata appearing in the Dublin Core fields creator, contributor, and date are examined. Preliminary conclusions are drawn regarding the effectiveness of Dublin Core in the Open Archives Initiative environment for cultural heritage materials.
ID:384
CLASS:4
Title: Towards a theory of cost management for digital libraries and electronic commerce
Abstract: One of the features that distinguishes digital libraries from traditional databases is new cost models for client access to intellectual property. Clients will pay for accessing data items in digital libraries, and we believe that optimizing these costs will be as important as optimizing performance in traditional databases. In this article we discuss cost models and protocols for accessing digital libraries, with the objective of determining the minimum cost protocol for each model. We expect that in the future information appliances will come equipped with a cost optimizer, in the same way that computers today come with a built-in operating system. This article makes the initial steps towards a thery and practice of intellectual property cost management.
ID:385
CLASS:4
Title: Comprehensive personalized information access in an educational digital library
Abstract: This paper explores two ways to help students locate most relevant resources in educational digital libraries. One method gives a more comprehensive access to educational resources, through multiple pathways of information access, including browsing and information visualization. The second method is to access personalized information through social navigation support. This paper presents the details of the Knowledge Sea II system for comprehensive personalized access to educational resources and also presents the results of a classroom study. The study delivered a convincing argument for the importance of providing multiple information presentations modes, showing that only about 10% of all resource accesses were made through the traditional search interface. We have also collected some solid evidence in favor of the social navigation support.
ID:386
CLASS:4
Title: On querying geospatial and georeferenced metadata resources in G-portal
Abstract: G-Portal is a web portal system providing a range of digital library services to access geospatial and georeferenced resources on the Web. Among them are the storage and query subsystems that provide a central repository of metadata resources organized under different projects. In GPortal, all metadata resources are represented in XML (Extensible Markup Language) and they are compliant to some resource schemas defined by their creators. The resource schemas are extended versions of a basic resource schema making it easy to accommodate all kinds of metadata resources while maintaining the portability of resource data. To support queries over the geospatial and georeferenced metadata resources, a XQuery-like query language known as RQL (Resource Query Language) has been designed. In this paper, we present the RQL language features and provide some experimental findings about the storage design and query evaluation strategies for RQL queries.
ID:387
CLASS:4
Title: A system for building expandable digital libraries
Abstract: Expandability is one of the main requirements of future digital libraries. This paper introduces a digital library service system, OpenDLib, that has been designed to be highly expandable in terms of content, services and usage. The paper illustrates the mechanisms that enable expandability and discusses their impact on the development of the system architecture.
ID:388
CLASS:4
Title: A multilingual, multimodal digital video library system
Abstract: This paper presents the iVIEW system, a multi-lingual, multi-modal digital video content management system for intelligent searching and access of English and Chinese video contents. iVIEW allows full content indexing, searching and retrieval of multi-lingual text, audio and video material. It consists image processing techniques for scenes and scene changes analyses, speech processing techniques for audio signal transcriptions, and multi-lingual natural language processing techniques for word relevance determination. iVIEW can host multi-lingual contents and allow multi-modal search. It facilitate content developers to perform multi-modal information processing of rich video media and to construct XML-based multimedia representation in enhancing multi-modal indexing and searching capabilities, so that the end users can enjoy viewing flexible and seamless delivery of multimedia contents in various browsing tools and devices.
ID:389
CLASS:4
Title: Measuring the user's experience with digital libraries
Abstract: In this paper, we propose a method for assessing user experience. Normally evaluation is based on usability or on the efficiency of or effectiveness of focused information search tasks. Yet all experiences with libraries (whether physical or virtual) need not be for the explicit purpose of finding, acquiring and using information. The experience and its playfulness and pleasure have equal value. To assess this experience, we modified a experiential value scale developed for online shopping and have tested it in the context of culture and heritage websites.
ID:390
CLASS:4
Title: Learning by building digital libraries
Abstract: The implications of using digital library software in educational contexts, for both students and software developers, are discussed using two case studies of students building digital libraries.
ID:391
CLASS:4
Title: Light-weight communal digital libraries
Abstract: We describe Kepler, a collection of light-weight utilities that allow for simple and quick digital library construction. Kepler bridges the gap between established, organization-backed digital libraries and groups of researchers that wish to publish their findings under their control, anytime, anywhere yet have the advantage of their personal libraries. The personal libraries, or "archivelets", are Open Archives Initiative (OAI) compliant and thus available for harvesting from OAI service providers. A Kepler archivelet can be installed in the order of minutes by an author on a personal machine and a Kepler group server in the order of hours.
ID:392
CLASS:4
Title: Hermes: a notification service for digital libraries
Abstract: The high publication rate of scholarly material makes searching and br owsing an inconvenient way to keep oneself up-to-date.  Instead of being the active part in information access, researchers want to be notified whenever a new paper in one's research area is published.While more and more publishing houses or portal sites offer notification services this approach has several disadvantages. We introduce the Hermes alerting service, a service that integrates a variety of different information providers making their heterogeneity transparent for the users. Hermes offers sophisticated filtering capabilities preventing the user from drowning in a flood of irrelevant information. From the user's point of view it integrates the providers into a single source.  Its simple provider interface makes it easy for publishers to join the service and thus reaching the potential readers directly.This paper presents the architecture of the Hermes service and discusses the issues of heterogeneity of information sources.  Furthermore, we discuss the benefits and disadvantages of message-oriented middleware for implementing such a service for digital libraries.
ID:393
CLASS:4
Title: Metadata aggregation and "automated digital libraries": a retrospective on the NSDL experience
Abstract: Over three years ago, the Core Integration team of the National Science Digital Library (NSDL) implemented a digital library based on metadata aggregation using Dublin Core and OAI-PMH. The initial expectation was that such low-barrier technologies would be relatively easy to automate and administer. While this architectural choice permitted rapid deployment of a production NSDL, our three years of experience have contradicted our original expectations of easy automation and low people cost. We have learned that alleged "low-barrier" standards are often harder to deploy than expected. In this paper we report on this experience and comment on the general cost, the functionality, and the ultimate effectiveness of this architecture.
ID:394
CLASS:4
Title: Automatic structured query transformation over distributed digital libraries
Abstract: Structured data and complex schemas are becoming the main way to represent the information many Digital Libraries provide, thus impacting the services they offer. When searching information among distributed Digital Libraries with heterogeneous schemas, the structured query with a given schema (the global or target schema) has to be transformed into a query over the schema of the digital library it will be submitted to (the source schema). Schema mappings define the rules for this query transformation. Schema matching is the problem of learning these mappings.In this paper we address the issue of automatically learning these mappings and transforming a structured query over the target schema into a new structured query over the source schema. We propose a simple and effective schema matching method based on the well known CORI selection algorithm and two ways of applying it. By evaluating the effectiveness of the obtained structured queries we show that the method works well in accessing distributed, heterogeneous digital libraries.
ID:395
CLASS:4
Title: Exploring digital libraries: integrating browsing, searching, and visualization
Abstract: Exploring services for digital libraries (DLs) include two major paradigms, browsing and searching, as well as other services such as clustering and visualization. In this paper, we formalize and generalize DL exploring services within a DL theory. We develop theorems to indicate that browsing and searching can be converted or mapped to each other under certain conditions. The theorems guide the design and implementation of exploring services for an integrated archaeological DL, ETANA-DL. Its integrated browsing and searching can support users in moving seamlessly between these operations, minimizing context switching, and keeping users focused. It also integrates browsing and searching into a single visual interface for DL exploration. A user study to evaluate ETANA-DL's exploring services helped validate our hypotheses.
ID:396
CLASS:4
Title: Accessing the alexandria digital library from geographic information systems
Abstract: We describe two experimental desktop library clients that offer improved access to geospatial data via the Alexandria Digital Library (ADL): ArcADL, an extension to ESRI's ArcView GIS, and vtADL, an extension to the Virtual Terrain Project's Enviro terrain visualization package ArcADL provides a simplified user interface to ADL's powerful underlying distributed geospatial search technology. Both clients use the ADL Access Framework to access library data that is available in multiple formats and retrievable by multiple methods Issues common to both clients and future scenarios are also considered.
ID:397
CLASS:4
Title: The digital ideakeeper: integrating digital libraries with a scaffolded environment for online inquiry
Abstract: Online inquiry is an important way of engaging learners in information--rich activities using online sources to explore questions in different fields, such as science. Online inquiry involves a set of interrelated activities, such as planning an investigation; seeking, analyzing, and making sense of online information; and synthesizing information into a final argument. However, learners may encounter several obstacles in trying to tackle an open--ended, complex process like online inquiry. Therefore, using a learner--centered design approach, we are developing the Digital Idea Keeper environment to extend digital libraries by integrating different tools and incorporating different scaffolding approaches to help learners effectively engage in online inquiry.
ID:398
CLASS:4
Title: Library leaders on digital libraries and the future of the research library: a panel discussion
Abstract: This panel presents perspectives from a group of research library leaders on the evolving relationships between the body of systems, services and technologies associated with digital libraries and the institution of the research library. Four panelists and the moderator will consider many questions, including whether libraries are being too timid or overly aggressive in engaging the world of digital libraries; the extent to which digital library technologies may threaten the future of the research library; and how changes in the practices of science and scholarship due to information technology and digital content will help shape the future of the research library and the integration of digital library technologies. We will also examine the possible roles of research libraries in helping to make digital library projects sustainable. The panel will also include time for questions from the audience.
ID:399
CLASS:5
Title: A generalized model management system for mathematical programming
Abstract: This paper examines mathematical programming software in the context of model management and decision support. The concept of a model management system (MMS) is introduced and compared to traditional modeling systems. An MMS is seen as a much more generalized software system that requires the confluence of existing operations research, database management, and artificial intelligence techniques. By incorporating powerful, abstraction-based representation structures, an MMS can support multiple levels of model abstraction, only one of which corresponds to traditional, solution-oriented modeling software. The database structures required to implement a knowledge-based MMS are discussed and a prototype system for mathematical programming, the Generalized eXperimental Math Programming system (GXMP), is described. An algebraic language developed for use in GXMP is described in detail.
ID:400
CLASS:5
Title: The spectrum of mathematical modeling and systems simulation
Abstract: The methodology involved in the modeling and simulation of physical, life and social science systems is viewed in perspective. A critical factor determining the validity of a model is the extent to which it can be derived from basic laws and insights into the internal structure of the system using deductive methods, rather than relying upon observations and measurements of the system input and outputs. Accordingly, the mathematical models as they arise in various application disciplines are arranged along a spectrum according to the relative amount of deduction and induction involved in their construction. This provides an insight into the ultimate validity of simulations and to what use they can properly be put.
ID:401
CLASS:5
Title: Simulation, mathematical modeling and optimization in industrial design: When and how to apply it?
Abstract: With the current technology, optimization has become a feasible and profitable avenue for problem solving in industrial design. This in turn brings simulation and modeling into the design process in order to obtain a mathematical description of the process in question. This paper addresses the problem of &ldquo;When and How to Apply Optimization in Industrial Design?&rdquo;. In addition, it reviews the most common optimization algorithms and how they should be selected. Furthermore, some of the common optimization packages are discussed. Four industrial applications are briefly studied. The first two are in the area of simulation, in particular, the simulation of a foundry and a computer workload simulation. The other two examples deal with optimization. The first of which develops an algorithm for economic tube grouping and the second one discusses the optimization of a boiler's circulation system.
ID:402
CLASS:5
Title: Generating parallel code from object oriented mathematical models
Abstract: For a long time efficient use of parallel computers has been hindered by dependencies introduced in software through low-level implementation practice. In this paper we present a programming environment and language called Object-Math (Object oriented Mathematical language for scientific computing), which aims at eliminating this problem by allowing the user to represent mathematical equation-based models directly in the system. The system performs analysis of mathematical models to extract parallelism and automatically generates parallel code for numerical solution.In the context of industrial applications in mechanical analysis, we have so far primarily explored generation of parallel code for solving systems of ordinary differential equations (ODEs), in addition to  preliminary work on generating code for solving partial differential equations. Two approaches to extracting parallelism have been implemented and evaluated: extracting parallelism at the equation system level and at the single equation level, respectively. We found that for several applications the corresponding systems of equations do not partition well into subsystems. This means that the equation system level approach is of restricted general applicability. Thus, we focused on the equation-level approach which yielded significant parallelism for ODE systems solution. For the bearing simulation applications we present here, the achieved speedup is however critically dependent on low communication latency of the parallel computer.
ID:403
CLASS:5
Title: Simulation and mathematical modeling of an on-line accounting system
Abstract: Two approaches are presented for analyzing and predicting performance of an on-line business data accounting system. The computer system's responsiveness to typical (high priority) file updating demands is examined by two methods of a priori study: simulation and mathematical modeling. A discrete event simulation model, written in FORTRAN, is developed to comprehensively describe system performance. This simulation model is based upon the isolation and sequential ordering of logical &ldquo;phases&rdquo; which are seen to occur during the servicing of a user's request. To supplement this model, two mathematical models are developed from assumptions of exponential interarrival and service time distributions. The first of the mathematical models presents &ldquo;worst case&rdquo; estimates in the sense that no simultaneity of Drum and Disc Pack operations is considered possible; whereas the second model provides &ldquo;best case&rdquo; estimates since it assumes that a maximum degree of file I/O simultaneity is achievable. As expected, the simulation results (in all cases examined) were between the upper and lower bound response time estimates provided by the mathematical models. Hence the mathematical models serve to substantiate the validity of the results obtained from the simulation, and in concert, the three models provide performance estimates which range from &ldquo;worst case&rdquo; to &ldquo;expected real world&rdquo; to &ldquo;best case.&rdquo; Thus it is shown how mathematical modeling can be coupled with simulation to increase the fidelity of system analysis.
ID:404
CLASS:5
Title: Comparing mathematical models on the problem of network inference
Abstract: In this paper we address the problem of finding gene regulatory networks from experimental DNA microarray data. We focus on the evaluation of the performance of different mathematical models on the inference problem. They are used to model the underlying dynamic system of artificial regulatory networks. The dynamics of the artificial systems represent different basic types of behavior,dimensionality and mathematical properties. They are all created with three commonly used approaches, namely linear weight matrices, H-systems, and S-systems. Due to the complexity of the inference problem, some researchers suggested evolutionary algorithms for this purpose. However, in many publications only one algorithm is used without any comparison to other optimization methods. Thus, we introduce a framework to systematically apply evolutionary algorithms for further comparative analysis.
ID:405
CLASS:5
Title: An investigation of several mathematical models of queueing systems
Abstract: A number of simple mathematical models were used to predict average response time of a timesharing system. The target system was a very simple trace driven simulation model, but the workloads were trace files obtained from a real system in normal operation. As such, the workloads were characterized by very high coefficients of variation in resource demands and think times. Mathematical models of the system included independent arrival models (M/M/1 and M/G/1, closed network models) admitting product from solutions, and a more general Markov model. Only the final model produced reasonable accuracy.A number of experiments were performed, in an effort to determine what properties of the system being modeled were responsible for the failure of all the simple mathematical models. The large variance in CPU time and the fact that the system was a closed network were found to be critical factors, and appeared to be the major causes for failure of models that do not take them into account.
ID:406
CLASS:5
Title: Next generation modeling II - applications: experiencing natural phenomena with virtual, constructed and mathematical models
Abstract: In this paper we discuss how different kinds of models can be combined in an educational setting to enable students to experience natural phenomena, here earthquakes. Different tools enable students to manipulate virtual models, construct physical models and formulate mathematical models. Ideally, the modelling processes and the resulting models complement each other to some degree. Virtual and physical models can then be driven by real data as well as mathematical models of the phenomena.
ID:407
CLASS:5
Title: A metadatabase system for semantic image search by a mathematical model of meaning
Abstract: In the design of multimedia database systems, one of the most important issues is to extract images dynamically according to the user's impression and the image's contents. In this paper, we present a metadatabase system which realizes the semantic associative search for images by giving keywords representing the user's impression and the image's contents.This metadatabase system provides several functions for performing the semantic associative search for images by using the metadata representing the features of images. These functions are realized by using our proposed mathematical model of meaning. The mathematical model of meaning is extended to compute specific meanings of keywords which are used for retrieving images unambiguously and dynamically. The main feature of this model is that the semantic associative search is performed in the orthogonal semantic space. This space is created for dynamically computing semantic equivalence or similarity between the metadata items of the images and keywords.
ID:408
CLASS:5
Title: Response gradient estimation using mathematical programming models of discrete-event system sample paths
Abstract: This paper illustrates the use of mathematical programming in computing gradient estimators. Consistency property of these estimators is established under the usual assumptions for IPA gradient estimator consistency. A finite difference tolerance limit is introduced. For complex discrete-event systems, more concise linear programming representations are developed. These new representations provide a direct way of calculating gradient estimates.
ID:409
CLASS:5
Title: Mathematical modeling and simulation of an algorithm for optimistic concurrency control in centralized database systems
Abstract: This paper presents the analysis of an algorithm for optimistic concurrency control in centralized database systems. The effectiveness of optimistic concurrency control in a centralized database system depends on the probability of transaction conflict being low. When conflict does occur, it is resolved by aborting the older transaction and allowing resubmission. The concern here is to examine the probability that a transaction is able to avoid conflict and commit. Specifically, a set of probabilistic formulas which provide an analysis of this probability is examined. Furthermore, a report of two simulation studies, the design and implementation of a GPSS simulation and the design of a simulation for the IBM token-ring network, is given.
ID:410
CLASS:5
Title: Mathematical programming models of discrete event system dynamics
Abstract: Analytical models for the dynamics of some discrete event systems are introduced where the system trajectories are solutions to linear and mixed-integer programs.
ID:411
CLASS:5
Title: Mathematical models of database degradation
Abstract: As data are updated, the initial physical structure of a database is changed and retrieval of specific pieces of data becomes more time consuming. This phenomenon is called database degradation. In this paper two models of database degradation are described. Each model refers to a different aspect of the problem.It is assumed that transactions are statistically independent and either add, delete, or update data. The first model examines the time during which a block of data is filling up. The second model examines the overflows from a block of data, which essentially describes the buildup of disorganization. Analytical results are obtained for both models. In addition, several numerical examples are presented which show that the mean number of overflows grows approximately linearly with time. This approximation is used to devise a simple formula for the optimal time to reorganize a stochastically growing database.
ID:412
CLASS:5
Title: Models for mathematical systems
Abstract: The purpose of this paper is to describe and illustrate a program, written for the IBM 7090, which defines a model for a finite collection of algebras for the computer. It is shown that the program contains a structure broad enough in scope to allow one to perform operations on such diverse mathematical concepts as differential equations, infinite series, and differential forms in a simple yet comprehensive manner, while also serving as a foundation upon which a variety of higher-level symbolic manipulation languages can be developed.
ID:413
CLASS:5
Title: Mathematics and hybrid modeling: mathematics for simulation
Abstract: I survey several mathematical techniques and results that are useful in the context of stochastic simulation. The concepts are introduced through the study of a simple model of ambulance operation to ensure clarity, concreteness and cohesion.
ID:414
CLASS:5
Title: Mathematical modeling of cyber attacks: a learning module to enhance undergraduate security curricula
Abstract: We have been experimenting with methods for improving undergraduate curricula and research experiences as well as the security courses for Computer Science and Information Systems students. Recent surges in attacks and intrusions reflect vulnerabilities in computer networks and emerge of sophisticated new attacks are always associated with determining evolving risks and preventing them. Innovative methods and tools can help attack defenses, prevent attack propagations, detect and respond to such attacks. Mathematical or statistical modeling of attacks is an important concept to introduce to students in security courses as they help assess vulnerability under a variety of conditions that predetermine the extent of damages to a system and, thereby, predict possible losses. This paper describes a learning module developed to help students understand basic statistical and mathematical modeling of unscrupulous attacks.
ID:415
CLASS:5
Title: Mathematical Models for Automatic Line Detection
Abstract: A particular decision-theoretic approach to the problem of detecting straight edges and lines in pictures is discussed. A model is proposed of the appearance of scenes consisting of prismatic solids, taking into account blurring, noise, and smooth variations in intensity over faces. A suboptimal statistical decision procedure is developed for the identification of a line within a narrow band in the field of view, given an array of intensity values from within the band. The performance of this procedure is illustrated and discussed.
ID:416
CLASS:5
Title: A mathematical model of a crankcase scavenged, two-stroke, spark ignited engine and comparisons with experimental data
Abstract: A detailed mathematical model of the thermodynamic events of a crankcase scavenged, two-stroke SI engine is described. Energy balances, mass continuity equations, the ideal gas law, and thermodynamic property relationships are combined to give a set of coupled ordinary differential equations which describe the thermodynamic states encountered by the engine systems during one cycle of operation. A computer program is used to integrate the equations, adjusting the initial estimates until the final conditions agree with the initial estimates, that is, until a cycle results. Experimental data from the simulated engine are compared with the computed results.
ID:417
CLASS:5
Title: A study of storage partitioning using a mathematical model of locality
Abstract: Both fixed and dynamic storage partitioning procedures are examined for use in multiprogramming systems. The storage requirement of programs is modeled as a stationary Gaussian process. Experiments justifying this model are described. By means of this model dynamic storage partitioning is shown to provide substantial increases in storage utilization and operating efficiency over fixed partitioning.
ID:418
CLASS:5
Title: The relational model for database management: version 2
Abstract: From the Preface (See Front Matter for full Preface)
ID:419
CLASS:5
Title: Computer-aided modeling and planning  (CAMP)
Abstract: Many planning methods are based on mathematical modeling. A multitude of computer aids covers different facets of the planning activity: data management, linear programming, statistical analysis, graphics, and word processing. However, the diversity and complexity of the available software inhibit the widespread use of computers for planning.The integrated Computer-Aided Modeling and Planning (CAMP) system offers a simple and coherent tool for the planner. A Data Definition Language provides the means for building data banks; a Model Definition Language provides the means for defining mathematical models featuring abstract linear programming, advanced array arithmetics, and assertions; a Picture Definition Language facilitates formation of tables and diagrams; a Text Definition Language combines word processing with illustrations of modeling results. The man-machine interface is based on interactive panels for controlling the planning process and on a command language for analyzing modeling results. A multilingual capability allows selection of the national language for interfacing with the system.The architecture of CAMP is presented, and its design, implementation, and use in regional planning are discussed.
ID:420
CLASS:5
Title: Some mathematical properties of simulation models
Abstract: A mathematical style of description of simulation models is introduced by using the formalism of system theory. Discrete event simulation models which use pseudorandom number generators are regarded as abstract objects described by a family of input-output time-functions and are proved to hold the property of aggregates.
ID:421
CLASS:5
Title: Algebra and models
Abstract: Science makes progress by constructing mathematical models, deducing their observable consequences, and testing them by experiment. Successful theoretical models are later taken as the basis for engineering methods and codes of practice for design of reliable and useful products. Models can play a similar central role in the progress and practical application of Computing Science.A model of a computational paradigm starts with choice of a carrier set of potential direct or indirect observations that can be made of a computational process. A particular process is modelled as the subset of observations to which it can give rise. Process composition is modelled by relating observations of a composite process to those of its components. Indirect observations play an essential role in such compositions. Algebraic properties of the composition operators are derived with the aid of the simple theory of sets and relations. Feasibility is checked by a mapping from a more operational model.A model constructed as a family of sets is easily adapted as a calculus of design for total correctness. A specification is given by an arbitrary set containing all observations permitted in the required product. It should be expressed as clearly as possible with the aid of the full power of mathematics and logic. A product meets a specification if its potential observations form a subset of its permitted observations. This principle requires that all envisaged failure modes of a product are modelled as indirect observations, so that their avoidance can be proved. Specifications of components can be composed mathematically by the same operators as the components themselves. This permits top-down proof of correctness of designs even before their implementation begins. Algebraic properties and reasoning are helpful throughout development. Non-determinism is seen as no problem, but rather as a part of the solution.
ID:422
CLASS:5
Title: Modelling legal reasoning in a mathematical environment through model theoretic semantics
Abstract: We introduce a mathematical model of legal reasoning using an underlying conditional logic semantics, to allow its tractability in some special cases. The main idea is to capture the entailment of legal consequences through a model of 0-1 programming. For such task, first we model legal reasoning with Lehmann's Lexicographic semantics and then we translate it to an instance of weighted MAXSAT problem, in order to compute the logical consequences of legal reasoning. Hence, combinatorial optimization algorithms can be used to yield the legal consequences of defeasible reasoning over legal conditional knowledge bases.
ID:423
CLASS:5
Title: A mathematical model of the briquette industry in Victoria
Abstract: This paper describes how a business model is created and used. In particular it focuses attention on a model which has been developed to represent a typical business comprising production, storage, distribution and demand in a competitive environment. It describes the situation of the briquette industry in Victoria. The paper is presented not only to illustrate one successful and valuable application, but also to indicate the powerful nature of mathematical models and the way in which all businesses can be so represented. The example used in this paper to high-light the various aspects of model buildings fits into an emerging pattern of quantitative studies which are contributing toward the preparation of investment decisions by the State Electricity Commission of Victoria.
ID:424
CLASS:5
Title: A qualitative simulation approach for fuzzy dynamical models
Abstract: This article deals with simulation of approximate models of dynamic systems. We propose an approach that is appropriate when the uncertainty intrinsic in some models cannot be reduced by traditional identification techniques, due to the impossibility of gathering experimental data about the system itself. The article presents a methodology for qualitative modeling and simulation of approximately known systems. The proposed solution is based on the Fuzzy Sets theory, extending the power of traditional numerical-logical methods. We have implemented a fuzzy simulator that integrates a fuzzy, qualitative approach and traditional, quantitative methods.
ID:425
CLASS:5
Title: Model representation with aesthetic computing: Method and empirical study
Abstract: We define a new methodology, aesthetic computing, for customizing discrete structures found in mathematics, programming, and computer simulation. The methodology is presented as a procedure, defined within the context of the semantic web, involving a successive chain of model transformations from a source model to a target model, with the source model being the discrete structure to represent and the target model being the geometric model. We also present an implementation based on this methodology, and a class where empirical studies were performed to assess student perceptions on how customized model structures affected their understanding and preferences regarding visual and interactive model representations. Students appear to prefer the methodology as a way to inject creativity into model building, and to allow them to explore alternative, analogical representations influenced by the fields of aesthetics and the arts.
ID:426
CLASS:5
Title: Experimental mathematics:  the role of computation in nonlinear science
Abstract: Computers have expanded the range of nonlinear phenomena that can be explored mathematically. An &ldquo;experimental mathematics facility,&rdquo; containing both special-purpose dedicated machines and general-purpose mainframes, may someday provide the ideal context for complex nonlinear problems.
ID:427
CLASS:5
Title: Integrating network optimization capabilities into a high-level modeling language
Abstract: Research in network optimization has reached the stage where large-scale problems-linear or non-linear, pure or generalized-are solved very efficiently with minimal computing resources. Representing such problems for solution on the computer, however, remains a rather cumbersome task. Taking advantage of developments in high-level modeling languages, we design and implement integrated systems to facilitate the representation and solution of network problems. Such systems integrate the flexibility and robustness of modeling languages with the efficiency of network optimizers.We describe two alternative modes for this integration, which can be achieved for linear and nonlinear problems alike. The use of the resulting systems is demonstrated with the solution of large-scale problems from diverse applications and with the implementation of network decomposition algorithms.
ID:428
CLASS:5
Title: Computer Science And Graduate Education In Applied Mathematics
Abstract: The term &ldquo;applied mathematics&rdquo; in the title and throughout this discussion includes all areas of the mathematical sciences rather than just classical applied mathematics. The comments in this paper are derived from two primary sources: an ad hoc committee formed at Clemson to investigate the interface between the mathematical sciences and computer science and ideas developed in the implementation of Clemson's NSF grant &ldquo;An Alternative in Higher Education in the Mathematical Sciences.&rdquo; The ideas gleaned from the grant activity were developed through actual experience and through comments from many of the departmental visitors supported by the grant, especially those sixty or so conferees from industry, government, and academia who participated in the grant-sponsored conference, &ldquo;Graduate Programs in the Applied Mathematical Sciences: Perspectives and Prospects&rdquo;[24].
ID:429
CLASS:5
Title: Model-theoretic semantics for the web
Abstract: Model-theoretic semantics is a formal account of the interpretations of legitimate expressions of a language. It is increasingly being used to provide Web markup languages with well-defined semantics. But a discussion of its roles and limitations for the Semantic Web has not yet received a coherent and detailed treatment. This paper takes the first steps towards such a treatment. The major result is an introductory explication of key ideas that are usually only implicit in existing accounts of semantics for the Web. References to more detailed accounts of these ideas are also provided. The benefit of this explication is increased awareness among Web users of some important issues inherent in using model-theoretic semantics for Web markup languages.
ID:430
CLASS:5
Title: Queueing Network-Model Human Processor (QN-MHP): A computational architecture for multitask performance in human-machine systems
Abstract: Queueing Network-Model Human Processor (QN-MHP) is a computational architecture that integrates two complementary approaches to cognitive modeling: the queueing network approach and the symbolic approach (exemplified by the MHP/GOMS family of models, ACT-R, EPIC, and SOAR). Queueing networks are particularly suited for modeling parallel activities and complex structures. Symbolic models have particular strength in generating a person's actions in specific task situations. By integrating the two approaches, QN-MHP offers an architecture for mathematical modeling and real-time generation of concurrent activities in a truly concurrent manner. QN-MHP expands the three discrete serial stages of MHP, of perceptual, cognitive, and motor processing, into three continuous-transmission subnetworks of servers, each performing distinct psychological functions specified with a GOMS-style language. Multitask performance emerges as the behavior of multiple streams of information flowing through a network, with no need to devise complex, task-specific procedures to either interleave production rules into a serial program (ACT-R), or for an executive process to interactively control task processes (EPIC). Using QN-MHP, a driver performance model was created and interfaced with a driving simulator to perform a vehicle steering, and a map reading task concurrently and in real time. The performance data of the model are similar to human subjects performing the same tasks.
ID:431
CLASS:5
Title: Mathematical reasoning in software engineering education
Abstract: Discrete mathematics, especially logic, plays an implicit role in software engineering similar to the role of continuous mathematics in traditional physically based engineering disciplines.
ID:432
CLASS:5
Title: A model for the management of dynamic web applications
Abstract: Organizations are looking for ways to develop and maintain dynamic web pages in a time-efficient way and looking for ways to reduce the number of failures, such as broken links. Although software vendors provide software supporting the development and maintenance of dynamic web applications, they are expensive and have no formal basis. In this paper, a mathematical model is used to describe a web interface. A web interface is regarded as a decision network and the surfing behaviour of a visitor is regarded as a decision process. The analysis of the model based on this provides both theoretical and practical insights. The mathematical model also constitutes a valuable framework for system development. It makes it possible to assess the effectiveness of websites and to predict the effect of any changes in the system.This paper concludes with a description of actual experience with this model in an operational environment.
ID:433
CLASS:5
Title: Mathematical modeling and Ada simulation of some synchronization processes
Abstract: Previously, a simulation model was proposed for the purpose of investigating synchronization, a phenomenon which is demonstrated in the well-known Rope Game (or Tug-of-War). Synchronous activity is evident in so-called self-organizing systems, particularly muscle and brain tissues. This paper gives an exact matrix description of the rope model and shows that study of the synchronous behavior of this model can be done by applying Markov chain analysis. In modeling neural networks, however, such features as refraction, inhibition, noise, and discrete neuron responses frequently are incorporated in simulation models. Simulations are presented that indicate certain neural network models can be more simply modeled in part using a matrix representation similar to that for the rope game. A lemma is proved and used to obtain a formula for neuron firing expected in steady state.
ID:434
CLASS:5
Title: A mixed integer mathematical programming model solution using branch and bound techniques (abstract only)
Abstract: An optimal allocation of work release and labor assignments on a paced assembly line using the objective criterion of minimal standard hours has been formulated as a mixed integer mathematical programming model. The results of our research lead to the development of an algorithm which solves the mathematical model formulation and a computer implementation demonstrates its use in an actual operating environment. The algorithm developed for solving the problem uses a branch and bound approach as its basic solution technique.Basically, the ingredients of a branch and bound algorithm are a lower bounding strategy, a branching strategy (which partitions the set of feasible solutions into subsets), and a search strategy (which determines the order in which the subsets are investigated). The algorithm presented here uses the method of relaxing difficult constraints as a lower bounding strategy. The lower constraints are those which contain integer variables. This approach results in an ordinary linear programming problem model formulation which is used for computing lower bounds. The branching strategy is a binary partitioning in which a particular assembly mode is either in the solution subset, or not. The search strategy used is the backtracking procedure in which the branching variables are heuristically preordered.The mixed integer mathematical model follows: The objective function is V(X) = CX where C is (l x n) vector and X is a (n x 1) vector subject to AX = d where A is a (m x n) vector d is a (m x 1) vector HX &le; h where H is a (1 x n) vector h is a (1 x 1) vector BX-DS &le; O where B is a (r x n) matrix D is a (r x n) matrix S is a (r x 1) vector BX-PS &ge; O where R is a (s x n) matrix Os &le; e where O is a (t x n) matrix e is a (t x 1) vectorAll variable are non-negative, the elements of the vector x arise from a continuous function, and the elements of the vector S are (0,1) integer values.The computer software used for solving the above model consists of two Fortran IV modules under the command of a language processor. Both software packages can be operated either interactively or under a batch processing mode. One of the computer software packages is labeled the &ldquo;Initialization program&rdquo; which is used to generate the coefficient vectors and matrices, i.e., C, A, d, H, h, B, D, R, O, and e presented in the above model. The other is labeled the &ldquo;Action program&rdquo; which is used to obtain an &ldquo;optimal&rdquo; solution for the problem. The computer software packages have been executed on a Xerox-560 computer in a limited fashion.In conclusion, there is an important by-product from our research so far; a way to find alternative optimal solutions. The branch and bound algorithm which we utilize is a partial enumeration technique in which subsets of feasible solutions are eliminated from consideration by comparing a lower bound on the objective function value (for a given subset) to the best solution obtained up to that point. Theoretically, alternative optimal solutions may be among those subsets of feasible solutions.
ID:435
CLASS:5
Title: Introduction to simulation modeling
Abstract: Since World War II system modeling has played an increasingly important role in the analysis of complex systems in both the private and public sectors. In the broadest sense, a model may be considered to be a representation of reality without the presence of reality itself. Hence, pictures, graphs, management games, computer programs and mathematical equations may be considered models of those systems which they represent. For the purposes of this discussion we will restrict our attention to that class of models which attempts to capture the relationship between the behavior of a measure or measures of system effectiveness and the behavior of those variables and parameters which influence the measure(s) of effectiveness and includes simulation and mathematical models. The specific focus of our attention will be on simulation models.
ID:436
CLASS:5
Title: DATAPLOT\&mdash;an interactive high-level language for graphics, non-linear fitting, data analysis, and mathematics
Abstract:  This paper describes the design philosphy and features of DATAPLOT&mdash;a high-level (free-format English-like syntax) language for:   1) graphics (continuous or discrete);   2) fitting (linear or non-linear);   3) general data analysis;   4) mathematics.   DATAPLOT was developed originally in 1977 in response to data analysis problems encountered at the National Bureau of Standards. It has subsequently been the most heavily-used interactive graphics and non-linear fitting language at NBS. It is a valuable tool not only for &ldquo;raw&rdquo; graphics, but also for manuscript preparation, modeling, data analysis, data summarization, and mathematical analysis. DATAPLOT may be run either in batch mode or interactively, although it was primarily designed for (and is most effectively used in) an interactive environmnet. DATAPLOT graphics may appear on many different types of output devices. Due to its modular design and underlying ANSI FORTRAN (PFORT) code, DATAPLOT is portable to a wide variety of computers.   The paper is divided into three general parts: part 1 deals with background motivation and design philosophy; part 2 deals with capability and implementation features; part 3 deals with a comparison of DATAPLOT to other systems/languages. 
ID:437
CLASS:5
Title: Modeling mania
Abstract: Invited Mike Huth, Imperial College London to be the guest editor for this column. What started as a simple idea evolved into a complete paper. I encourage you to read Mike's insightful article "Mathematics for the exploration of requirements" in this inroads issue. Below is a little background to ease you into an area that is becoming relevant and important in software systems development - modeling.
ID:438
CLASS:5
Title: Integration of a primal simplex network algorithm with a large-scale mathematical programming system
Abstract: In this paper we discuss the implementation of a primal simplex algorithm for network problems in the MPSIII mathematical programming system. Because of the need to interface with the rest of the MPS this implementation is unorthodox, but computationally effective, and has a number of advantages over &ldquo;stand alone&rdquo; network optimizers. It is argued that a similar approach is appropriate for other general-purpose mathematical programming systems, and has applications beyond pure network optimization.
ID:439
CLASS:5
Title: Fundamentals of digital simulation modeling
Abstract: This paper and the tutorial session with which it is associated treat the fundamental concepts of digital simulation. The topics discussed include system modeling, simulation models and their advantages and disadvantages relative to mathematical models, the development of simulation and current applications, the role of simulation modeling in systems analysis and simulation languages. The paper and the tutorial are presented at a level which requires no previous exposure to digital simulation. However, familiarity with the fundamentals of probability, probability distributions and inferential statistics will facilitate the participant's understanding of the material presented.
ID:440
CLASS:5
Title: A mathematical modeling approach to the automatic selection of database designs
Abstract: This paper provides an overview of a methodology developed to support systems analysts in the process of database design. The design approach is built upon an analytic model composed of (1) parametric descriptions for components of a generalized database organization, (2) costing equations which can evaluate a proposed modular database design, (3) an analyst interface which accepts an arbitrary database organization for evaluation, and (4) search procedures which automatically generate and compare thousands of alternative designs. Performance is measured as the sum of storage, retrieval, and maintenance costs and is estimated from parameters of the proposed design, the problem description and the storage environment. A virtual, record-frame view of secondary storage has been developed in which data records are added, deleted and modified with minimal effect on existing data structures. Application of the modeling approach to a realistic design problem is described, and modeling accuracy to within four percent is claimed.
ID:441
CLASS:5
Title: Solving stochastic mathematical programs with complementarity constraints using simulation
Abstract: Recently, simulation-based methods have been successfully used for solving challenging stochastic optimization problems and equilibrium models. Here we report some of the recent progress we had in broadening the applicability of so-called the sample-path method to include the solution of certain stochastic mathematical programs with equilibrium constraints. We first describe the method and the class of stochastic mathematical programs with complementarity constraints that we are interested in solving and then outline a set of sufficient conditions for its almost-sure convergence. We also illustrate an application of the method to solving a toll pricing problem in transportation networks. These developments also make it possible to solve certain stochastic bilevel optimization problems and Stackelberg games, involving expectations or steady-state functions, using simulation.
ID:442
CLASS:5
Title: A computer model to determine pathogen transport through environmental pathways
Abstract: A computer program was developed to model the transport of pathogens through environmental pathways as a result of the application of treated sewage sludge. Specific sludge application cases included the use of treated sludge as a cropland fertilizer, as a soil conditioner by the general public, and as a feed supplement for ruminant animals. A comprehensive review of relevant literature sources led to the definition of environmental pathways from the point of sludge production to points of potential human contact. Along these pathways, discrete points were designated where it was desired to compute pathogen populations. In this model, each point in these pathways is treated as a mathematical state. The transfer of pathogens between these states is described by a set of ordinary differential equations derived using conservation principles, environmental parameters, and relationships developed from data obtained in the literature review. These equations are then integrated to determine the pathogen populations at each state. This computerized model has been used in several applications and has helped to assess the risks associated with certain sludge utilization and treatment practices.
ID:443
CLASS:5
Title: A logic-based foundation of discrete event modeling and simulation
Abstract: A logic-based foundation of discrete event modeling and simulation is presented by defining (1) its fundamental concepts and terms from a perspective commonly held by logicians, (2) a modal Discrete Event Logic LDE. The ways of expressing models using LDE are discussed and compared with the ways of expressing models in simulation languages that support the event scheduling world view. The logic-based foundation provides fundamentally new insights. It asserts that events are logical propositions and the use of temporal operators is implicit in discrete event modeling and simulation languages. However, existing languages utilize only a few temporal operators in a restricted manner. The logic-based foundation  enhances the ways of expressing models by using the operators implicit in existing languages in more general ways, new operators, and a parallel connective ||. The logic LDE and notions implicit in it form a new framework for understanding, defining, and studying logical combinations of events, variables, and time, and expressions containing a wide range of temporal operators including next, if, when, whenever, until, while, unless, and at.
ID:444
CLASS:5
Title: SMM: mathematical framework of a scalable mobility model
Abstract: In this paper, we present a novel mathematical framework of a mobility model that can be applied to a large number of possible horizontal environments, ranging from local area networks (LANs) to wide area networks (WANs) for the prediction and tracking of mobile users. This new mobility model, termed 'Scalable Mobility Model' (SMM), provides a realistic set of paths for both individual and aggregate subscriber movement by assigning mobile users into specific classes of mobility based on their mobility characteristics, attraction points, geographical environments and time periods. The core technique used to implement these important mobility features in SMM is the introduction of a new concept referred to as the Pole of Gravity. Our mobility model has been decomposed into three processes termed as the physical, gravity and fluid sub-models. Using this new concept, we show how SMM can effectively characterize user mobility for the City Area Model of Avon district and the City Center of Bristol, UK, having an extension of 40 km by 40 km and 8 km by 8 km respectively. We also present simulation results to illustrate the effect of accurate mobility by comparing our realistic mobility model, SMM, with the well know Random Waypoint model. Specifically, we show how the choice of a mobility model affects channel utilization and handover performance issues for the mobile environment.
ID:445
CLASS:5
Title: Five principles for the formal validation of models of software metrics
Abstract: The goal of software metrics is the improvement of the software process. Five principles are fundamental to the formal validation of models of software metrics:--Attribute Type--what attribute(s) of software behavior are we measuring?;The mathematical postulates of a measure function--a model must have the utility for comparison; this unique criterion must be passed by every effective model of measure;Metrical Vindication--applying the model directly to measure actual software module(s); how consistent and reliable are the results of the measures?;Feedback Effect--how does the metric help us to identify faults and errors (of design) or improve testing and maintenance; what is a metric if it is just a number?;Units of Measure--what are we measuring with respect to dimensions: size, length/depth, extent, degree of variation, degradation, etc.?; a measure without unit(s) is like a building without a roof.Without principles, there is nothing to validate. Every good science is a body of relevant principles. Some worked examples on some of these principles are presented. Some of these examples in a way, expose the failures or frustrations resulting from the applications of some models of measure presently being used in industry and science. Not every mathematical function can be used as a model of measurement.
ID:446
CLASS:5
Title: A curriculum model for a graduate degree program in systems analysis
Abstract: A much needed master's level graduate degree program in systems analysis has been designed and proposed for implementation at Miami University. There are many graduate curricula that emphasize information systems, computer science, or operations research; but our proposal is unique in its attempt to combine these varied, yet related, disciplines. This paper describes the details of the proposed curriculum which largely conforms to the major curriculum recommendations. The proposal is sufficienctly general to be adopted as a model by programs of similar mix and emphasis.
ID:447
CLASS:5
Title: Estimation of parameters and eigenmodes of multivariate autoregressive models
Abstract: Dynamical characteristics of a complex system can often be inferred from analysis of a stochastic time series model fitted to observations of the system. Oscillations in geophysical systems, for example, are sometimes characterized by principal oscillation patterns, eigenmodes of estimated autoregressive (AR) models of first order. This paper describes the estimation of eigenmodes of AR models of arbitrary order. AR processes of any order can be decomposed into eigenmodes with characteristic oscillation periods, damping times, and excitations. Estimated eigenmodes and confidence intervals for the eigenmodes and their oscillation periods and damping times can be computed from estimated models parameters. As a computationally efficient method of estimating the parameters of AR models  from high-dimensional data, a stepwise least squares algorithm is proposed. This algorithm computes models of successively decreasing order. Numerical simulations indicate that, with the least squares algorithm, the AR model coefficients and the eigenmodes derived from the coefficients and eigenmodes are rough approximations of the confidence intervals inferred from the simulaitons.
ID:448
CLASS:5
Title: Usability analysis with Markov models
Abstract: How hard to users to find interactive devices to use to achieve their goals, and how can we get this information early enough to influence design? We show that Markov modeling can obtain suitable measures, and we provide formulas that can be used for a large class of systems. We analyze and consider alternative designs for various real examples. We introduce a &ldquo;knowledege/usability graph,&rdquo; which shows the impact of even a smaller amount of knowledge for the user, and the extent to which designers' knowledge may bias their views of usability. Markov models can be built into design tools, and can therefore be made very convenient for designers to utilize. One would hope that in the future, design tools would include such mathematical analysis, and no new design skills would be required to evaluate devices. A particular concern of this paper is to make the approach accessible. Complete program code and all the underlying mathematics are provided in appendices to enable others to replicate and test all results shown.
ID:449
CLASS:5
Title: Proof of a fundamental result in self-similar traffic modeling
Abstract: We state and prove the following key mathematical result in self-similar traffic modeling: the superposition of many ON/OFF sources (also known as packet trains) with strictly alternating ON- and OFF-periods and whose ON-periods or OFF-periods exhibit the Noah Effect (i.e., have high variability or infinite variance) can produce aggregate network traffic that exhibits the Joseph Effect (i.e., is self-similar or long-range dependent). There is, moreover, a simple relation between the parameters describing the intensities of the Noah Effect (high variability) and the Joseph Effect (self-similarity). This provides a simple physical explanation for the presence of self-similar traffic patterns in modern high-speed network traffic that is consistent with traffic measurements at the source level. We illustrate how this mathematical result can be combined with modern high-performance computing capabilities to yield a simple and efficient linear-time algorithm for generating self-similar traffic traces.We also show how to obtain in the limit a L&amp;eacute;vy stable motion, that is, a process with stationary and independent increments but with infinite variance marginals. While we have presently no empirical evidence that such a limit is consistent with measured network traffic, the result might prove relevant for some future networking scenarios.
ID:450
CLASS:5
Title: On the achievements of high school students studying computational models
Abstract: One of the units in the relatively new high school CS curriculum which is being implemented in Israel is a theoretical unit on computational models. It includes deterministic and non-deterministic finite automata, regular and non-regular languages, closure properties of regular languages, pushdown automata, closure properties of context free languages, Turing machines, the Church-Turing thesis and the halting problem. This paper focuses on part of a study we conducted dealing with the achievements of high school students studying this unit. Specifically, this paper compares the achievements of students on the technical parts of this unit vs. its theoretical parts. We also examine the correlation between achievements of students studying the Computational Models unit, and two other factors: The students' previous computer-related background (not necessarily computer science) and the level on which they studied mathematics.
ID:451
CLASS:5
Title: A positive systems model of TCP-like congestion control: asymptotic results
Abstract: We study communication networks that employ drop-tail queueing and Additive-Increase Multiplicative-Decrease (AIMD) congestion control algorithms. It is shown that the theory of nonnegative matrices may be employed to model such networks. In particular, important network properties, such as: 1) fairness; 2) rate of convergence; and 3) throughput, can be characterized by certain nonnegative matrices. We demonstrate that these results can be used to develop tools for analyzing the behavior of AIMD communication networks. The accuracy of the models is demonstrated by several NS studies.
ID:452
CLASS:5
Title: The nested rectangular array as a model of data
Abstract: Data, like electricity and gravity, are part of the world in which we live. Some occur naturally, as in the genetic code, while most occur as a consequence of language and social organization. The search for a theory of data, which begins with the choice of a model, is as important and interesting as the development of theories in physics, economics, and psychology. Most models of data are collections, such as the unnested array of APL, the one-axis nested list of LISP, and the set, which is nested but lacks the properties of order, repetitions, type, and multiple axes inherent in rectangular arrangement. Nested rectangular arrays have all these properties. The existence of simple, universally valid equations in both set theory and linear algebra suggests that equally simple equations may hold for all arrays. The principles of nested collections developed in set theory apply with few changes to the nesting of arrays. A one-sorted theory of arrays, in which type is preserved for empty arrays, provides an algebra of operations interpreted not only for data but also types of data.
ID:453
CLASS:5
Title: The mathematical validity of software metrics
Abstract: Mathematical modelling, especially in software engineering metrics, requires more emphasis to be placed on the validity of the selected mathematical tools and techniques to be used. There are a plethora of occurrences in the recent literature of the misapplication of quantitative techniques together with errors in the underlying mathematics. Software engineering metrics needs to take more care in its use of mathematics if it is to gain credence in the scientific and engineering communities.
ID:454
CLASS:5
Title: Modeling and analysis of dynamic coscheduling in parallel and distributed environments
Abstract: Scheduling in large-scale parallel systems has been and continues to be an important and challenging research problem. Several key factors, including the increasing use of off-the-shelf clusters of workstations to build such parallel systems, have resulted in the emergence of a new class of scheduling strategies, broadly referred to as dynamic coscheduling. Unfortunately, the size of both the design and performance spaces of these emerging scheduling strategies is quite large, due in part to the numerous dynamic interactions among the different components of the parallel computing environment as well as the wide range of applications and systems that can comprise the parallel environment. This in turn makes it difficult to fully explore the benefits and limitations of the various proposed dynamic coscheduling approaches for large-scale systems solely with the use of simulation and/or experimentation.To gain a better understanding of the fundamental properties of different dynamic coscheduling methods, we formulate a general mathematical model of this class of scheduling strategies within a unified framework that allows us to investigate a wide range of parallel environments. We derive a matrix-analytic analysis based on a stochastic decomposition and a fixed-point iteration. A large number of numerical experiments are performed in part to examine the accuracy of our approach. These numerical results are in excellent agreement with detailed simulation results. Our mathematical model and analysis is then used to explore several fundamental design and performance tradeoffs associated with the class of dynamic coscheduling policies across a broad spectrum of parallel computing environments.
ID:455
CLASS:5
Title: A modeling language for vehicle motion control behavioral specification
Abstract: Error-free engineering of high integrity applications such as vehicle motion control (VMC) requires unambiguous behavioral specification. As system engineering progresses from requirements modeling to functional design, to system implementation on a distributed platform, the specifications of the system artifacts and work products must be transferred across different engineering environments and stages in models without loss of semantics. Modeling environments currently available for industrial use, with their native modeling languages, do not provide the capability of unambiguous behavior modeling across tools and engineering stages. In this paper, we identify certain fundamental requirements for high integrity systems and show that these requirements are not satisfied in current and proposed international standards, and two commercial modeling tools. A modeling language for VMC behavioral specification, eFSM, is proposed as a candidate for standardization and for adoption by the community in this domain. The language is based on a general mathematical modeling framework and an extended finite state machine paradigm. It adds unambiguous semantics essential to the VMC behavioral specification. An experimental prototype of the eFSM has been developed and evaluated relative to the requirements for modeling high integrity systems.
ID:456
CLASS:5
Title: The equivalence of sequential and associate information structure models
Abstract: Interpreters for programming languages may be defined in terms of the information structures (data structures) generated during program execution. This paper develops a class of proof techniques for proving equivalence between two classes of programming language interpreters referred to as &lt;u&gt;associative interpreters&lt;/u&gt; and &lt;u&gt;sequential interpreters&lt;/u&gt;. The relation between associative and sequential interpreters is briefly illustrated first for arithmetic expression evaluation and then for lambda calculus evaluation, and the strategy for proving equivalence is briefly described. The proof technique is worked out in detail both for arithmetic expression evaluation and for lambda calculus evaluation. The relatively trivial case of arithmetic expression evaluation is considered in detail in order to illustrate the basic structure of the proof in a context familiar to the uninitiated. The proof of equivalence of associative and sequential lambda calculus interpreters demonstrates a nontrivial equivalence proof and at the same time provides valuable insights into the relation between mathematical definitions of the lambda calculus and practical implementations of the lambda calculus. It is shown that an understanding of lambda calculus interpretation in turn provides insights into interpretation mechanisms for block structure languages like ALGOL 60.
ID:457
CLASS:5
Title: A compilation of automatic differentiation tools presented at the 1995 international convention on industrial and applied mathematics, Hamburg
Abstract: This document was compiled for the minisymposium on automatic differentiation tools presented at the 1995 International Convention on Industrial and Applied Mathematics, Hamburg. The document was compiled by Chris Bischof and Fred Dilley of Argonne National Laboratory with contributions by Mike Bartholomew-Biggs, Stephen Brown, Alan Carle, Bruce Christianson, David Cowey, Frederic Eyssette, David M. Gay, Ralf Giering, Andreas Griewank, Jim Horwedel, Peyvand Khademi, K. Kubota, Andrew Mauer, Michael B. Monagan, John Pryce, John Reid, Andreas Rhodin, Nicole Rostaing-Schmidt, and Jean Utke.
ID:458
CLASS:5
Title: Concept inventories in computer science for the topic discrete mathematics
Abstract: This report describes concept inventories, specialized assessment instruments that enable educational researchers to investigate student (mis)understandings of concepts in a particular domain. While students experience a concept inventory as a set of multiple-choice items taken as a test, this belies its purpose, its careful development, and its validation. A concept inventory is not intended to be a comprehensive instrument, but rather a tool that probes student comprehension of a carefully selected subset of concepts that give rise to the most common and pervasive mismodelings. The report explains how concept inventories have been developed and used in other STEM fields, then outlines a project to explore the feasibility of concept inventories in the computing field. We use the domain of discrete mathematics to illustrate a suggested plan of action.
ID:459
CLASS:5
Title: Striving for mathematical thinking
Abstract: Computer science and software engineering are young, maturing disciplines. As with other mathematically based disciplines, such as the natural sciences, economics, and engineering, it takes time for the mathematical roots to grow and flourish. For computer science and software engineering, others have planted these seeds over many years, and it is our duty to nurture them. This working group is dedicated to promoting mathematics as an important tool for problem-solving and conceptual understanding in computing.
ID:460
CLASS:5
Title: The mathematics of statistical machine translation: parameter estimation
Abstract: We describe a series of five statistical models of the translation process and give algorithms for estimating the parameters of these models given a set of pairs of sentences that are translations of one another. We define a concept of word-by-word alignment between such pairs of sentences. For any given pair of such sentences each of our models assigns a probability to each of the possible word-by-word alignments. We give an algorithm for seeking the most probable of these alignments. Although the algorithm is suboptimal, the alignment thus obtained accounts well for the word-by-word relationships in the pair of sentences. We have a great deal of data in French and English from the proceedings of the Canadian Parliament. Accordingly, we have restricted our work to these two languages; but we feel that because our algorithms have minimal linguistic content they would work well on other pairs of languages. We also feel, again because of the minimal linguistic content of our algorithms, that it is reasonable to argue that word-by-word alignments are inherent in any sufficiently large bilingual corpus.
ID:461
CLASS:5
Title: Polyhedral sculpture: the path from computational artifact to real-world mathematical object
Abstract: Mathematics educators often despair at the subject's austere, "abstract" reputation. This paper describes recent work in developing an application named HyperGami, whose purpose is to integrate both the abstract and "real-world" aspects of mathematics by allowing children to design and construct polyhedral models and sculptures. We describe a sample HyperGami sculpture, and present our observations during the past year of pilot studies with elementary and middle school students.
ID:462
CLASS:5
Title: Model reliability and software quality assurance in simulation of nuclear fuel waste management systems
Abstract: As is the case with all scientific simulation studies, computerized simulation of nuclear fuel waste management systems can introduce and hide various types of errors. Frameworks to clarify issues of model reliability and software quality assurance are offered. Potential problems with reference to the main areas of concern for reliability and quality are discussed; e.g. experimental issues, decomposition, scope, fidelity, verification, requirements, testing, correctness, robustness are treated with reference to the experience gained in the past. A list comprising over 80 most common computerization errors is provided. Software tools and techniques used to detect and to correct computerization errors are discussed.
ID:463
CLASS:5
Title: Integrating Boolean and vector models of information retrieval with passage retrieval
Abstract: In the context of information retrieval, we propose here to merge in a single mathematical framework: the Boolean model, the vector space model, and passage retrieval in a single mathematical framework based on signal theory. In this framework, we define the weight wd,t of the term t in the document d not as a number, but as a function.
ID:464
CLASS:5
Title: A modeling lab for discovery-learning in computer science
Abstract: This paper describes our recent successful effort to obtain grant funding to enhance an existing computer lab with new hardware and software in order to provide a state-of-the-art computerized presentation/modeling/discovery-learning environment. The focus is on the project's rationale, objectives, implementation, impact on our curriculum and assessment. There is a discussion of a national workshop that was recently conducted in the lab and the potential for future workshops. Two modeling examples are presented, and conclusions are given about the project's accomplishments and its future impact.
ID:465
CLASS:5
Title: A mathematical model of the finding of usability problems
Abstract: For 11 studies, we find that the detection of usability problems as a function of number of users tested or heuristic evaluators employed is well modeled as a Poisson process. The model can be used to plan the amount of evaluation required to achieve desired levels of thoroughness or benefits. Results of early tests can provide estimates of the number of problems left to be found and the number of additional evaluations needed to find a given fraction. With quantitative evaluation costs and detection values, the model can estimate the numbers of evaluations at which optimal cost/benefit ratios are obtained and at which marginal utility vanishes. For a &ldquo;medium&rdquo; example, we estimate that 16 evaluations would be worth their cost, with maximum benefit/cost ratio at four.
ID:466
CLASS:5
Title: Rapid prototyping: a 3d visualization tool takes on sculpture and mathematical forms
Abstract: Many technical and scientific objects are far too complex to be properly understood through pictures. 3D representations that can be touched and physically manipulated by the observer convey information not obtainable from 2D projections. Thanks to some emerging affordable rapid prototyping (RP) technologies, such models are beginning to find a role in design, science, and manufacturing. RP is already firmly established in the automotive industry and among designers of consumer products, including household appliances, toys, and electronics. With this personal case study from the arts and mathematics, I hope to encourage designers from other application domains to use RP technologies as a truly 3D physical visualization tool.
ID:467
CLASS:5
Title: A quadratic-tensor model algorithm for nonlinear least-squares problems with linear constraints
Abstract: A new algorithm is presented for solving nonlinear least-squares and nonlinear equation problems. The algorithm is based on approximating the nonlinear functions using the quadratic-tensor model proposed by Schnabel and Frank. The problem statement may include simple bounds or more general linear constraints on the unknowns. The algorithm uses a trust-region defined by a box containing the current values of the unknowns. The objective function (Euclidean length of the functions) is allowed to increase at intermediate steps. These increases are allowed as long as our predictor indicates that a new set of best values exists in the trust-region. There is logic provided to retreat to the current best values, should that be required. The computations for the model-problem require a  constrained nonlinear least-squares solver. This is done using a simpler version of the algorithm. In its present form the algorithm is effective for problems with linear constraints and dense Jacobian matrices. Results on standard test problems are presented in the Appendix. The new algorithm appears to be efficient in terms of function and Jacobian evaluations.
ID:468
CLASS:5
Title: Modeling spatially correlated data in sensor networks
Abstract: The physical phenomena monitored by sensor networks, for example, forest temperature or water contamination, usually yield sensed data that are strongly correlated in space. With this in mind, researchers have designed a large number of sensor network protocols and algorithms that attempt to exploit such correlations.There is an increasing need to synthetically generate large traces of spatially correlated data representing a wide range of conditions to carefully study the performance of these algorithms. Further, a mathematical model for generating synthetic traces would provide guidelines for designing more efficient algorithms. These reasons motivate us to obtain a simple and accurate model of spatially correlated sensor network data.The proposed model is Markovian in nature and can capture correlation in data irrespective of the node density, the number of source nodes, or the topology. We describe a rigorous mathematical procedure and a simple practical method to extract the model parameters from real traces. We also show how to efficiently generate synthetic traces on a given topology using these parameters. The correctness of the model is verified by statistically comparing synthetic and real data. Further, the model is validated by comparing the performance of algorithms whose behavior depends on the degree of spatial correlation in data, under real and synthetic traces. The real traces are obtained from remote sensing data, publicly available sensor data, and sensor networks that we deploy. We show that the proposed model is more general and accurate than the commonly used jointly Gaussian model. Finally, we create tools that can be easily used by researchers to synthetically generate traces of any size and degree of correlation.
ID:469
CLASS:5
Title: Modeling the performance of interface contraction
Abstract: Automatic differentiation is a technique used to transform a computer code implementing some mathematical function into another program capable of evaluating the function and its derivatives. Compared to numerical differentiation, the derivatives obtained from applying automatic differentiation are free from truncation error, and their computation often requires less time. To increase the efficiency of a black box approach of automatic differentiation, a technique called interface contraction may be used. Interface contraction exploits the local structure of a code to temporarily reduce the global number of derivatives propagated through the code. Two performance models are introduced to predict the potential improvement in the execution time of a program making use of interface contraction compared to a program generated by a black box approach of automatic differentiation. The performance models are validated by numerical experiments carried out on different computing platforms. The computer codes used in the experiments stem from the application areas of neutron scattering and biostatistics.
ID:470
CLASS:5
Title: Symbolic mathematical computation\&mdash;introduction and overview
Abstract: A specific model depicting the nature of research and development work in symbolic mathematical computation is presented. The model provides the organization for this introduction and overview. Basic concepts and issues are adumbrated from the user's point of view, from the mathematician's point of view, and from the designer/implementer's point of view. The model focuses attention on the need for measurement by displaying the scientifically necessary, but currently nonexistent, information feedback loops. A vigorous attempt is made to place the work reported at this symposium in the perspective provided by the model. This examination culminates in a proposal.
ID:471
CLASS:5
Title: System optimization: Mathematical programming techniques for optimal computer use
Abstract: IN THIS PAPER we consider the application of mathematical programming techniques for the solution of allocation, assignment, or selection problems of digital computer uses involving large amounts of data input and output in a series of computer runs. Files may be input to several runs in a series of machine runs; further, a file may originally be an output of one of the computer runs. We seek to optimize the allocation or selection of computer memory to blocks of records for each file. Also, we shall seek to optimize the assignment of input-output devices if more than one type of such devices is available. Aside from other applications, we have a memory allocation problem. The minimization of use of memory locations for mostly scientific computing problems was the subject of the ACM Storage Allocation Symposium held in Princeton, N. J. on June 23 - 24, 19611. Wolman2 discusses memory allocation in situations where, e.g., &ldquo;a general-purpose computer performs the control, switching, and storage functions in a data communication system with message storage.&rdquo; White3 describes the &ldquo;Relative Effects of Central Processor and Input-Output Speeds Upon Throughput on the Large Computer.&rdquo; Delgalvis and Davison4 derive a computational procedure to evaluate the input-output buffer storage requirements of a real-time system.
ID:472
CLASS:5
Title: Modeling the student and the discipline in CAI drill and practice
Abstract: Models built into computer assisted instructional courses have several advantages. They make the underlying theoretical assumptions more explicit and, at the same time, give a clearer direction to the actual development of the CAI program. The purpose of this discussion is to present some of the areas in which models have had an implicit or explicit impact and to indicate how our current work is focused by these efforts. The main purpose of the modeling discussed here is to provide better, more effective instruction (models of the learner) with substantially generated curriculum (models of the discipline). The drill and practice context is emphasized because that is one with a history of models in both areas and one which has demonstrated potential.
ID:473
CLASS:5
Title: ECONOF: a model and tool to strategically manage continuous training
Abstract: Results obtained from our past research programs were used to provide managers with models and tools that concern the process of organizational knowledge management. The models and tools are based on actual data. They aim at allowing the alignment of the continuous training to the business strategic plan. The analysis of empirical data allowed the finding of factors, criteria and weights to be incorporated in a model named ECONOF. This paper first presents this multicriterion model with the software tool related. An example of criteria and subcriteria is presented. The process of finding criteria with their associate weights is explained. Results produced by ECONOF are then presented. The model helps managers to find continuous training activities that fit the priorities and resources set in the strategic plan. Then, we explain why we decided to move towards a mathematical model. The basic mathematical model that was developed from a subset of criteria and subcriteria used and validated with the existing ECONOF multicriterion model is then presented. Future enhancements of the mathematical model are finally mentioned.
ID:474
CLASS:5
Title: A Mathematical Model for Performability of Beowulf Clusters
Abstract: Beowulf clusters have become very popular as an alternative to supercomputers world-wide. However, the most pressing issues of today's cluster solutions is the need for high availability and performance. Such systems, clearly, are prone to break-downs. Even if cover is provided with some probability c, there will be reconfiguration and/or rebooting delays to resume the operation of a cluster. In this paper, the performance modelling for Beowulf multiprocessor systems is presented. For these systems, one head processor and several identical processors serving a common stream of arriving jobs is considered. To account for delays due to reconfiguration and rebooting, such systems are modelled and solved for exact performability measures, for both bounded and unbounded queuing capacities, using the spectral expansion method.
ID:475
CLASS:5
Title: Towards a semantic view of an extended entity-relationship model
Abstract: Nearly all query languages discussed recently for the Entity-Relationship (ER) model do not possess a formal semantics. Languages are often defined by means of examples only. The reason for this phenomenon is the essential gap between features of query languages and theoretical foundations like algebras and calculi. Known languages offer arithmetic capabilities and allow for aggregates, but algebras and calculi defined for ER models do not. This paper introduces an extended ER model concentrating nearly all concepts of known so-called semantic data models in a few syntactical constructs. Moreover, we provide our extended ER model with a formal mathematical semantics. On this basis a well-founded calculus is developed taking into account data operations on arbitrary   user-defined data types and aggregate functions. We pay special attention to arithmetic operations, as well as multivalued terms allowing nested queries, in a uniform and consistent manner. We prove our calculus only allows the formulation of safe terms and queries yielding a finite result, and to be (at least) as expressive as the relational calculi.
ID:476
CLASS:5
Title: Some connections between mathematical logic and complexity theory
Abstract: However difficult the fundamental problems of theoretical computer science may seem, there is very little to suggest that they are anything more than knotty combinatorial problems. So, when we look for reasons for our inability to resolve P &equil; NP and related questions, we most likely find them dealing with a lack of understanding of particular computational problems and their lower bounds. This is the sense of Hopcroft's prediction: &ldquo;...within the next five years, nobody will prove that any of these problems takes more than let's say n2 time. I think that's a reasonably safe conjecture and it also illustrates how little we know about lower bounds.&rdquo; [MT]. Hopcroft's guess is uncanny in its accuracy&mdash;after six years and considerable effort by many researchers, his conjecture remains unchallenged. The results in this paper offer a possible explanation for our failure to resolve these problems. Roughly, the main result of the sequel links lower bounds and a branch of mathematical logic known as model theory. In particular, we prove that the existence of nonpolynomial lower bounds is equivalent to the existence of nonstandard models of a sizable fragment of arithmetic. Since these are deep logical issues and there are very few techniques for handling them, and since the nonstandard models in question are non-effective, it seems plausible that this linking of complexity theory and logic explains our failure to obtain nontrivial lower bounds. One of the aims of mathematical logic is to clarify the relation between mathematical theories and their interpretations&mdash;or models.
ID:477
CLASS:5
Title: Position statement for EUROCAL 85: the efficiency of mathematical models
Abstract: Nature has a way of producing mathematical models to beholders with an open mind for beauty. Those models provide a challenge to explore their constructive aspects, to investigate their properties by algorithmic methods implying a way to prove them, and to using them as a basis for further experimentation.
ID:478
CLASS:5
Title: Verifying and validating simulation models
Abstract: This paper discusses verification and validation of simulation models. The different approaches to deciding model validity am presented; how model verification and validation relate to the model development process are discussed; various validation techniques are defined, conceptual model validity, model verification, operational validity, and data validity are described; ways to document results are given; and a recommended procedure is presented.
ID:479
CLASS:5
Title: Multinational capital budgeting: A simulation model
Abstract: The rapid growth of multinational corporations has hastened the need for the development of robust models to handle the increased risk and complexity. Particularly in capital budgeting, careful analysis and adequate reflection of the critical variables are essential. The great number of relevant variables, their significant interrelationships, and the high degree of uncertainty render mathematical models highly complex or infeasible to solve. To overcome these shortcomings, a &ldquo;Hertz-type&rdquo; simulation model is formulated for the multinational firm. The important international variables&mdash;foreign exchange rates, foreign tax methodology, host government controls, and other social, economic, and political factors&mdash;are reflected in the model. A two stage approach is utilized: first, investment projects are analyzed by the subsidiary and if they pass this first screening they are proposed for the parent's consideration; second, the parent evaluates the attractiveness of projects from its point of view and ranks proposals for acceptance considering all global opportunities. The model is designed so that sensitivity analysis can be easily performed.
ID:480
CLASS:5
Title: Real natural gas reservoir data Vs. natural gas reservoir models
Abstract: The gas reservoir per se model is an exceedingly simple model of a natural gas reservoir designed to develop the physical relationship between ultimate recovery and rate(s) of withdrawal for production regulation policy assessment. To be responsive, the model must be able to consider rates of withdrawal both far lower and higher than current practices which are dependent on current policies. For this model, as for every model, a reasonable question arises, "Does the model actually work as supposed?" What makes this question of great concern is that one cannot resort to replicated experiments in either real or model reservoirs to check a gas reservoir model. One can, however, challenge the model with real gas reservoir data. This is what we did and found that this exceedingly simple model fits real gas reservoir data in a very satisfying manner.
ID:481
CLASS:5
Title: Queuing analysis of polling models
Abstract: A polling model is a system of multiple queues accessed by a single server in cyclic order. Polling models provide performance evaluation criteria for a variety of demand-based, multiple-access schemes in computer and communication systems. This paper presents an overview of the state of the art of polling model analysis, as well as an extensive list of references. In particular, single-buffer systems and infinite-buffer systems with exhaustive, gated, and limited service disciplines are treated. There is also some discussion of systems with a noncyclic order of service and systems with priority. Applications to computer networks are illustrated, and future research topics are suggested.
ID:482
CLASS:5
Title: The inside story: including physiology in structural plant models
Abstract: Using models of frangipani, cotton and birch plants, this paper shows how physiology can be included in structural plant models through local plant component resource modelling, crop level modelling and canonical mathematical modelling at the level of the individual plant. These simulations are more than just pictorial representations of these plants, and more than just three-dimensional structural representations changing over time. They respond to their environment as they grow, which is achieved by including aspects of physiology in the models. However, they do not require detailed and complex quantitative understanding of the individual plant's physiology. This paper demonstrates the possibility of constructing such adaptive virtual plant simulations, with environmentally sensitive complex emergent structure, by modelling physiology in simple, yet effective ways.
ID:483
CLASS:5
Title: Modeling software design diversity: a review
Abstract: Design diversity has been used for many years now as a means of achieving a degree of fault tolerance in software-based systems. While there is clear evidence that the approach can be expected to deliver some increase in reliability compared to a single version, there is no agreement about the extent of this. More importantly, it remains difficult to evaluate exactly how reliable a particular diverse fault-tolerant system is. This difficulty arises because assumptions of independence of failures between different versions have been shown to be untenable: assessment of the actual level of dependence present is therefore needed, and this is difficult. In this tutorial, we survey the modeling issues here, with an emphasis upon the impact these have upon the problem of assessing the reliability of fault-tolerant systems. The intended audience is one of designers, assessors, and project managers with only a basic knowledge of probabilities, as well as reliability experts without detailed knowledge of software, who seek an introduction to the probabilistic issues in decisions about design diversity.
ID:484
CLASS:5
Title: Modeling input processes
Abstract: Computer models for various applications are closely scrutinized both from the standpoint of questioning the correctness of the underlying mathematical model with respect to the process it is attempting to model, and from the standpoint of verifying that the computer model correctly implements the underlying mathematical model. A process that receives less scrutiny, but is none the less of equal importance, concerns the individual and joint modeling of the inputs. This modeling effort clearly has a great impact on the credibility of results obtained from simulation studies. Model characteristics are reviewed that have a direct bearing on the model input process and reasons are given for using probabilistic based modeling with the inputs. Discussions are presented on how to model distributions for individual inputs and how to model multivariate input structures when dependence and other constraints may be present.
ID:485
CLASS:5
Title: The gestalt of scientific programming: problem, model, method, implementation, assessment
Abstract: The process of solving a problem in computational science neither begins nor ends with designing and writing a computer program. The process entails isolating the problem, devising a mathematical model, identifying a computational method, producing an implementation, and assessing the solution. Unfortunately, the introductory programming courses taken by science and engineering students frequently focus only on implementation issues. As a result, such students are often ill-equipped to solve computational problems.We have created a course and written an accompanying textbook that present an introduction to scientific programming. Both are organized around the process for solving computational science problems sketched above. In this paper we illustrate this approach by describing two representative problems from the course and textbook. Along the way, we present Java applets that were designed to illustrate some of the ideas that underlie the two problems.
ID:486
CLASS:5
Title: Verification and validation of simulation models
Abstract: In this paper we discuss verification and validation of simulation models. Four different approaches to deciding model validity are described; two different paradigms that relate verification and validation to the model development process are presented; various validation techniques are defined; conceptual model validity, model verification, operational validity, and data validity are discussed; a way to document results is given; a recommended procedure for model validation is presented; and accreditation is briefly discussed.
ID:487
CLASS:5
Title: An investigation of potential success factors for an introductory model-driven programming course
Abstract: In order to improve the course design of a CS1 model-driven programming course we study potential indicators of success for such a course. We explain our specific interpretation of objects-first. Of eight potential indicators of success, we have found only two to be significant at a 95% confidence interval: math grade from high school and course work. The two significant indicators explain 24.2% of the variation of the exam grade. The result concerning math grade contradicts earlier findings. We discuss four aspects of our research: the explanation power of the potential success indicators, the impact of our findings on teaching, limits of what to conclude from the available data, and the variety of the notion "objects-first". Because of the variety of interpretations of "objects-first", the present research is necessary as a supplement to earlier research in order to make generalizable results on the success factors for objects-first programming.
ID:488
CLASS:5
Title: Verification and validation: verification and validation of simulation models
Abstract: In this paper we discuss verification and validation of simulation models. Four different approaches to deciding model validity are described; two different paradigms that relate verification and validation to the model development process are presented; various validation techniques are defined; conceptual model validity, model verification, operational validity, and data validity are discussed; a way to document results is given; a recommended procedure for model validation is presented; and accreditation is briefly discussed.
ID:489
CLASS:5
Title: Contextual grammars as generative models of natural languages
Abstract: The paper discusses some classes of contextual grammars---mainly those with "maximal use of selectors"---giving some arguments that these grammars can be considered a good model for natural language syntax.A contextual grammar produces a language starting from a finite set of words and interatively adding contexts to the currently generated words, according to a selection procedure: each context has associated with it a selector, a set of words; the context is adjoined to any occurrence of such a selector in the word to be derived. In grammars with maximal use of selectors, a context is adjoined only to selectros for which no superword is a selector. Maximality can be defined either locally or globally (with respect to all selectors in the grammar). The obtained families of languages are incomparable with that of Chomsky context-free languages (and with other families of languages that contain linear languages and that are not "too large"; see Section 5) and have a series of properties supporting the assertion that these grammars are a possible adequate model for the syntax of natural languages. They are able to straightforwardly describe all the usual restrictions appearing in natural (and artificial) languages, which lead to the non-context-freeness of these languages: reduplication, crossed dependencies, and multiple agreements; however, there are center-embedded constructions that cannot be covered by these grammars.While these assertions concern only the weak generative capacity of contextual grammars, some ideas are also proposed for associating a structure to the generated words, in the form of a tree, or of a dependence relation (as considered in descrpitive linguistics and also similar to that in link grammars).
ID:490
CLASS:5
Title: Nondeterministic polynomial-time computations and models of arithmetic
Abstract: A semantic, or model theoretic, approach is proposed to study the problems P =? NP and NP =? co-NP. This approach seems to avoid the difficulties that recursion-theoretic approaches appear to face in view of the result of Baker et al. on relativizations of the P =? NP question; moreover, semantical methods are often simpler and more powerful than syntactical ones. The connection between the existence of certain partial extensions of nonstandard models of arithmetic and the question NP =? co-NP is discussed. Several problems are stated about nonstandard models, and a possible link between the Davis-Matijasevi@@@@-Putnam-Robinson theorem on Diophantine sets and the NP =? co-NP question is mentioned.
ID:491
CLASS:5
Title: Intelligent CAI: The role of the curriculum in suggesting computational models of reasoning
Abstract: Computer-assisted instruction (CAI) offers many opportunities for the application of artificial intelligence (AI) techniques. One advantage of doing AI research within the CAI paradigm is that the curriculum provides a ready framework for the evaluation of any AI model that we might propose. In this paper we describe the models of informal mathematical reasoning that we have employed in developing a CAI system, called EXCHECK, for teaching set theory and other mathematically based courses at Stanford University. Specificially, we discuss how the maturing of mathematical reasoning is accommodated in the EXCHECK model. Methodologically, we wish to conclude that there is a good deal to be learned by implementing entire college curricula within a CAI system, and solving whatever information processing problems are present within those curricula.
ID:492
CLASS:5
Title: Applications of mathematical system theory to system design, modelling and simulation
Abstract: A mathematical system theoretic framework is described within which the necessary elaboration of the classical System Design, Modelling, and Simulation (SDMS) might be carried out. The applications of the new, elaborated problem-solving methodology to the design and analysis of communications systems is discussed as well as the concept of modelling as the design of an information system.
ID:493
CLASS:5
Title: Data structure models for programming languages
Abstract: This paper introduces a class of models (information structure models) for characterizing computations in terms of the data structures to which they give rise during execution, shows how such models can be used to characterize automata, digital computers and programming languages, considers in some detail the data structures generated during the execution of programs in block structure languages, develops a model for a non-block structure language (SNOBOL 4) and indicates how information structure models may be used in the semantic definition and formal characterization of programming languages. Sections 1 and 2 discuss the reasons for studying the relation between data structures and programming languages, section 3 introduces the notion of an information structure model and considers the classification of interpreters, and section 4 shows how automata, computers and programming languages may be characterized as sequential information structure models. Section 5 underlines the importance of introducing cells and references as semantic primitives of computational models. Section 6 develops models of implementation of block structure languages, section 7 considers the limitations of stack structure, and section 8 considers the hardware realization of block structure implementation of the Burroughs B6500. Section 9 develops an information structure model for the non-block structure language SNOBOL 4, while section 10 briefly discusses information structure models of language definition and the use of information structure models in proofs that programs have certain property. A final subsection considers the relative merits of axiomatic definition versus implementation-dependent definition of programming languages.
ID:494
CLASS:5
Title: A simple mathematical model of adaptive routing in wormhole <i>k</i>-ary <i>n</i>-cubes
Abstract: Many fully-adaptive algorithms have been proposed for k-ary n-cubes over the past decade. The performance characteristics of most of these algorithms have been analysed by means of software simulation only. This paper proposes a simple yet reasonably accurate analytical model to predict message latency in wormhole-routed k-ary n-cubes with fully adaptive routing. This model requires a running time of O(1) which is the fastest model yet reported in the literature while maintaining reasonable accuracy.
ID:495
CLASS:5
Title: Using a familiar package to demonstrate a difficult concept: using an excel spreadsheet model to explain the concepts of neural networks to undergraduates
Abstract: A course introducing neural networks to second year undergraduates with mixed disciplinary backgrounds needed a tool to reduce the overheads of simplifying the complex mathematical and programming skills normally associated with the subject. An Excel model was produced that had the added benefit of reducing anxiety, as all students taking the course are competent with Excel spreadsheets.
ID:496
CLASS:5
Title: GEMM-based level 3 BLAS: high-performance model implementations and performance evaluation benchmark
Abstract: The level 3 Basic Linear Algebra Subprograms (BLAS) are designed to perform various matrix multiply and triangular system solving computations. Due to the complex hardware organization of advanced computer architectures the development of optimal level 3 BLAS code is costly and time consuming. However, it is possible to develop a portable and high-performance level 3 BLAS library mainly relying on a highly optimized GEMM, the routine for the general matrix multiply and add operation. With suitable partitioning, all the other level 3 BLAS can be defined in terms of GEMM and a small amount of level 1 and level 2 computations. Our contribution is twofold. First, the model implementations in Fortran 77 of the GEMM-based level 3 BLAS are structured to reduced effectively data traffic in a memory hierarchy. Second, the GEMM-based level 3 BLAS performance evaluation benchmark is a tool for evaluating and comparing different implementations of the level 3 BLAS with the GEMM-based model implementations.
ID:497
CLASS:5
Title: The JigCell Model Builder: A Spreadsheet Interface for Creating Biochemical Reaction Network Models
Abstract: Converting a biochemical reaction network to a set of kinetic rate equations is tedious and error prone. We describe known interface paradigms for inputing models of intracellular regulatory networks: graphical layout (diagrams), wizards, scripting languages, and direct entry of chemical equations. We present the JigCell Model Builder, which allows users to define models as a set of reaction equations using a spreadsheet (an example of direct entry of equations) and outputs model definitions in the Systems Biology Markup Language, Level 2. We present the results of two usability studies. The spreadsheet paradigm demonstrated its effectiveness in reducing the number of errors made by modelers when compared to hand conversion of a wiring diagram to differential equations. A comparison of representatives of the four interface paradigms for a simple model of the cell cycle was conducted which measured time, mouse clicks, and keystrokes to enter the model, and the number of screens needed to view the contents of the model. All four paradigms had similar data entry times. The spreadsheet and scripting language approaches require significantly fewer screens to view the models than do the wizard or graphical layout approaches.
ID:498
CLASS:5
Title: An ontology for trajectory simulation
Abstract: From the concept exploration for a weapon system to training simulators, from hardware-in-the-loop simulators to mission planning tools, trajectory simulations are used throughout the life cycle of a weapon system. A trajectory simulation can be defined as a computational tool to calculate the flight path and flight parameters of munitions. There is a wide span of trajectory simulations differing widely with respect to their performance and fidelity characteristics, from simple point-mass simulations to six--seven degrees of freedom hardware-in-the-loop missile simulations. From our observations, it is a common practice in the industry that developments of these simulations are carried out as isolated projects although they rely on the same body of knowledge. We envision an ontology that will capture the common knowledge in trajectory simulation domain and make domain knowledge available for reuse. Trajectory Simulation Ontology, dubbed TSONT, is being developed to realize this vision.
ID:499
CLASS:6
Title: Distributed protocols for ensuring both coverage and connectivity of a wireless sensor network
Abstract: Wireless sensor networks have attracted a lot of attention recently. Such environments may consist of many inexpensive nodes, each capable of collecting, storing, and processing environmental information, and communicating with neighboring nodes through wireless links. For a sensor network to operate successfully, sensors must maintain both sensing coverage and network connectivity. This issue has been studied in wang et al. [2003] and Zhang and Hou [2004a], both of which reach a similar conclusion that coverage can imply connectivity as long as sensors' communication ranges are no less than twice their sensing ranges. In this article, without relying on this strong assumption, we investigate the issue from a different angle and develop several necessary and sufficient conditions for ensuring coverage and connectivity of a sensor network. Hence, the results significantly generalize the results in Wang et al. [2003] and Zhang and Hou [2004a]. This work is also a significant extension of our earlier work [Huang and Tseng 2003; Huang et al. 2004], which addresses how to determine the level of coverage of a given sensor network but does not consider the network connectivity issue. Our work is the first work allowing an arbitrary relationship between sensing ranges and communication distances of sensor nodes. We develop decentralized solutions for determining, or even adjusting, the levels of coverage and connectivity of a given network. Adjusting levels of coverage and connectivity is necessary when sensors are overly deployed, and we approach this problem by putting sensors to sleep mode and tuning their transmission powers. This results in prolonged network lifetime.
ID:500
CLASS:6
Title: An address-light, integrated MAC and routing protocol for wireless sensor networks
Abstract: We propose an address-light, integrated MAC and routing protocol (abbreviated AIMRP) for wireless sensor networks (WSNs). Due to the broad spectrum of WSN applications, there is a need for protocol solutions optimized for specific application classes. AIMRP is proposed for WSNs deployed for detecting rare events which require prompt detection and response. AIMRP organizes the network into concentric tiers around the sink(s), and routes event reports by forwarding them from one tier to another, in the direction of (one of) the sink(s). AIMRP is address-light in that it does not employ unique per-node addressing, and integrated since the MAC control packets are also responsible for finding the next-hop node to relay the data, via an anycast query. For reducing the energy expenditure due to idle-listening, AIMRP provides a power-saving algorithm which requires absolutely no synchronization or information exchange. We evaluate AIMRP through analysis and simulations, and compare it with another MAC protocol proposed for WSNs, S-MAC. AIMRP outperforms S-MAC for event-detection applications, in terms of total average power consumption, while satisfying identical sensor-to-sink latency constraints.
ID:501
CLASS:6
Title: Network protocol system monitoring: a formal approach with passive testing
Abstract: We study network protocol system monitoring for fault detection using a formal technique of passive testing that is a process of detecting system faults by passively observing its input/output behaviors without interrupting its normal operations. After describing a formal model of event-driven extended finite state machines, we present two algorithms for passive testing of protocol system control and data portions. Experimental results on OSPF and TCP are reported.
ID:502
CLASS:6
Title: Performance evaluation and simulations of routing protocols in ad hoc networks
Abstract: A mobile ad hoc network (MANET) is a collection of wireless mobile nodes communicating with each other using multi-hop wireless links without any existing network infrastructure or centralized administration. In recent years, a variety of routing protocols targeted specifically at this environment have been developed and some performance simulations are made. However, the related works took the simulation model with a constant network size and a varying pause times or mobility velocities. And these works do not take into account the influence on the protocols when the mobile nodes' pause time is invariable but the network size is changing. On the contrary, This paper considers the problem from a different perspective, using the simulation model with a dynamic network size and an invariable pause time which should be zero under weakest case because a longer pause time of the node may be insignificant for mobile Ad hoc network with frequently and fastly moving nodes. Furthermore, based on the QoS(delay, jitter, throughput, loss ratio), routing load and the connectivity (to our knowledge, we firstly use the jitter and the connectivity as the valued metrics in the simulation of wireless ad hoc network protocols), this paper systematically discuses the performance evaluation and comparison of four typical routing protocols of ad hoc networks with the different simulation model and metrics, and drew more complete and valuable conclusion.
ID:503
CLASS:6
Title: The DARPA wideband network protocol
Abstract: This paper discusses the Dual Bus Protocol (DBP) developed for the Terrestrial Wideband Network (TWBNET), a high-speed trans-continental network that supports distributed real-time applications and protocol research. DBP is a descendant of the QPSX protocol proposed as the IEEE 802.6 Metropolitan Area Network (MAN) standard, with enhancements to create a protocol suitable for a wide area network and to provide network services such as reserved bandwidth. In addition, the protocol was designed to be scalable for use in networks that are larger and faster than the TWBNET. This paper describes the DBP and its network environment and provides an analysis of the performance of the protocol based on both simulations and TWBNET measurements.
ID:504
CLASS:6
Title: Energy Efficient Protocols for Sensing Multiple Events in Smart Dust Networks
Abstract: Wireless Sensor Networks are comprised of a vast numberof ultra-small, autonomous computing and communicationdevices, with restricted energy, that co-operate to accomplisha large sensing task. In this work: a) We proposeextended versions of two data propagation protocols forsuch networks: the Sleep-Awake Probabilistic ForwardingProtocol (SW-PFR) and the Hierarchical Threshold sensitiveEnergy Efficient Network protocol (H-TEEN). Thesenon-trivial extensions improve the performance of the originalprotocols, by introducing sleep-awake periods in thePFR protocol to save energy, and introducing a hierarchyof clustering in the TEEN protocol to better cope with largenetworks, b) We implemented the two protocols and performedan extensive simulation comparison of various importantmeasures of their performance with a focus on energyconsumption, c) We investigate in detail the relativeadvantages and disadvantages of each protocol, d) We discussa possible hybrid combination of the two protocols towardsoptimizing certain goals.
ID:505
CLASS:6
Title: Protocol scrubbing: network security through transparent flow modification
Abstract: This paper describes the design and implementation of protocol scrubbers. Protocol scrubbers are transparent, interposed mechanisms for explicitly removing network scans and attacks at various protocol layers. The transport scrubber supports downstream passive network-based intrusion detection systems by converting ambiguous network flows into well-behaved flows that are unequivocally interpreted by all downstream endpoints. The fingerprint scrubber restricts an attacker's ability to determine the operating system of a protected host. As an example, this paper presents the implementation of a TCP scrubber that eliminates insertion and evasion attacks--attacks that use ambiguities to subvert detection--on passive network-based intrusion detection systems, while preserving high performance. The TCP scrubber is based on a novel, simplified state machine that performs in a fast and scalable manner. The fingerprint scrubber is built upon the TCP scrubber and removes additional ambiguities from flows that can reveal implementation-specific details about a host's operating system.
ID:506
CLASS:6
Title: Comparative performance evaluation of scatternet formation protocols for networks of bluetooth devices
Abstract: This paper describes the results of the first ns2-based comparative performance evaluation among four major solutions presented in the literature for forming multi-hop networks of Bluetooth devices (scatternet formation). The four protocols considered in this paper are BlueTrees [1], BlueStars [2], BlueNet [3] and the protocol presented in [4] which proposes geometric techniques for topology reduction combined with cluster-based scatternet formation. We implemented the operations of the four protocols from device discovery to scatternet formation. By means of a thorough performance evaluation we have identified protocol parameters and Bluetooth technology features that affect the duration of the formation process and the properties of the produced scatternet. We have investigated how possible modifications of the BT technology (e.g., backoff duration, possibility for a BT inquirer to identify itself) make device discovery more efficient for scatternet formation in multi-hop networks. We have then discussed implementation concerns for each of the selected protocols. Finally, we have analyzed the protocols overhead as well as the effect of the different protocols operations on key metrics of the generated scatternets, which includes the time needed for forming a scatternet, the number of its piconets, the number of slaves per piconet, the number of roles assumed by each node and the scatternet route lengths.
ID:507
CLASS:6
Title: Unmanaged Internet Protocol: taming the edge network management crisis
Abstract: Though appropriate for core Internet infrastructure, the Internet Protocol is unsuited to routing within and between emerging ad-hoc edge networks due to its dependence on hierarchical, administratively assigned addresses. Existing ad-hoc routing protocols address the management problem but do not scale to Internet-wide networks. The promise of ubiquitous network computing cannot be fulfilled until we develop an Unmanaged Internet Protocol (UIP), a scalable routing protocol that manages itself automatically. UIP must route within and between constantly changing edge networks potentially containing millions or billions of nodes, and must still function within edge networks disconnected from the main Internet, all without imposing the administrative burden of hierarchical address assignment. Such a protocol appears challenging but feasible. We propose an architecture based on self-certifying, cryptographic node identifies and a routing algorithm adapted from distributed hash tables.
ID:508
CLASS:6
Title: Architectural analysis and instruction-set optimization for design of network protocol processors
Abstract: TCP/IP protocol processing latency has been an important issue in high-speed networks. In this paper, we present an architectural study of TCP/IP protocol. We port the TCP/IP protocol stack from the 4.4 FreeBSD to the SimpleScalar simulation environment. The architectural characteristics, such as instruction level parallelism and cache behavior, are studied through simulation. We also compare the characteristics of TCP/IP protocol to that of SPECint benchmark programs. It turns out that the former is quite different from the latter due to the unique processing structure. Furthermore, in order to improve the effectiveness of instruction cache, frequent instruction pairs are analyzed, and corresponding architectural optimizations are made to the instruction set architecture. The performance is evaluated in the simulator. We find that a 23% improvement can be achieved by taking advantage of the optimization. The instruction set optimizations proposed in this paper will be helpful for the design of new programmable protocol processors in future.
ID:509
CLASS:6
Title: Rushing attacks and defense in wireless ad hoc network routing protocols
Abstract: In an ad hoc network, mobile computers (or nodes) cooperate to forward packets for each other, allowing nodes to communicate beyond their direct wireless transmission range. Many of the proposed routing protocols for ad hoc networks operate in an on-demand fashion, as on-demand routing protocols have been shown to often have lower overhead and faster reaction time than other types of routing based on periodic (proactive) mechanisms. Significant attention recently has been devoted to developing secure routing protocols for ad~hoc networks, including a number of secure on-demand routing protocols, that defend against a variety of possible attacks on network routing. In this paper, we present the rushing attack, a new attack that results in denial-of-service when used against all previous on-demand ad~hoc network routing protocols. For example, DSR, AODV, and secure protocols based on them, such as Ariadne, ARAN, and SAODV, are unable to discover routes longer than two hops when subject to this attack. This attack is also particularly damaging because it can be performed by a relatively weak attacker. We analyze why previous protocols fail under this attack. We then develop Rushing Attack Prevention (RAP), a generic defense against the rushing attack for on-demand protocols. RAP incurs no cost unless the underlying protocol fails to find a working route, and it provides provable security properties even against the strongest rushing attackers.
ID:510
CLASS:6
Title: Ad hoc-VCG: a truthful and cost-efficient routing protocol for mobile ad hoc networks with selfish agents
Abstract: We introduce a game-theoretic setting for routing in a mobile ad hoc network that consists of greedy, selfish agents who accept payments for forwarding data for other agents if the payments cover their individual costs incurred by forwarding data. In this setting, we propose Ad hoc-VCG, a reactive routing protocol that achieves the design objectives of truthfulness (i.e., it is in the agents' best interest to reveal their true costs for forwarding data) and cost-efficiency (i.e., it guarantees that routing is done along the most cost-efficient path) in a game-theoretic sense by paying to the intermediate nodes a premium over their actual costs for forwarding data packets. We show that the total overpayment (i.e., the sum of all premiums paid) is relatively small by giving a theoretical upper bound and by providing experimental evidence. Our routing protocol implements a variation of the well-known mechanism by Vickrey, Clarke, and Groves in a mobile network setting. Finally, we analyze a very natural routing protocol that is an adaptation of the Packet Purse Model [8] with auctions in our setting and show that, unfortunately, it does not achieve cost-efficiency or truthfulness.
ID:511
CLASS:6
Title: Network routing with path vector protocols: theory and applications
Abstract: Path vector protocols are currently in the limelight, mainly because the inter-domain routing protocol of the Internet, BGP (Border Gateway Protocol), belongs to this class. In this paper, we cast the operation of path vector protocols into a broad algebraic framework and relate the convergence of the protocol, and the characteristics of the paths to which it converges, with the monotonicity and isotonicity properties of its path compositional operation. Here, monotonicity means that the weight of a path cannot decrease when it is extended, and isotonicity means that the relationship between the weights of any two paths with the same origin is preserved when both are extended to the same node. We show that path vector protocols can be made to converge for every network if and only if the algebra is monotone, and that the resulting paths selected by the nodes are optimal if and only if the algebra is isotone as well.Many practical conclusions can be drawn from instances of the generic algebra. For performance-oriented routing, typical in intra-domain routing, we conclude that path vector protocols can be made to converge to widest or widest-shortest paths, but that the composite metric of IGRP (Interior Gateway Protocol), for example, does not guarantee convergence to optimal paths. For policy-based routing, typical in inter-domain routing, we formulate existing guidelines as instances of the generic algebra and we propose new ones. We also show how a particular instance of the algebra yields a sufficient condition for signaling correctness of internal BGP.
ID:512
CLASS:6
Title: Performance Modeling and Simulation of Dynamic and Rapid Auto-configuration Protocols for Ad-hoc Wireless Networks
Abstract: The use of wireless communications networks hasgained phenomenal momentum, resulting in thewidespread deployment and expansion of wireless networkinfrastructure. The dynamic and unpredictableenvironment characteristic of wireless ad-hoc networkscoupled with the scarcity of wireless network resources,limit and may even preclude the use of conventional subnetconfiguration protocols like the Dynamic HostConfiguration Protocol (DHCP) [1]. The problem of auto-configurationis further exacerbated by the high degrees ofmobility in ad-hoc networks. The Dynamic Registrationand Configuration Protocol (DRCP)[2] is an auto-configurationprotocol that has been proposed toovercome these shortcomings and facilitates dynamic,rapid and efficient configuration in the unpredictable ad-hocwireless network environment. This paper describesthe performance modeling and simulation of the DRCPprotocol. More specifically, it helps analyze and answercritical questions related to protocol performance, such asprotocol convergence time, protocol overheads,scalability, etc., under realistic operating conditions. Ourcontributions in this paper are two-fold. First, we analyzeprotocol performance and provide useful insights into itsoperation and use in wireless ad-hoc networks. Next, weillustrate the power of modeling and simulation (M&S),since the complexity of the underlying ad-hoc networks,precludes the use of closed form expressions for analysis.M&S allows us to preserve the dynamics of the underlyingnetwork and to analyze performance under realisticoperating conditions.
ID:513
CLASS:6
Title: SHARP: a hybrid adaptive routing protocol for mobile ad hoc networks
Abstract: A central challenge in ad hoc networks is the design of routing protocols that can adapt their behavior to frequent and rapid changes in the network. The performance of proactive and reactive routing protocols varies with network characteristics, and one protocol may outperform the other in different network conditions. The optimal routing strategy depends on the underlying network topology, rate of change, and traffic pattern, and varies dynamically. This paper introduces the Sharp Hybrid Adaptive Routing Protocol (SHARP), which automatically finds the balance point between proactive and reactive routing by adjusting the degree to which route information is propagated proactively versus the degree to which it needs to be discovered reactively. SHARP enables each node to use a different application-specific performance metric to control the adaptation of the routing layer. This paper describes application-specific protocols built on top of SHARP for minimizing packet overhead, bounding loss rate, and controlling jitter. Simulation studies show that the resulting protocols outperform the purely proactive and purely reactive protocols across a wide range of network characteristics.
ID:514
CLASS:6
Title: Lightweight sensing and communication protocols for target enumeration and aggregation
Abstract: The development of lightweight sensing andcommunication protocols is a key requirement for designing resource constrained sensor networks. This paper introduces a set of efficient protocols and algorithms, DAM, EBAM, and EMLAM, for constructing and maintaining sensor aggregates that collectively monitor target activity in the environment. A sensor aggregate comprises those nodes in a network that satisfy a grouping predicate for a collaborative processing task. The parameters of the predicate depend on the task and its resource requirements. Since the foremost purpose of a sensor network is to selectively gather information about the environment, the formation of appropriate sensor aggregates is crucial for optimally allocating resources to sensing and communication tasks.This paper makes minimal assumptions about node onboard processing and communication capabilities so as to allow possible implementations on resource-constrained hardware. Factors affecting protocol performance are discussed. The paper presents simulation results showing how the protocol performance varies as key network and task parameters are varied. It also provides probabilistic analyses of network behavior consistent with the simulation results. The protocols have been experimentally validated on a sensor network testbed comprising 25 Berkeley MICA sensor motes.
ID:515
CLASS:6
Title: CDMA-based MAC protocol for wireless ad hoc networks
Abstract: We propose a CDMA-based power controlled medium access protocol for mobile ad hoc networks (MANETs). Unlike previously proposed protocols, ours accounts for the multiple access interference (MAI), thereby addressing the notorious near-far problem that undermines the throughput performance in MANETs. Channel-gain information obtained from overheard RTS and CTS packets over an out-of-band control channel is used to dynamically bound the transmission power of mobile terminals in the vicinity of a receiver. By properly estimating the required transmission power for data packets, the proposed protocol allows for interference-limited simultaneous transmissions to take place in the neighborhood of a receiving terminal. Simulation results indicate that compared to the IEEE 802.11 approach, the proposed protocol achieves a significant increase in network throughput at no additional cost in energy consumption.
ID:516
CLASS:6
Title: ATP: a reliable transport protocol for ad-hoc networks
Abstract: Existing works have approached the problem of reliable transport in ad-hoc networks by proposing mechanisms to improve TCP's performance over such networks. In this paper we show through detailed arguments and simulations that several of the design elements in TCP are fundamentally inappropriate for the unique characteristics of ad-hoc networks. Given that ad hoc networks are typically stand-alone, we approach the problem of reliable transport from the perspective that it is justifiable to develop an entirely new transport protocol that is not a variant of TCP. Towards this end, we present a new reliable transport layer protocol for ad-hoc networks called ATP (ad-hoc transport protocol). We show through ns2 based simulations that ATP outperforms both default TCP and TCP-ELFN.
ID:517
CLASS:6
Title: Congestion control performance of R-DSDV protocol in multihop wireless ad hoc networks
Abstract: Ad hoc wireless networks are composed of mobile nodes communicating through wireless links, without any fixed backbone infrastructure. Frequent topology changes due to node mobility make routing in such dynamic networks a challenging problem. Moreover, successful message routing implies every mobile node is potentially capable of acting as a router, thus supporting store-and-forward mechanisms. However, resource limitations on these nodes also require a control on congestion due to message forwarding. In this paper, we consider our recently proposed randomized version of the well-known Destination-Sequenced Distance Vector (DSDV) routing protocol, referred to as R-DSDV, and validate its performance through extensive simulation experiments. Our results demonstrate that a probabilistic control on message traffic based on local tuning of protocol parameters is feasible, and that R-DSDV outperforms the basic DSDV protocol by significantly reducing the average queue size associated with each mobile node and hence the average packet delay.
ID:518
CLASS:6
Title: MR<sup>2</sup>RP: the multi-rate and multi-range routing protocol for IEEE 802.11 ad hoc wireless networks
Abstract: This paper discusses the issue of routing packets over an IEEE 802.11 ad hoc wireless network with multiple data rates (1/2/5.5/11 Mb/s). With the characteristics of modulation schemes, the data rate of wireless network is inversely proportional with the transmission distance. The conventional shortest path of minimum-hops approach will be no longer suitable for the contemporary multi-rate/multi-range wireless networks (MR2WN). In this paper, we will propose an efficient delay-oriented multi-rate/multi-range routing protocol (MR2RP) for MR2WN to maximize the channel utilization as well as to minimize the network transfer delay from source to destination. By analyzing the medium access delay of the IEEE 802.11 medium access control (MAC) protocol, the proposed MR2RP is capable of predicting the transfer delay of a routing path and finding the best one, which has the minimum transfer delay from source to destination. The proposed MR2RP may choose a longer path but with less contention competitors and buffer queuing delay. Simulation results show that MR2RP performs the load balancing and fast routing very well, and its call blocking probability is obviously lower than that of conventional minimum-hops approach with fixed transmission rate.
ID:519
CLASS:6
Title: A high speed transport protocol for datagram/virtual circuit networks
Abstract: We present a design and preliminary analysis of an end-to-end transport protocol that is capable of high throughput consistent with the evolving wideband physical networks based on fiber optic transmission lines and high capacity switches. Unlike the current transport protocols in which changes in control state information are exchanged between the two communicating entities only when some significant event occurs, our protocol exchanges relevant and full state information periodically, routinely and frequently. We show that this results in reducing the complexity of protocol processing by removing many of the procedures required to recover from the inadequacies of the network such as bit-errors, packet loss, out of sequence packets and makes it more amenable to parallel processing. Also, to increase channel utilization in the presence of high speed, long latency networks, and to support datagrams, we propose an efficient implementation of selective repeat method of error control used in our protocol. Thus, we utilize small extra bandwidth to simplify protocol processing; a trade-off that appears proper since electronic speeds for protocol processing are far slower than fiber transmission rates. Our preliminary estimates indicate that 20,000 packets/second can be handled in a completely software implementation on a 10 MIP microprocessor using 8% of its cycles.
ID:520
CLASS:6
Title: On-demand multicast routing protocol in multihop wireless mobile networks
Abstract: An ad hoc network is a dynamically reconfigurable wireless network with no fixed infrastructure or central administration. Each host is mobile and must act as a router. Routing and multicasting protocols in ad hoc networks are faced with the challenge of delivering data to destinations through multihop routes in the presence of node movements and topology changes. This paper presents the On-Demand Multicast Routing Protocol (ODMRP) for wireless mobile and hoc networks. ODMRP is a mesh-based, rather than a conventional tree-based, multicast scheme and uses a forwarding group concept; only a subset of nodes forwards the multicast packets via scoped flooding. It applies on-demand procedures to dynamically build routes and maintain multicast group membership. ODMRP is well suited for ad hoc wireless networks with mobile hosts where bandwidth is limited, topology changes frequently, and power is constrained. We evaluate ODMRP performance with other multicast protocols proposed for ad hoc networks via extensive and detailed simulation.
ID:521
CLASS:6
Title: An on-demand minimum energy routing protocol for a wireless ad hoc network
Abstract: A minimum energy routing protocol reduces the energy consumption of the nodes in a wireless ad hoc network by routing packets on routes that consume the minimum amount of energy to get the packets to their destination. This paper identifies the necessary features of an on-demand minimum energy routing protocol and suggests mechanisms for their implementation. We highlight the importance of efficient caching techniques to store the minimum energy route information and propose the use of an 'energy aware' link cache for storing this information. We compare the performance of an on-demand minimum energy routing protocol in terms of energy savings with an existing on-demand ad hoc routing protocol via simulation. We discuss the implementation of Dynamic Source Routing (DSR) protocol using the Click modular router on a real life test-bed consisting of laptops and wireless Ethernet cards. Finally we describe the modifications we have made to the DSR router to make it energy aware.
ID:522
CLASS:6
Title: A lightweight idempotent messaging protocol for faulty networks
Abstract: As parallel machines scale to one million nodes and beyond, it becomes increasingly difficult to build a reliable network that is able to guarantee packet delivery. Eventually large systems will need to employ fault-tolerant messaging protocols that afford correct execution in the presence of a lossy network. In this paper we present a lightweight protocol that preserves message idempotence and is easy to implement in hardware. We identify the requirements for a correct implementation of the protocol. Experiments are performed in simulation to determine implementation parameters that optimize performance. We find that an aggressive implementation on a fat tree network results in a slowdown of less than 2x compared to buffered wormhole routing on a fault-free network.
ID:523
CLASS:6
Title: Comparison of broadcasting techniques for mobile ad hoc networks
Abstract: Network wide broadcasting in Mobile Ad Hoc Networks provides important control and route establishment functionality for a number of unicast and multicast protocols. Considering its wide use as a building block for other network layer protocols, the MANET community needs to standardize a single methodology that efficiently delivers a packet from one node to all other network nodes. Despite a considerable number of proposed broadcasting schemes, no comprehensive comparative analysis has been previously done. This paper provides such analysis by classifying existing broadcasting schemes into categories and simulating a subset of each, thus supplying a condensed but comprehensive side by side comparison.The simulations are designed to pinpoint, in each, specific failures to network conditions that are relevant to MANETs, e.g., bandwidth congestion and dynamic topologies. In addition, protocol extensions using adaptive responses to network conditions are proposed, implemented and analyzed for one broadcasting scheme that performs well in the comparative study.
ID:524
CLASS:6
Title: Characterizing the interaction between routing and MAC protocols in ad-hoc networks
Abstract: We empirically study the effect of mobility and interaction between various input parameters on the performance of protocols designed for wireless ad-hoc networks. An important objective is to study the interaction of the routing and MAC layer protocols under different mobility parameters. We use three basic mobility models: grid mobility model, random waypoint model, and exponential correlated random model. The performance of protocols is measured in terms of various quality of service measures including (i) latency, (ii) throughput, (iii) number of packets received and (iv) long term fairness. Three different commonly studied routing protocols are used: AODV, DSR and LAR scheme 1. Similarly three well known MAC protocols are used: MACA, 802.11 and CSMA.Our main contribution is simulation based experiments coupled with emph rigorous statistical analysis to characterize the emph interaction between the above stated parameters. Such methods allow us to analyze complicated experiments with large input space in a systematic manner. From our results, we conclude the following: No single MAC or routing protocol dominated the other protocols in their class. More interestingly, no MAC/routing protocol combination was better than other combinations over all mobility models and response variables.In general, it is not meaningful to speak about a MAC or a routing protocol in isolation. Presence of interaction leads to trade-offs between the amount of control packets generated by each layer. The results raise the possibility of improving the performance of a particular MAC layer protocol by using a cleverly designed routing protocol or vice-versa..
ID:525
CLASS:6
Title: A dynamic core based multicast routing protocol for ad hoc wireless networks
Abstract: Ad hoc wireless networks are self-organizing dynamic topology networks formed by a collection of mobile nodes through radio links. Minimal configuration absence of infrastructure and quick deployment make them convenient for emergency situations other than military applications. Multicasting plays a very crucial role in the application of Ad hoc networks. As the number of participants increases scalability of the multicast protocol becomes an important issue. Among the existing multicast protocols On Demand Multicast Routing Protocol (ODMRP) perfo exhibits a high packet delivery ratio even at high mobility. But ODMRP suffers from higher control overhead as the network size and the number of sources increase.In this paper we propose an efficient multicast routing protocol for Ad hoc wireless networks. This protocol reduces the control overhead by dynamically classifying the sources into Active and Passive categories. The control overhead is significantly reduced by about 30% compared to ODMRP which contributes to the scalability of the protocol. We study the effectiveness of the proposed multicast routing protocol by simulation studies and the results show that the multicast efficiency is increased by 10--15% and packet delivery ratio is also improved at high network load.
ID:526
CLASS:6
Title: Negotiation-based protocols for disseminating information in wireless sensor networks
Abstract: In this paper, we present a family of adaptive protocols, called SPIN (Sensor Protocols for Information via Negotiation), that efficiently disseminate information among sensors in an energy-constrained wireless sensor network. Nodes running a SPIN communication protocol name their data using high-level data descriptors, called meta-data. They use meta-data negotiations to eliminate the transmission of redundant data throughout the network. In addition, SPIN nodes can base their communication decisions both upon application-specific knowledge of the data and upon knowledge of the resources that are available to them. This allows the sensors to efficiently distribute data given a limited energy supply. We simulate and analyze the performance of four specific SPIN protocols: SPIN-PP and SPIN-EC, which are optimized for a point-to-point network, and SPIN-BC and SPIN-RL, which are optimized for a broadcast network. Comparing the SPIN protocols to other possible approaches, we find that the SPIN protocols can deliver 60% more data for a given amount of energy than conventional approaches in a point-to-point network and 80% more data for a given amount of energy in a broadcast network. We also find that, in terms of dissemination rate and energy usage, the SPIN protocols perform close to the theoretical optimum in both point-to-point and broadcast networks.
ID:527
CLASS:6
Title: Query localization techniques for on-demand routing protocols in ad hoc networks
Abstract: Mobile ad hoc networks are characterized by multi-hop wireless links, absence of any cellular infrastructure, and frequent host mobility. Design of efficient routing protocols in such networks is a challenging issue. A class of routing protocols called on-demand protocols has recently found attention because of their low routing overhead. We propose a technique that can reduce the routing overhead even further. The on-demand protocols depend on query floods to discover routes whenever a new route is needed. Our technique utilizes prior routing histories to localize the query flood to a limited region of the network. Simulation results demonstrate excellent reduction of routing overheads with this mechanism. This also contributes to a reduced level of network congestion and better end-to-end delay performance of data packets.
ID:528
CLASS:6
Title: Scalable routing protocol for ad hoc networks
Abstract: In this paper we present a scalable routing protocol for ad hoc networks. The protocol is based on a geographic location management strategy that keeps the overhead of routing packets relatively small. Nodes are assigned home regions and all nodes within a home region know the approximate location of the registered nodes. As nodes travel, they send location update messages to their home regions and this information is used to route data packets. In this paper, we derive theoretical performance results for the protocol and prove that the control packet overhead scales linearly with node speed and N3/2 with increasing number of nodes. These results indicate that our protocol is well suited to relatively large ad hoc networks where nodes travel at high speed. Finally, we use simulations to validate our analytical model.
ID:529
CLASS:6
Title: An efficient multicast routing protocol in wireless mobile networks
Abstract: Providing multicast service to mobile hosts in wireless mobile networking environments is difficult due to frequent changes of mobile host location and group membership. If a conventional multicast routing protocol is used in wireless mobile networks, several problems may be experienced since existing multicast routing protocols assume static hosts when they construct the multicast delivery tree. To overcome the problems, several multicast routing protocols for mobile hosts have been proposed. Although the protocols solve several problems inherent in multicast routing proposals for static hosts, they still have problems such as non-optimal delivery path, datagram duplication, overheads resulting from frequent reconstruction of a multicast tree, etc. In this paper, we summarize these problems of multicast routing protocols and propose an efficient multicast routing protocol based on IEFT mobile IP in wireless mobile networks. The proposed protocol introduces a multicast agent, where a mobile host receives a tunneled multicast datagram from a multicast agent located in a network close to it or directly from the multicast router in the current network. While receiving a tunneled multicast datagram from a remote multicast agent, the local multicast agent may start multicast join process, which makes the multicast delivery route optimal. The proposed protocol reduces data delivery path length and decreases the amount of duplicate copies of multicast datagrams. We examined and compared the performance of the proposed protocol and existing protocols by simulation under various environments and we got an improved performance over the existing proposals.
ID:530
CLASS:6
Title: A Five-Phase Reservation Protocol (FPRP) for Mobile Ad Hoc Networks
Abstract: A new single channel, time division multiple access (TDMA)-based broadcast scheduling protocol, termed the Five-Phase Reservation Protocol (FPRP), is presented for mobile ad hoc networks. The protocol jointly and simultaneously performs the tasks of channel access and node broadcast scheduling. The protocol allows nodes to make reservations within TDMA broadcast schedules. It employs a contention-based mechanism with which nodes compete with each other to acquire TDMA slots. The FPRP is free of the "hidden terminal" problem, and is designed such that reservations can be made quickly and efficiently with negligible probability of conflict. It is fully-distributed and parallel (a reservation is made through a localized conversation between nodes in a 2-hop neighborhood), and is thus scalable. A "multihop ALOHA" policy is developed to support the FPRP. This policy uses a multihop, pseudo-Bayesian algorithm to calculate contention probabilities and enable faster convergence of the reservation procedure. The performance of the protocol, measured in terms of scheduling quality, scheduling overhead and robustness in the presence of nodal mobility, has been studied via simulations. The results showed that the protocol works very well in all three aspects. Some future work and applications are also discussed.
ID:531
CLASS:6
Title: A Survey of Energy Efficient Network Protocols for Wireless Networks
Abstract: Wireless networking has witnessed an explosion of interest from consumers in recent years for its applications in mobile and personal communications. As wireless networks become an integral component of the modern communication infrastructure, energy efficiency will be an important design consideration due to the limited battery life of mobile terminals. Power conservation techniques are commonly used in the hardware design of such systems. Since the network interface is a significant consumer of power, considerable research has been devoted to low-power design of the entire network protocol stack of wireless networks in an effort to enhance energy efficiency. This paper presents a comprehensive summary of recent work addressing energy efficient and low-power design within all layers of the wireless network protocol stack.
ID:532
CLASS:6
Title: Performance of multipath routing for on-demand protocols in mobile ad hoc networks
Abstract: Mobile ad hoc networks are characterized by multi-hop wireless links, absence of any cellular infrastructure, and frequent host mobility. Design of efficient routing protocols in such networks is a challenging issue. As class of routing protocols called on-demandprotocols hs recently found attention because of their low routing overhead. The on-demand protocols depend on query floods to discover routes whenever a new route is needed. Such floods take up a substantial portion of network bandwidth. We focus on a particular on-demand protocol, called Dynamic Source Routing, and show how intelligent use of multipath techniques can reduce the frequency of query floods. We develop an analytic modeling framework to determine the relative frequency of query floods for various techniques. Our modeling effort shows that while multipath routing is significantly better than single path routing, the performance advantage is small beyond a few paths and for long paths lengths. It also shows that providing all intermediate nodes in the primary (shortest) route with alternative paths has a significantly better performance than providing only the source with alternate paths. We perform some simulation experiments which validate these findings.
ID:533
CLASS:6
Title: An energy consumption model for performance analysis of routing protocols for mobile ad hoc networks
Abstract: A mobile ad hoc network (or manet) is a group of mobile, wireless nodes which cooperatively form a network independent of any fixed infrastructure or centralized administration. In particular, a manet has no base stations: a node communicates directly with nodes within wireless range and indirectly with all other nodes using a dynamically-computed, multi-hop route via the other nodes of the manet.Simulation and experimental results are combined to show that energy and bandwidth are substantively different metrics and that resource utilization in manet routing protocols is not fully addressed by bandwidth-centric analysis. This report presents a model for evaluating the energy consumption behavior of a mobile ad hoc network. The model was used to examine the energy consumption of two well-known manet routing protocols. Energy-aware performance analysis is shown to provide new insights into costly protocol behaviors and suggests opportunities for improvement at the protocol and link layers.
ID:534
CLASS:6
Title: Comparison of network protocol and architecture for distributed virtual simulation environment
Abstract: In any distributed virtual simulation environment, the underlying network architecture and its protocols play an important part in its performance. This paper describes the different underlying protocols used in the support of the RTI implementation in the Federated Simulations Development Kit (FDK). The communication FM and MCAST modules were modified to support different protocols. The performance of two different protocols: TCP and a new Lightweight Reliable Multicast, called Pseudo Reliable Multicast Protocol (PRMP), running on top of two different network architectures Ethernet and Asynchronous Transfer Mode (ATM) were compared. The latter protocol was developed specifically to support the distributed virtual simulation environment. Furthermore, in the case of the ATM network architecture, the use of native ATM-API was also implemented and its performance compared with the other protocols. The benchmarks used to compare their performance are Latency and Time Advance Request Benchmark. The results show that PRMP outperforms the other protocol techniques when the number of subscribers are large and when the bandwidth is limited. But it has some additional latency overhead, due to additional processing required to provide the reliability needed by the sender and receivers. Comparing the network architecture, the benchmark performance of the above protocols operating on top of 100BaseT switch network performs much better than over ATM network, although the transmission speed is much higher in the case of the latter.
ID:535
CLASS:6
Title: Physical layer driven protocol and algorithm design for energy-efficient wireless sensor networks
Abstract: The potential for collaborative, robust networks of microsensors has attracted a great deal of research attention. For the most part, this is due to the compelling applications that will be enabled once wireless microsensor networks are in place; location-sensing, environmental sensing, medical monitoring and similar applications are all gaining interest. However, wireless microsensor networks pose numerous design challenges. For applications requiring long-term, robust sensing, such as military reconnaissance, one important challenge is to design sensor networks that have long system lifetimes. This challenge is especially difficult due to the energy-constrained nature of the devices. In order to design networks that have extremely long lifetimes, we propose a physical layer driven approach to designing protocols and algorithms. We first present a hardware model for our wireless sensor node and then introduce the design of physical layer aware protocols, algorithms, and applications that minimize energy consumption of the system. Our approach prescribes methods that can be used at all levels of the hierarchy to take advantage of the underlying hardware. We also show how to reduce energy consumption of non-ideal hardware through physical layer aware algorithms and protocols.
ID:536
CLASS:6
Title: The use of connectionless network layer protocols over FDDI networks
Abstract: Methods for running the DoD IP and OSI connectionless network layer protocols over the FDDI medium are presented. Issues specific to the interaction between network layer protocols and FDDI are discussed, and some possible approaches to problems encountered are evaluated. The OSI protocol suite is examined in particular detail.This work was supported in part by National Science Foundation agreement no. NCR 8720904.
ID:537
CLASS:6
Title: Simulation-based performance evaluation of routing protocols for mobile ad hoc networks
Abstract: In this paper we evaluate several routing protocols for mobile, wireless, ad hoc networks via packet&dash;level simulations. The ad hoc networks are multi&dash;hop wireless networks with dynamically changing network connectivity owing to mobility. The protocol suite includes several routing protocols specifically designed for ad hoc routing, as well as more traditional protocols, such as link state and distance vector, used for dynamic networks. Performance is evaluated with respect to fraction of packets delivered, end&dash;to&dash;end delay, and routing load for a given traffic and mobility model. Both small &lpar;30 nodes&rpar; and medium sized &lpar;60 nodes&rpar; networks are used. It is observed that the new generation of on&dash;demand routing protocols use much lower routing  load, especially with small number of peer&dash;to&dash;peer conversations. However, the traditional link state and distance vector protocols provide, in general, better packet delivery and end&dash;to&dash;end delay performance.
ID:538
CLASS:6
Title: Caching strategies in on-demand routing protocols for wireless ad hoc networks
Abstract: An on-demand routing protocol for wireless and hoc networks is one that searches for and attempts to discover a route to some destination node only when a sending node originates a data packet addressed to that node. In order to avoid the need for such a route discovery to be performed before each data packet is sent, such routing protocols must cache routes previously discovered. This paper presents an analysis of the effects of different design choices for this caching in on-demand routing protocols in wireless ad hoc networks, dividing the problem into choices of cache structure, cache capacity, and cache timeout. Our analysis is based on the Dynamic Source Routing protocol (DSR), which operates entirely on-demand. Using detailed simulations of wireless ad hoc networks of 50 mobile nodes, we studied a large number of different caching algorithms that utilize a range of design choices, and simulated each cache primarily over a set of 50 different movement scenarios drawn from 5 different types of mobility models. We also define a set of new mobility metrics that allow accurate characterization of the relative difficulty that a given movement scenario presents to an ad hoc network routing protocol, and we analyze each mobility metric's ability to predict the actual difficulty in terms of routing overhead experienced by the routing protocol across the scenarios in our study.
ID:539
CLASS:6
Title: PAMAS\&mdash;power aware multi-access protocol with signalling for ad hoc networks
Abstract: In this paper we develop a new multiaccess protocol for ad hoc radio networks. The protocol is based on the original MACA protocol with the adition of a separate signalling channel. The unique feature of our protocol is that it conserves battery power at nodes by intelligently powering off nodes that are not actively transmitting or receiving packets. The manner in which nodes power themselves off does not influence the delay or throughput characteristics of our protocol. We illustrate the power conserving behavior of PAMAS via extensive simulations performed over ad hoc networks containing 10-20 nodes. Our results indicate that power savings of between 10% and 70% are attainable in most systems. Finally, we discuss how the idea of power awareness can be built into other multiaccess protocols as well.
ID:540
CLASS:6
Title: An extensible probe architecture for network protocol performance measurement
Abstract: This paper describes the architecture and implementation of Windmill, a passive network protocol performance measurement tool. Windmill enables experimenters to measure a broad range of protocol performance metrics by both reconstructing application-level network protocols and exposing the underlying protocol layers' events. Windmill is split into three functional components: a dynamically compiled Windmill Protocol Filter (WPF), a set of abstract protocol modules, and an extensible experiment engine. To demonstrate Windmill's utility, the results from several experiments are presented. The first set of experiments suggests a possible cause for the correlation between Internet routing instability and network utilization. The second set of experiments highlights: Windmill's ability to act as a driver for a complementary active Internet measurement apparatus, its ability to perform online data reduction, and the non-intrusive measurement of a closed system.
ID:541
CLASS:6
Title: A preservation-based multicast (RBM) routing protocol for mobile networks: initial route construction phase
Abstract: We propose a combined multicast routing, resource reservation and admission control protocol, termed Reservation-Based Multicast (RBM), that borrows the &ldquo;Rendez-vous Point&rdquo; or &ldquo;Core&rdquo; concept from multicast routing algorithms proposed for the Internet, but which is intended for operation in mobile networks and routes hierarchically-encoded data streams based on user-specified fidelity requirements, real-time delivery thresholds and prevailing network bandwidth constraints. The protocol exhibits the fully distributed operation and receiver-initiated orientation of these proposed algorithms; but, unlike them, the protocol is tightly coupled to a class of underlying, distributed, unicast routing protocols thereby facilitating operation in a dynamic topology. This paper focuses on the initial route construction phase, assumed to occur during a static &ldquo;snapshot&rdquo; of the dynamic topology, and is therefore applicable to fixed networks as well, e.g. the Internet.
ID:542
CLASS:6
Title: A simple and efficient routing protocol for the UMTS Access network
Abstract: This paper presents a simple network layer protocol that integrates routing and connectionless transfer of data in a wireless environment. The protocol is specifically geared towards supporting transfer of signalling in mobile networks based on a rooted tree topology. Exploiting the special characteristics of such a topology allows the specification of a very simple and processing efficient routing function. Using the routing function, a connectionless message transport service is implemented. The connec- tionless transport service is comparable to that of typical network layer protocols of existing data networks. The protocol has originally been specified to carry signalling messages in the control plane of mobile, cellular systems but has the potential to be used also in other environments.
ID:543
CLASS:6
Title: Protocol discovery in multiprotocol networks
Abstract: Interoperability requires that communicating systems support compatible protocols. Maintaining compatible protocols is problematic in heterogeneous networks, especially in a wireless infrastructure where hosts can move from one protocol environment to another. It is possible to improve the flexibility of a communication network's operation by deploying systems that support multiple protocols. These multiprotocol systems require support mechanisms that enable users to effectively access the different protocols. Of particular importance is the need to determine which of several protocols to use for a given communication task. In this work, we propose architectures for a protocol discovery system that uses directory services and protocol feedback mechanisms to determine which protocols are supported. We describe the issues related to protocol discovery and present protocol features necessary to support multiprotocol systems.
ID:544
CLASS:6
Title: Cache behavior of network protocols
Abstract: In this paper we present a performance study of memory reference behavior in network protocol processing, using an Internet-based protocol stack implemented in the x-kernel running in user space on a MIPS R4400-based Silicon Graphics machine. We use the protocols to drive a validated execution-driven architectural simulator of our machine. We characterize the behavior of network protocol processing, deriving statistics such as cache miss rates and percentage of time spent waiting for memory. We also determine how sensitive protocol processing is to the architectural environment, varying factors such as cache size and associativity, and predict performance on future machines.We show that network protocol cache behavior varies widely, with miss rates ranging from 0 to 28 percent, depending on the scenario. We find instruction cache behavior has the greatest effect on protocol latency under most cases, and that cold cache behavior is very different from warm cache behavior. We demonstrate the upper bounds on performance that can be expected by improving memory behavior, and the impact of features such as associativity and larger cache sizes. In particular, we find that TCP is more sensitive to cache behavior than UDP, gaining larger benefits from improved associativity and bigger caches. We predict that network protocols will scale well with CPU speeds in the future.
ID:545
CLASS:6
Title: A survey of UNI signaling systems and protocols for ATM networks
Abstract: The main aspect covered by signaling systems and protocols for ATM networks concerns the possibility to manage, maintain, and control a user-driven communication between arbitrary ATM end-systems connected to an ATM network. The tasks and procedures defined for, e.g., setting-up an ATM connection, are often very different concerning the rrelevant specifications of various working bodies (such as ITU-T or ATM-Forum) or certain vendors, although the basis to be done for maintaining ATM connections are always principally the same. The reason for this situation is, that the intentions of working bodies are different and each one of them follows specific strategies for certain scenarios (such as for point-to-point unicast or point-to-multipoint multicast). Nevertheless, various types of characteristics (such as addressing, multicast, or interworking) are requested from applications residing on top of ATM networks.Therefore, this survey of signaling systems and protocols for ATM networks identifies for several of selected approaches (such as Q.2931, UNI 3.1, or CMAP) important characteristics and relevant scenarios. Furthermore, a table-based comparison of some approaches has been added
ID:546
CLASS:6
Title: AIRMAIL: a link-layer protocol for wireless networks
Abstract: This paper describes the design and performance of a link-layer protocol for indoor and outdoor wireless networks. The protocol is asymmetric to reduce the processing load at the mobile, reliability is established by a combination of automatic repeat request and forward error correction, and link-layer packets are transferred appropriately during handoffs. The protocol is named AIRMAIL (AsymmetrIc Reliable Mobile Access In Link-layer). The asymmetry is needed in the design because the mobile terminals have limited power and smaller processing capability than the base stations. The key ideas in the asymmetric protocol design consist of placing bulk of the intelligence in the base station as opposed to placing it symmetrically, in requiring the mobile terminal to combine several acknowledgments into a single acknowledgment to conserve power, and in designing the base stations to send periodic status messages, while making the acknowledgment from the mobile terminal event-driven. The asymmetry in the protocol design results in a one-third reduction of compiled code. The forward error correction technique incorporates three levels of channel coding which interact adaptively. The motivation for using a combination of forward error correction and link-layer retransmissions is to obtain better performance in terms of end-to-end throughput and latency by correcting errors in an unreliable wireless channel in addition to end-to-end correction rather than by correcting errors only by end-to-end retransmissions. The coding overhead is changed adaptively so that bandwidth expansion due to forward error correction is minimized. Integrity of the link during handoffs (in the face of mobility) is handled by window management and state transfer. The protocol has been implemented. Experimental performance results based on the implementation are presented.
ID:547
CLASS:6
Title: Inter-organization networks: implications of access control: requirements for interconnection protocol
Abstract: When two or more distinct organizations interconnect their internal computer networks they form an Inter-Organization Network(ION). IONs support the exchange of cad/cam data between manufacturers and subcontractors, software distribution from vendors to users, customer input to suppliers' order-entry systems, and the shared use of expensive computational resources by research laboratories, as examples. This paper analyzes the technical implications of interconnecting networks across organization boundaries.After analyzing the organization context in which IONs are used, we demonstrate that such interconnections are not satisfied by traditional network design criteria of connectivity and transparency. To the contrary, a primary high-level requirement is access control, and participating organizations must be able to limit connectivity and make network boundaries visible. We describe a scheme based on non-discretionary control which allows interconnecting organizations to combine gateway, network, and system-level mechanisms to enforce cross-boundary control over invocation and information flow, while minimizing interference with internal operations.Access control requirements such as these impose new requirements on the underlying interconnection protocols. We demonstrate such alternative interconnection protocols that support loose coupling across administrative boundaries and that accommodate the necessary control mechanisms. Message-based gateways that support non-real-time invocation of services (e.g., file and print servers, financial transactions, VLSI design tools, etc.) are a promising basis for such loose couplings.
ID:548
CLASS:6
Title: Protocol service decomposition for high-performance networking
Abstract: In this paper we describe a new approach to implementing network protocols that enables them to have high performance and high flexibility, while retaining complete conformity to existing application programming interfaces. The key insight behind our work is that an application's interface to the network is distinct and separable from its interface to the operating system. We have separated these interfaces for two protocol implementations, TCP/IP and UDP/IP, running on the Mach 3.0 operating system and UNIX server. Specifically, library code in the application's address space implements the network protocols and transfers data to and from the network, while an operating system server manages the heavyweight abstractions that applications use when manipulating the network through operations other than send and receive. On DECstation 5000/200 systems connected by 10Mb/sec Ethernet, this approach to protocol decomposition achieves TCP/IP throughput of 1088 KB/second, which is comparable to that of a high-quality in-kernel TCP/IP implementation, and substantially better than a server-based one. Our approach achieves small-packet UDP/IP round trip latencies of 1.23 ms, again comparable to a kernel-based implementation and more than twice as fast as a server-based one.
ID:549
CLASS:6
Title: Implementing network protocols at user level
Abstract: Traditionally, network software has been structured in a monolithic fashion with all protocol stacks executing either within the kernel or in a single trusted user-level server. This organization is motivated by performance and security concerns. However, considerations of code maintenance, ease of debugging, customization, and the simultaneous existence of multiple protocols argue for separating the implementations into more manageable user-level libraries of protocols. This paper describes the design and implementation of transport protocols as user-level libraries.We begin by motivating the need for protocol implementations as user-level libraries and placing our approach in the context of previous work. We then describe our alternative to monolithic protocol organization, which has been implemented on Mach workstations connected not only to traditional Ethernet, but also to a more modern network, the DEC SRC ANI. Based on our experience, we discuss the implications for host-network interface design and for overall system structure to support efficient user-level implementations of network protocols.
ID:550
CLASS:6
Title: Integration of security in network routing protocols
Abstract: There are two sources of threats to secure operation of routing protocols in networks. The first source of threats is subverted routers that legitimately participate in a routing protocol. The second source of threats is intruders which may illegally attempt to interfere in routing protocols by masquerading as routers. In this paper, we first analyse the security requirements of network routing protocols and then discuss the necessary measures which can be adopted to make the operation of these protocols secure.
ID:551
CLASS:6
Title: Pre-allocation media access control protocols for multiple access WDM photonic networks
Abstract: Media access control protocols for an optically interconnected star-coupled system with pre-allocated WDMA channels are introduced and compared. The photonic network is based on a passive star-coupled WDM&ndash;based configuration with high topological connectivity and low complexity. The channels are pre-allocated to the nodes with this approach, where each node has a home channel that it uses either for all data packet transmissions or all data packet receptions. A home channel may be shared if the number of nodes exceeds the number of channels in the system. This approach does not require both tunable transmitters and tunable receivers. The performance of a generalized random access protocol is compared to a protocol based on interleaved time multiplexing. Both  protocols are designed to operate in a multiple-channel multiple-access environment and require each node to possess a tunable transmitter and a fixed (or slow tunable) receiver. Semi-markov analytic models are developed to investigate the performance of the two protocols. The analytic models are validated through simulation and performance is evaluated in terms of network throughput and packet delay with variations in system parameters.
ID:552
CLASS:6
Title: Energy-aware geographic routing in lossy wireless sensor networks with environmental energy supply
Abstract: Wireless sensor networks are characterized by multihop wireless lossy links and resource constrained nodes. Energy efficiency is a major concern in such networks. In this paper, we study Geographic Routing with Environmental Energy Supply (GREES) and propose two protocols, GREES-L and GREES-M, which combine geographic routing and energy-aware routing techniques and take into account the realistic lossy wireless channel condition and the renewal capability of environmental energy supply when making routing decisions. Simulation results show that GREESs are more energy efficient than the corresponding residual energy based protocols and geographic routing protocols without energy awareness. GREESs can maintain higher mean residual energy on nodes, and achieve better load balancing in terms of having smaller standard deviation of residual energy on nodes. Both GREES-L and GREES-M exhibit graceful degradation on end-to-end delay, but do not compromise the end-to-end throughput performance.
ID:553
CLASS:6
Title: Modelling adversaries and security objectives for routing protocols in wireless sensor networks
Abstract: The literature is very broad considering routing protocols in wireless sensor networks (WSNs). However, security of these routing protocols has fallen beyond the scope so far. Routing is a fundamental functionality in wireless networks, thus hostile interventions aiming to disrupt and degrade the routing service have a serious impact on the overall operation of the entire network. In order to analyze the security of routing protocols in a precise and rigorous way, we propose a formal framework encompassing the definition of an adversary model as well as the "general" definition of secure routing in sensor networks. Both definitions take into account the feasible goals and capabilities of an adversary in sensor environments and the variety of sensor routing protocols. In spirit, our formal model is based on the simulation paradigm that is a successfully used technique to prove the security of various cryptographic protocols. However, we also highlight some differences between our model and other models that have been proposed for wired or wireless networks. Finally, we illustrate the practical usage of our model by presenting the formal description of a simple attack against an authenticated routing protocol, which is based on the well-known TinyOS routing.
ID:554
CLASS:6
Title: SIGF: a family of configurable, secure routing protocols for wireless sensor networks
Abstract: As sensor networks are deployed in adversarial environments and used for critical applications such as battlefield surveillance and medical monitoring, security weaknesses become a big concern. The severe resource constraints of WSNs give rise to the need for resource bound security solutions.In this paper we present SIGF (Secure Implicit Geographic Forwarding), a configurable secure routing protocol family for wireless sensor networks that provides "good enough" security and high performance. By avoiding or limiting shared state, the protocols prevent many common attacks against routing, and contain others to the local neighborhood.SIGF makes explicit the tradeoff between security provided and state which must be stored and maintained. It comprises three protocols, each forming a basis for the next: SIGF-0 keeps no state, but provides probabilistic defenses; SIGF-1 uses local history and reputation to protect against certain attacks; and SIGF-2 uses neighborhood-shared state to provide stronger security guarantees.Our performance evaluation shows that SIGF achieves high packet delivery ratios with low overhead and end-to-end delay. We evaluate the security of SIGF protocols under various security attacks and show that it effectively contains the damage from compromised nodes and defends against black hole, selective forwarding, Sybil, and some denial of service attacks.
ID:555
CLASS:6
Title: Testing methodology for an ad hoc routing protocol
Abstract: Ad hoc protocols, Testing, Verification, Model checking, PLTL, SPIN, Simulations. In this paper, we define a model of an ad hoc routing protocol, i.e. the OLSR (Optimized Link-State Routing) protocol. This model handles novel constraints related to such networks and issues new challenges to treat these constraints. In the network community, the practice is based on simulation models that allow to perform performance measures but no formal methods are used. We propose to promote the use of formal description techniques such as the promela and SDL languages that are both well accepted in the community of communication protocols. Until now, few works exist that handle the formal description of ad hoc networks, this network has as a main feature the absence of infrastructure. So, conformance testing and verification need to be revisited in order to bridge the gap between these new protocols and formal methods. In order to test and verify such protocols we need first to dispose of a formal model of what we want to verify and test. This is what we propose herein
ID:556
CLASS:6
Title: Routing protocols for efficient communication in wireless ad-hoc networks
Abstract: In this paper we demonstrate the significant impact of the user mobility rates on the performance on two different approaches for designing routing protocols for ad-hoc mobile networks: (a) the route creation and maintenance approach and (b) the "support" approach, that forces few hosts to move acting as "helpers" for message delivery. We study a set of representative protocols for each approach, i.e. DSR and ZRP for the first approach and RUNNERS for the second. We have implemented the three protocols and performed a large scale and detailed simulation study of their performance. Our findings are: (i) DSR achieves low message delivery rates but manages to deliver messages very fast; (ii) ZRP behaves well in networks of low mobility rate, while its performance drops for networks of highly mobile users; (iii) RUNNERS seem to tolerate well (and in fact benefit from) high mobility rates. Based on our investigation, we design and implement two new protocols that result from the synthesis of the investigated routing approaches. We conducted an extensive, comparative simulation study of their performance. The new protocols behave well both in networks of diverse mobility motion rates, and in some cases they even outperform the original ones by achieving lower message delivery delays
ID:557
CLASS:6
Title: Experimental analysis of a transport protocol for ad hoc networks (TPA)
Abstract: Many previous papers have pointed out that TCP performance in multi-hop ad hoc networks is not optimal. This is due to several TCP design principles that reflect the characteristics of wired networks dominant at the time when TCP was designed, but are not adequate for multi-hop ad hoc networks. For example, congestion phenomena in multi-hop networks are very different than in traditional wired networks, and route failures and route changes may be frequent events. To overcome these problems, in a previous work we presented a novel transport protocol  named TPA  specifically tailored to multi-hop ad hoc networks. In this paper we perform an experimental analysis of TPA in static multi-hop scenarios. Specifically, we compare TPA and TCP performance in a chain topology with different number of hops and traffic patterns. We also consider the effect of the routing protocol. Our experimental results show that TPA protocol outperforms TCP significantly both in terms of throughput and energy consumption
ID:558
CLASS:6
Title: State-of-the-art in protocol research for underwater acoustic sensor networks
Abstract: In this paper, architectures for two-dimensional and three-dimensional underwater sensor networks are discussed. A detailed overview on the current solutions for medium access control, network, and transport layer protocols are given and open research issues are discussed.
ID:559
CLASS:6
Title: A localized IP-address auto-configuration protocol for wireless ad-hoc networks
Abstract: We present a localized IP auto-con.guration protocol for wireless ad-hoc networks, called OASIS. OASIS introduces the idea of position-dependent IP-addresses using a cellular structure of the underlying network. Within a cell, nodes try to obtain a con.ict-free IP-address using a distributed mutual exclusion style algorithm. We show the correctness, and present an asymptotic analysis of the overhead of OASIS. Further, we present extensions to OASIS protocol to cope with message losses and node mobility. OASIS avoids problems due to network partitions and mergers, supports concurrent node joins/leaves, incurs localized control overhead per IP-address acquisition (independent of the number of nodes in the network), and hence it is scalable.
ID:560
CLASS:6
Title: High performance wireless switch protocol for IEEE 802.11 wireless networks
Abstract: All mobile stations (STAs) in IEEE 802.11 infrastructure wireless local area networks (IWLAN) are coordinated by an access point (AP). Within the 2.4 GHz unlicensed industry, science, and medicine (ISM) band defined in the IEEE 802.11 2.4 GHz physical layer (PHY) specifications, three channels are available for concurrently transferring data packets at the coverage area of an AP. In most of small/medium enterprises or home environments, an AP with one selected channel is sufficient for covering whole service area, but this implies that the radio resources for the remaining two channels are wasted. In order to overcome the drawback, we propose a new and simple media access control (MAC) protocol, named wireless switch protocol (WSP), for increasing the throughput of IEEE 802.11 IWLAN network to support high quality multimedia traffic. This is achieved by allowing any pair of STAs in IWLAN to exchange data packets in one of other idle channels after their handshake with each other in the common channel controlled by AP. Simulation results show that the total network throughput of WSP depends on the time taken by channel switching, and on the 'Intranet' and 'Internet' traffic distribution, where the Intranet and Internet mean data transmission between STAs in IWLAN and between the STA and wired host, respectively. When all data packets are Intranet traffic and the traffic load is heavy, the ratio of Goodput for the proposed WSP to that of IEEE 802.11 standard approximates 400%. In the worse case of all Internet traffic, the proposed WSP still obtains the similar throughput as that of IEEE 802.11 standard.
ID:561
CLASS:6
Title: SYN-MAC: a distributed medium access control protocol for synchronized wireless networks
Abstract: In this paper, we propose a novel medium access control (MAC) protocol, called SYN-MAC (for SYNchronized MAC), based on a binary countdown approach tailored for wireless networks. SYN-MAC has several attractive features such as simplicity, robustness, high efficiency, fairness, and quality of service capability. We evaluate SYN-MAC in terms of collision probability, system throughput, and packet delay, via both analysis and simulation. Our results show that, with properly chosen parameters, SYN-MAC can achieve a very low collision probability, packet delay tolerance, and extremely high channel efficiency (of &gt;90%) under a wide range of traffic load. As a result, SYN-MAC may serve as an alternative to IEEE 802.11 for the wireless stations in synchronized networks.
ID:562
CLASS:6
Title: Ariadne: a secure on-demand routing protocol for ad hoc networks
Abstract: An ad hoc network is a group of wireless mobile computers (or nodes), in which individual nodes cooperate by forwarding packets for each other to allow nodes to communicate beyond direct wireless transmission range. Prior research in ad hoc networking has generally studied the routing problem in a non-adversarial setting, assuming a trusted environment. In this paper, we present attacks against routing in ad hoc networks, and we present the design and performance evaluation of a new secure on-demand ad hoc network routing protocol, called Ariadne. Ariadne prevents attackers or compromised nodes from tampering with uncompromised routes consisting of uncompromised nodes, and also prevents many types of Denial-of-Service attacks. In addition, Ariadne is efficient, using only highly efficient symmetric cryptographic primitives.
ID:563
CLASS:6
Title: A Self-Reorganizing Slot Allocation protocol for multi-cluster sensor networks
Abstract: This paper presents a Self-Reorganizing Slot Allocation (SRSA) mechanism for TDMA based Medium Access Control (MAC) in wireless sensor networks. With TDMA, a node can achieve significant energy savings by remaining active only during allocated slots for transmissions and receptions. In multi-cluster networks, it is often necessary for nodes to use either CDMA or FDMA for preventing interference across neighbor clusters. The goal of this paper is to provide an alternative design that can reduce inter-cluster TDMA interference without having to use spectrum expensive CDMA or FDMA. The primary contribution of this paper is to demonstrate that with adaptive slot allocation, it is possible to reduce such interference under low loading conditions, which is often the case for sensor networks with monitoring applications. The second contribution is to design a feedback based adaptive allocation reorganization protocol that can significantly reduce those interferences without relying on any global synchronization mechanisms. We present the design of SRSA and provide a simulation based characterization of the protocol in comparison with TDMA-over-CDMA, TDMA with random slot allocation and CSMA MAC protocols. The results indicate that with moderate cluster overlapping and low traffic, SRSA can significantly reduce inter-cluster TDMA interference while delivering TDMA-over-CDMA like energy efficiency, at the cost of higher delivery latency compared to TDMA-over-CDMA. Assuming its low complexity and narrow-band operation unlike TDMA-over-CDMA, SRSA can be an ideal sensor MAC protocol for applications that can tolerate relatively larger delivery latency but not frequent packet drops
ID:564
CLASS:6
Title: A simulation study of a MAC layer protocol for wireless networks with asymmetric links
Abstract: Asymmetric links are common in wireless networks for a variety of physical, logical, operational, and legal considerations. An asymmetric link supports uni-directional communication between a pair of mobile stations and requires a set of relay stations for the transmission of packets in the other direction. We introduce a MAC layer protocol for wireless networks with Asymmetric links (AMAC). The MAC layer protocol requires fewer nodes to maintain silence during a transmission exchange than the protocols proposed in [1, 2]. We present a set of concepts and metrics characterizing the ability of a medium access control protocol to silence nodes which could cause collisions.
ID:565
CLASS:6
Title: The Anchor Location Service (ALS) protocol for large-scale wireless sensor networks
Abstract: Location-based routing (LBR) is one of the most widely used routing strategies in large-scale wireless sensor networks. With LBR, small, cheap and resource-constrained nodes can perform the routing function without the need of complex computations and large amounts of memory space. Further, nodes do not need to send energy consuming periodic advertisements because routing tables, in the traditional sense, are not needed. One important assumption made by most LBR protocols is the availability of a location service or mechanism to find other nodes' positions. Although several mechanisms exist, most of them rely on some sort of flooding procedure unsuitable for large-scale wireless sensor networks, especially with multiple and moving sinks and sources. In this paper, we introduce the Anchor Location Service (ALS) protocol, a grid-based protocol that provides sink location information in a scalable and efficient manner and therefore supports location-based routing in large-scale wireless sensor networks. The location service is evaluated mathematically and by simulations and also compared with a well-known grid-based routing protocol. Our results demonstrate that ALS not only provides an efficient and scalable location service but also reduces the message overhead and the state complexity in scenarios with multiple and moving sinks and sources, which are not usually included in the literature.
ID:566
CLASS:6
Title: A real-world framework to evaluate cross-layer protocols for wireless multihop networks
Abstract: The MAC layer implementation of today's commodity 802.11 wire-less network devices cannot easily be changed. But many cross-layer protocols for MANETs rely on a modified MAC layer. Therefore it is hard to test such protocols in real world environments. We propose to use a sensor network platform, the ESB sensor nodes, for this purpose. We present a software framework to make cross-layer protocol implementations and methodical experimentation feasible. The framework consists of software tools and modules for many frequently occurring tasks. It provides an extended link layer that increases the flexibility for protocol implementations on higher layers and it enables multihop communication on the ESB nodes by a network layer with static routing. An experimenter is supported by mechanisms to deploy routing tables, to gather network topol-ogy information and to obtain packet logs from all network nodes. We also give some experimentation results from an implementation of a cross-layer protocol using the framework.
ID:567
CLASS:6
Title: SmartGossip: an improved randomized broadcast protocol for sensor networks
Abstract: We investigate four performance metrics for randomized broadcast protocols on sensor networks: the fraction of nodes that receive the message (coverage), the number of first-time receivers per transmission (energy efficiency), the node-average normalized time till reception (per hop latency), and the average number of control messages per node (overhead). Our focus is to evaluate the extent to which the exchange of local information (either active or passive) can improve protocol performance. To this end we study via simulation three protocols from the literature that exploit local information (GOSSIP3 from [8], SPIN-1 from [10], and PUSH&PULL from [12])and compare their performance against the well known GOSSIP1 ([8]) protocol which does not employ any local information in making transmission decisions. Our findings are that i) local information is of course quite valuable in increasing protocol performance, and ii) it is possible to obtain high coverage and efficiency but one must then incur either increased delay or increased overhead. We study the strengths and weaknesses of the above protocols and propose the new SmartGossip protocol which combines several ideas from the above protocols, as well as several new mechanisms, to achieve superior performance.
ID:568
CLASS:6
Title: Routing and link-layer protocols for multi-channel multi-interface ad hoc wireless networks
Abstract: Wireless technologies, such as IEEE 802.11a, that are used in ad hoc networks provide for multiple non-overlapping channels. Most ad hoc network protocols that are currently available are designed to use a single channel. However, the available network capacity can be increased by using multiple channels. This paper presents new protocols specifically designed to exploit multiple channels. Our protocols simplify the use of multiple channels by using multiple interfaces, although the number of interfaces per host is typically smaller than the number of channels. We propose a link layer protocol to manage multiple channels, and it can be implemented over existing IEEE 802.11 hardware. We also propose a new routing metric for multi-channel multi-interface networks, and the metric is incorporated into an on-demand routing protocol that operates over the link layer protocol. Simulation results demonstrate the effectiveness of the proposed approach in significantly increasing network capacity, by utilizing all the available channels, even when the number of interfaces per host is smaller than the number of channels.
ID:569
CLASS:6
Title: Experimental comparisons between SAODV and AODV routing protocols
Abstract: There have been various secure routing protocols proposed for mobile ad hoc networks. Most of these protocols are analyzed by two standard techniques: simulation and security analysis. There has been a lack of work related to the performance of secure routing protocols in real network testbed. In this paper, we present quantitative results for the performance comparisons between AODV and SAODV routing protocols by using a small-scale experimental testbed, which consists of 10 laptops within a 250 m by 100 m rugby field. Apart from outdoor testing, we also compare the results with those obtained via simulation and indoor emulation. The workload includes both UDP and TCP traffic. Results show that SAODV is effective in preventing routing message tampering and data dropping attacks. For outdoor experiments, we also estimate the average distance within a communication gray zone under different bit rates.
ID:570
CLASS:6
Title: Salvaging route reply for on-demand routing protocols in mobile ad-hoc networks
Abstract: On-demand routing protocols are preferred in mobile ad hoc networks where resources such as energy and bandwidth are constrained. In these protocols, a source discovers a route to a destination typically by flooding the entire or a part of the network with a route request (RREQ) message. The destination sends a route reply (RREP) message to the source after receiving the RREQ. The RREP travels hop by hop on the discovered route in reverse direction or on another route to the source. Sometimes the RREP can not be sent to the intended next hop by an intermediate node due to the dynamic network topology or network congestion. Existing on-demand routing protocols handle the undeliverable RREP as a normal data packet - discard the packet and send a route error message to the destination (initiator of the RREP). This is highly unacceptable because a RREP message has a lot at stake - it is obtained by a large number of RREQ transmissions, which is an expensive and time-consuming process. Furthermore, the source may have to start another round of route discovery to establish the route because of the loss of the RREP. This will exacerbate the situation. In this paper, we propose the idea of salvaging route reply (SRR) to improve the performance of on-demand routing protocols. SRR attempts to salvage an undeliverable RREP in two possible ways: looking up the route cache for an alternate path and conducting a one-hop SRR route discovery. We present an implementation of SRR in AODV routing protocol. The results of an extensive simulation study confirm the performance improvement in all critical metrics, namely, packet delivery ratio, control overhead and end-to-end delay.
ID:571
CLASS:6
Title: A prioritized battery-aware routing protocol for wireless ad hoc networks
Abstract: It is a challenge area in the field of ad hoc networks to support prioritized routing for time sensitive applications, such as multimedia communications, IP telephony and interactive games. However the existing protocols did not consider the special battery discharging behavior of wireless devices. The limited power supply on wireless devices becomes the bottleneck for prioritized routing in ad hoc networks. Recent study in battery technology reveals that the behavior of battery discharging is more complex than we used to think. Battery powered wireless devices might waste a huge amount of energy if we do not carefully schedule and budget their discharging. In this paper we study the effect of battery behavior on prioritized routing in ad hoc networks. We provide a solution to measure the battery status with a simplified battery model. Based on this model we then present a prioritized battery-aware routing protocol (PBAR). The protocol is sensitive to the battery status of routing nodes and can avoid energy loss. We use the battery data from actual PDA, laptop and cellphone to evaluate the performance of our protocol. The results show that the PBAR performs well for prioritized service and can save a significant amount of energy compared to existing protocols. The network lifetime is also increased as well as its data throughput. As far as we know, this is the first work considering battery-awareness with an accurate analytical on-line computable battery model in ad hoc prioritized routing.
ID:572
CLASS:6
Title: On designing incentive-compatible routing and forwarding protocols in wireless ad-hoc networks: an integrated approach using game theoretical and cryptographic techniques
Abstract: In many applications, wireless ad-hoc networks are formed by devices belonging to independent users. Therefore, a challenging problem is how to provide incentives to stimulate cooperation. In this paper, we study ad-hoc games---the routing and packet forwarding games in wireless ad-hoc networks. Unlike previous work which focuses either on routing or on forwarding, this paper investigates both routing and forwarding. We first uncover an impossibility result---there does not exist a protocol such that following the protocol to always forward others' traffic is a dominant action. Then we define a novel solution concept called cooperation-optimal protocols. We present Corsac, a cooperation-optimal protocol consisting of a routing protocol and a forwarding protocol. The routing protocol of Corsac integrates VCG with a novel cryptographic technique to address the challenge in wireless ad-hoc networks that a link's cost (ie, its type) is determined by two nodes together. Corsac also applies efficient cryptographic techniques to design a forwarding protocol to enforce the routing decision, such that fulfilling the routing decision is the optimal action of each node in the sense that it brings the maximum utility to the node. Additionally, we extend our framework to a practical radio propagation model where a transmission is successful with a probability. We evaluate our protocols using simulations. Our evaluations demonstrate that our protocols provide incentives for nodes to forward packets.
ID:573
CLASS:6
Title: Effects of routing computations in content-based routing networks with mobile data sources
Abstract: This paper presents the first quantitative evaluation of the role of routing computations on performance when mobility is introduced to a content-based routing network. Additionally, the paper identifies the factors that affect the performance of a distributed publish/subscribe architecture supporting mobile publishers, formalizes publisher mobility protocols for distributed publish/subscribe systems, and develops and evaluates protocols that reduce the costs associated with supporting mobile publishers in publish/subscribe systems. Our results show that ignoring route computation time paints a false picture of the scalability of content-based routing networks, but that with appropriate protocols the adverse effects can be mitigated.
ID:574
CLASS:6
Title: Reliable MAC broadcast protocol in directional and omni-directional transmissions for vehicular ad hoc networks
Abstract: This paper presents the design, implementation and simulation results of a reliable Medium Access Control (MAC) broadcast protocol for Vehicular Ad hoc Networks for omni-directional and directional transmissions. The IEEE 802.11 MAC protocol uses control frames for handshaking to reliably communicate unicast data. In contrast, the broadcast data is transmitted without any control frames. This results in increased collisions due to hidden terminal problem, which in turn reduces the reliability of the broadcast service. This problem also exists in MAC protocols based on directional transmissions. To overcome this problem in Directional MAC (DMAC), we adapted Batch Mode Multicast MAC (BMMM) protocol, which uses control frames for broadcast transmissions. We implemented BMMM in NS-2 for omni-directional and Directional MAC protocols. Simulations are run for city traffic scenarios and the results are compared with IEEE 802.11 unreliable broadcast support. The simulations and comparison are done for two variants of BMMM protocol implementation integrated with DMAC.
ID:575
CLASS:6
Title: Rigorous specification and conformance testing techniques for network protocols, as applied to TCP, UDP, and sockets
Abstract: Network protocols are hard to implement correctly. Despite the existence of RFCs and other standards, implementations often have subtle differences and bugs. One reason for this is that the specifications are typically informal, and hence inevitably contain ambiguities. Conformance testing against such specifications is challenging.In this paper we present a practical technique for rigorous protocol specification that supports specification-based testing. We have applied it to TCP, UDP, and the Sockets API, developing a detailed 'post-hoc' specification that accurately reflects the behaviour of several existing implementations (FreeBSD 4.6, Linux 2.4.20-8, and Windows XP SP1). The development process uncovered a number of differences between and infelicities in these implementations.Our experience shows for the first time that rigorous specification is feasible for protocols as complex as TCP@. We argue that the technique is also applicable 'pre-hoc', in the design phase of new protocols. We discuss how such a design-for-test approach should influence protocol development, leading to protocol specifications that are both unambiguous and clear, and to high-quality implementations that can be tested directly against those specifications.
ID:576
CLASS:6
Title: Navigation protocols in sensor networks
Abstract: We develop distributed algorithms for adaptive sensor networks that respond to directing a target through a region of space. We model this problem as an online distributed motion planning problem. Each sensor node senses values in its perception space and has the ability to trigger exceptions events we call &ldquo;danger&rdquo; and model as &ldquo;obstacles&rdquo;. The danger/obstacle landscape changes over time. We present algorithms for computing distributed maps in perception space and for using these maps to compute adaptive paths for a mobile node that can interact with the sensor network. We give the analysis to the protocol and report on hardware experiments using a physical sensor network consisting of Mote sensors. We also show how to reduce searching space and communication cost using Voronoi diagram.
ID:577
CLASS:6
Title: NetPrIDE an integrated environment for developing and visualizing computer network protocols
Abstract: In this paper we present NetPrIDE, an integrated development environment for designing, implementing and visualizing computer network protocols, which has primarily been used for teaching computer networks. NetPrIDE makes use of an abstract and formal notation to clearly and firmly specify a protocol: once the protocol has been specified and the network topology has been fixed, the implementation and the visualization of the protocol is performed in a completely automated way.
ID:578
CLASS:6
Title: Probabilistic multi-path vs. deterministic single-path protocols for dynamic ad-hoc network scenarios
Abstract: We investigate the performance of different protocol stacks under various application scenarios. Our method of choice is a full-fledged simulation in QualNet, testing the complete protocol stack over fairly large-scale networks. We find that the relative ranking of protocols strongly depends on the network scenario, the session load, the mobility level, and the choice of protocol parameters. We show that the Parametric Probabilistic Protocols, which we generalize from their original definition, can outperform standard routing protocols, such as AODV or Gossiping or Shortest-Path, in a variety of realistic scenarios.
ID:579
CLASS:6
Title: A Configurable Network Protocol for Cluster Based Communications using Modular Hardware Primitives on an Intelligent NIC
Abstract: The high overhead of generic protocols like TCP/IP provides strong motivation for the development of a better protocol architecture for cluster-based parallel computers. Reconfigurable computing has a unique opportunity to contribute hardware level protocol acceleration while retaining the flexibility to adapt to changing needs. Specifically, applications on a cluster have various quality of service needs. In addition, these applications typically run for a long time relative to the reconfiguration time of an FPGA. Thus, it is possible to provide application-specific protocol processing to improve performance and reduce space utilization. Reducing space utilization permits the use of a greater portion of the FPGA for other application-specific processing. This paper focuses on work to create a set of parameterizable components that can be put together as needed to obtain a customized protocol for each application. To study the feasibility of such an architecture, hardware components were built that can be stitched together as needed to provide the required functionality. Feasibility is demonstrated using four different protocol configurations, namely: (1) unreliable packet transfer; (2) reliable, unordered message transfer without duplicate elimination; (3) reliable, unordered message transfer with duplicate elimination; and (4) reliable, ordered message transfer with duplicate elimination. The different configurations illustrate trade-offs between chip space and functionality.
ID:580
CLASS:6
Title: Efficient and robust protocols for local detection and propagation in smart dust networks
Abstract: Smart Dust is a set of a vast number of ultra-small fully autonomous computing and communication devices, with very restricted energy and computing capabilities, that co-operate to quickly and efficiently accomplish a large sensing task. Smart Dust can be very useful in practice, i.e., in the local detection of a remote crucial event and the propagation of data reporting its realization. In this work we make an effort towards the research on smart dust from an algorithmic point of view. We first provide a simple but realistic model for smart dust and present an interesting problem, which is how to propagate efficiently information on an event detected locally. Then we present various smart dust protocols for local detection and propagation that are simple enough to be implemented on real smart dust systems, and perform, under some simplifying assumptions, a rigorous average case analysis of their efficiency and energy consumption (and their interplay). This analysis leads to concrete results showing that our protocols are very efficient and robust. We also validate the analytical results by extensive experiments.
ID:581
CLASS:6
Title: Scenario-based comparison of source-tracing and dynamic source routing protocols for ad hoc networks
Abstract: We present source tracing as a new viable approach to routing in ad hoc networks in which routers communicate the second-to-last hop and distance in preferred paths to destinations. We introduce a table-driven protocol (BEST) in which routers maintain routing information for all destinations, and an on-demand routing protocol (DST) in which routers maintain routing information for only those destinations to whom they need to forward data. Simulation experiments are used to compare these protocols with DSR, which has been shown to incur less control overhead that other on-demand routing protocols. The simulations show that DST requires far less control packets to achieve comparable or better average delays and percentage of packet delivered than DSR, and that BEST achieves comparable results to DSR while maintaining routing information for all destinations.
ID:582
CLASS:6
Title: Building the blocks of protocol design and analysis: challenges and lessons learned from case studies on mobile ad hoc routing and micro-mobility protocols
Abstract: With the emergence of new application-specific sensor and Ad-hoc networks, increasingly complex and custom protocols will be designed and deployed. We propose a framework to systematically design and evaluate networking protocols based on a 'building block' approach. In this approach, each protocol is broken down into a set of parameterized modules called "building blocks", each having its own specific functionality. The properties of these building blocks and their interaction define the overall behavior of the protocol. In this paper, we aim to identify the major research challenges and questions in the building block approach. By addressing some of those questions, we point out potential directions to analyze and understand the behavior of networking protocols systematically. We discuss two case studies on utilizing the building block approach for analyzing Ad-hoc routing protocols and IP mobility protocols in a systematic manner.
ID:583
CLASS:6
Title: Network protocol development with <i>nsclick</i>
Abstract: Ad hoc network protocols are often developed, tested and evaluated using simulators. However, when the time comes to deploy those protocols for use or testing on real systems the protocol must be reimplemented for the target platform. This usually results in two, completely separate code-bases that must be maintained. Bugs which are found and fixed under simulated conditions must also be fixed separately in the deployed implementation, and vice versa. There is ample opportunity for the two implementations to drift apart, possibly to the point where the deployed and simulated version have little actual resemblance to each other. Testing the deployed version may also require construction of a testbed, a potentially time-consuming and expensive endeavor. Even if constructing an actual testbed is feasible, simulators are very useful for running large, repeatable scenarios for tasks such as protocol evaluation and regression testing. Furthermore, since the implementation may require modification of the kernel network stack, there's a good chance that a particular implementation may only run on specific versions of specific operating systems. To address these issues, we constructed the nsclick simulation environment by embedding the Click Modular Router inside of the popular &#60;i>ns-2&#60;/i> network simulator. Routing protocols may be implemented as Click graphs and easily moved between simulation and any operating system supported by Click. This paper describes the design, use, validation and performance of nsclick.
ID:584
CLASS:6
Title: Wireless sensor networks protocols for efficient collision avoidance in multi-path data propagation
Abstract: Data propagation in wireless sensor networks can be performed either by hop-by-hop single transmissions or by multi-path broadcast of data. Although several energy-aware MAC layer protocols exist that operate very well in the case of single point-to-point transmissions, none is especially designed and suitable for multiple broadcast transmissions.In this paper we propose a family of new protocols suitable of multi-path broadcast of data, and show, through a detailed and extended simulation evaluation, that our parameter-based protocols significantly reduce the number of collisions and thus increase the rate of successful message delivery (to above 90%) by trading off the average propagation delay. At the same time, our protocols are shown to be very energy efficient, in terms of the average energy dissipation per delivered message.
ID:585
CLASS:6
Title: The performance impact of traffic patterns on routing protocols in mobile ad hoc networks
Abstract: In this paper, we examine the communication model widely used in simulation studies of mobile ad hoc networks (MANETs). We find that the communication model uses an overly simplistic traffic pattern which restricts the number of connections that originate from each source node to be one or two, and thus the communication model may not represent traffic patterns in many potential applications in MANETs. We then propose a new communication model which extends the previous communication model to include a more general traffic pattern that varies the number of connections per source node. We study the performance impact of traffic patterns on various routing protocols via detailed simulations of a MANET of 112 mobile nodes. Our simulation results show that many of the conclusions drawn in previous protocol comparison studies no longer hold under the new communication model. These results motivate the need for performance evaluation of MANETs to not only include rich and diverse mobility models as has been done in the past but also include diverse traffic patterns that stress a wide set of protocol design issues.
ID:586
CLASS:6
Title: Reducing radio energy consumption of key management protocols for wireless sensor networks
Abstract: The security of sensor networks is a challenging area. Key management is one of the crucial parts in constructing the security among sensor nodes. However, key management protocols require a great deal of energy consumption, particularly in the transmission of initial key negotiation messages. In this paper, we examine three previously published sensor network security schemes: SPINS and C&R for master-key-based schemes, and Eschenhaur-Gligor (EG) for distributed-key-based schemes. We then present two new low-power schemes, which we call BROSK and OKS as alternatives to master-key-based schemes and distributed-key-based schemes, respectively. Compared to SPINS and C&R protocols, BROSK can reduce energy consumption by up to 12X by reducing the number of data transmissions in the key negotiation process. Compared with EG, OKS reduces energy by up to 96% and reduces memory requirements by up to 78%.
ID:587
CLASS:6
Title: Analyzing control traffic overhead versus mobility and data traffic activity in mobile Ad-Hoc network protocols
Abstract: This paper proposes a general, parameterized model for analyzing protocol control overhead in mobile ad-hoc networks. A probabilistic model for the network topology and the data traffic is proposed in order to estimate overhead due to control packets of routing protocols. Our analytical model is validated by comparisons with simulations, both taken from literature and made specifically for this paper. For example, our model predicts linearity of control overhead with regard to mobility as observed in existing simulations results. We identify the model parameters for protocols like AODV, DSR and OLSR. Our model then allows accurate predictions of which protocol will yield the lowest overhead depending on the node mobility and traffic activity pattern.
ID:588
CLASS:6
Title: Failure recovery for structured P2P networks: protocol design and performance evaluation
Abstract: Measurement studies indicate a high rate of node dynamics in p2p systems. In this paper, we address the question of how high a rate of node dynamics can be supported by structured p2p networks. We confine our study to the hypercube routing scheme used by several structured p2p systems. To improve system robustness and facilitate failure recovery, we introduce the property of K-consistency, K &#8805; 1, which generalizes consistency defined previously. (Consistency guarantees connectivity from any node to any other node.) We design and evaluate a failure recovery protocol based upon local information for K-consistent networks. The failure recovery protocol is then integrated with a join protocol that has been proved to construct K-consistent neighbor tables for concurrent joins. The integrated protocols were evaluated by a set of simulation experiments in which nodes joined a 2000-node network and nodes (both old and new) were randomly selected to fail concurrently over 10,000 seconds of simulated time. In each such "churn" experiment, we took a "snapshot" of neighbor tables in the network once every 50 seconds and evaluated connectivity and consistency measures over time as a function of the churn rate, timeout value in failure recovery, and K. Storage and communication overheads were also evaluated. We found our protocols to be effective, efficient, and stable for an average node lifetime as low as 8.3 minutes (the median lifetime measured for Napster and Gnutella was 60 minutes [10]).
ID:589
CLASS:6
Title: A rendezvous reservation protocol for energy constrained wireless infrastructure networks
Abstract: This paper considers a low power wireless infrastructure network that uses multi-hop communications to provide end user connectivity. A generalized Rendezvous Reservation Protocol (RRP) is proposed which permits multi-hop infrastructure nodes to adapt their power consumption in a dynamic fashion. When nodes have a long-term association, power consumption can be reduced by having them periodically rendezvous for the purpose of exchanging data packets. In order to support certain applications, the system invokes a connection set up process to establish the end-to-end path and selects node rendezvous rates along the intermediate nodes to meet the application's quality of service (QoS) needs. Thus, the design challenge is to dynamically determine rendezvous intervals based on incoming applications' QoS needs, while conserving battery power. In this paper, we present the basic RRP mechanism and an enhanced mechanism called Rendezvous Reservation Protocol with Battery Management (RRP-BM) that incorporates node battery level information. The performance of the system is studied using discrete-event simulation based experiments for different network topologies. The chief metrics considered are average power consumption and system lifetime (that is to be maximized). The QoS metrics specified are packet latency and end-to-end setup latency. It is shown that the use of the RRP-BM can increase the lifetime up to 48% as compared to basic RRP by efficiently reducing the energy consumption.
ID:590
CLASS:6
Title: Network classless time protocol based on clock offset optimization
Abstract: Time synchronization is critical in distributed environments. A variety of network protocols, middleware and business applications rely on proper time synchronization across the computational infrastructure and depend on the clock accuracy. The Network Time Protocol (NTP) is the current widely accepted standard for synchronizing clocks over the Internet. NTP uses a hierarchical scheme in order to synchronize the clocks in the network. In this paper we present a novel non-hierarchical peer-to-peer approach for time synchronization termed CTP--Classless Time Protocol. This approach exploits convex optimization theory in order to evaluate the impact of each clock offset on the overall objective function. We define the clock offset problem as an optimization problem and derive its optimal solution. Based on the solution we develop a distributed protocol that can be implemented over a communication network, prove its convergence to the optimal clock offsets and show its properties. For compatibility, CTP may use the packet format and number of measurements used by NTP. We also present methodology and numerical results for evaluating and comparing the accuracy of time synchronization schemes. We show that the CTP outperforms hierarchical schemes such as NTP in the sense of clock accuracy with respect to a universal clock.
ID:591
CLASS:6
Title: "GANGS": an energy efficient MAC protocol for sensor networks
Abstract: Recent advances in wireless communication and electronics have enabled the development of low-cost sensor networks. Low energy storage is one of the critical features of nodes in these networks. Communication protocols at different layers have been proposed in order to reduce the energy consumption. This paper presents a MAC layer protocol, named "GANGS", as a method of saving energy in sensor networks. Probabilistic markov chain models are established to evaluate and compare the performance of IEEE802.11 and GANGS.
ID:592
CLASS:6
Title: Transport protocols for high performance
Abstract: The Explicit Control Protocol and other new congestion-control systems greatly improve application performance over a range of network infrastructure, including extremely high-speed and high-delay links. What then is next for TCP and other established but less-capable Internet protocols?
ID:593
CLASS:6
Title: On the Accuracy and Stablility of Clocks Synchronized by the Network Time Protocol in the Internet System
Abstract: This paper describes a series of experiments involving over 100,000 hosts of the Internet system and located in the U.S., Europe and the Pacific. The experiments are designed to evaluate the availability, accuracy and reliability of international standard time distribution using the Internet and the Network Time Protocol (NTP), which has been designated an Internet Standard protocol. NTP is designed specifically for use in a large, diverse internet system operating at speeds from mundane to lightwave. In NTP a distributed subnet of time servers operating in a self-organizing, hierarchical, master-slave configuration exchange precision timestamps in order to synchronize host clocks to each other and national time standards via wire or radio.The experiments are designed to locate Internet hosts and gateways that provide time by one of three time distribution protocols and evaluate the accuracy of their indications. For those hosts that support NTP, the experiments determine the distribution of errors and other statistics over paths spanning major portions of the globe. Finally, the experiments evaluate the accuracy and reliability of precision timekeeping using NTP and typical Internet paths involving ARPANET, NSFNET and regional networks. The experiments demonstrate that timekeeping throughout most portions of the Internet can be maintained to an accuracy of a few tens of milliseconds and a stability of a few milliseconds per day, even in cases of failure or disruption of clocks, time servers or networks.
ID:594
CLASS:6
Title: A network-aware MAC and routing protocol for effective load balancing in ad hoc wireless networks with directional antenna
Abstract: Use of directional antenna in the context of ad hoc wireless networks can largely reduce radio interference, thereby improving the utilization of wireless medium. Our major contribution in this paper is to devise a routing strategy, along with a MAC protocol, that exploits the advantages of directional antenna in ad hoc networks for improved system performance. In this paper, we have illustrated a MAC and routing protocol for ad hoc networks using directional antenna with the objective of effective load balancing through the selection of maximally zone disjoint routes. Zone-disjoint routes would minimize the effect of route coupling by selecting routes in such a manner that data communication over one route will minimally interfere with data communication over the others. In our MAC protocol, each node keeps certain neighborhood status information dynamically in order that each node is aware of its neighborhood and communications going on in its neighborhood at that instant of time. This status information from each node is propagated periodically throughout the network. This would help each node to capture the approximate network status periodically that helps each node to become topology-aware and aware of communications going on in the network, although in an approximate manner. With this status information, each intermediate node adaptively computes routes towards destination. The performance of the proposed framework has been evaluated on QualNet Network Simulator with DSR (as in QualNet) as a benchmark. Our proposed mechanism shows four to five times performance improvement over DSR, thus demonstrating the effectiveness of this proposal.
ID:595
CLASS:6
Title: Ensuring cache freshness in on-demand ad hoc network routing protocols
Abstract: In a wireless ad hoc network, nodes cooperate to forward packets for each other over possibly multi-hop paths, to allow nodes not within direct wireless transmission range to communicate. Many routing protocols have been proposed for the ad hoc network environment, several of which operate on-demand and utilize a route cache listing links that this node has learned. In such protocols, aggressive caching of overheard routes can significantly improve performance; in particular, overhead can be reduced by leverag-ing information received in packets overheard or forwarded from other nodes, including other routing packets and the source routes on other data packets. Unfortunately, such information sharing can substantially increase the risk of cache cross-pollution, since stale routing information in one node's cache, representing a link that no longer exists, can easily be added into the caches of other nodes. Even when a node has actually learned that a link no longer exists, it is still possible for that node to again hear the stale information. In this paper, we present a new mechanism which we call epoch numbers, to reduce this problem of cache staleness, by preventing the re-learning of stale knowledge of a link after having earlier heard that the link has broken. Our scheme does not rely on ad hoc mechanisms such as short-lived negative caching; rather, we allow a node having heard both of a broken link and a discovery of the same link to sequence the two events in order to determine whether the link break or the link discovery occurred before the other.
ID:596
CLASS:6
Title: Message traffic control capabilities of the R-DSDV protocol in mobile ad hoc networks
Abstract: Mobile and wireless Ad hoc networks are composed of mobile stations communicating through wireless links, without any fixed backbone support. Frequent topology changes caused by node mobility make routing in ad hoc wireless networks a challenginq problem. Message routing requires mobiles to act as routers, by means of store and forward mechanisms. However, limitations on capabilities of mobiles require a control on node congestion due to message forwarding. In this paper, we consider a randomized version of the Destination-Sequenced Distance Vector (DSDV) routing protocol, which we refer to as R-DSDV. We discuss the DSDV algorithm as well as the congestion control mechanism used within the R-DSVD protocol. We also address the feasibility of congestion control using a congestion-related routing metric, the effectiveness of which is evaluated through a probabilistic model. Finally, we report on the simulation experiments we carried out to evaluate and assess the R-DSDV's performance on the ns simulator.
ID:597
CLASS:6
Title: X-MAC: a short preamble MAC protocol for duty-cycled wireless sensor networks
Abstract: In this paper we present X-MAC, a low power MAC protocol for wireless sensor networks (WSNs). Standard MAC protocols developed for duty-cycled WSNs such as BMAC, which is the default MAC protocol for TinyOS, employ an extended preamble and preamble sampling. While this "low power listening" approach is simple, asynchronous, and energy-efficient, the long preamble introduces excess latency at each hop, is suboptimal in terms of energy consumption, and suffers from excess energy consumption at nontarget receivers. X-MAC proposes solutions to each of these problems by employing a shortened preamble approach that retains the advantages of low power listening, namely low power communication, simplicity and a decoupling of transmitter and receiver sleep schedules. We demonstrate through implementation and evaluation in a wireless sensor testbed that X-MAC's shortened preamble approach significantly reduces energy usage at both the transmitter and receiver, reduces per-hop latency, and offers additional advantages such as flexible adaptation to both bursty and periodic sensor data sources.
ID:598
CLASS:6
Title: Sink mobility protocols for data collection in wireless sensor networks
Abstract: In wireless sensor networks data propagation is usually performed by sensors transmitting data towards a static control center (sink). Inspired by important applications (mostly related to ambient intelligence) and as a first step towards introducing mobility, we propose the idea of having a sink moving in the network area and collecting data from sensors. We propose four characteristic mobility patterns for the sink along with different data collection strategies. Through a detailed simulation study, we evaluate several important performance properties of each protocol. Our findings demonstrate that by taking advantage of the sink's mobility, we can significantly reduce the energy spent in relaying traffic and thus greatly extend the lifetime of the network.
ID:599
CLASS:7
Title: Pattern recognition in HCI: a viable approach?: a CHI '94 workshop
Abstract: Over recent years there has been a steadily increasing interest in the use of pattern recognition techniques (in particular neural networks) in human-computer interaction This has focused largely on applications such as speech and gesture recognition where the problems are quite well understood but has also considered less traditional domains such task analysis, user modelling and information retrieval. In 1991 we held a workshop at CHI entitled "Neural Networks and Pattern Recognition in CHI" [1] where the aim was to consider the range of possible applications for these techniques within HCI. It was a success, leading to the publication of a book on subject [2] which has sold well internationally and is still in demand, but three years on pattern recognition seems no nearer to being accepted within the mainstream of HCI, remaining largely associated with speech and gesture.
ID:600
CLASS:7
Title: An interactive pattern recognition laboratory (IPRL)
Abstract: This paper describes an interactive pattern recognition laboratory. The laboratory was designed for both research and teaching. For the researcher, it provides standard pattern recognition functions, a hierarchically organized pattern recognition data base, and a multidimensional graphic display capability. For the student it provides, in addition to the above capabilities, a vehicle for developing new pattern recognition algorithms. In addition to not having to develop support software, the student may compare the performance of his algorithms in the same environment as the existing ones.
ID:601
CLASS:7
Title: Neural networks and pattern recognition in human-computer interaction
Abstract: This paper reports on the activities of the workshop held on Sunday 28th April at the CHI'91 conference. Participants were there to discuss different ideas, methods and approaches to using pattern recognition in human-computer interaction.The workshop aimed to bring together researchers using novel methodologies, such as neural networks, in HCI applications, as well as practitioners using alternative or more traditional methods to perform pattern recognition tasks in HCI. The intention was to explore the scope and limitations of each type of approach and its requirements, for example in terms of representation and resources. The workshop considered the relationships between the different approaches and the possibility of developing hybrid methodologies to resolve HCI problems.Researchers working with both traditional and novel pattern recognition methods that have applications to human-computer interaction, and those with strong views either way, submitted position statements outlining their interest and viewpoints. Their research results are summarised in this report; in addition, the discussions on methods, on how the work reported interrelates, and on future areas of interest are presented. Major results from the use of neural network systems and other pattern recognition systems in the interface are presented, with application areas ranging from the interpretation of gestural input to the automatic determination of user task. Fuller details of the research can be found in a book based on the proceedings[2].
ID:602
CLASS:7
Title: Limitations in pattern recognition and problem solving
Abstract: This paper discusses the &ldquo;standard&rdquo; techniques used by problem solving and pattern recognition programs. It is pointed out that evaluation functions (often called discriminant functions) lie at the heart of these programs. Simplicity appears to be an important property of evaluation functions because evaluation functions which are both relatively accurate and efficient are in some sense simple. In addition, simple evaluation functions are easier to learn because there are fewer parameters to estimate. The real difficulty is that no general method exists which extracts a good set of features for a particular problem. Even if this were possible one is still faced with the task of combining these features to obtain the &ldquo;answer&rdquo;. In the case of pattern recognition this combination takes the form of connectives such as arithmetic operations or Boolean operations. However, in the case of problem solving, things are much more complicated since features are at the bottom of a search procedure which looks at many different problem states. This presents the difficulty of making good use of such a large volume of information.
ID:603
CLASS:7
Title: Discovery and learning techniques for pattern recognition
Abstract: The problem of pattern recognition is that of grasping the meaning of complex entities. A great variety of problem areas attempt to cope with Just such complexities. The importance of discovery and induction methods embedded within a pattern recognition program lies in their potential generality. The program, rather than the programmer, can be asked to discover and learn about the problem area. Pattern recognition should ultimately provide powerful techniques for use in such research areas as form perception, target recognition, language translation, theorem proving, game playing, and the testing of psychological models. Research on some of these applications is already underway. To the extent that discovery and induction can be successfully employed by the program itself, they should be used. This paper describes a program that makes a beginning attempt at such use.
ID:604
CLASS:7
Title: Computers in the study of learning: namer\&mdash;A pattern-recognition system for generating sentences about relations between line drawings
Abstract: THIS PAPER reports on a series of experimental programs which are used to recognize line drawings and the spatial relationships between them. At the pattern-recognition level the programs learn to associate a name with a generalized bit pattern representing a line drawing. At the relation-learning level, the programs abstract characteristics which relate to such spatial concepts as &ldquo;above,&rdquo; &ldquo;left,&rdquo; &ldquo;thicker than,&rdquo; etc. The names that have been learned in association with a drawing, and relation names which the program selects as true for the spatial relations between two drawings, are substituted into a simple generation grammar; variations of sentences that are true for the picture are then generated.
ID:605
CLASS:7
Title: Application of game tree searching techniques to sequential pattern recognition
Abstract: A sequential pattern recognition (SPR) procedure does not test all the features of a pattern at once. Instead, it selects a feature to be tested. After receiving the result of that test, the procedure either classifies the unknown pattern or selects another feature to be tested, etc. Medical diagnosis is an example of SPR. In this paper the authors suggest that SPR be viewed as a one-person game played against nature (chance). Virtually all the powerful techniques developed for searching two-person, strictly competitive game trees can easily be incorporated either directly or by analogy into SPR procedures. In particular, one can incorporate the &ldquo;miniaverage backing-up procedure&rdquo; and the &ldquo;gamma procedure,&rdquo; which are the analogues of the &ldquo;minimax backing-up procedure&rdquo; and the &ldquo;alpha-beta procedure,&rdquo; respectively. Some computer simulated experiments in character recognition are presented. The results indicate that the approach is promising.
ID:606
CLASS:7
Title: Low resolution character recognition by dual eigenspace and synthetic degraded patterns
Abstract: As the rapid progress of digital imaging technology, the requirements of character recognition for text embedded in image increase dramatically. Many image text characters are in low resolution with heavy degradation. Traditional OCR methods don't have good recognition performance on these degraded images due to poor binarization. In this paper, a novel feature extraction method based on dual eigenspace and synthetic pattern generation is proposed to recognize character images under low resolution. A subpixel grayscale normalization method is first used to normalize the low resolution character images. The dual eigenspace performs classification from coarse to fine. The multi-templates generated from the synthetic patterns provide good robustness against real degradation. Experimental results indicate that our method is very effective on low resolution Japanese character images.
ID:607
CLASS:7
Title: Pattern recognition and synthesis for sign language translation system
Abstract: Sign language is one means of communication for hearing-impaired people. Words and sentences in sign language are mainly represented by hands' gestures. In this report, we show a sign language translation system which we are developing. The system translates Japanese sign language into Japanese and vice versa. In this system, hand shape and position data are inputted using DataGlove. Inputted hand motions are recognized and translated into Japanese sentences. Japanese text is translated into sign language represented as 3-D computer-graphic animation of sign language gestures.
ID:608
CLASS:7
Title: Complex preprocessing for pattern recognition
Abstract: The construction of pattern recognition machines may eventually depend upon the development of highly complex preprocessors. This claim is supported by a discussion of the importance of perceptual grouping. Since complex preprocessing will assess more of the basic structure of a visual scene, internal representations will have to be more descriptive in nature. Two approches to descriptive internal representation are mentioned. Two of the author's programs are reviewed. One plays the Oriental game of GO at a human level and the other can recognize digitized hand printed characters. Both programs use a geometry preserving representation of features, so that calculations involving the features can assess the original geometry of the input. In addition, the GO program calculates groups of stones and performs other types of &ldquo;complex&rdquo;processing. Practical and philosophical arguments are given for the use of internal representation by pattern recognition programs.
ID:609
CLASS:7
Title: Artificial neural network-based image pattern recognition
Abstract: This paper addresses the use of a multi-layer fully-connected perceptron neural network for implementing a pattern recognizer. The input of the neural network is a set of seven standardized invariant moments in both the training procedure and recognition procedure. This standardization results in significantly increasing the accuracy of recognition. The neural network in this paper can recognize the shape of patterns regardless of the size, location or brightness. Images are captured and transformed to binary images through a global threshold technique. The weights of the network are computed using the back propagation algorithm. An example is given to demonstrate this neural network pattern recognizer.
ID:610
CLASS:7
Title: The identification of mammalian species through the classification of hair patterns using image pattern recognition
Abstract: The identification of mammals through the use of their hair is important in the fields of forensics and ecology. The application of computer pattern recognition techniques to this process provides a means of reducing the subjectivity found in the process, as manual techniques rely on the interpretation of a human expert rather than quantitative measures. The first application of image pattern recognition techniques to the classification of African mammalian species using hair patterns is presented. This application uses a 2D Gabor filter-bank and motivates the use of moments to classify hair scale patterns. Application of a 2D Gabor filter-bank to hair scale processing provides results of 52% accuracy when using a filter-bank of size four and 72% accuracy when using a filter-bank of size eight. These initial results indicate that 2D Gabor filters produce information that may be successfully used to classify hair according to images of its patterns.
ID:611
CLASS:7
Title: An object-oriented framework of pattern recognition systems
Abstract: In this paper, we describe a purely object-oriented framework of pattern recognition systems. Its aim is in dealing with knowledge representation issues in pattern recognition. In our approach, everything works in an entirely autonomous and decentralized manner. Even a search procedure for sample-concept matching is distributed onto every concept object itself by being implemented in what we introduced as the recursive agent-blackboard model. We developed an experimental prototype of character recognition systems in Smalltalk-80, which proved the ability of the object-oriented framework and the cooperative search procedure.
ID:612
CLASS:7
Title: Computer pattern recognition techniques: electrocardiographic diagnosis
Abstract: The use of programmed digital computers as general pattern classification and recognition devices is one phase of the current lively interest in artificial intelligence. It is important to choose a class of signals which is, at present, undergoing a good deal of visual inspection by trained people for the purpose of pattern recognition. In this way comparisons between machine and human performance may be obtained. A practical result also serves as additional motivation. Clinical electrocardiograms make up such a class of signals.The approach to the problem presented here centers upon the use of multiple adaptive matched filters that classify normalized signals. The present report gives some of the background for the application of this method.
ID:613
CLASS:7
Title: Pattern recognition in APL with application to reactor diagnostics
Abstract: The paper describes implementation in APL of some methods of pattern recognition. These general-purpose techniques of data analysis are illustrated by application to Nuclear Power Plant Diagnostics. In particular we consider vibration spectra analysis, including simple descriptive statistics, smoothing and peak extractions, multidimensional scaling for data visualization, informative features selection, cluster analysis and classification.Implementation of algorithms used in the paper has been done in Dyalog APL. The paper discusses benefits of using APL for the problem area.Application is based on analysis of real vibration characteristics measured at the Nuclear Power Plant in Novovoronehz. The paper discusses the technology of the analysis, the discovered data structure, and malfunction diagnostics.The paper also mentions using the implemented techniques in the training of engineers for Nuclear Power plant and other applications.
ID:614
CLASS:7
Title: Some Results on Multicategory Pattern Recognition
Abstract: Some problems arising in multicategory (many pattern types) pattern recognition are treated mathematically, and formulas are derived which describe some inherent limitations associated therewith. The principal results concern the &ldquo;dimensional&rdquo; and &ldquo;correlational&rdquo; effects and their degradation of a multimeasurement recognition system.
ID:615
CLASS:7
Title: Combining environmental cues \& head gestures to interact with wearable devices
Abstract: As wearable sensors and computing hardware are becoming a reality, new and unorthodox approaches to seamless human-computer interaction can be explored. This paper presents the prototype of a wearable, head-mounted device for advanced human-machine interaction that integrates speech recognition and computer vision with head gesture analysis based on inertial sensor data. We will focus on the innovative idea of integrating visual and inertial data processing for interaction. Fusing head gestures with results from visual analysis of the environment provides rich vocabularies for human-machine communication because it renders the environment into an interface: if objects or items in the surroundings are being associated with system activities, head gestures can trigger commands if the corresponding object is being looked at. We will explain the algorithmic approaches applied in our prototype and present experiments that highlight its potential for assistive technology. Apart from pointing out a new direction for seamless interaction in general, our approach provides a new and easy to use interface for disabled and paralyzed users in particular.
ID:616
CLASS:7
Title: ARIADNE: pattern-directed inference and hierarchical abstraction in protein structure recognition
Abstract: The macro-molecular structural conformations of proteins exhibit higher order regularities whose recognition is complicated by many factors. ARIADNE searches for similarities between structural descriptors and hypothesized protein structure at levels more abstract than the primary sequence.
ID:617
CLASS:7
Title: Bitext maps and alignment via pattern recognition
Abstract: Texts that are available in two languages (bitexts) are becoming more and more plentiful, both in private data warehouses and on publicly accessible sites on the World Wide Web. As with other kinds of data, the value of bitexts largely depends on the efficacy of the available data mining tools. The first step in extracting useful information from bitexts is to find corresponding words and/or text segment boundaries in their two halves (bitext maps).This article advances the state of the art of bitext mapping by formulating the problem in terms of pattern recognition. From this point of view, the success of a bitext mapping algorithm hinges on how well it performs three tasks: signal generation, noise filtering, and search. The Smooth Injective Map Recognizer (SIMR) algorithm presented here integrates innovative approaches to each of these tasks. Objective evaluation has shown that SIMR's accuracy is consistently high for language pairs as diverse as French/English and Korean/English. If necessary, SIMR's bitext maps can be efficiently converted into segment alignments using the Geometric Segment Alignment (GSA) algorithm, which is also presented here.SIMR has produced bitext maps for over 200 megabytes of French-English bitexts. GSA has converted these maps into alignments. Both the maps and the alignments are available from the Linguistic Data Consortium.
ID:618
CLASS:7
Title: Pattern recognition applied to the acquisition of a grammatical classification system from unrestricted English text
Abstract: Within computational linguistics, the use of statistical pattern matching is generally restricted to speech processing. We have attempted to apply statistical techniques to discover a grammatical classification system from a Corpus of 'raw' English text. A discovery procedure is simpler for a simpler language model; we assume a first-order Markov model, which (surprisingly) is shown elsewhere to be sufficient for practical applications. The extraction of the parameters of a standard Markov model is theoretically straightforward; however, the huge size of the standard model for a Natural Language renders it incomputable in reasonable time. We have explored various constrained models to reduce computation, which have yielded results of varying success.
ID:619
CLASS:7
Title: Structural pattern recognition of Carotid pulse waves using a general waveform parsing system
Abstract: A general waveform parsing system with application to structural pattern recognition of carotid pulse waves is described. The carotid arterial pulse wave is of medical importance because of variation in its structure induced by arterial aging and cardiovascular disease. The syntax-driven waveform analysis system has been applied with good results to these pulse waves to detect and measure structural variations. The waveform parsing system is modeled on a compiler-compiler system and allows the user to enter application specific information as data. It is thus general enough to be applicable to other waveforms.
ID:620
CLASS:7
Title: Pictorial pattern recognition and the phase problem of x-ray crystallography
Abstract: The availability of interactive, three-dimensional, computer graphics systems coupled to powerful digital computers encourages the development of algorithms adapted to this environment. Pictorial pattern recognition techniques make possible a number of approaches to X-ray structure determination based on molecular model building, i.e. the use of chemical information to frame &ldquo;structural hypotheses&rdquo; which can computationally be tested and refined by reference to the experimental data.Application of standard pattern recognition algorithms is hindered by the fact that the cross-correlation between a model and the correct structure cannot be computed because of a fundamental incompleteness in the measured data. However, it is possible to compute an upper bound to such a cross-correlation. A simple example demonstrates that this information can be the basis of a technique for structure determination that can make effective use of an interactive graphics system.Model building by cross-correlations has intrinsic advantages over usual crystallographic techniques based on the autocorrelation or Patterson function, especially for large structures. This is significant, for crystallography of biological macromolecules has been and will continue to be a field of intense interest.
ID:621
CLASS:7
Title: On pattern recognition and description using many sorted predicate calculi
Abstract: A pattern is a set of binary or ternary relations. A description of the pattern is a formula of many sorted predicate calculus with metric spaces defined on indices of predicate constants which is satisfied by the given pattern. The pattern recognition problem is to find whether the formula is satisfied by the given relation. The pattern description problem is to form from the given pattern the corresponding formula. To solve this problem usual training methods1 are applied together with techniques used for program synthesis2. The limitations imposed by these techniques imply limitations to our approach.
ID:622
CLASS:7
Title: A new shell for the development of alarm pattern recognition expert systems
Abstract: This paper presents the first version of GENESIS, an expert system shell suitable for the development of alarm pattern recognition expert systems (APRES). GENESIS Includes a series of algorithms and procedures especially designed for a rapid and systematic construction of APRES. The Inputs required by GENESIS are the fault trees of the system under analysis, the probability of occurrence of each fault in the trees, and the set of symptoms (alarms and measurements) associated to the occurrence of each individual fault. With this Information, GENESIS generates a set of production rules which relates faults and symptoms. The shell uses these rules and the probability of occurrence of each of the faults In order to generate optimal alarm pattern recognition strategies (algorithm of the Inference engine). A strategy helps the operator to recognize which alarm pattern is occurring without having to search the entire set of patterns. All the alarm pattern recognition strategies are generated off-line, as a consequence, the response of the system will be very fast. This feature makes GENESIS a powerful tool for the development of real-time APRES.
ID:623
CLASS:7
Title: Three-dimensional object recognition
Abstract: A general-purpose computer vision system must be capable of recognizing three-dimensional (3-D) objects. This paper proposes a precise definition of the 3-D object recognition problem, discusses basic concepts associated with this problem, and reviews the relevant literature. Because range images (or depth maps) are often used as sensor input instead of intensity images, techniques for obtaining, processing, and characterizing range data are also surveyed.
ID:624
CLASS:7
Title: Computational strategies for object recognition
Abstract: This article reviews the available methods for automated identification of objects in digital images. The techniques are classified into groups according to the nature of the computational strategy used. Four classes are proposed: (1) the simplest strategies, which work on data appropriate for feature vector classification, (2) methods that match models to symbolic data structures for situations involving reliable data and complex models, (3) approaches that fit models to the photometry and are appropriate for noisy data and simple models, and (4) combinations of these strategies, which must be adopted in complex situations. Representative examples of various methods are summarized, and the classes of strategies with respect to their appropriateness for particular applications.
ID:625
CLASS:7
Title: Face recognition: A literature survey
Abstract: As one of the most successful applications of image analysis and understanding, face recognition has recently received significant attention, especially during the past several years. At least two reasons account for this trend: the first is the wide range of commercial and law enforcement applications, and the second is the availability of feasible technologies after 30 years of research. Even though current machine recognition systems have reached a certain level of maturity, their success is limited by the conditions imposed by many real applications. For example, recognition of face images acquired in an outdoor environment with changes in illumination and/or pose remains a largely unsolved problem. In other words, current systems are still far away from the capability of the human perception system.This paper provides an up-to-date critical survey of still- and video-based face recognition research. There are two underlying motivations for us to write this survey paper: the first is to provide an up-to-date review of the existing literature, and the second is to offer some insights into the studies of machine recognition of faces. To provide a comprehensive survey, we not only categorize existing recognition techniques but also present detailed descriptions of representative methods within each category. In addition, relevant topics such as psychophysical studies, system evaluation, and issues of illumination and pose variation are covered.
ID:626
CLASS:7
Title: A new binary code for pattern recognition by parallel computation
Abstract: In most pattern recognition schemes, common geometric transformations such as rotation, translation, and perspectivity require computations whose complexity and execution time increase rapidly with increasing grid resolution (number of grid cells). A new code which embodies such transformations as simple, locally applied algorithms (such as rewriting substrings of code as single digits) has been found. By applying these algorithms to the code, the problem of recognizing straight lines on the quadratic lattice has been completely solved. Recognition is achieved by applying a sequence of affine transformations to reduce lines to standard position. This corresponds to reducing a code string to a single digit. The recognition algorithms are parallel (applied simultaneously to entire code string) and are independent of the number of cells in the grid and the slope and position of the line relative to the grid. They are based on some interesting connections between the new code and continued fractions, Farey series, and affine transformations.
ID:627
CLASS:7
Title: Model-based recognition in robot vision
Abstract: This paper presents a comparative study and survey of model-based object-recognition algorithms for robot vision. The goal of these algorithms is to recognize the identity, position, and orientation of randomly oriented industrial parts. In one form this is commonly referred to as the "bin-picking" problem, in which the parts to be recognized are presented in a jumbled bin. The paper is organized according to 2-D, 2&frac12;-D, and 3-D object representations, which are used as the basis for the recognition algorithms. Three central issues common to each category, namely, feature extraction, modeling, and matching, are examined in detail. An evaluation and comparison of existing industrial part-recognition systems and algorithms is given, providing insights for progress toward future robot vision systems.
ID:628
CLASS:7
Title: A comparative study of neural network algorithms applied to optical character recognition
Abstract: Three simple general purpose networks are tested for pattern classification on an optical character recognition problem. The feed-forward (multi-layer perceptron) network, the Hopfield network and a competitive learning network are compared. The input patterns are obtained by optically scanning images of printed digits and uppercase letters. The resulting data is used as input for the networks with two-state input nodes; for others, features are extracted by template matching and pixel counting. The classification capabilities of the networks are compared with a nearest neighbour algorithm applied to the same feature vectors. The feed-forward network reaches the same recognition rates as the nearest neighbour algorithm, even when only a small percentage of the possible connections is used. The Hopfield network performs less well, and overloading of the network remains a problem. Recognition rates with the competitive learning network, if input patterns are clustered well, are again as high as the nearest neighbour algorithm.
ID:629
CLASS:7
Title: Model-based object recognition in dense-range images\&mdash;a review
Abstract: The goal in computer vision systems is to analyze data collected from the environment and derive an interpretation to complete a specified task. Vision system tasks may be divided into data acquisition, low-level processing, representation, model construction, and matching subtasks. This paper presents a comprehensive survey of model-based vision systems using dense-range images. A comprehensive survey of the recent publications in each subtask pertaining to dense-range image object recognition is presented.
ID:630
CLASS:7
Title: Face recognition based on polar frequency features
Abstract: A novel biologically motivated face-recognition algorithm based on polar frequency is presented. Polar frequency descriptors are extracted from face images by Fourier--Bessel transform (FBT). Next, the Euclidean distance between all images is computed and each image is now represented by its dissimilarity to the other images. A pseudo-Fisher linear discriminant was built on this dissimilarity space. The performance of discrete Fourier transform (DFT) descriptors and a combination of both feature types was also evaluated. The algorithms were tested on a 40- and 1196-subjects face database (ORL and FERET, respectively). With five images per subject in the training and test datasets, error rate on the ORL database was 3.8, 1.25, and 0.2&percnt; for the FBT, DFT, and the combined classifier, respectively, as compared to 2.6&percnt; achieved by the best previous algorithm. The most informative polar frequency features were concentrated at low-to-medium angular frequencies coupled to low radial frequencies. On the FERET database, where an affine normalization preprocessing was applied, the FBT algorithm outperformed only the PCA in a rank recognition test. However, it achieved performance comparable to state-of-the-art methods when evaluated by verification tests. These results indicate the high informative value of the polar frequency content of face images in relation to recognition and verification tasks and that the Cartesian frequency content can complement information about the subjects' identity, but possibly only when the images are not prenormalized. Possible implications for human face recognition are discussed.
ID:631
CLASS:7
Title: Large vocabulary sign language recognition based on hierarchical decision trees
Abstract: The major difficulty for large vocabulary sign language or gesture recognition lies in the huge search space due to a variety of recognized classes. How to reduce the recognition time without loss of accuracy is a challenge issue. In this paper, a hierarchical decision tree is first presented for large vocabulary sign language recognition based on the divide-and-conquer principle. As each sign feature has the different importance to gestures, the corresponding classifiers are proposed for the hierarchical decision to gesture attributes. One- or two- handed classifier with little computational cost is first used to eliminate many impossible candidates. The subsequent hand shape classifier is performed on the possible candidate space. SOFM/HMM classifier is employed to get the final results at the last non-leaf nodes that only include few candidates. Experimental results on a large vocabulary of 5113-signs show that the proposed method drastically reduces the recognition time by 11 times and also improves the recognition rate about 0.95% over single SOFM/HMM.
ID:632
CLASS:7
Title: A similarity measure for motion stream segmentation and recognition
Abstract: Recognition of motion streams such as data streams generated by different sign languages or various captured human body motions requires a high performance similarity measure. The motion streams have multiple attributes, and motion patterns in the streams can have different lengths from those of isolated motion patterns and different attributes can have different temporal shifts and variations. To address these issues, this paper proposes a similarity measure based on singular value decomposition (SVD) of motion matrices. Eigenvector differences weighed by the corresponding eigenvalues are considered for the proposed similarity measure. Experiments with general hand gestures and human motion streams show that the proposed similarity measure gives good performance for recognizing motion patterns in the motion streams in real time.
ID:633
CLASS:7
Title: Speech recognition enhancement by lip information
Abstract: Though technology in speech recognition has progressed recently, Automatic Speech Recognition (ASR) is vulnerable to noise. Lip-information is thought to be useful for speech recognition in noisy situations, such as in a factory or in a car.This paper describes speech recognition enhancement by lip-information. Two types of usage are dealt with. One is the detection of start and stop of speech from lip-information. This is the simplest usage of lip-information. The other is lip-pattern recognition, and it is used for speech recognition together with sound information. The algorithms for both usages are proposed, and the experimental system shows they work well. The algorithms proposed here are composed of simple image-processing. Future progress in image-processing will make it possible to realize them in real-time.
ID:634
CLASS:7
Title: Signal processing technique utilising fourier transform methods and Artificial Neural Network pattern recognition for interpreting complex data from a multipoint optical fibre sensor system
Abstract: A multipoint (2 sensing elements) optical fibre based sensor system capable of detecting ethanol in water supplies is presented. The active sensing elements consist of an exposed core U-bend configuration in order to maximise sensitivity and the sensing system is interrogated using Optical Time Domain Reflectometry (OTDR). Artificial Neural Network (ANN) Pattern Recognition techniques have been applied to the optical fibre sensor system data in order to accurately classify each sensor element test condition. In order to reduce the computational resources of the ANN required to accurately classify the sensor system data, novel signal processing techniques utilising Fourier Transform methods are applied to the resulting OTDR data. Results are presented for the interrogation and classification of two sensors on a single fibre loop.
ID:635
CLASS:7
Title: Dynamic programming as applied to feature subset selection in a pattern recognition system
Abstract: This paper proposes dynamic programming search procedures to expedite the feature subset selection processes in a pattern recognition system. It is shown that in general the proposed procedures require far less number of subsets to be evaluated than the exhaustive search procedure. For example, a problem of selecting the best subset of 4 features from a set of 24 features requires an evaluation of [equation] &equil; 10626 subsets by using the exhaustive search procedure; on the other hand, it requires only 175 and 136 subsets to be considered by employing the proposed procedures I and II, respectively, to solve the same problem. While the number of subsets to be evaluated for the dynamic programming search procedures is slightly greater than that for the without-replacement search procedure, the best feature subset selected by the proposed methods may, however, not necessarily contain all of the best single features selected in the previous stages.
ID:636
CLASS:7
Title: An experimental laboratory for pattern recognition and signal processing
Abstract: An interactive computer-controlled scanning and display system has been in operation at the IBM Thomas J. Watson Research Center for three years. The system includes two flying-spot scanners and a TV camera specially interfaced to a process control digital computer, dot-mode and vector displays, analog input and output facilities, and a variety of other experimental equipment. The system design and programming support are described and typical applications in scanner control, optical character recognition, and image processing are presented.
ID:637
CLASS:7
Title: A cellular automaton for pattern recognition by parallel computation
Abstract: A cellular automaton that recognizes arbitrary straight lines projected on grids has been designed. All cells interact simultaneously with their nearest neighbors. The interactions correspond to the rewriting algorithms of Rothstein's code for straight lines (see immediately preceding abstract). The logical design and number of states are fixed, i.e. independent of the slope and position of the line and the number of cells in the grid. Simple changes in the transition graph of this automaton yield other automata that recognize polygonal approximation of curves and detect such properties as topological connectivity. These designs are also fixed in the above sense. The code operations corresponding to line recognition can be interpreted as the application of a kind of Euclidean division algorithm to the slope of the line. Thus, the cellular automaton can be seen as a parallel computer whose fundamental operation is base-independent parallel division.
ID:638
CLASS:7
Title: Fast detection of communication patterns in distributed executions
Abstract: Understanding distributed applications is a tedious and difficult task. Visualizations based on process-time diagrams are often used to obtain a better understanding of the execution of the application. The visualization tool we use is Poet, an event tracer developed at the University of Waterloo. However, these diagrams are often very complex and do not provide the user with the desired overview of the application. In our experience, such tools display repeated occurrences of non-trivial communication patterns, appearing throughout the trace data and cluttering the display space. This paper describes an event abstraction facility which tries to simplify the execution visualization shown by Poet by efficiently detecting and abstracting such patterns.A user can define patterns, subject to only very few constraints, and store them in a hierarchical pattern library. We also provide the user with the possibility to annotate the source code as a help in the abstraction process. We detect these communication patterns by employing an enhanced efficient multiple string matching algorithm. The results indicate that the matching process is indeed very fast. A user can experiment with multiple patterns at potentially different levels in the hierarchy, checking for their occurrence in the trace file, while trying to gain some understanding in a short period of time.
ID:639
CLASS:7
Title: Segmentation and recognition of multi-attribute motion sequences
Abstract: In this work, we focus on fast and efficient recognition of motions in multi-attribute continuous motion sequences. 3D motion capture data, animation motion data, and sensor data from gesture sensing devices are examples of multi-attribute continuous motion sequences. These sequences have multiple attributes rather than only one attribute as time series data has. Motions can have different rates and durations, and the resulting data can thus have different lengths. Also, motion data can have noises due to transitions between successive motions. Hence, traditional distance measuring approaches used for time series data (such as Euclidean distances or dynamic time-warped distances) are not suitable for recognition in multi-attribute motion sequences. Hence, we have defined a similarity measure based on the analysis of singular value decomposition (SVD) properties of similar multi-attribute motions. A five-phase algorithm has then been proposed that gives good pruning power by exploiting the proximity of continuous motion data. We experimented this algorithm with data from different sources: 3D motion capture devices, animation motions, and CyberGlove gesture sensing device. These experiments show that our algorithm can segment and recognize long motion streams with high accuracy and in real time without knowing beforehand the number of motions in a stream.
ID:640
CLASS:7
Title: A new idiom recognition framework for exploiting hardware-assist instructions
Abstract: Modern processors support hardware-assist instructions (such as TRT and TROT instructions on IBM zSeries) to accelerate certain functions such as delimiter search and character conversion. Such special instructions have often been used in high performance libraries, but they have not been exploited well in optimizing compilers except for some limited cases. We propose a new idiom recognition technique derived from a topological embedding algorithm [4] to detect idiom patterns in the input program more aggressively than in previous approaches. Our approach can detect a pattern even if the code segment does not exactly match the idiom. For example, we can detect a code segment that includes additional code within the idiom pattern. We implemented our new idiom recognition approach based on the Java Just-In-Time (JIT) compiler that is part of the J9 Java Virtual Machine, and we supported several important idioms for special hardware-assist instructions on the IBM zSeries and on some models of the IBM pSeries. To demonstrate the effectiveness of our technique, we performed two experiments. The first one is to see how many more patterns we can detect compared to the previous approach. The second one is to see how much performance improvement we can achieve over the previous approach. For the first experiment, we used the Java Compatibility Kit (JCK) API tests. For the second one we used IBM XML parser, SPECjvm98, and SPCjbb2000. In summary, relative to a baseline implementation using exact pattern matching, our algorithm converted 75% more loops in JCK tests. We also observed significant performance improvement of the XML parser by 64%, of SPECjvm98 by 1%, and of SPECjbb2000 by 2% on average on a z990. Finally, we observed the JIT compilation time increases by only 0.32% to 0.44%.
ID:641
CLASS:7
Title: Offline handwritten Chinese character recognition by radical decomposition
Abstract: Offline handwritten Chinese character recognition is a very hard pattern-recognition problem of considerable practical importance. Two popular approaches are to extract features holistically from the character image or to decompose characters structurally into component parts---usually strokes. Here we take a novel approach, that of decomposing into radicals on the basis of image information (i.e., without first decomposing into strokes). During training, 60 examples of each radical were represented by "landmark" points, labeled semiautomatically, with radicals in different characteristic positions treated as distinctly different radicals. Kernel principal-component analysis then captured the main (nonlinear) variations around the mean radical. During the recognition, the dynamic tunneling algorithm was used to search for optimal shape parameters in terms of chamfer distance minimization. Considering character composition as a Markov process in which up to four radicals are combined in some assumed sequential order, we can recognize complete, hierarchically-composed characters by using the Viterbi algorithm. This gave a character recognition rate of 93.5% characters correct (writer-independent) on a test set of 430,800 characters from 2,154 character classes composed of 200 radical categories, which is comparable to the best reported results in the literature. Although the initial semiautomatic landmark labeling is time consuming, the decomposition approach is theoretically well-motivated and allows the different sources of variability in Chinese handwriting to be handled separately and by the most appropriate means--either learned from example data or incorporated as prior knowledge. Hence, high generalizability is obtained from small amounts of training data, and only simple prior knowledge needs to be incorporated, thus promising robust recognition performance. As such, there is very considerable potential for further development and improvement in the direction of larger character sets and less constrained writing conditions.
ID:642
CLASS:7
Title: Patterns of entry and correction in large vocabulary continuous speech recognition systems
Abstract: A study was conducted to evaluate user performance andsatisfaction in completion of a set of text creation tasks usingthree commercially available continuous speech recognition systems.The study also compared user performance on similar tasks usingkeyboard input. One part of the study (Initial Use) involved 24users who enrolled, received training and carried out practicetasks, and then completed a set of transcription and compositiontasks in a single session. In a parallel effort (Extended Use),four researchers used speech recognition to carry out real worktasks over 10 sessions with each of the three speech recognitionsoftware products. This paper presents results from the Initial Usephase of the study along with some preliminary results from theExtended Use phase. We present details of the kinds of usabilityand system design problems likely in current systems and severalcommon patterns of error correction that we found.
ID:643
CLASS:7
Title: SketchREAD: a multi-domain sketch recognition engine
Abstract: We present SketchREAD, a multi-domain sketch recognition engine capable of recognizing freely hand-drawn diagrammatic sketches. Current computer sketch recognition systems are difficult to construct, and either are fragile or accomplish robustness by severely limiting the designer's drawing freedom. Our system can be applied to a variety of domains by providing structural descriptions of the shapes in that domain; no training data or programming is necessary. Robustness to the ambiguity and uncertainty inherent in complex, freely-drawn sketches is achieved through the use of context. The system uses context to guide the search for possible interpretations and uses a novel form of dynamically constructed Bayesian networks to evaluate these interpretations. This process allows the system to recover from low-level recognition errors (e.g., a line misclassified as an arc) that would otherwise result in domain level recognition errors. We evaluated Sketch-READ on real sketches in two domains--family trees and circuit diagrams--and found that in both domains the use of context to reclassify low-level shapes significantly reduced recognition error over a baseline system that did not reinterpret low-level classifications. We also discuss the system's potential role in sketch based user interfaces.
ID:644
CLASS:7
Title: Cloud pattern recognition
Abstract: Cloud cover photographs transmitted from meteorological satellites must be processed and interpreted before weather maps can be issued. Most of the routine processing can be handled by present day digital computer techniques; however, the recognition and interpretation of cloud patterns such as vortices indicating hurricanes, must still be performed by humans due to the lack of suitable recognition mechanisms. This paper investigates the feasibility of using a perceptron-type computer for the recognition of vortex patterns. A formula is derived which enables the prediction of machine performance as a function of problem complexity and perceptron size (number of logic units). It is shown that the problem complexity can be estimated through optical correlation measurements on cloud cover negatives. These measurements are described and a computer routine is developed which mechanizes the prediction equations and examines the experimental data gained from 10,000 measurements. The results of the computer program are presented and their meaning is discussed.
ID:645
CLASS:7
Title: Sensing from the basement: a feasibility study of unobtrusive and low-cost home activity recognition
Abstract: The home deployment of sensor-based systems offers many opportunities, particularly in the area of using sensor-based systems to support aging in place by monitoring an elder's activities of daily living. But existing approaches to home activity recognition are typically expensive, difficult to install, or intrude into the living space. This paper considers the feasibility of a new approach that "reaches into the home" via the existing infrastructure. Specifically, we deploy a small number of low-cost sensors at critical locations in a home's water distribution infrastructure. Based on water usage patterns, we can then infer activities in the home. To examine the feasibility of this approach, we deployed real sensors into a real home for six weeks. Among other findings, we show that a model built on microphone-based sensors that are placed away from systematic noise sources can identify 100% of clothes washer usage, 95% of dishwasher usage, 94% of showers, 88% of toilet flushes, 73% of bathroom sink activity lasting ten seconds or longer, and 81% of kitchen sink activity lasting ten seconds or longer. While there are clear limits to what activities can be detected when analyzing water usage, our new approach represents a sweet spot in the tradeoff between what information is collected at what cost.
ID:646
CLASS:7
Title: Speech recognition in parallel
Abstract: Concomitantly with recent advances in speech coding, recognition and production, parallel computer systems are now commonplace delivering raw computing power measured in hundreds of MIPS and Megaflops. It seems inevitable that within the next decade or so, gigaflop parallel processors will be achievable at modest cost. Indeed, gigaflops per cubic foot is now becoming a standard of measure for parallel computers.
ID:647
CLASS:7
Title: Contour-based partial object recognition using symmetry in image databases
Abstract: This paper discusses the problem of partial object recognition in image databases. We propose the method to reconstruct and estimate partially occluded shapes and regions of objects in images from overlapping and cutting. We present the robust method for recognizing partially occluded objects based on symmetry properties, which is based on the contours of objects. Our method provides simple techniques to reconstruct occluded regions via a region copy using the symmetry axis within an object. Based on the estimated parameters for partially occluded objects, we perform object recognition on the classification tree. Since our method relies on reconstruction of the object based on the symmetry rather than statistical estimates, it has proven to be remarkably robust in recognizing partially occluded objects in the presence of scale changes, rotation, and viewpoint changes.
ID:648
CLASS:7
Title: Optimizing syntax patterns for discovering protein-protein interactions
Abstract: We propose a method for automated extraction of protein-protein interactions from scientific text. Our system matches sentences against syntax patterns typically describing protein interactions. We define a set of 22 patterns, each a regular expression consisting of anchor positions and parameterizable constraints. This small set is then refined and optimized using a genetic algorithm on a training set. No heuristic definitions are necessary, and the final pattern set can be generated completely without manual curation. Our method can be applied to any syntax pattern-based protein-protein interaction system and thus complements related work on building comprehensive sets of such patterns. The application of different fitness-functions during evolution provides an easy way to tune the system either toward precision, recall, or f-measure. We evaluate our system on two samples, one derived from the BioCreAtIvE corpus, the other from references in the DIP. The automatic refinement of patterns adds up to 16% to the precision, and 5% to the recall of our system. We additionally study the impact of a proper protein name recognition, which could improve precision by about 17% and recall by 12%.
ID:649
CLASS:7
Title: Speech recognition and manner of speaking in noise and in quiet
Abstract: Currently speech recognition is accomplished by matching spoken utterances with reference patterns of words that were spoken by an individual at an earlier time. Recognition is highly dependent upon background noise. The purpose of this study was to assess the extent to which subjects &ldquo;manner&rdquo; of speaking in noise, as separate from the noise itself, affected recognition. Subjects generated reference patterns in quiet and in noise and then spoke lists of digits in quiet and in noise for the speech system to recognize. Noise was delivered over earphones so it would not go into the speech recognition system through the microphone. Training and recognition were done from tape recordings, with the playback level of the tape was always set to the same, intermediate level. The data suggest that manner of speaking, for about half of the subjects is very different in noise compared with quiet. The data also imply that if recognition will be done in both quiet and noise, the safest alternative is to start out with patterns generated in noise.
ID:650
CLASS:7
Title: Timing models for prosody and cross-word coarticulation in connected speech
Abstract: Gauging durations of acoustic intervals is useful for recognizing the phrasing and stress pattern of an utterance. It aids in the recognition of segments that are differentiated by duration, and it can improve segment recognition in general because knowing the stress and phrasing reduces the vocabulary search space. However, models of speech timing that compute acoustic segment lengths cannot capture spectral dynamics, and they rapidly become unwieldy in connected speech, where many effects interact to determine interval durations. I will review two results from recent work on articulatory dynamics that suggest a more workable alternative. Browman and Goldstein have developed a general model of the timing of articulatory gestures. Using this model they can describe many assimilations and apparent deletions of segments at word boundaries in terms of simple manipulations of intergestural timing, an account which should be useful for predicting the lenition pattern and for interpreting the resulting spectra in order to recover the underlying form. Beckman, Edwards, and Fletcher have applied Browman and Goldstein's model in examining articulatory correlates of global tempo decrease, phrase-final position, and sentence accent. Their data show that these three different lengthening effects are functionally distinct and suggest that the kinematics of formant transitions and amplitude curves can be used for distinguishing among the effects to parse the prosodic organization of an utterance.
ID:651
CLASS:7
Title: Player action recognition in broadcast tennis video with applications to semantic analysis of sports game
Abstract: Recognition of player actions in broadcast sports video is a challenging task due to low resolution of the players in video frames. In this paper, we present a novel method to recognize the basic player actions in broadcast tennis video. Different from the existing appearance-based approaches, our method is based on motion analysis and considers the relationship between the movements of different body parts and the regions in the image plane. A novel motion descriptor is proposed and supervised learning is employed to train the action classifier. We also propose a novel framework by combining the player action recognition with other multimodal features for semantic and tactic analysis of the broadcast tennis video. Incorporating action recognition into the framework not only improves the semantic indexing and retrieval performance of the video content, but also conducts highlights ranking and tactics analysis in tennis matches, which is the first solution to our knowledge for tennis game. The experimental results demonstrate that our player action recognition method outperforms existing appearance-based approaches and the multimodal framework is effective for broadcast tennis video analysis.
ID:652
CLASS:7
Title: Face and body gesture recognition for a vision-based multimodal analyzer
Abstract: For the computer to interact intelligently with human users, computers should be able to recognize emotions, by analyzing the human's affective state, physiology and behavior. In this paper, we present a survey of research conducted on face and body gesture and recognition. In order to make human-computer interfaces truly natural, we need to develop technology that tracks human movement, body behavior and facial expression, and interprets these movements in an affective way. Accordingly in this paper, we present a framework for a vision-based multimodal analyzer that combines face and body gesture and further discuss relevant issues.
ID:653
CLASS:7
Title: Facial emotion recognition by adaptive processing of tree structures
Abstract: We present an emotion recognition system based on a probabilistic approach to adaptive processing of Facial Emotion Tree Structures (FETS). FETS are made up of localized Gabor features related to the facial components according to the Facial Action Coding System. The proposed model is an extension of the probabilistic based recursive neural network model applying in face recognition by Cho and Wong [1]. The robustness of the model in an emotion recognition system is evaluated by testing with known and unknown subjects with different emotions. The experiment results shows that the proposed model significantly improved the recognition rate in terms of generalization.
ID:654
CLASS:7
Title: Georgia tech gesture toolkit: supporting experiments in gesture recognition
Abstract: Gesture recognition is becoming a more common interaction tool in the fields of ubiquitous and wearable computing. Designing a system to perform gesture recognition, however, can be a cumbersome task. Hidden Markov models (HMMs), a pattern recognition technique commonly used in speech recognition, can be used for recognizing certain classes of gestures. Existing HMM toolkits for speech recognition can be adapted to perform gesture recognition, but doing so requires significant knowledge of the speech recognition literature and its relation to gesture recognition. This paper introduces the Georgia Tech Gesture Toolkit GT2k which leverages Cambridge University's speech recognition toolkit, HTK, to provide tools that support gesture recognition research. GT2k provides capabilities for training models and allows for both real--time and off-line recognition. This paper presents four ongoing projects that utilize the toolkit in a variety of domains.
ID:655
CLASS:7
Title: A pattern compiler
Abstract: A pattern compiler for the SCRATCHPAD system provides an efficient implementation of sets of user-defined pattern-replacement rules for symbolic mathematical computation such as tables of integrals or summation identities. Rules are compiled together, with common search paths merged and factored out and with the resulting code optimized for efficient recognition over all patterns. Matching principally involves structural comparison of expression trees and evaluation of predicates. Pattern recognizers are &ldquo;fully compiled&rdquo; if values of match variables can be determined by solving equations at compile time. Recognition times for several pattern matchers are compared.
ID:656
CLASS:7
Title: Measuring precision for static and dynamic design pattern recognition as a function of coverage
Abstract: We strive to detect design pattern like patterns in software. This cannot be done efficiently with sufficient precision using only static analysis; we need to combine static and dynamic analysis. In this process, the pattern candidates produced from static analysis are monitored during executions of the software: Candidates detected by static analysis violating the expected dynamic protocol of the pattern are excluded. In this article, we investigate where to put effort when trying to perform high precision pattern detection in code. We do so by investigating which parameters are most important to improve the precision of the detection process: precision of initial static analysis or coverage of the dynamic analysis. Varying the precision of the dynamic analysis is a third important parameter, but this parameter is left as a constant during our experiments. The results show that simple behavioral protocols double the precision when 30% coverage is obtained. We also have indications that simple behavioral protocols give very high precision when high coverage is obtained. In such case, the quality of the static analysis is only interesting for precision if high coverage cannot be reached.
ID:657
CLASS:7
Title: Pattern recognition and pattern-directed inference in a program for playing go
Abstract: Skilled human go play presumes the ability to recognize and make inferences from many different kinds of complex patterns. The go playing program described here deals with these various pattern recognition activities in terms of a small set of basic scanning and recognition mechanisms. All of the program's inference processes are defined with respect to these mechanisms.
ID:658
CLASS:7
Title: Application of pattern recognition to shock-Trauma studies
Abstract: This paper reports the results of a study to determine pattern vectors (Profiles) composed of physiological and biochemical measurements which reflect the severity of injury to traumatized individuals. Profiles, selected by clinicians at the University of Maryland Center for the Study of Trauma, were obtained from the Center data bank and subjected to pattern analyses using OLPARS, an on-line pattern analysis and recognition system, located at Rome Air Development Center, Rome, New York. Prognosis regions were delineated in the Eigenvector Plane and the Discriminant Plane. The time courses of individual patients were plotted in the Eigenvector Plane.
ID:659
CLASS:7
Title: An Integrated Memory Array Processor Architecture for Embedded Image Recognition Systems
Abstract: Embedded processors for video image recognition require to address both the cost (die size and power) versus real-time performance issue, and also to achieve high flexibility due to the immense diversity of recognition targets, situations, and applications. This paper describes IMAP, a highly parallel SIMD linear processor and memory array architecture that addresses these trading-off requirements. By using parallel and systolic algorithmic techniques, despite of its simple architecture IMAP achieves to exploit not only the straightforward per image row data level parallelism (DLP), but also the inherent DLP of other memory access patterns frequently found in various image recognition tasks, under the use of an explicit parallel C language (1DC). We describe and evaluate IMAP-CE, a latest IMAP processor, which integrates 128 of 100MHz 8 bit4-way VLIW PEs, 128 of 2KByte RAMs, and one 16 bit RISC control processor, into a single chip. The PE instruction set is enhanced for supporting 1DC codes. IMAP-CE is evaluated mainly by comparing its performance running 1DC codes with that of a 2.4GHz Intel P4 running optimized C codes. Based on the use of parallelizing techniques, benchmark results show a speedup of up to 20 for image filter kernels, and of 4 for a full image recognition application.
ID:660
CLASS:7
Title: Learning from facial aging patterns for automatic age estimation
Abstract: Age Specific Human-Computer Interaction (ASHCI) has vast potential applications in daily life. However, automatic age estimation technique is still underdeveloped. One of the main reasons is that the aging effects on human faces present several unique characteristics which make age estimation a challenging task that requires non-standard classification approaches. According to the speciality of the facial aging effects, this paper proposes the AGES (AGing pattErn Subspace) method for automatic age estimation. The basic idea is to model the aging pattern, which is defined as a sequence of personal aging face images, by learning a representative subspace. The proper aging pattern for an unseen face image is then determined by the projection in the subspace that can best reconstruct the face image, while the position of the face image in that aging pattern will indicate its age. The AGES method has shown encouraging performance in the comparative experiments either as an age estimator or as an age range estimator.
ID:661
CLASS:7
Title: Relaxing stylus typing precision by geometric pattern matching
Abstract: Fitts' law models the inherent speed-accuracy trade-off constraint in stylus typing. Users attempting to go beyond the Fitts' law speed ceiling will tend to land the stylus outside the targeted key, resulting in erroneous words and increasing users' frustration. We propose a geometric pattern matching technique to overcome this problem. Our solution can be used either as an enhanced spell checker or as a way to enable users to escape the Fitts' law constraint in stylus typing, potentially resulting in higher text entry speeds than what is currently theoretically modeled. We view the hit points on a stylus keyboard as a high resolution geometric pattern. This pattern can be matched against patterns formed by the letter key center positions of legitimate words in a lexicon. We present the development and evaluation of an "elastic" stylus keyboard capable of correcting words even if the user misses all the intended keys, as long as the user's tapping pattern is close enough to the intended word.
ID:662
CLASS:7
Title: Recognition of island structures for map generalization
Abstract: In this paper we describe work on the automatic recognition of island structures. In an initial phase several test persons were asked to mark groups of islands that they perceived on test maps. Based on these experimental results the island structures were categorized with respect to size and shape, and their construction described using principles from Gestalt theory. Based on those descriptions of island structures we will present an algorithm for the detection of large groups of islands based on a Minimal Spanning Tree (MST). Therefore, we apply split and merge operations on the MST. For the automated characterization of the shape and orientation of island groups we propose to use principal components obtained from a PCA. The results of the algorithm are then visually compared with the island groups previously marked by test persons and shortcomings of the approach are discussed.
ID:663
CLASS:7
Title: VLSI architectures for high speed recognition of context-free languages and finite-state languages
Abstract: This paper presents two VLSI architectures for the recognition of context-free languages and finite-state languages. The architecture for context-free languages consists of n(n+1)/2 identical cells and it is capable of recognizing an input string of length n in 2n time units. The architecture for finite-state languages consists of n cells and it can recognize a string of length n in constant time. Since both architectures have characteristics such as modular layout, simple constrol and dataflow pattern, high degree of multiprocessing and/or pipelining, etc., they are very suitable for VLSI implementation.
ID:664
CLASS:7
Title: ME-based biomedical named entity recognition using lexical knowledge
Abstract: In this paper, we present a two-phase biomedical NE-recognition method based on a ME model: we first recognize biomedical terms and then assign appropriate semantic classes to the recognized terms. In the two-phase NE-recognition method, the performance of the term-recognition phase is very important, because the semantic classification is performed on the region identified at the recognition phase. In this study, in order to improve the performance of term recognition, we try to incorporate lexical knowledge into pre- and postprocessing of the term-recognition phase. In the preprocessing step, we use domain-salient words as lexical knowledge obtained by corpus comparison. In the postprocessing step, we utilize &chi;2-based collocations gained from Medline corpus. In addition, we use morphological patterns extracted from the training data as features for learning the ME-based classifiers. Experimental results show that the performance of NE-recognition can be improved by utilizing such lexical knowledge.
ID:665
CLASS:7
Title: Using tone information in Cantonese continuous speech recognition
Abstract: In Chinese languages, tones carry important information at various linguistic levels. This research is based on the belief that tone information, if acquired accurately and utilized effectively, contributes to the automatic speech recognition of Chinese. In particular, we focus on the Cantonese dialect, which is spoken by tens of millions of people in Southern China and Hong Kong. Cantonese is well known for its complicated tone system, which makes automatic tone recognition very difficult. This article describes an effective approach to explicit tone recognition of Cantonese in continuously spoken utterances. Tone feature vectors are derived, on a short-time basis, to characterize the syllable-wide patterns of F0 (fundamental frequency) and energy movements. A moving-window normalization technique is proposed to reduce the tone-irrelevant fluctuation of F0 and energy features. Hidden Markov models are employed for context-dependent acoustic modeling of different tones. A tone recognition accuracy of 66.4% has been achieved in the speaker-independent case. The recognized tone patterns are then utilized to assist Cantonese large-vocabulary continuous speech recognition (LVCSR) via a lattice expansion approach. Experimental results show that reliable tone information helps to improve the overall performance of LVCSR.
ID:666
CLASS:7
Title: On the convergence of image compression and object recognition
Abstract: Over the past four decades, image compression and object recognition have evolved from pixel-level to region-level processing, and thence to feature-based resolution. For example, compression has progressed from entropy coding of a bit or pixel stream, to transform coding applied to rectangular encoding blocks, to feature-based compression that employs segmentation of isospectral or isotextural regions. Similarly, object recognition has progressed from operations on individual pixel intensities or spectral signatures, to region- or feature-based processing employing segmentation. Recent progress in image compression indicates that significantly decreased bit rate (thus, significantly increased compression ratio) can be obtained by isolating or segmenting, then compressing scene objects, which is called object-based compression or OBC.In this paper, the relationship between object segmentation and compression is presented theoretically, then exemplified in terms of current research in OBC. The relationship between object compression and recognition is also discussed theoretically. Recent work in object recognition is shown to be closely related theoretically to OBC. Two recently-developed paradigms, Mu&ntilde;oz et al.'s region growing algorithm and Campbell et al.'s Quick-Sketch, which support very efficient compression and accurate recognition/retrieval of image objects, are summarized. Additionally. a performance model is given for OBC that isolates space complexity bottlenecks for future enhancement and implementation.
ID:667
CLASS:7
Title: Face recognition with Multilevel B-Splines and Support Vector Machines
Abstract: This paper presents a new face recognition system, based on Multilevel B-splines and Support Vector Machines. The idea is to consider face images as heightfields, in which the height relative to each pixel is given by the corresponding gray level. Such heightfields are approximated using Multilevel B-Splines, and the coefficients of approximation are used as features for the classification process, which is performed using Support Vector Machines. The proposed approach was thoroughly tested, using ORL, Yale, Stirling and Bern face databases. The obtained results are very encouraging, outperforming traditional methods like eigenface, elastic matching or neural-networks based recognition systems.
ID:668
CLASS:7
Title: Pattern width at a given angle
Abstract: That the pattern feature &ldquo;width as a function of angle&rdquo; possesses several possible interpretations is demonstrated in this paper, which is a review of the width concept in pattern recognition and the geometrical concept itself.The object of the work is to clarify how the word description can be made precise so that computer algorithms for feature extraction may be obtained; the focus is on theoretical subject matter. The results consist of a set-theoretic definition of width-at-angle, a theorem relating it to the pattern boundary radius vector, and descriptions of alternate widths. All widths are calculated for an illustrative example; graphical and tabular comparisons are given. Substantial variation in width-at-angle magnitude is found. The principal conclusion is that the set-theoretic width-at-angle is a useful pattern feature when it can be easily computed. Further investigation of the information contained in only part of a width function is recommended for cases where computation of width-at-angle is difficult.
ID:669
CLASS:7
Title: Contextual recognition of head gestures
Abstract: Head pose and gesture offer several key conversational grounding cues and are used extensively in face-to-face interaction among people. We investigate how dialog context from an embodied conversational agent (ECA) can improve visual recognition of user gestures. We present a recognition framework which (1) extracts contextual features from an ECA's dialog manager, (2) computes a prediction of head nod and head shakes, and (3) integrates the contextual predictions with the visual observation of a vision-based head gesture recognizer. We found a subset of lexical, punctuation and timing features that are easily available in most ECA architectures and can be used to learn how to predict user feedback. Using a discriminative approach to contextual prediction and multi-modal integration, we were able to improve the performance of head gesture detection even when the topic of the test set was significantly different than the training set.
ID:670
CLASS:7
Title: Recognition of two-person interactions using a hierarchical Bayesian network
Abstract: Recognizing human interactions is a challenging task due to the multiple body parts of interacting persons and the concomitant occlusions. This paper presents a method for the recognition of two-person interactions using a hierarchical Bayesian network (BN). The poses of simultaneously tracked body parts are estimated at the low level of the BN, and the overall body pose is estimated at the high level of the BN. The evolution of the poses of the multiple body parts are processed by a dynamic Bayesian network. The recognition of two-person interactions are expressed in terms of semantic verbal descriptions at multiple levels; individual body-part motions at low level, single-person actions at middle level, and twoperson interactions at high level. Example sequences of interacting persons illustrate the success of the proposed framework.
ID:671
CLASS:7
Title: Array form representation of idiom recognition system for numerical programs
Abstract: Today, PSE emerges as a promising approach for providing programmers with high-level abstract functions Particularly for numerical programs which essentially handle large arrays, abstract representation of array-handling functions is very important. Idiom recognition can be a bridge between abstract source programs and concrete architectures. It can remove obstacles of gaps between the two that cannot be bridged by today's state of the art compilers. A major problem in idiom recognition is intermediate representation. This paper applies term rewriting theory---a very general framework --- to an idiom recognition system. Specifically, we apply it to the idiom recognition problem of Fortran90/95 matrix manipulations, and show that the Fortran90/95 system is never a trivial system. Straight forms are introduced to make the idiom recognition system more powerful. We make a completion procedure based on this Fortran90/95 system, and show some non-trivial idiom recognition using our theory.
ID:672
CLASS:7
Title: Human action recognition using star skeleton
Abstract: This paper presents a HMM-based methodology for action recogni-tion using star skeleton as a representative descriptor of human posture. Star skeleton is a fast skeletonization technique by connecting from centroid of target object to contour extremes. To use star skeleton as feature for action recognition, we clearly define the fea-ture as a five-dimensional vector in star fashion because the head and four limbs are usually local extremes of human shape. In our proposed method, an action is composed of a series of star skeletons over time. Therefore, time-sequential images expressing human action are transformed into a feature vector sequence. Then the fea-ture vector sequence must be transformed into symbol sequence so that HMM can model the action. We design a posture codebook, which contains representative star skeletons of each action type and define a star distance to measure the similarity between feature vec-tors. Each feature vector of the sequence is matched against the codebook and is assigned to the symbol that is most similar. Conse-quently, the time-sequential images are converted to a symbol posture sequence. We use HMMs to model each action types to be recognized. In the training phase, the model parameters of the HMM of each category are optimized so as to best describe the training symbol sequences. For human action recognition, the model which best matches the observed symbol sequence is selected as the recog-nized category. We implement a system to automatically recognize ten different types of actions, and the system has been tested on real human action videos in two cases. One case is the classification of 100 video clips, each containing a single action type. A 98% recog-nition rate is obtained. The other case is a more realistic situation in which human takes a series of actions combined. An action-series recognition is achieved by referring a period of posture history using a sliding window scheme. The experimental results show promising performance.
ID:673
CLASS:7
Title: Recognizing behavioral patterns atruntime using finite automata
Abstract: During reverse engineering, developers often need to understand the undocumented design of a software. In particular, recognizing design patterns in the software can provide reverse engineers with considerable insight on the software structure and its internal characteristics. Researchers have therefore proposed techniques based on static analysis to automatically recover design patterns in a program. Unfortunately, most design patterns comprise not only structural, but also significant behavioral aspects. Although static analysis is well suited for the recognition of structural aspects, it is typically limited and imprecise in analyzing behavior. To address this limitation, we present a new technique that complements our existing static analysis with a dynamic analysis, so as to perform a more accurate design-pattern recognition. The dynamic analysis is based on (1) transforming behavioral aspects of design patterns into finite automata, (2) identifying and instrumenting relevant method calls, and (3) monitoring relevant calls at runtime and matching them against the automata. The results of the dynamic analysis are then used to compute the likelihood of a pattern to be in the code. This paper describes our technique and presents a preliminary empirical study performed to assess the technique.
ID:674
CLASS:7
Title: Face recognition using multi-feature and radial basis function network
Abstract: In this paper, a face recognition algorithm using multi feature and Radial basis Function Network (RBFN) is proposed. The algorithm consists of three steps. In the first step, a coarse classification is performed using Fourier frequency spectrum feature, and only the first k gallery images with minimum Euclidean distance to the probe image are retained. In the second step, the Principal Component Analysis (PCA) and Linear Discriminant Analysis (LDA) features of frequency spectrum are extracted, which will be taken as the input of the RBFN in the third step. In the last step, the classification is carried out by using RBFN. The proposed approach has been tested on ORL face database and Shimon database. The experimental results have demonstrated that the performance of this algorithm is much superior to the other algorithms on the same database.
ID:675
CLASS:7
Title: iSTART: paraphrase recognition
Abstract: Paraphrase recognition is used in a number of applications such as tutoring systems, question answering systems, and information retrieval systems. The context of our research is the iSTART reading strategy trainer for science texts, which needs to understand and recognize the trainee's input and respond appropriately. This paper describes the motivation for paraphrase recognition and develops a definition of the strategy as well as a recognition model for paraphrasing. Lastly, we discuss our preliminary implementation and research plan.
ID:676
CLASS:7
Title: Combination of Fisher scores and appearance based features for face recognition
Abstract: A novel feature generation scheme which combines multiclass mapping of Fisher scores and appearance based features for face recognition (FR) is proposed in this paper. Multi-class mapping of Fisher scores is based on partial derivative analysis of parameters of hidden Markov model (HMM), and appearance based features are obtained directed from face images. Linear discriminant analysis (LDA) is used to analyze the feature vectors generated under this scheme. Recognition performance improvement is observed over stand-alone HMM method as well as Fisherface method, which also uses appearance based feature vectors. Moreover, by reducing the number of models involved in the training and testing stages, the proposed feature generation scheme can maintain very high discriminative power at much lower computational complexity comparing to that of the traditional HMM based FR system. Experimental results are provided to demonstrate the viability of this scheme for face recognition.
ID:677
CLASS:7
Title: Experiments with some algorithms that find central solutions for pattern classification
Abstract: In two-class pattern recognition, it is a standard technique to have an algorithm finding hyperplanes which separates the two classes in a linearly separable training set. The traditional methods find a hyperplane which separates all points in one class from all points in the other, but such a hyperplane is not necessarily centered in the empty space between the two classes. Since a central hyperplane does not favor one class or the other, it should have a lower error rate in classifying new points and is therefore better than a noncentral hyperplane. Six algorithms for finding central hyperplanes are tested on three data sets. Although frequently used in practice, the modified relaxation algorithm is very poor. Three algorithms which are defined in the paper are found to be quite good.
ID:678
CLASS:7
Title: An implicit segmentation-based method for recognition of handwritten strings of characters
Abstract: This paper describes an implicit segmentation-based method for recognition of strings of characters (words or numerals). In a two-stage HMM-based method, an implicit segmentation is applied to segment either words or numeral strings, and in the verification stage, foreground and background features are combined to compensate the loss in terms of recognition rate when segmentation and recognition are performed in the same process. A rigorous experimental protocol shows the performance of the proposed method for isolated characters, numeral strings, and words.
ID:679
CLASS:7
Title: Implementing protocols via declarative event patterns
Abstract: This paper introduces declarative event patterns (DEPs) as a means to implement protocols while improving their traceability, comprehensibility, and maintainability. DEPs are descriptions of sequences of events in the execution of a system that include the ability to recognize properly nested event structures. DEPs allow a developer to describe a protocol at a high-level, without the need to express extraneous details. A developer can indicate that specific actions be taken when a given pattern occurs. DEPs are automatically translated into the appropriate instrumentation and automaton for recognizing a given pattern. Support for DEPs has been implemented in a proof-of-concept extension to the AspectJ language that is based on advanced compiler technology. A case study is described that compares the use of DEPs in the implementation of a protocol (FTP user authentication) to the use of a set of other approaches, both object-oriented and aspect-oriented.
ID:680
CLASS:7
Title: Towards automatic analysis of social interaction patterns in a nursing home environment from video
Abstract: In this paper, we propose an ontology-based approach for analyzing social interaction patterns in a nursing home from video. Social interaction patterns are broken into individual activities and behavior events using a multi-level context hierarchy ontology framework. To take advantage of an ontology in representing how social interactions evolve, we design and refine the ontology based on knowledge gained from 80 hours of video recorded in the public spaces of a nursing home. The ontology is implemented using a dynamic Bayesian network to statistically model the multi-level concepts defined in the ontology. We have developed a prototype system to illustrate the proposed concept. Experiment results have demonstrated feasibility of the proposed approach. The objective of this research is to automatically create concise and comprehensive reports of activities and behaviors of patients to support physicians and caregivers in a nursing facility
ID:681
CLASS:7
Title: Automatic recognition of Chinese unknown words based on roles tagging
Abstract: This paper presents a unified solution, which is based on the idea of "roles tagging", to the complicated problems of Chinese unknown words recognition. In our approach, an unknown word is identified according to its component tokens and context tokens. In order to capture the functions of tokens, we use the concept of roles. Roles are tagged through applying the Viterbi algorithm in the fashion of a POS tagger. In the resulted most probable roles sequence, all the eligible unknown words are recognized through a maximum patterns matching. We have got excellent precision and recalling rates, especially for person names and transliterations. The result and experiments in our system ICTCLAS shows that our approach based on roles tagging is simple yet effective.
ID:682
CLASS:7
Title: The reconstruction of binary patterns from their projections
Abstract: Given the horizontal and vertical projections of a finite binary pattern f, can we reconstruct the original pattern f? In this paper we give a characterization of patterns that are reconstructable from their projections. Three algorithms are developed to reconstruct both unambiguous and ambiguous patterns. It is shown that an unambiguous pattern can be perfectly reconstructed in time m &times; n and that a pattern similar to an ambiguous pattern can also be constructed in time m &times; n, where m, n are the dimensions of the pattern frame.
ID:683
CLASS:7
Title: Hierarchical parsing and recognition of hand-sketched diagrams
Abstract: A long standing challenge in pen-based computer interaction is the ability to make sense of informal sketches. A main difficulty lies in reliably extracting and recognizing the intended set of visual objects from a continuous stream of pen strokes. Existing pen-based systems either avoid these issues altogether, thus resulting in the equivalent of a drawing program, or rely on algorithms that place unnatural constraints on the way the user draws. As one step toward alleviating these difficulties, we present an integrated sketch parsing and recognition approach designed to enable natural, fluid, sketch-based computer interaction. The techniques presented in this paper are oriented toward the domain of network diagrams. In the first step of our approach, the stream of pen strokes is examined to identify the arrows in the sketch. The identified arrows then anchor a spatial analysis which groups the uninterpreted strokes into distinct clusters, each representing a single object. Finally, a trainable shape recognizer, which is informed by the spatial analysis, is used to find the best interpretations of the clusters. Based on these concepts, we have built SimuSketch, a sketch-based interface for Matlab's Simulink software package. An evaluation of SimuSketch has indicated that even novice users can effectively utilize our system to solve real engineering problems without having to know much about the underlying recognition techniques.
ID:684
CLASS:7
Title: A ROM random-pulse computer for classifying binary patterns
Abstract: This paper presents a novel design of a non-adaptive binary pattern classifier. The structure employs random-pulse (stochastic) computing elements to realize nonlinear discriminant functions in pattern recognition. A machine design configuration illustrates how a ROM without addressing circuits stores modes and simultaneously executes parallel stochastic multiplications required in discriminant function computations&mdash;demonstrating efficient hardware utilization.
ID:685
CLASS:7
Title: An automatic sign recognition and translation system
Abstract: A sign is something that suggests the presence of a fact, condition, or quality. Signs are everywhere in our lives. They make our lives easier when we are familiar with them. But sometimes they pose problems. For example, a tourist might not be able to understand signs in a foreign country. This paper discusses problems of automatic sign recognition and translation. We present a system capable of capturing images, detecting and recognizing signs, and translating them into a target language. We describe methods for automatic sign extraction and translation. We use a user-centered approach in system development. The approach takes advantage of human intelligence if needed and leverage human capabilities. We are currently working on Chinese sign translation. We have developed a prototype system that can recognize Chinese sign input from a video camera that is a common gadget for a tourist, and translate the signs into English or voice stream. The sign translation, in conjunction with spoken language translation, can help international tourists to overcome language barriers. The technology can also help a visually handicapped person to increase environmental awareness.
ID:686
CLASS:7
Title: Real time facial expression recognition in video using support vector machines
Abstract: Enabling computer systems to recognize facial expressions and infer emotions from them in real time presents a challenging research topic. In this paper, we present a real time approach to emotion recognition through facial expression in live video. We employ an automatic facial feature tracker to perform face localization and feature extraction. The facial feature displacements in the video stream are used as input to a Support Vector Machine classifier. We evaluate our method in terms of recognition accuracy for a variety of interaction and classification scenarios. Our person-dependent and person-independent experiments demonstrate the effectiveness of a support vector machine and feature tracking approach to fully automatic, unobtrusive expression recognition in live video. We conclude by discussing the relevance of our work to affective and intelligent man-machine interfaces and exploring further improvements.
ID:687
CLASS:7
Title: Using the Gamera framework for the recognition of cultural heritage materials
Abstract: This paper presents a new toolkit for the creation of customized structured document recognition applications by domain experts. This open-source system, called Gamera, allows a user, with particular knowledge of the documents to be recognized, to combine image processing and recognition tools in an easy-to-use, interactive, graphical scripting environment. Gamera is one of the key technology components in a proposed international project for the digitization of diverse types of humanities documents.
ID:688
CLASS:7
Title: A framework for knowledge representation and use in pattern analysis
Abstract: In this paper a prototype Expert System oriented to signal and pattern analysis is described together with a general methodology based on a hypothesize-and-test strategy similar to the one used by a human expert. This paper focuses on the knowledge base architecture and on its use. In order to make it capable of dealing with noisy patterns, the knowledge description is based on Fuzzy logic and the inference engine is able to reason about the knowledge it uses. The system is being applied to the phonetic analysis of the voice signal in speech recognition, as a case study.
ID:689
CLASS:7
Title: Distributed pointing for multimodal collaboration over sketched diagrams
Abstract: A problem faced by groups that are not co-located but need to collaborate on a common task is the reduced access to the rich multimodal communicative context that they would have access to if they were collaborating face-to-face. Collaboration support tools aim to reduce the adverse effects of this restricted access to the fluid intermixing of speech, gesturing, writing and sketching by providing mechanisms to enhance the awareness of distributed participants of each others' actions.In this work we explore novel ways to leverage the capabilities of multimodal context-aware systems to bridge co-located and distributed collaboration contexts. We describe a system that allows participants at remote sites to collaborate in building a project schedule via sketching on multiple distributed whiteboards, and show how participants can be made aware of naturally occurring pointing gestures that reference diagram constituents as they are performed by remote participants.The system explores the multimodal fusion of pen, speech and 3D gestures, coupled to the dynamic construction of a semantic representation of the interaction, anchored on the sketched diagram, to provide feedback that overcomes some of the intrinsic ambiguities of pointing gestures.
ID:690
CLASS:7
Title: Human activity recognition for automatic visual surveillance of wide areas
Abstract: The problem of automatic recognition of human activities is among the most important and challenging open areas of research in Computer Vision. This paper presents a methodology to automatically recognize the human activities embedded in video sequences acquired in outdoor environments by a single large view camera. The activity recognition process is performed in three steps: first of all the binary shape of moving people are segmented, then the human body posture is estimated frame by frame and finally, for each activity to be recognized, a temporal model of the detected postures is generated by Discrete Hidden Markov Models. The system has been tested on image sequences acquired in a real archaeological site meanwhile actors perform both legal and illegal actions. Four kinds of activities have been automatically classified with high percentage of correct decisions. Time performance tests are very encouraging for using the proposed method in real time applications.
ID:691
CLASS:7
Title: Crossmodal error dorrection of continuous handwriting recognition by speech
Abstract: In recognition-based user interface, users' satisfaction is determined not only by recognition accuracy but also by effort to correct recognition errors. In this paper, we introduce a crossmodal error correction technique, which allows users to correct errors of Chinese handwriting recognition by speech. The focus of the paper is a multimodal fusion algorithm supporting the crossmodal error correction. By fusing handwriting and speech recognition, the algorithm can correct errors in both character extraction and recognition of handwriting. The experimental result indicates that the algorithm is effective and efficient. Moreover, the evaluation also shows the correction technique can help users to correct errors in handwriting recognition more efficiently than the other two error correction techniques.
ID:692
CLASS:7
Title: PhoneGuide: museum guidance supported by on-device object recognition on mobile phones
Abstract: We present PhoneGuide -- an enhanced museum guidance system that uses camera-equipped mobile phones and on-device object recognition.Our main technical achievement is a simple and light-weight object recognition approach that is realized with single-layer perceptron neuronal networks. In contrast to related systems which perform computationally intensive image processing tasks on remote servers, our intention is to carry out all computations directly on the phone. This ensures little or even no network traffic and consequently decreases cost for online times. Our laboratory experiments and field surveys have shown that photographed museum exhibits can be recognized with a probability of over 90%.We have evaluated different feature sets to optimize the recognition rate and performance. Our experiments revealed that normalized color features are most effective for our method. Choosing such a feature set allows recognizing an object below one second on up-to-date phones. The amount of data that is required for differentiating 50 objects from multiple perspectives is less than 6KBytes.
ID:693
CLASS:7
Title: A nearest neighbor approach to letter recognition
Abstract: The nearest neighbor classifier (NNC) is a non-parametric classification technique that classifies a test pattern to the class of its nearest neighbor in the training data. In this research, we applied the NNC to a standard letter recognition data and obtained a superior classification rate in comparison to extant approaches. A prime drawback to the NNC technique has been the relative inefficiency of the model. A modified NNC was implemented and applied to the same recognition problem. It is found that if we choose a suitable threshold minimum difference for classification, we can reduce the CPU time by half without lowering the performance of the classifier.
ID:694
CLASS:7
Title: Facial expression recognition for multiplayer online games
Abstract: The Multiplayer Online Game (MOG) becomes more popular than any other types of computer games for its collaboration, communication and interaction ability. However, compared with the ordinary human communication, the MOG still has many limitations, especially in communication using facial expressions. Although detailed facial animation has already been achieved in a number of MOGs, players have to use text commands to control avatars expressions. In this paper, we briefly review the state of the art in facial expression recognition and propose an automatic expression recognition system that can be integrated into a MOG to control the avatar's facial expressions. We evaluate and improve a number of algorithms to meet the specific requirements of such a system and propose an efficient implementation. In particular, our proposed system uses fixed and less facial landmarks to reduce the computational load with little degradation of the recognition performance.
ID:695
CLASS:7
Title: The analysis of two-dimensional patterns using picture processing grammars
Abstract: A method for the description of the hierarchical structure of two-dimensional pictures is proposed. The model is called picture-processing grammar. It can be regarded as an extension of phrase-structure grammars to the two-dimensional case. A picture analysis program is described. It accepts picture-processing grammar in tabular form and processes pictures using that grammar. Experiments have been performed to analyze handwritten numerals, mathematical expressions and line drawings. Some practical applications are discussed.
ID:696
CLASS:7
Title: Pattern discovery in sequences under a Markov assumption
Abstract: In this paper we investigate the general problem of discovering recurrent patterns that are embedded in categorical sequences. An important real-world problem of this nature is motif discovery in DNA sequences. We investigate the fundamental aspects of this data mining problem that can make discovery "easy" or "hard." We present a general framework for characterizing learning in this context by deriving the Bayes error rate for this problem under a Markov assumption. The Bayes error framework demonstrates why certain patterns are much harder to discover than others. It also explains the role of different parameters such as pattern length and pattern frequency in sequential discovery. We demonstrate how the Bayes error can be used to calibrate existing discovery algorithms, providing a lower bound on achievable performance. We discuss a number of fundamental issues that characterize sequential pattern discovery in this context, present a variety of empirical results to complement and verify the theoretical analysis, and apply our methodology to real-world motif-discovery problems in computational biology.
ID:697
CLASS:1
Title: High-performance packet classification algorithm for many-core and multithreaded network processor
Abstract: Packet classification is crucial for the Internet to provide more value-added services and guaranteed quality of service. Besides hardware-based solutions, many software-based classification algorithms have been proposed. However, classifying at 10Gbps speed or higher is a challenging problem and it is still one of the performance bottlenecks in core routers. In general, classification algorithms face the same challenge of balancing between high classification speed and low memory requirements. This paper proposes a modified Recursive Flow Classification (RFC) algorithm, Bitmap-RFC, which significantly reduces the memory requirements of RFC by applying a bitmap compression technique. To speed up classifying speed, we experiment on exploiting the architectural features of a many-core and multithreaded architecture from algorithm design to algorithm implementation. As a result, Bitmap-RFC strikes a good balance between speed and space. It can not only keep high classification speed but also reduce memory space significantly.This paper investigates the main NPU software design aspects that have dramatic performance impacts on any NPU-based implementations: memory space reduction, instruction selection, data allocation, task partitioning, and latency hiding. We experiment with an architecture-aware design principle to guarantee the high performance of the classification algorithm on an NPU implementation. The experimental results show that the Bitmap-RFC algorithm achieves 10Gbps speed or higher and has a good scalability on Intel IXP2800 NP.
ID:698
CLASS:1
Title: Aspect-oriented programming with type classes
Abstract: We consider the problem of adding aspects to a strongly typed language which supports type classes. We show that type classes as supported by the Glasgow Haskell Compiler can model an AOP style of programming via a simple syntax-directed transformation scheme where AOP programming idioms are mapped to type classes. The drawback of this approach is that we cannot easily advise functions in programs which carry type annotations. We sketch a more principled approach which is free of such problems by combining ideas from intentional type analysis with advanced overloading resolution strategies. Our results show that type-directed static weaving is closely related to type class resolution -- the process of typing and translating type class programs.
ID:699
CLASS:1
Title: Text classification from positive and unlabeled documents
Abstract: Most existing studies of text classification assume that the training data are completely labeled. In reality, however, many information retrieval problems can be more accurately described as learning a binary classifier from a set of incompletely labeled examples, where we typically have a small number of labeled positive examples and a very large number of unlabeled examples. In this paper, we study such a problem of performing Text Classification WithOut labeled Negative data TC-WON). In this paper, we explore an efficient extension of the standard Support Vector Machine (SVM) approach, called SVMC (Support Vector Mapping Convergence) [17]for the TC-WON tasks. Our analyses show that when the positive training data is not too under-sampled, SVMC significantly outperforms other methods because SVMC basically exploits the natural "gap" between positive and negative documents in the feature space, which eventually corresponds to improving the generalization performance. In the text domain there are likely to exist many gaps in the feature space because a document is usually mapped to a sparse and high dimensional feature space. However, as the number of positive training data decreases, the boundary of SVMC starts overfitting at some point and end up generating very poor results.This is because when the positive training data is too few, the boundary over-iterates and trespasses the natural gaps between positive and negative class in the feature space and thus ends up fitting tightly around the few positive training data.
ID:700
CLASS:1
Title: An extensive empirical study of feature selection metrics for text classification
Abstract: Machine learning for text classification is the cornerstone of document categorization, news filtering, document routing, and personalization. In text domains, effective feature selection is essential to make the learning task efficient and more accurate. This paper presents an empirical comparison of twelve feature selection methods (e.g. Information Gain) evaluated on a benchmark of 229 text classification problem instances that were gathered from Reuters, TREC, OHSUMED, etc. The results are analyzed from multiple goal perspectives-accuracy, F-measure, precision, and recall-since each is appropriate in different situations. The results reveal that a new feature selection metric we call 'Bi-Normal Separation' (BNS), outperformed the others by a substantial margin in most situations. This margin widened in tasks with high class skew, which is rampant in text classification problems and is particularly challenging for induction algorithms. A new evaluation methodology is offered that focuses on the needs of the data mining practitioner faced with a single dataset who seeks to choose one (or a pair of) metrics that are most likely to yield the best performance. From this perspective, BNS was the top single choice for all goals except precision, for which Information Gain yielded the best result most often. This analysis also revealed, for example, that Information Gain and Chi-Squared have correlated failures, and so they work poorly together. When choosing optimal pairs of metrics for each of the four performance goals, BNS is consistently a member of the pair---e.g., for greatest recall, the pair BNS + F1-measure yielded the best performance on the greatest number of tasks by a considerable margin.
ID:701
CLASS:1
Title: On effective classification of strings with wavelets
Abstract: In recent years, the technological advances in mapping genes have made it increasingly easy to store and use a wide variety of biological data. Such data are usually in the form of very long strings for which it is difficult to determine the most relevant features for a classification task. For example, a typical DNA string may be millions of characters long, and there may be thousands of such strings in a database. In many cases, the classification behavior of the data may be hidden in the compositional behavior of certain segments of the string which cannot be easily determined apriori. Another problem which complicates the classification task is that in some cases the classification behavior is reflected in global behavior of the string, whereas in others it is reflected in local patterns. Given the enormous variation in the behavior of the strings over different data sets, it is useful to develop an approach which is sensitive to both the global and local behavior of the strings for the purpose of classification. For this purpose, we will exploit the multi-resolution property of wavelet decomposition in order to create a scheme which can mine classification characteristics at different levels of granularity. The resulting scheme turns out to be very effective in practice on a wide range of problems.
ID:702
CLASS:1
Title: Classifying properties: an alternative to the safety-liveness classification
Abstract: Traditionally, verification properties have been classified as safety or liveness properties. While this taxonomy has an attractive simplicity and is useful for identifying the appropriate analysis algorithm for checking a property, determining whether a property is safety, liveness, or neither can require significant mathematical insight on the part of the analyst. In this paper, we present an alternative property taxonomy. We argue that this taxonomy is a more natural classification of the kinds of questions that analysts want to ask. Moreover, most classes in our taxonomy have a known, direct mapping to the safety-liveness classification, and thus the appropriate analysis algorithm can be automatically determined.
ID:703
CLASS:1
Title: Type classes in Haskell
Abstract: This article defines a set of type inference rules for resolving overloading introduced by type classes, as used in the functional programming language Haskell. Programs including type classes are transformed into ones which may be typed by standard Hindley-Milner inference rules. In contrast to other work on type classes, the rules presented here relate directly to Haskell programs. An innovative aspect of this work is the use of second-order lambda calculus to record type information in the transformed program.
ID:704
CLASS:1
Title: Automated Facial Expression Classification and affect interpretation using infrared measurement of facial skin temperature variations
Abstract: Machines would require the ability to perceive and adapt to affects for achieving artificial sociability. Most autonomous systems use Automated Facial Expression Classification (AFEC) and Automated Affect Interpretation (AAI) to achieve sociability. Varying lighting conditions, occlusion, and control over physiognomy can influence the real life performance of vision-based AFEC systems. Physiological signals provide complementary information for AFEC and AAI. We employed transient facial thermal features for AFEC and AAI. Infrared thermal images with participants' normal expression and intentional expressions of happiness, sadness, disgust, and fear were captured. Facial points that undergo significant thermal changes with a change in expression termed as Facial Thermal Feature Points (FTFPs) were identified. Discriminant analysis was invoked on principal components derived from the Thermal Intensity Values (TIVs) recorded at the FTFPs. The cross-validation and person-independent classification respectively resulted in 66.28&percnt; and 56.0&percnt; success rates. Classification significance tests suggest that (1) like other physiological cues, facial skin temperature also provides useful information about affective states and their facial expression; (2) patterns of facial skin temperature variation can complement other cues for AFEC and AAI; and (3) infrared thermal imaging may help achieve artificial sociability in robots and autonomous systems.
ID:705
CLASS:1
Title: Unsupervised band removal leading to improved classification accuracy of hyperspectral images
Abstract: Remotely-sensed images of the earth's surface are used across a wide range of industries and applications including agriculture, mining, defence, geography and geology, to name but a few. Hyperspectral sensors produce these images by providing reflectance data from the earth's surface over a broad range of wavelengths or bands. Some of the bands suffer from a low signal-to noise ratio (SNR) and do not contribute to the subsequent classification of pixels within the hyperspectral image. Users of hyperspectral images typically become familiar with individual images or sensors and often manually omit these bands before classification.We propose a process that automatically determines the spectral bands that may not contribute to classification and removes these bands from the image. Removal of these bands improves the classification performance of a well-researched hyperspectral test image by over 10% whilst reducing the size of the image from a data storage perspective by almost 30%. The process does not rely on prior knowledge of the sensor, the image or the phenomenology causing the SNR problem.In future work, we aim to develop compression algorithms that incorporate this process to achieve satisfactory compression ratios whilst maintaining acceptable classification accuracies.
ID:706
CLASS:1
Title: Question classification using HDAG kernel
Abstract: This paper proposes a machine learning based question classification method using a kernel function, Hierarchical Directed Acyclic Graph (HDAG) Kernel. The HDAG Kernel directly accepts structured natural language data, such as several levels of chunks and their relations, and computes the value of the kernel function at a practical cost and time while reflecting all of these structures. We examine the proposed method in a question classification experiment using 5011 Japanese questions that are labeled by 150 question types. The results demonstrate that our proposed method improves the performance of question classification over that by conventional methods such as bag-of-words and their combinations.
ID:707
CLASS:1
Title: Q<sup>2</sup>C@UST: our winning solution to query classification in KDDCUP 2005
Abstract: In this paper, we describe our ensemble-search based approach, Q2C@UST (http://webprojectl.cs.ust.hk/q2c/), for the query classification task for the KDDCUP 2005. There are two aspects to the key difficulties of this problem: one is that the meaning of the queries and the semantics of the predefined categories are hard to determine. The other is that there are no training data for this classification problem. We apply a two-phase framework to tackle the above difficulties. Phase I corresponds to the training phase of machine learning research and phase II corresponds to testing phase. In phase I, two kinds of classifiers are developed as the base classifiers. One is synonym-based and the other is statistics based. Phase II consists of two stages. In the first stage, the queries are enriched such that for each query, its related Web pages together with their category information are collected through the use of search engines. In the second stage, the enriched queries are classified through the base classifiers trained in phase I. Based on the classification results obtained by the base classifiers, two ensemble classifiers based on two different strategies are proposed. The experimental results on the validation dataset help confirm our conjectures on the performance of the Q2C@UST system. In addition, the evaluation results given by the KDDCUP 2005 organizer confirm the effectiveness of our proposed approaches. The best F1 value of our two solutions is 9.6% higher than the best of all other participants' solutions. The average F1 value of our two submitted solutions is 94.4% higher than the average F1 value from all other submitted solutions.
ID:708
CLASS:1
Title: Using classification to generate text
Abstract: The IDAS natural-language generation system uses a KL-ONE type classifier to perform content determination, surface realisation, and part of text planning. Generation-by-classification allows IDAS to use a single representation and reasoning component for both domain and linguistic knowledge, which is difficult for systems based on unification or systemic generation techniques.
ID:709
CLASS:1
Title: Semantic video classification by integrating flexible mixture model with adaptive EM algorithm
Abstract: Digital video now plays an important role in medical education and healthcare, but our ability to automatic video indexing at semantic level is currently primitive. In this paper, we propose a novel framework to enable more effective semantic video classification and indexing in a specific surgery education video domain. Specifically, this framework includes: (a) A novel semantic-sensitive video content characterization and representation framework by using principal video shots and their perceptual multimodal features. (b) A novel semantic medical concept interpretation technique by using flexible mixture model. (c) A semantic video classifier by using an adaptive Expectation-Maximization (EM) algorithm for automatic parameter estimation and model selection (i.e., selecting the optimal number of mixture Gaussian components). Since more effective video content characterization framework has been integrated with an adaptive EM algorithm for video classification, our semantic video classifier has improved the classification accuracy significantly. For skin classification, its accuracy is close to 95.5%. For semantic surgical video classification, it achieves overall &asymp; 84.6% accuracy.
ID:710
CLASS:1
Title: Machine learning in DNA microarray analysis for cancer classification
Abstract: The development of microarray technology has supplied a large volume of data to many fields. In particular, it has been applied to prediction and diagnosis of cancer, so that it expectedly helps us to exactly predict and diagnose cancer. To precisely classify cancer we have to select genes related to cancer because extracted genes from microarray have many noises. In this paper, we attempt to explore many features and classifiers using three benchmark datasets to systematically evaluate the performances of the feature selection methods and machine learning classifiers. Three benchmark datasets are Leukemia cancer dataset, Colon cancer dataset and Lymphoma cancer data set. Pearson's and Spearman's correlation coefficients, Euclidean distance, cosine coefficient, information gain, mutual information and signal to noise ratio have been used for feature selection. Multi-layer perceptron, k-nearest neighbour, support vector machine and structure adaptive self-organizing map have been used for classification. Also, we have combined the classifiers to improve the performance of classification. Experimental results show that the ensemble with several basis classifiers produces the best recognition rate on the benchmark dataset.
ID:711
CLASS:1
Title: What's the code?: automatic classification of source code archives
Abstract: There are various source code archives on the World Wide Web. These archives are usually organized by application categories and programming languages. However, manually organizing source code repositories is not a trivial task since they grow rapidly and are very large (on the order of terabytes). We demonstrate machine learning methods for automatic classification of archived source code into eleven application topics and ten programming languages. For topical classification, we concentrate on C and C++ programs from the Ibiblio and the Sourceforge archives. Support vector machine (SVM) classifiers are trained on examples of a given programming language or programs in a specified category. We show that source code can be accurately and automatically classified into topical categories and can be identified to be in a specific programming language class.
ID:712
CLASS:1
Title: Using conjunction of attribute values for classification
Abstract: Advances in the efficient discovery of frequent itemsets have led to the development of a number of schemes that use frequent itemsets to aid developing accurate and efficient classifiers. These approaches use the frequent itemsets to generate a set of composite features that expand the dimensionality of the underlying dataset. In this paper, we build upon this work and (i) present a variety of schemes for composite feature selection that achieve a substantial reduction in the number of features without adversely affecting the accuracy gains, and (ii) show (both analytically and experimentally) that the composite features can lead to improved classification models even in the context of support vector machines, in which the dimensionality can automatically be expanded by the use of appropriate kernel functions.
ID:713
CLASS:1
Title: Parametric type classes
Abstract: We propose a generalization to Haskell's type classes where a class can have type parameters besides the placeholder variable.  We show that this generalization is essential to represent container classes with overloaded data constructor and selector operations.  We also show that the resulting type system has principal types and present unification and type reconstruction algorithms.
ID:714
CLASS:1
Title: Using a low-cost electroencephalograph for task classification in HCI research
Abstract: Modern brain sensing technologies provide a variety of methods for detecting specific forms of brain activity. In this paper, we present an initial step in exploring how these technologies may be used to perform task classification and applied in a relevant manner to HCI research. We describe two experiments showing successful classification between tasks using a low-cost off-the-shelf electroencephalograph (EEG) system. In the first study, we achieved a mean classification accuracy of 84.0% in subjects performing one of three cognitive tasks - rest, mental arithmetic, and mental rotation - while sitting in a controlled posture. In the second study, conducted in more ecologically valid setting for HCI research, we attained a mean classification accuracy of 92.4% using three tasks that included non-cognitive features: a relaxation task, playing a PC based game without opponents, and engaging opponents within the game. Throughout the paper, we provide lessons learned and discuss how HCI researchers may utilize these technologies in their work.
ID:715
CLASS:1
Title: On the use of linear programming for unsupervised text classification
Abstract: We propose a new algorithm for dimensionality reduction and unsupervised text classification. We use mixture models as underlying process of generating corpus and utilize a novel, L1-norm based approach introduced by Kleinberg and Sandler [19]. We show that our algorithm performs extremely well on large datasets, with peak accuracy approaching that of supervised learning based on Support Vector Machines (SVMs) with large training sets. The method is based on the same idea that underlies Latent Semantic Indexing (LSI). We find a good low-dimensional subspace of a feature space and project all documents into it. However our projection minimizes different error, and unlike LSI we build a basis, that in many cases corresponds to the actual topics. We present results of testing of our algorithm on the abstracts of arXiv - an electronic repository of scientific papers, and the 20 Newsgroup dataset - a small snapshot of 20 specific newsgroups.
ID:716
CLASS:1
Title: Survey on classes of interpretations and some of their applications
Abstract: We introduce classes of interpretations. We characterize the free and Herbrand interpretations for a class. We define the algebraic, equational, relational and first-order classes of interpretations, study their properties and relate them to the literature. We apply this study to derive complete proof systems for deducing (in some (in) equational logic) all (in) equalitions valid in a class.
ID:717
CLASS:2
Title: Teaching manufacturing systems simulation in a computer aided teaching studio
Abstract: A computer aided teaching studio provides a unique environment for teaching an introductory simulation course to manufacturing engineers. Each meeting can consist of an appropriate combination of lecture and computer-based activities, depending on the topic. Assigned exercises aid students in learning methods. Emphasis can be placed on the solution of case problems that serve as metaphors for realistic simulation projects. Since students have co-op or full time industrial experience, an industry-based project of the student's own definition serves as a course capstone. The case problem and project orientation of the course supported by the computer aided teaching studio makes examinations unnecessary. Case problems are based on a set of case studies derived from topics of interest to practicing manufacturing engineers. Cases are organized into four modules: basic systems organizations, lean manufacturing, material handling, and supply chain management. Only the simulation methods needed to support the case studies are presented.
ID:718
CLASS:2
Title: Performance interpolation for computer simulation models: a simulation-based approach
Abstract: This paper proposes a new approach for interpolation in order to obtain an efficient algorithm which will help to reduce the time and computational efforts for estimating system performance at multiple settings from a simulation run at only two or more parameter settings. The algorithm properties and the validity of the estimates were examined by applying it to a multi-component reliability model with a known analytic solution. When implementation of this algorithm becomes operational under a true multi-tasking system, it will provide helpful insights for realization of similar software on parallel computer systems.
ID:719
CLASS:2
Title: Asserting the inherent benefits of hands-on laboratory projects vs. computer simulations
Abstract: Laboratory work has long been an integral element of courses in many fields, including computer science, computer engineering, and electrical engineering. This paper examines the use of a hands-on laboratory as part of a Computer Architecture course and explores the benefits of such an experience compared to similar laboratory work utilizing computer simulations. Specifically, this paper addresses the inherent benefits of a physical laboratory by drawing from findings in the fields of learning science, cognitive science, and educational research.
ID:720
CLASS:2
Title: Simulation of the HMS 5050 computer system
Abstract: The HMS 5050 Computer System was designed to allow Computer Science students at Michigan State University access to a computer which has an interrupt system and programmable data channels. The HMS 5050 simulator, which runs on MSU's CDC 6500, enables the students to implement a major component of an operating system, and has been used successfully there since fall term 1972. In this paper we present the design goals of the HMS 5050, discuss its architecture and the structure of its simulator, and summarize classroom experience with the simulator.
ID:721
CLASS:2
Title: Reliability simulation of Spaceborne Computer Systems
Abstract: The Automatically Reconfigurable Modular Multiprocessor System (ARMMS) is being developed by the Marshall Space Flight Center to provide a Spaceborne Computer System which satisfies both the reliability and computational requirements of a wide range of Space Missions. This paper discusses the use of digital simulation in assessing the reliability and fault tolerance of proposed ARMMS designs. The reliability model employs Monte Carlo simulation techniques and has been used to simulate a variety of ARMMS architectures and system configurations. When compared to a mathematical model, the simulator is subject to fewer simplifying assumptions and also provides additional statistical measures of ARMMS fault tolerance. Results of simulation exercises are discussed and illustrate the effects of different fault tolerant computing features which include hardware error detection/correction, automatic reconfiguration in response to failure, spare system modules to replace those which have failed, and provisions for graceful degradation of the system to some minimal processing capability.
ID:722
CLASS:2
Title: Simulation of a Computer Aided Routing System (CARS)
Abstract: CARS is s system designed to provide a taxi-like service at a mass transit-like cost. It allows potential passengers to request service from their via telephone, with calls being processed by a central computer facility. The computer periodically executes a routing algorithm which assigns vehicles to passengers and communicates this routing information to the vehicles. The system is 'real time' in that it will pick up a passenger and shortly after a request will deliver him to his destination within a guaranteed time (with a minimum number of deviations for collecting and delivering other passengers). The key to CARS is the routing algorithm. Since labor and vehicular costs are a major portion of the total system cost, an algorithm is required which can provide an effective dynamic service with a minimum number of vehicles. A variety of such algorithms have been proposed, but these algorithms can not be evaluated in an analytic fashion. Hence, a comprehensive simulation model has been developed to test and compare these routing algorithms. The model facilitates the investigation of relationships between such parameters as number of vehicles and quality of service. This paper describes the methodology of the simulation model and the economic gains (in terms of the need for fewer vehicles) realized through its use. The use of an ARDS storage tube display to produce graphical output from the model is also discussed.
ID:723
CLASS:2
Title: The script processing technique in modeling/simulation and its role in the generation of animated computer graphics
Abstract: The script processing method provides the modeler with an extremely powerful technique for developing simulations of force-on-force engagements that are detailed and/or complex in nature. Through the use of the script processing technique, it is possible to simulate the actions and reactions of opposing forces (logically) in parallel on a computer with a single CPU. The cornerstone of this technique is the input script and associated processing software. Many different scenarios and tactics can be played easily due to the flexibility of the script concept. Just as a script directs players within a framework of scenes and activities for a screenplay, the simulation script directs elements in particular actions such as movement, weapon firing, et cetera. It also provides for contingencies based on the recognition of script-defined situations.The script concept lends itself as a natural driver to control the production of computer generated motion pictures. The discrete script events dictate the plot of the animated film and describe the movements and interaction between the picture elements. By algorithmic interpolation between script events, the discrete script format can be filled in to simulate the analog film medium. The Transportation Safeguards Effectiveness Model (TSEM) is a good example of the use of the script processing technique. This program will be used to demonstrate the above mentioned techniques in simulation and animated motion picture generation.The graphics can also serve to guide the creation of macro/micro terrain features for the simulation scenario. In this way, the modeler has control over the placement of obstacles to both movement and line-of-sight calculations, for example. Also, the discrete script generated event vectors can be created off-line, a movie produced and viewed, and decisions made concerning the viability of this particular script. These capabilities enhance the instruction and training of defender force configurations.
ID:724
CLASS:2
Title: Financial simulation model for the computer business
Abstract: This paper describes a model used for financial simulation of computer systems, their component cabinets, and the Univac Data Processing Division of Sperry Rand Corporation. The analyses derived from the model are part of the company's short-range (2-year period) and long-range (6-year period) planning procedures. This model, which runs on UNIVAC&reg; 1108 computer, provides the means through which both short- and long-range effects of certain types of decisions can be traced in greater detail and speed than by previous procedures. The model has been utilized for long-range revenue forecasting, for measuring effects of alternative marketing programs, and for estimating manpower requirements.
ID:725
CLASS:2
Title: A simulation course for computer science students
Abstract: A suggested topical coverage for an upper division and graduate course for computer science students in discrete simulation is presented. The components and order of coverage within each topical area are delineated. Several alternative approaches are suggested and compared based upon student reaction and feedback. Conclusions are drawn.
ID:726
CLASS:2
Title: The simulation of a fault tolerant computer system
Abstract: The properties of a fault tolerant computer system based on a hexagonal grid of processing elements (called the FMPA system) is investigated through discrete event simulation. An hypothetical test environment is used to investigate the robustness of the system, and to study the sensitivity of the system to processor and bus speeds, to the assignment of tasks to the processors, and the performance of the system after component failure. The system, at least as tested, is remarkably robust, and even seems to perform better in the face of moderate component failure. A description of the simulation program is included, as are suggestions for further research.
ID:727
CLASS:2
Title: A simulation study of cost of delays in computer systems
Abstract: The purpose of this paper is t o demonstrate the effectiveness of a partial cost analysis of computer system performance by simulation methods. The competing factors of cost of delay to Jobs and the mean system cost averaged over each job are considered in the analysis. Job characteristics are generated from a set of input means by Monte Carlo methods, and the processing of these jobs is simulated using a next-event type of model incorporating the scheduling logic and the gross hardware characteristics of the computer system. The results of such a partial cost analysis should be combined with other cost considerations to gain an overall cost picture. Rather than replacing accepted measures of system performance such as benchmark tests, the analysis may rely on these methods to provide some of the input information, such as the mean amount of central processor time requested. The characteristic feature of the type of analysis described here is the inclusion of the cost of delay to jobs as a relevant cost consideration.
ID:728
CLASS:2
Title: The application of computer simulation in a flight vehicle CAD system
Abstract: This paper describes an effort in applying computer simulation to the design of flight vehicle systems. The flight vehicle computer aided design (CAD) system is in itself a simulation of the designer's thinking processes. The system includes many modules to simulate the knowledge structure of a designer group. And it is possible to be adjusted and replenished in time just as in the case of human designers who have to do likely. It is able to input, output, store and generale information under external human manipulation, together with inter-exchanges of data between its modules within the system. The design process goes on iteratively just like in the case with human designers.Several examples of applying simulation techniques to the CAD system are then presented. They includes a flight dynamics simulation module, a strapdown inertial navigation subsystem simulation module and a simulation approach for an on-board seeking subsystem's scanning process.
ID:729
CLASS:2
Title: Object-oriented simulation of computer architectures using C++
Abstract: Object-oriented languages such as C++ allow class definitions which eliminate the need for writing special-purpose simulators in many cases. Simulating digital logic components and computer architectures is one case where the simulation model can be effectively and conveniently expressed in the programming language itself.A class library supporting: schematic organization, multi-level digital-signal representation, and implementations of a modest set of component primitives has been developed. This library supports two forms of hierarchical arrangements; first, the digital signals themselves can be expressed as vectors (as for a bus), either directly or by composition, and second, the digital components can be arranged hierarchically as modules, and the modules can be used in an identical manner in which the primitives are used.The library code described here is available from the author.
ID:730
CLASS:2
Title: Implementation of a simulated display processor for computer graphics education
Abstract: To provide student experience at the detail level of graphics output, a simulated graphics display processor was written in FORTRAN to run on a CDC 6400 computer equipped with microfilm graphics output. The simulated processor has a command set conforming to the course textbook, a memory of 4096 16-bit words and accepts directions only in absolute octal code. This last feature caused the class to write an octal code generator which accepts graphic primatives as commands.
ID:731
CLASS:2
Title: An introduction to CAPS: computer-aided programming for simulation
Abstract: This paper describes CAPS, a simulation system which enables an analyst without programming experience to quickly produce (in hours) guaranteed executable programs through the use of an interactive dialog. The result is a substantial reduction in both time and effort from the point of problem definition to the availability of model output for decision making. CAPS was developed by Dr. A. T. Clementson of the University of Birmingham and this paper draws heavily upon his work. (See Ref. 1) The user dialog with CAPS is described and examples of the ease of use are given, including an actual model.
ID:732
CLASS:2
Title: Development of credible computer system simulation models
Abstract: The Problems encountered during a simulation effort are influenced by the &lt;u&gt;objectives&lt;/u&gt; of the simulation. Verification and validation of the simulation model are two such problems which affect the credibility (and usability) of the model.A simulation methodology for &lt;u&gt;Program Design Analysis&lt;/u&gt; is described. The goal of this simulation application is to test a design &lt;u&gt;before&lt;/u&gt; it is implemented.Techniques are described which enhance the credibility of simulation models. The relationship between Program Design Analysis and the reliability of the system being developed is explored.
ID:733
CLASS:2
Title: A simulation study of data transfer between two anynchronous devices: An example of the use of GPSS in computer systems design
Abstract: This paper is a conceptual description of a GPSS simulation model employed to investigate the transfer of data from a rotating storage device to a high speed communications channel. The hardware characteristics are studied within the framework of the total system.
ID:734
CLASS:2
Title: Computer simulation of irregular shaped lesions in radiographs
Abstract: Facing an ever-increasing demand for diagnostic radiological examinations, the radiologist has turned to other means for assistance. In some cases this has been the utilization of trained technical assistants. New methods and techniques have been tested. In this learning process, simulated lesions can be useful in training of assistants. It can also be an integral part of the evaluation of their abilities to perform the required functions. Second, the study of radiographic images may be quantitatively explored as to their use in diagnosis. Previous radiographic simulations have made use of photographic and television simulations. However, greater quantitative control can be achieved by the utilization of the digital computer. This system provides a qualitative and quantitative control plus a high degree of flexibility throughout the system. Images and radiographs can be studied to determine the ability of the trained observer to perceive information as displayed in the traditional radiograph1. The purpose of this paper is to describe the system used to simulate lesions in the chest radiograms and the effect of shape on the detectability of these lesions. The general effect of contrast and lesion size must continue to be considered during the generation of the lesions. Various levels of contrast must be generated to test the Weber-Fechner law for complex images. Both sharp edges and Gaussian examples were used in determining the threshold of perception for each lesion. The background and immediate surrounding area were used to determine the contrast. The results were not unexpected. The useful lesion shape previously tested consisted of the nodular variety. This, however, is not the only lesion presented to the radiologist; therefore, this experiment concentrated on lesions developing in the bronchus and radiating outward. A series of lesions was generated at various contrast levels, shapes, and sizes. These were then shown to radiologists and their detection ability as a function of contrast and size was measured with a fixed viewing distance.
ID:735
CLASS:2
Title: APL in Computer-Assisted Instruction: Simulation of Stochastic Processes in science teaching
Abstract: The significance of APL for the application in CAI is discussed. In the frame of a basic course 'Mathematics for Physicists' a series of programs were written in APL to simulate stochastic processes: Galton board, diffusion, transport of charged particles, diffraction of light, zero-point fluctuations of a moving-coil galvanometer. These programs are described, together with the outlines of the simulation methods used.
ID:736
CLASS:2
Title: Simulated annealing and resource location in computer networks
Abstract: This paper examines the problem of locating resources such as databases, controllers, and data processors on a computer network. The integer programming problem in location variables y and interconnection variables x is solved using two simulated annealing algorithms. Pure simulated annealing for this problem has complexity O(2N2+N). In hybrid simulated annealing (HSA), for fixed y, the problem in x becomes a special case of the transporation problem; the worst case solution for HSA is O(N.2N). In parallel simulated annealing (PSA), a decomposition procedure yields knapsack problems for x when y = 1, and x = 0 when y = 0; this is solved in O(Nk2N). Numerical results show that the computation time taken by the simulated annealing algorithms are comparable to a Lagrangian relaxation procedure, and the solutions are on the average within 8 % of a lower bound.
ID:737
CLASS:3
Title: Separating access control policy, enforcement, and functionality in extensible systems
Abstract: Extensible systems, such as Java or the SPIN extensible operating system, allow for units of code, or extensions, to be added to a running system in almost arbitrary fashion. Extensions closely interact through low-latency but type-safe interfaces to form a tightly integrated system. As extensions can come from arbitrary sources, not all of whom can be trusted to conform to an organization's security policy, such structuring raises the question of how security constraints are enforced in an extensible system. In this paper, we present an access control mechanism for extensible systems to address this problem. Our access control mechanism decomposes access control into a policy-neutral enforcement manager and a security policy manager, and it is transparent to extensions in the absence of security violations. It structures the system into protection domains, enforces protection domains through access control checks, and performs auditing of system operations. The access control mechanism works by inspecting extensions for their types and operations to determine which abstractions require protection and by redirecting procedure or method invocations to inject access control operations into the system. We describe the design of this access control mechanism, present an implementation within the SPIN extensible operating systems, and provide a qualitative as well as quantitative evaluation of the mechanism.
ID:738
CLASS:3
Title: Concurrency control in a system for distributed databases (SDD-1)
Abstract: This paper presents the concurrency control strategy of SDD-1. SDD-1, a System for Distributed Databases, is a prototype distributed database system being developed by Computer Corporation of America. In SDD-1, portions of data distributed throughout a network may be replicated at multiple sites. The SDD-1 concurrency control guarantees database consistency in the face of such distribution and replication.This paper is one of a series of companion papers on SDD-1 [4, 10, 12, 21].
ID:739
CLASS:3
Title: Toward a framework for power control in cellular systems
Abstract: Efficiently sharing the spectrum resource is of paramount importance in wireless communication systems, in particular in Personal Communications where large numbers of wireless subscribers are to be served. Spectrum resource sharing involves protecting other users from excessive interference as well as making receivers more tolerant to this interference. Transmitter power control techniques fall into the first category. In this paper we describe the power control problem, discuss its major factors, objective criteria, measurable information and algorithm requirements. We attempt to put the problem in a general framework and propose an evolving knowledge-bank to share, study and compare between algorithms.
ID:740
CLASS:3
Title: Assessing merge potential of existing engine control systems into a product line
Abstract: Engine Control Systems (ECS) for automobiles have many variants for many manufactures and several markets. To improve their development efficiency, exploiting ECS commonalities and predicting their variability are mandatory. The concept of software product line engineering meets this ECS business background. However, we should carefully investigate the expected technical, economical, and organizational effects of introducing the strategy into existing products. Thereafter, a strategy will be derived systematically and realize the desired benefits.This paper reports an experience with the up-front investigation performed for Hitachi's ECS. We focus on the approach to plan the migration of the existing family of individual systems into a future product line. The approach assesses potential ways of merging software from existing variants and eventually defines a procedure for performing the migration. To get a high quality strategy, we integrate the approach of software measurement, the expertise of software architects, and reverse engineering techniques.
ID:741
CLASS:3
Title: Dual Flow Nets: Modeling the control/data-flow relation in embedded systems
Abstract: This paper addresses the interrelation between control and data flow in embedded system models through a new design representation, called Dual Flow Net (DFN). A modeling formalism with a very close-fitting control and data flow is achieved by this representation, as a consequence of enhancing its underlying Petri net structure. The work presented in this paper does not only tackle the modeling side in embedded systems design, but also the validation of embedded system models through formal methods. Various introductory examples illustrate the applicability of the DFN principles, whereas the capability of the model to with complex designs is demonstrated through the design and verification of a real-life Ethernet coprocessor.
ID:742
CLASS:3
Title: Separating data and control: support for adaptable consistency protocols in collaborative systems
Abstract: Consistency control is critical for the correct functioning of distributed collaboration support systems. A large number of consistency control methods have appeared in the literature with different design tradeoffs and usability implications. However, there has been relatively little work on how to accommodate different protocols and variations in one framework to address the dynamic needs of collaboration. In this paper, we propose a novel approach for supporting adaptable consistency protocols in collaborative systems. Our approach cleanly separates data and control, allowing consistency protocols to be dynamically attached to shared data at the object level. Protocols can be switched at run time without modifying source code.
ID:743
CLASS:3
Title: A metrics system for quantifying operational coupling in embedded computer control systems
Abstract: One central issue in system structuring and quality prediction is the interdependencies of system modules. This paper proposes a novel technique for determining the operational coupling in embedded computer control systems. It allows us to quantify dependencies between modules, formed by different kinds of relationships in a solution, and therefore promotes a more systematic approach to the reasoning about modularity. Compared to other existing coupling metrics, which are often implementation-technology specific such as confining to the inheritance and method invocation relationships in OO software, this metrics system considers both communication and synchronization and can be applied throughout system design. The metrics system has two parts. The first part supports a measurement of coupling by considering individual relationship types separately. The quantification is performed by considering the topology of connections, as well as the multiplicity, replication, frequency, and accuracy of component properties that appear in a relationship. The second part provides a methodology for combining coupling by individual relationship types into an overall coupling, where domain specific heuristics and technology constraints are used to determine the weighting.
ID:744
CLASS:3
Title: Supporting access control policies across multiple operating systems
Abstract: The evaluation of computer systems has been an important issue for many years, as evidenced by the introduction of industry evaluation guides such as the Rainbow Books and the more recent Common Criteria for IT Security Evaluation. As organizations depend on the Internet for their daily operations, the need for evaluation is even more apparent due to new security risks. It is not uncommon for large organizations to evaluate different systems, such as operating systems, to identify which would best fit their security policy. Each system would undoubtedly use different methods to represent access control policies. The security policy would therefore need to be translated into specific access control policies that each system understands, which is challenging when large and complex systems are involved. In this paper, we focus on the evaluation of operating systems. We describe Chameleos, a policy specification language that is designed to specify the access control policies of multiple operating systems. The strength of Chameleos is its flexibility to cater to many operating systems, while remaining sufficiently extensible to support the specific features of each system. We describe the design and architecture of Chameleos, and demonstrate that Chameleos can flexibly and effectively represent the access control policies of grsecurity and SELinux - two very different systems.
ID:745
CLASS:3
Title: Towards an engineering tool for implementing reusable distributed control systems
Abstract: The IEC model for distributed control systems (DCSs) was adopted for the implementation of a new generation engineering tool. However, it was found that this approach does not exploit all the benefits of the object and component technologies. In this paper, we present the enhanced 4-layer architecture that proved to be very helpful in the identification of the key abstractions required for the design of the new generation of function block based engineering tools. Despite being IEC-compliant, the proposed approach introduces a number of extensions and modifications to the IEC-model to improve the development process. The Unified Modelling Language is exploited during the requirements phase of DCSs, but the use of the FB construct is confected during the design phase.
ID:746
CLASS:3
Title: A time-sharing budget control system
Abstract: The University of Denver has had a punched-card accounting system for many years. It has grown from an IBM 402 through a 407 to a 1401 with very little change in the system. Meanwhile, on the other side of the campus a modern Computing Center has been developed, with a Burroughs B5500 including time-sharing facilities and a large disk file. During this period, the University enrollment and annual budget have grown, and the card-oriented system can no longer provide the timely information and the variety of reports and summaries needed. In the spring of 1967 it was decided to begin conversion of all of the University financial systems to the B5500. This course was chosen instead of expanding the 1401 system because of the high cost of duplication of such sophisticated equipment and because it was estimated that it would not cause a significant increase in work load on the B5500.
ID:747
CLASS:3
Title: PCC: a modeling technique for mixed control/data flow systems
Abstract: Many signal processing systems make use of event driven mechanisms-typically based on finite state machines (FSMs)-to control the operation of the computationally intensive (data flow) parts. The state machines in turn are often fueled by external inputs as well as by feedback from the signal processing portions of the system. Packet-based transmission systems are a good example for such a close interaction between data and control flow. For a smooth design flow with a maximum degree of modularity it is of crucial importance to be able to model the complete functionality of the system, containing both control and data flow, within one single design environment. While the degree of abstraction should be sufficiently high to model and simulate efficiently, the link to implementation has to be fully supported. For these reasons we developed a computational model that integrates the specification of control and data flow. It combines the notion of multirate dynamic data flow graphs with event driven process activation. Thus, it maintains the flexibility and expressive power of data flow representations while enabling designers to efficiently control these operations by incorporating control automata that may have been designed using protocol compilers or state machine tools.
ID:748
CLASS:3
Title: Integrating UML diagrams for production control systems
Abstract: This paper proposes to use SDL block diagrams, UML class diagrams, and UML behavior diagrams like collaboration diagrams, activity diagrams, and statecharts as a visual programming language. We describe a modeling approach for flexible, autonomous production agents, which are used for the decentralization of production control systems. In order to generate a (Java) implementation of a production control system from its specification, we define a precise semantics for the diagrams and we define how different (kinds of) diagrams are combined to a complete executable specification.Generally, generating code from UML behavior diagrams is not well understood. Frequently, the semantics of a UML behavior diagram depends on the topic and the aspect that is modeled and on the designer that created it. In addition, UML behavior diagrams usually model only example scenarios and do not describe all possible cases and possible exceptions.We overcome these problems by restricting the UML notation to a subset of the language that has a precise semantics. In addition, we define which kind of diagram should be used for which purpose and how the different kinds of diagrams are integrated to a consistent overall view.
ID:749
CLASS:3
Title: Security management for administration and control of corporate-wide, diverse systems
Abstract: The importance of high level management of complex information systems, extending over several heterogeneous and geographically distributed computing platforms, is rapidly increasing. The design of a comprehensive and enterprise-wide security strategy, including the efficient administration of large user groups while maintaining the access rights of tens of thousands of users, is next to impossible without support from sophisticated and powerful software toolsets. In this paper we highlight some applications of the software product Security Administration Manager (SAM). With SAM, the staff responsible for security administration has at its disposal an object-oriented tool to monitor the security management of a complex IS-environment.
ID:750
CLASS:3
Title: Communicating control knowledge to a deductive database system
Abstract: In relational or deductive database systems the user can hardly (or only in a rather implicit way) change the deduction process used for answering a query. For example, the user cannot specify that&ndash;for a given query&ndash;some rules of a deductive database are irrelevant for computing the answer of that query and hence should be disregarded, or that&ndash;while computing the answer of a query&ndash;some tuples should be preferred over other tuples. In [Sch91] we have introduced a deductive database system which offers the user a framework for specifying such control knowledge. Thereby the user can adapt the deduction process of our deductive database system to the application at hand. In this paper we will briefly recapture the architecture of this system. Then we will  present two examples, and we will show how these two examples can be solved more efficiently with our system.
ID:751
CLASS:3
Title: The automated production control documentation system: a case study in cleanroom software engineering
Abstract: A prototype software system was developed for the U.S. Naval Underwater Systems Center(NUSC) as a demonstration of the Cleanroom Software Engineering methodology. The Cleanroom method is a team approach to the incremental development of software under statistical quality control. Cleanroom's formal methods of Box Structure specification and design, functional verification, and statistical testing were used by a four-person team to develop the Automated Production Control Documentation(APCODOC) system, a relational database application. As is typical in Cleanroom developments, correctness of design and code were ensured through team reviews. Eighteen errors were found during functional verification of the design, and nineteen errors were found during walkthrough of the 1820 lines of  FOXBASE code. The software was not executed by developers prior to independent testing (i.e., there was no debugging). There were no errors in compilation, no failures during statistical certification testing, and the software was certified at the target levels of reliability and confidence. Team members attribute the ultimate error-free compilation and failure-free execution of the software to the rigor of the methodology and the intellectual control afforded by the team approach.
ID:752
CLASS:3
Title: Middleware support for transparency and user control in context-aware systems
Abstract: Pervasive computing environments require applications that reduce user distraction from other tasks. Context-awareness attempts to address this problem by making applications more adaptive and autonomous. Context-aware pervasive systems rely on information about the context and user preferences to guide their behaviour. However, context-aware applications do not always behave as users expect, and can cause users to feel loss of control over their applications. To mitigate these problems, context-aware systems must provide mechanisms to strike a suitable balance between user control and software autonomy. This has implications on the way that middleware for context-aware systems must be designed. Most current middleware solutions for context aware systems support the gathering and management of context information, while some also support the management and evaluation of user preferences; however, few middleware solutions address the issue of providing transparency (to facilitate user understanding of application actions) and user control. This paper describes the most relevant work in this area, as well as ongoing research on extending a previously developed middleware to better support transparency and control.
ID:753
CLASS:3
Title: Using predicate fields in a highly flexible industrial control system
Abstract: Predicate fields allow an object's structure to vary at runtime based on the object's state: a predicate field is present or not, depending on the values of other fields. Predicate fields and related concepts have not previously been evaluated outside a research environment. We present a case study of two industrial applications with similar requirements, one of which uses predicate fields and one of which does not. The use of predicate fields was motivated by requirements for high flexibility, by unavailability of many requirements, and by high user interface development costs. Despite an implementation of predicate fields as a library (rather than as a language extension), developers found them natural to use, and in many cases they significantly reduced development effort.
ID:754
CLASS:3
Title: An enhanced GA to improve the search process reliability in tuning of control systems
Abstract: Evolutionary Algorithms (EAs) have been largely applied to optimisation and synthesis of controllers. In spite of several successful applications and competitive solutions, the stochastic nature of EAs and the uncertainty of the results have considerably hindered their use in industrial applications. In this paper we propose a Genetic Algorithm (GA) for tuning controllers for classical first and second order plants with actuator nonlinearities. To increase the robustness of the algorithm we introduce two features: 1) genetic operators that perform directional mutations, 2) selection tournaments organized by genome vicinity. The experiment results show that the proposed GA is able to guarantee high performance and low variance in the results from different runs. The increased reliability, compared to the results from a classical GA, seems to favour particularly the application of Evolutionary Computation (EC) in tuning of control systems, where, thanks to this approach, a large search space can be searched repeatedly with high consistency in the solutions.
ID:755
CLASS:3
Title: A mini-computer based library control system
Abstract: One of the major problems encountered in any large scale programming project is the control of the software. Invariably, such large programs are divided into many smaller elements since these are easier to code, test and document. However, such a division adds new complexity to the task of Configuration Management since the many source modules, data base elements, JCL (Job Control Language) and DATA files must be controlled with the goal of maximizing program integrity and minimizing the chances of procedural errors. Furthermore, whenever any program is released either for field test or for final production, an entire change control procedure must be implemented in order to trace, install, debug and verify fixes or extensions to the original program. These maintenance activities can account for up to 80 percent of the entire programming cost in a large, multi-year project. The library control program (SYSM) presented here was developed to aid in these processes. It has facilities for capturing all elements of a program (commonly called baselining), editing any element or group of elements that have been baselined to build an updated version of the program, adding and/or deleting elements of a program, and listing the current contents of a given element or elements. SYSM is written mainly in FORTRAN, and runs on a Hewlett-Packard HP-21MX computer with two tape drives, the vendor supplied RTE-II or RTE-III operating system, and at least 16K of user available core. It can be used to control code targeted for either the HP21MX itself, or, using the optional HP/LSI-11 link program, code targeted for a Digital Equipment Corp. LSI-11 system.
ID:756
CLASS:3
Title: Adaptive storage control for page frame supply in large scale computer systems
Abstract: A real storage management algorithm called Adaptive Control of Page-frame Supply (ACPS) is described. ACPS employees three strategies: prediction of the demand for real page frames, page replacement based on the prediction, and working set control. Together, these strategies constitute the real page frame allocation method, and contribute to short and stable response times in conversational processing environments.ACPS is experimentally applied to the VOS3 operating system. Evaluation of ACPS on a real machine shows that TSS response times are not affected too strongly by king-size jobs and ACPS is successful in avoiding paging delay and thrashing. ACPS prevents extreme shortages of real storage in almost all cases.
ID:757
CLASS:4
Title: Fourth-phase digital libraries: pacing, linking, annotating and citing in multimedia collections
Abstract: We discuss the implications of the use of current multimedia collections and posit that it is possible to build what we term fourth-phase digital libraries (4PDLs). In 4PDLs users can take advantage of both the powerful audiovisual channels and the proven practices developed for media such as text. We demonstrate how various technologies can be integrated to produce a 4PDL.
ID:758
CLASS:4
Title: Using resources across educational digital libraries
Abstract: This article reports on analyses of usage and design activities by users of the Instructional Architect (IA), an end-user authoring tool designed to support easy access to and use of NSDL and online resources in creating instructional materials. This analysis provides a unique window for understanding how users use resources from multiple digital libraries, and the related issues of resource granularity and context dependence. Analyses suggest that active use and design with online resources is relegated to 'early adopters'. These users designed significantly more instructional projects with more content and more online resources than less-active users. Users in general appeared to value digital library resources, and at a smaller granularity than cataloged.
ID:759
CLASS:4
Title: Addressing the challenge of visual information access from digital image and video libraries
Abstract: While it would seem that digital video libraries should benefit from access mechanisms directed to their visual contents, years of TREC Video Retrieval Evaluation (TRECVID) research have shown that text search against transcript narrative text provides almost all the retrieval capability, even with visually oriented generic topics. A within-subjects study involving 24 novice participants on TRECVID 2004 tasks again confirms this result. The study shows that satisfaction is greater and performance is significantly better on specific and generic information retrieval tasks from news broadcasts when transcripts are available for search. Additional runs with 7 expert users reveal different novice and expert interaction patterns with the video library interface, helping explain the novices' lack of success with image search and visual feature browsing for visual information needs. Analysis of TRECVID visual features well suited for particular tasks provides additional insights into the role of automated feature classification for digital image and video libraries.
ID:760
CLASS:4
Title: Enabling interoperability for autonomous digital libraries: an API to citeseer services
Abstract: We introduce CiteSeer-API, a public API to CiteSeer-like services CiteSeer-API is SOAP/WSDL based and allows for easy programatical access to all the specific functionalities offered by CiteSeer services, including full text search of documents and citations and citation--based document discovery. CiteSeer-API is currently showcased on SMEALSearch [10]. a digital library search engine for business academic publications.
ID:761
CLASS:4
Title: Implementing digital libraries (panel session)
Abstract: This panel will address some of the practical issues of implementing digital libraries. Everyone seems to agree that digital libraries are in their infancy. Many of us watch in amazement as new developments occur. In the year 2000 building a production digital library means analyzing tradeoffs between stability, innovation, and costs/benefits. In this panel we will address some of the more interesting issues of digital library implementation.One of the critical challenges is the economics of digital libraries. Institutions are forming consortia out of necessity and this raises issues of trust, cooperation and commitment. In order for institutions to deliver web-based resources effectively sophisticated cross-organizational access management tools are needed to  authenticate and authorize.Institutions are developing new tools and exporting them from research departments into libraries. How well does this collaboration work?The above issues are only a sampling of the challenges this panel will explore.
ID:762
CLASS:4
Title: Contextualizing the information space in federated digital libraries
Abstract: Rapid growth in the volume of documents, their diversity, and terminological variations render federated digital libraries increasingly difficult to manage. Suitable abstraction mechanisms are required to construct meaningful and scalable document clusters, forming a cross-digital library information space for browsing and semantic searching. This paper addresses the above issues, proposes a distributed semantic framework that achieves a logical partitioning of the information space according to topic areas, and provides facilities to contextualize and landscape the available document sets in subject-specific categories.
ID:763
CLASS:4
Title: Communication channels and the adoption of digital libraries for electronic theses and dissertations
Abstract: This research used diffusion of innovation theory to explore factors that influence adoption of digital libraries for electronic theses and dissertations (ETD-DL) among members of the Networked Digital Library of Theses and Dissertations (NDLTD) Communication channels were categorized as being either interpersonal or mediated, and the perceived importance of these channels was assessed both within and between organizations. A web-based survey collected data from the 133 universities in 26 countries that were NDLTD members in December 2002. Respondents were members of the university's 'ETD Committee' and represented academic administrators, faculty, librarians, and computer systems specialists. Surveys were received from 95 respondents representing 65 universities in 14 countries. Twenty-one of these universities were outside the United States, and represented countries with a wide range of economic development.Results provide insights into university attitudes towards distributed digital libraries. For example, results suggest that interpersonal channels of communication about digital library adoption are more important than mediated channels within the organization. However, mediated channels of communication are more important for those universities that have decided to adopt the ETD-DL but have not yet implemented the DL. There were also significant differences in the importance attributed to these channels by individuals in different jobs. The results suggest strategies that could encourage development of digital libraries within other social systems. The study also illustrates the importance of planning for the human factor in digital library management. Carefully constructed strategies that address all the parties involved in DL adoption and that account for differences in communication style will more readily facilitate successful adoption of distributed digital libraries.
ID:764
CLASS:4
Title: Small screen access to digital libraries
Abstract: This paper looks at the possibilities of taking existing digital library technology and using it for educating those who do not normally have access to the Internet. We have built a system which allows WAP devices to access an HTML based digital libary. Whilst building such a system is technically possible, our work has shown that there are a wide range of usability issues which need to be tackled. We investigate these problems, suggest improvements and outline where future research needs to take place.
ID:765
CLASS:4
Title: Building personal digital libraries from network sources
Abstract: Our work is focused on personal digital libraries and personal information spaces. In this context, a personal digital library (PDL) is a collection of multimedia objects (text, graphics and audio), created by an individual and/or drawn from resources elsewhere on the Internet. The benefits of this approach include a reduction in user disorientation and an increased likelihood that the user will find relevant material since the structure of the information space is defined and customized entirely by the user. This is achieved through metadata and cataloging facilities which allow for the creation and maintenance of the personal digital library.
ID:766
CLASS:4
Title: Generating fuzzy semantic metadata describing spatial relations from images using the R-histogram
Abstract: Automatic generation of semantic metadata describing spatial relations is highly desirable for image digital libraries Relative spatial relations between objects in an image convey important information about the image. Because the perception of spatial relations is subjective, we propose a novel framework for automatic metadata generation based on fuzzy k-NN classification that generates fuzzy semantic metadata describing spatial relations between objects in an image. For each pair of objects of interest, the corresponding R-Histogram is computed and used as input for a set of fuzzy k--NN classifiers. The R-Histogram is a quantitative representation of spatial relations between two objects The outputs of the classifiers are soft class labels for each of the following eight spatial relations: 1) LEFT OF, 2) RIGHT OF, 3) ABOVE, 4) BELOW, 5) NEAR, 6) FAR, 7) INSIDE, 8) OUTSIDE Because the classifier-training stage involves annotating the training images manually, it is desirable to use as few training images as possible. To address this issue, we applied existing prototype selection techniques and also devised two new extensions. We evaluated the performance of different fuzzy k-NN algorithms and prototype selection algorithms empirically on both synthetic and real images. Preliminary experimental results show that our system is able to obtain good annotation accuracy (92%--98% on synthetic images and 82%--93% on real images) using only a small training set (4--5 images).
ID:767
CLASS:4
Title: HCI and CSCW in the context of digital libraries
Abstract: We describe work conducted to explore issues related to human-computer interaction (HCI) and computer-supported cooperative work (CSCW) in the development of digital libraries. In this context, we have designed and prototyped environments that facilitate collaboration among distributed users while still responding to their specific individual needs and preferences. The results of the work include operational interfaces for large information spaces and collaborative environments for an actual digital library which is part of a large federation of digital collections.
ID:768
CLASS:4
Title: Effective and scalable solutions for mixed and split citation problems in digital libraries
Abstract: In this paper, we consider two important problems that commonly occur in bibliographic digital libraries, which seriously degrade their data qualities: Mixed Citation (MC) problem (i.e., citations of different scholars with their names being homonyms are mixed together) and Split Citation (SC) problem (i.e., citations of the same author appear under different name variants). In particular, we investigate an effective yet scalable solution since citations in such digital libraries tend to be large-scale. After formally defining the problems and accompanying challenges, we present an effective solution that is based on the state-of-the-art sampling-based approximate join algorithm. Our claim is verified through preliminary experimental results.
ID:769
CLASS:4
Title: PDLib: personal digital libraries with universal access
Abstract: We propose a universally available personal digital library system. It is "personal" in the sense that each user is provided with a general purpose document repository (i.e. a personal digital library). It is "universally available" in the sense that it allows the user to access her/his personal personal digital library from most computing devices connected to the Internet, including mobile phones, PDAs and laptops, therefore granting access "from anyplace at anytime."
ID:770
CLASS:4
Title: Visual querying for digital libraries using dynamic hypertext aggregates: the DH31CI prototype
Abstract: In the last few years, digital libraries have received a lot of attention given a maturation of recent technological achievements, particularly in the case of wide-spread computer networks, high-capacity storage media and more powerful personal computers [I]. Nevertheless, user needs must often be expressed through cryptic command languages that are still difficult to learn and to master. Documents relevant to the query are usually presented as a fiat list of titles that can be called by the user.
ID:771
CLASS:4
Title: XML semantics and digital libraries
Abstract: The lack of a standard formalism for expressing the semantics of an XML vocabulary is a major obstacle to the development of high-function interoperable digital libraries. XML document type definitions (DTDs) provide a mechanism for specifying the syntax of an XML vocabulary, but there is no comparable mechanism for specifying the semantics of that vocabulary --- where semantics simply means the basic facts and relationships represented by the occurrence of XML constructs. A substantial loss of functionality and interoperability in digital libraries results from not having a common machine-readable formalism for expressing these relationships for the XML vocabularies currently being used to encode content. Recently a number of projects and standards have begun taking up related topics. We describe the problem and our own project.
ID:772
CLASS:4
Title: Windowing time in digital libraries
Abstract: This paper discusses the specification, organization, and utility of time references identified in digital library materials, emphasizing how to treat date references that cannot be resolved to a single day. The HistoryMakers oral history archive is used to illustrate the concept of windowing such time in digital library interfaces.
ID:773
CLASS:4
Title: Collaborative visual interfaces to digital libraries
Abstract: This paper argues for the design of collaborative visual interfaces to digital libraries that support social navigation. As an illustrative example we present work in progress on the design of a three-dimensional document space for a scholarly community - namely faculty, staff, and students at the School of Library and Information Science, Indiana University.
ID:774
CLASS:4
Title: Developing digital libraries education and training programs
Abstract: Gaining education and training in the field of Digital Libraries is a difficult prospect. Relevant courses and experiences are usually scattered among different programs and institutions. Often, course content does not include the necessary mix of the theoretical and practical treatment. The workshop is aimed at developers, researchers, educators, and administrators interested in educational programs for training next generation of digital library professionals - both information technologists and librarians.
ID:775
CLASS:4
Title: Image recognition for digital libraries
Abstract: The interpretation of natural scenes, generally so obvious and effortless for humans, still remains a challenge in computer vision. To allow the search of image-based documents in digital libraries, we propose to design classifiers able to annotate images with keywords. First, we propose an image representation appropriate for scene description. Images are segmented into regions, and then indexed according to the presence of given region types. Second, we propound a classification scheme designed to separate images in the descriptor space. This is achieved by combining feature selection and kernel-method-based classification
ID:776
CLASS:4
Title: Harvesting translingual vocabulary mappings for multilingual digital libraries
Abstract: This paper presents a method of information harvesting and consolidation to support the multilingual information requirements for cross-language information retrieval within digital library systems. We describe a way to create both customized bilingual dictionaries and multilingual query mappings from a source language to many target languages. We will describe a multilingual conceptual mapping resource with broad coverage (over 100 written languages can be supported) that is truly multilingual as opposed to bilingual parings usually derived from machine translation. This resource is derived from the 10+ million title online library catalog of the University of California. It is created statistically via maximum likelihood associations from word and phrases in book titles of many languages to human assigned subject headings in English. The 150,000 subject headings can form interlingua mappings between pairs of languages or from one language to several languages. While our current demonstration prototype maps between ten languages (English, Arabic, Chinese, French, German, Italian, Japanese, Portuguese, Russian, Spanish), extensions to additional languages are straightforward. We also describe how this resource is being expanded for languages where linguistic coverage is limited in our initial database, by automatically harvesting new information from international online library catalogs using the Z39.50 networked library search protocol.
ID:777
CLASS:5
Title: Modeling tuberculosis in areas of high HIV prevalence
Abstract: We describe a discrete event simulation model of tuberculosis (TB) and HIV disease, parameterized to describe the dual epidemics in Harare, Zimbabwe. TB and HIV are the leading causes of death from infectious disease among adults worldwide and the number of TB cases has risen significantly since the start of the HIV epidemic, particularly in Sub-Saharan Africa, where the HIV epidemic is most severe. There is a need to devise new strategies for TB control in countries with a high prevalence of HIV. This model has been designed to investigate strategies for reducing TB transmission by more efficient TB case detection. The model structure and its validation are discussed.
ID:778
CLASS:5
Title: Measures, models and measurements for time-shared computer utilities
Abstract: Recent literature1-6has summarized many of the characteristics of time-shared systems which have been or are being built for experimental or commercial application. Fortunately system designers are not waiting for a formal theory before experimenting. Unfortunately some of the results are so diverse in effectiveness that greater emphasis on analysis must be achieved. If predictability cannot lower the risks associated with the tremendous investments required to implement information processing utilities, progress in this field may be markedly decreased. The present paper presents a characterization of the time-sharing system environment, a set of measures associated with the system, an integrated summary of models and a discussion of measurements. In the final section new proposals for systems, measures, models and measurements are considered.
ID:779
CLASS:5
Title: A small college response to the mathematics recommendations of curriculum 2001
Abstract: Recent curricula recommendations by the ACM/IEEE Curriculum 2001 [3] have focused new attention to the role of mathematics in computer science programs. The challenge presented to small colleges is to address these recommendations while working with the limited resources typical of our institutions. In this paper we describe recent efforts to update our mathematics requirements for our computer science major and the ripple effect that lead to changes both in our discrete mathematics course offerings and in the course requirements for our mathematical and computational degree programs.
ID:780
CLASS:5
Title: Cellular-functional modeling of heterogeneous objects
Abstract: The paper presents an approach to modeling heterogeneous objects as multidimensional point sets with multiple attributes (hypervolumes). A theoretical framework is based on a hybrid model of hypervolumes combining a cellular representation and a constructive representation using real-valued functions. This model allows for independent but unifying representation of geometry and attributes, and makes it possible to represent dimensionally non-homogeneous entities and their cellular decompositions. Hypervolume model components such as objects, operations and relations are introduced and outlined. The framework's inherent multidimensionality allowing, in particular, to deal naturally with time dependence promises to model complex dynamic objects composed of different materials with constructive building of their geometry and attributes. Attributes given at each point can represent properties of arbitrary nature (material, photometric, physical, statistical, etc.). To demonstrate a particular application of the proposed framework, we present an example of multimaterial modeling - a multilayer geological structure with cavities and wells. Another example illustrating the treatment of attributes other than material distributions is concerned with time-dependent adaptive mesh generation where function representation is used to describe object geometry and density of elements in the cellular model of the mesh. The examples have been implemented by using a specialized modeling language and software tools being developed by the authors.
ID:781
CLASS:5
Title: Verification, validation, and accreditation: verification, validation, and accreditation of simulation models
Abstract: This paper discusses verification, validation, and accreditation of simulation models. The different approaches to deciding model validity are presented; how model verification and validation relate to the model development process are discussed; various validation techniques are defined; conceptual model validity, model verification, operational validity, and data validity are described; ways to document results are given; a recommended procedure is presented; and accreditation is briefly discussed.
ID:782
CLASS:5
Title: Documentation for a model: a hierarchical approach
Abstract: A set of documents and their organization according to functional requirements in order to produce information that will facilitate the use of models are described. The authors discuss the role of models in the policy process and of documentation in the assessment of such models.
ID:783
CLASS:5
Title: Connectivity in wireless ad-hoc networks with a log-normal radio model
Abstract: In this paper we study connectivity in wireless ad-hoc networks by modeling the network as an undirected geometric random graph. The novel aspect in our study is that for finding the link probability between nodes we use a radio model that takes into account statistical variations of the radio signal power around its mean value. We show that these variations, that are unavoidably caused by the obstructions and irregularities in the surroundings of the transmitting and the receiving antennas, have two distinct effects on the network. Firstly, they reduce the amount of correlation between links causing the geometric random graph tend to behave like a random graph with uncorrelated links. Secondly, these variations increase the probability of long links, which enhances the probability of connectivity for the network.Another new result in our paper is an equation found for the calculation of the giant component size in wireless ad-hoc networks, that takes into account the level of radio signal power variations. With simulations we show that for the planning and design of wireless ad-hoc networks or sensor networks the giant component size is a good measure for "connectivity".
ID:784
CLASS:5
Title: Development and utilization of a space station mission simulation model
Abstract: Over the past few years the growing complexity and costs of systems required to support space research and technology have generated a need for improving overall program management and concept evaluation techniques. Some of the more recent areas of study in space research have been devoted to the conceptual design of orbiting, manned space stations capable fulfilling basic, space related, research objectives. These system designs must reflect operational requirements for maximum utilization of available resources and identify important parameters for consideration in future plans.
ID:785
CLASS:5
Title: Workflow performance and scalability analysis using the layered queuing modeling methodology
Abstract: The design and implementation of a workflow management system is typically a large and complex task. Decisions need to be made about the hardware and software platforms, the data structures, the algorithms, and network interconnection of various modules utilized by various users and administrators. These decisions are further complicated by requirements such as flexibility, robustness, modifiability, availability, performance, and usability. As the size of workflow systems increases, organizations are finding that the standard server/client architectures, and off-the-shelf solutions are not adequate. We can further see that in the farther future, very large-scale workflow systems (VLSW) will become more complex, and more prevalent. Thus, one further requirement is an emphasis of this document: scalability. For the purposes of our scalable workflow investigations, we describe a framework, a taxonomy, a model, and a methodology to investigate the performance of various workflow architectures as the size of the system (number of workcases) grows very large.First, this paper presents a novel workflow architectural framework and taxonomy. In fact, most current workflow architectures fall into only one of the many categories of this taxonomy: the centralized server/client category. The paper next explains a performance analysis methodology useful for exploring this taxonomy. The methodology deploys a layered queuing model, and performs mathematical analysis on this model using a modified MOL (method of layers) combined with a linearization algorithm. Finally, the paper utilizes this methodology to compare and contrast the various architectural categories, providing interesting results about performance as the number of workcases increases. Our analytic results suggest that (a) for VLSW performance determination, software architecture is as important as hardware architecture, and (b) alternatives to the client server architecture provide significantly better scalability.
ID:786
CLASS:5
Title: Mathematical manipulatives as designed artifacts: the cognitive, affective, and technological dimensions
Abstract: Mathematical manipulatives---tangible objects with a pedagogical purpose---have become popular tools in mathematics education. But typically, the notion of a "manipulative" carries with it a number of additional assumptions: that these objects are designed for elementary (as opposed to advanced) mathematics instruction; that they have little in the way of emotional meaning for their users; and that they are relatively simple, "low-tech" objects. In this paper we challenge these assumptions. Drawing on our experiences in two related projects in educational computing, we suggest that manipulatives may be designed for advanced mathematical topics; that they may offer creative (and thus affectively important) opportunities for students; and that they may be designed in ways that accompany or incorporate computational media.
ID:787
CLASS:5
Title: AUTOMAST: automatic mathematical analysis and symbolic translation
Abstract: A procedure for numerically solving systems of ordinary differential equations is shown to also generate symbolic solutions. The procedure is based on a finite Taylor series expansion that includes an estimate of the error in the final result. A computer program is described that reads in a system of such equations and then generates the expansions for all of the dependent variables. The expansions are determined symbolically, hence any non-numeric parameters in the original equations are carried automatically into the final expansions. Thus the exact influence of any parameters on the problem solution can be easily displayed.
ID:788
CLASS:5
Title: Computer based development of large scale ecological models problems and prospects
Abstract: Modelling an ecosystem requires knowledge of the system, obtained with experiments, and its abstraction within a mathematical framework. Systems methods can be used effectively in the latter phase of the modelling process. Indeed, when coupled with experimental work, these mathematical methods can help in the development of an ecologically realistic mathematical model. These models formalize hypotheses proposed to describe the ecosystem structure and explain its behavior. For example, a forest is not only made of trees, but also of shrubs, fungi and other flora. Animals contribute to modify and influence the forest, and chemical nutrients cycle between flora, fauna and soil. A mathematical model of this ecosystem would try to conceptualize relationships among these domains. If this model is set in dynamical terms, e.g., a set of differential equations, then the model behavior should be similar to the forest behavior.
ID:789
CLASS:5
Title: Mathematics for the exploration of requirements
Abstract: The exploration of requirements is as complex as it is important in ensuring a successful software production and software life cycle. Increasingly, tool-support is available for aiding such explorations. We use a toy example and a case study of modelling and analysing some requirements of the global assembly cache of .NET to illustrate the opportunities and challenges that mathematically founded exploration of requirements brings to the computer science and software engineering curricula.
ID:790
CLASS:5
Title: Discrete differential forms for computational modeling
Abstract: The emergence of computers as an essential tool in scientific research has shaken the very foundations of differential modeling. Indeed, the deeply-rooted abstraction of smoothness, or differentiability, seems to inherently clash with a computer's ability of storing only finite sets of numbers. While there has been a series of computational techniques that proposed discretizations of differential equations, the geometric structures they are supposed to simulate are often lost in the process.
ID:791
CLASS:5
Title: Topological framework for part families
Abstract: One of the fundamental unsolved problems in geometric design of mechanical solids has been the lack of a proper notion of family or class. Numerous heuristic and often incompatible definitions are used throughout the CAD industry, and it is usually not clear how to generate members of a family or, to decide if a given object belongs to an assumed family. Until these difficulties are resolved, no guarantees or standards for parametric modeling are possible, and all efforts to allow exchange of parametric representations between different CAD systems are likely to remain futile. Standardizing on a particular definition may be difficult, because parametric families depend intrinsically not only on shape but also on its representation. We classify families into parameter-space and representation-space, and show that both types are representation-induced families. We propose a formal framework for families based on the notion of topological categories. Every parametric family is defined by the representation-induced topological space of solids that are closed under the continuous maps in the assumed topology. We illustrate several well defined families and formally define a special but important case of CSG-induced family that generalizes to the more general case of feature-induced families.
ID:792
CLASS:5
Title: The role of mathematics in the computer science curriculum
Abstract: There has been much debate in the past few years about the appropriate mathematics requirements for an undergraduate computer science major. The discussion has focused primarily on two issues: (1) the underlying mathematical content of computer science courses and (2) the content of mathematics courses which would serve as appropriate cognate requirements for computer science major programs. While this discussion has been helpful, it has been too narrowly focused--it has not started from an understanding of the relationship between the disciplines of mathematics and computer science, but rather has sought to identify mathematical prerequisites that computer science majors need in order to take existing computer science courses. This paper is a small step in seeking to apply an understanding of the relationship between the disciplines of mathematics and computer science to the undergraduate computer science curriculum.
ID:793
CLASS:5
Title: Attribute based interfaces for geometric modeling
Abstract: Computer Gaming has some unique modeling needs not anticipated with the traditional modeling techniques that evolved in CAD/CAM or animation. Real-time display, economical data base, novice user interaction, collaborative design, cost effective animations and tight polygon count are examples of modeling needs that are desirable in all graphics environments, but they gain added emphasis in gaming. Mathematical and topological specifications, however, often impede the preceding facilities. B-spine surface modeling (NURBS) is the current convention. It requires a rectangular arrangement of surface patches that create large databases and costly evaluations while imposing a heavy burden on the uninitiated designer because they do not always fit the natural configuration indicated by the object. We describe a new design method, FreeDimension, which enables freely designable topologies by incorporating multisided surface patches and curve T-junctions. It fosters design by allowing one to focus on the feature curves of the object, while eliminating curves that only exist due to the underlying mathematics. We also describe the efficiency of FreeDimension in computation and storage, which makes this method attractive for interactive and collaborative applications.
ID:794
CLASS:5
Title: TCP symbiosis: congestion control mechanisms of TCP based on Lotka-Volterra competition model
Abstract: In this paper, we propose TCP Symbiosis, which has a robust, self-adaptive and scalable congestion control mechanism for TCP. Our method is quite different from existing approaches. We change the window size of a TCP connection in response to information of the physical and available bandwidths of the end-to-end network path. The bandwidth information is obtained by an inline network measurement technique we have previously developed. Using the bandwidth information we can resolve the inherent problems in existing AIMD/MIMD-based algorithms such as periodic packet loss and unfairness caused by the difference in RTT. We borrow algorithms from biophysics to update the window size: the logistic growth model and the Lotka-Volterra competition model. This is because these models describe changes in the population size of a species that depends on the living environment. The population of a species can be viewed as the window size of a TCP connection and the living environment as the bandwidth of the bottleneck link. The greatest advantage of using these models is that we can refer to previous discussions and results for various characteristics of the mathematical models, including scalability, convergence, fairness and stability in these models. Through mathematical analysis and extensive simulation experiments, we compare the proposed mechanism with traditional TCP Reno, HighSpeed TCP, Scalable TCP and FAST TCP, and exhibit its effectiveness in terms of scalability to the network bandwidth and delay, convergence time, fairness among competing connections, and stability.
ID:795
CLASS:5
Title: An outline of a mathematical model for the definition and manipulation of data
Abstract: This paper presents a constructive model for data which suggests some precise definitions of notions like type, name, constants, declarations etc. The model is based on an old idea of looking at data as a mapping from a set of names to a set of values. We will study two different kinds of assignments and also show how the model can be used to give some hints for new data structuring methods. In particular we have given a definition of a sequence and we have shown how this data structure can be used to give constructive definitions of structures like stacks, files and queues. We have also studied tree traversals i.e. the correspondence between various trees and sequences.
ID:796
CLASS:5
Title: Analysis of integration models for service composition
Abstract: This paper studies service integration infrastructures that support the execution of megaservices --- large-scale applications that are composed of autonomous service modules. Integration infrastructures are classified according to their control-flow and data-flow structures. We analyze the effects of data-flows on the performances of the centralized and distributed data-flow models. A mathematical model is built to compare the performances of megaservices. Particularly, aggregated cost and response time metrics are defined and evaluated. We arrive at the conclusion that the distributed data-flow model is in general superior in performance. We also identify the key system parameters as well as system bottlenecks. The analysis provides recommendations for a few techniques to build high-performance and scalable service integration infrastructures based on the distribution of data-flows.
ID:797
CLASS:6
Title: HO-RSVP: a protocol providing QoS support for seamless handover between wireless networks
Abstract: RSVP is basically designed for fixed networks and does not provide mobility support. In order to provide QoS support for mobility in a wireless environment, we present a new resource reservation protocol for seamless handover. HO-RSVP integrates with Mobile IPv4 to maintain a continuous QoS guarantee between two mobile nodes. In the protocol, the resource reservation remains unaffected in the unchanged segments of the signal path in case of mobility. It is only necessary to make a new reservation in the changed segments. The protocol can also prevent the mobile node from moving to a performance-degraded access network through resource pre-reservation before handover. When the receiver is mobile, resource reservation can be refreshed in the data path for the sender after handover. When the sender is mobile, a procedure is initiated to tear down the old reservation after handover
ID:798
CLASS:6
Title: A real options framework to value network, protocol, and service architecture
Abstract: This paper proposes a real options framework for evaluating architectural choices and the economic value of these alternative choices of networks, protocols, and services. Using proven financial techniques of real options, our model explores the value of distributed architecture compared to the benefits of centralized control. Voice and email case studies that agree with our theory and model are presented. We apply our model to illustrate the value of end-to-end structure, why SIP-based VoIP is winning, and the value of open garden service business models allowing third parties to provide network services/applications. This work illustrates the potential of real options to help quantify the economic value of network, protocol, and service architectures.
ID:799
CLASS:6
Title: Towards provable security for ad hoc routing protocols
Abstract: We propose a formal framework for the security analysis of on-demand source routing protocols for wireless ad hoc networks. Our approach is based on the well-known simulation paradigm that has been proposed to prove the security of cryptographic protocols. Our main contribution is the application of the simulation-based approach in the context of ad hoc routing. This involves a precise definition of a real-world model, which describes the real operation of the protocol, and an ideal-world model, which captures what the protocol wants to achieve in terms of security. Both models take into account the peculiarities of wireless communications and ad hoc routing. Then, we give a formal definition of routing security in terms of indistinguishability of the two models from the point of view of honest parties. We demonstrate the usefulness of our approach by analyzing two "secure" ad hoc routing protocols, SRP and Ariadne. This analysis leads to the discovery of as yet unknown attacks against both protocols. Finally, we propose a new ad hoc routing protocol and prove it to be secure in our model.
ID:800
CLASS:6
Title: A framework of secure location service for position-based ad hoc routing
Abstract: In large and dense mobile ad hoc networks, position-based routing protocols can offer significant performance improvement over topology-based routing protocols by using location information to make forwarding decisions. However, so far security issues in position-based routing protocols has not been widely considered. In this paper, we identify several security problems of position-based routing protocols in mobile ad hoc networks. To avoid these problems, we propose the Secure Grid Location Service (SGLS), which enhances the original GLS protocol with secure features. Countermeasures employed by SGLS against feasible attacks use both a broadcast authentication protocol and a reputation system for monitoring. Simulation results showed that SGLS can detect and isolate message dropping attackers efficiently.
ID:801
CLASS:6
Title: IFTP-W: a TCP-friendly protocol for multimedia applications over wireless networks
Abstract: Recent growth in the use of multimedia applications on wireless networks is calling for the development of a protocol that is both TCP-friendly and capable of conforming to the constraints of wireless networks. This paper presents IFTP-W, an end-to-end congestion control protocol we designed to meet both requirements. IFTP-W is a TCP-friendly protocol for media streams that allows for applications to choose a section of a packet to be verified by a checksum, with the remaining portion deemed error-insensitive and not checked for corrupted bits. One corrupted bit in a video or audio stream may cause a discolored pixel or distorted millisecond of audio; however, in many codecs, receiving the partially damaged packet results in better overall performance than dropping the packet. IFTP-W allows a greater percentage of packets to be transmitted, resulting in a higher goodput and throughput and hence improved performance over wireless networks suffering high bit error rates.
ID:802
CLASS:6
Title: A study of protocol analysis for packet switched network
Abstract: Communication failures may occur because of residual hardware or software implementation flaws, operator errors, transmission noises and transient or permanent machine failures. For packet switched network operation, some means are necessary to detect the errors and to analyze the phenomena to identify the causes of the errors, since, generally, it is almost impossible to predict errors or to implement systems without errors or failures. This paper describes general aspects of communication protocol analysis, protocol analysis technologies for CCITT X.25 and the protocol analyzer to be used in DDX packet switched network operation.
ID:803
CLASS:6
Title: An adaptive wireless local area network protocol that improves throughput via adaptive control of direct sequence spread spectrum parameters
Abstract: We develop and analyze an elegant, opportunistic medium access control (MAC) protocol based on the proposed MAC standard for wireless local area networks (WLAN)---IEEE 802.11. Our adaptation of 802.11 is called CATER (Code Adapts To Enhance Reliability) and allows communicating stations to reconfigure their transceivers to use a longer pseudo-noise (PN) code when retransmissions are unsuccessful over a degraded channel. Results show that our protocol continues to function, permitting up to 14 percent normalized aggregate throughput, at times when IEEE 802.11 fails. In addition, throughput experiences only a small decrease due to protocol overhead during periods when stations experience a good channel with few bit errors.
ID:804
CLASS:6
Title: Knowledge-based monitoring and control: an approach to understanding behavior of TCP/IP network protocols
Abstract: Complex, dynamic, and evolving network environments present difficult challenges for monitoring and control. We have encoded some of the expertise of human networking experts into a knowledge-based system that uses production rules and opportunistic scheduling, and have been using this system to better understand the behavior of the TCP/IP protocols and the applications that use them. Novel aspects of this research include understanding how to encode knowledge from this domain, and how to reason efficiently on real networking problems. The prototype system&mdash;KNOBS/TCP&mdash;can correctly identify many common problems that network experts would normally be required to find (e.g., improper or inefficient retransmission and ACK strategies, silly-window-syndrome, a subset of reset and connection closing anomalies, and basic problems with auxiliary protocols such as address resolution, and routing). Preliminary measurements indicate that the resulting system is reasonably fast and will scale well. In some important test cases, speedup of two orders of magnitude over analogous manual and partially automated techniques has been observed.
ID:805
CLASS:6
Title: Weak duplicate address detection in mobile ad hoc networks
Abstract: Auto-configuration is a desirable goal in implementing mobile ad hoc networks. Specifically, automated dynamic assignment (without manual intervention) of IP addresses is desirable. In traditional networks, such dynamic address assignment is often performed using the Dynamic Host Configuration Protocol (DHCP). Implementing DHCP, however, requires access to a DHCP server. In mobile ad hoc networks, it is difficult to guarantee access to a DHCP server, since ad hoc networks can become partitioned due to host mobility. Therefore, alternative mechanisms must be employed. One plausible approach is to allow a node to pick a tentative address randomly (or using some locally available information), and then use a "duplicate address detection" (DAD) procedure to detect duplicate addresses. The previously proposed DAD procedures make use of timeouts and do not always perform correctly in presence of partitions. In networks where message delays cannot be bounded, use of timeouts can lead to unreliability. Therefore, we propose an alternative approach (which can be used in conjunction with previously proposed schemes). We refer to the proposed approach as "weak" duplicate address detection. The goal of weak DAD is to prevent a packet from being routed to the "wrong" destination node, even if two nodes in the network happen to have chosen the same IP address. We also propose an enhanced version of the weak DAD scheme, which removes a potential shortcoming of the weak DAD approach.
ID:806
CLASS:6
Title: Scalable multicast protocol in IP-based mobile networks
Abstract: In this paper, we present an alternative design, RBMoM (Range-Based Mobile Multicast), for efficiently supporting multicast for mobile hosts on the Internet. The current version of Mobile IP proposes two approaches to support mobile multicast, which are remote subscription and bi-directional tunneling. The former provides the shortest routes for delivery of multicast datagrams to mobile hosts; the latter hides host mobility from all other members of the group (therefore, no any overhead in the multicast tree maintenance). RBMoM intends to trade off between the shortest delivery path and the frequency of the multicast tree reconfiguration by controlling the service range of the multicast home agent (MHA). Actually, we will find that remote subscription and bi-directional tunneling are the extremes of RBMoM. From the point of view of the MHA and the service range concepts, RBMoM is a generalization of both approaches and a unifying mobile multicast approach. The simulation results show that RBMoM can adapt to the fluctuation of both host movement and the number of mobile group members, and outperforms the current two Mobile IP multicast solutions.
ID:807
CLASS:6
Title: An adaptive-transmission protocol for frequency-hop wireless communication networks
Abstract: An energy-efficient adaptive-transmission protocol for mobile frequency-hop spread-spectrum wireless communication networks is described and evaluated. The purpose of the protocol is to permit each of the mobile terminals to adjust its transmitter power and code rate to match the characteristics of the time-varying communication links in the network. The proposed adaptive-transmission protocol bases its choice of transmission parameters on a very simple form of side information that is easy to obtain in a FH communication receiver. The performance of the adaptive-transmission protocol is evaluated for networks in which each communication link may have a time-varying propagation loss and intermittent partial-band interference. Our results demonstrate that the adaptive-transmission protocol can improve the utility of a link and reduce energy consumption by adjusting the transmission parameters in response to changes in the side information.
ID:808
CLASS:6
Title: Packet types: abstract specification of network protocol messages
Abstract: In writing networking code, one is often faced with the task of interpreting a raw buffer according to a standardized packet format. This is needed, for example, when monitoring network traffic for specific kinds of packets, or when unmarshaling an incoming packet for protocol processing. In such cases, a programmer typically writes C code that understands the grammar of a packet and that also performs any necessary byte-order and alignment adjustments. Because of the complexity of certain protocol formats, and because of the low-level of programming involved, writing such code is usually a cumbersome and error-prone process. Furthermore, code written in this style loses the domain-specific information, viz. the packet format, in its details, making it difficult to maintain.
ID:809
CLASS:6
Title: Network measurement of the VMTP request-response protocol in the V distributed system
Abstract: Communication systems are undergoing a change in use from stream to request-response or transaction communication. In addition, communication systems are becoming increasingly based on high-speed, low delay, low error rate channels. These changes call for a new generation of networks, network interfaces, and transport protocol design. The performance characteristics of request-response protocols on these high-performance networks should guide the design of this new generation, yet relatively little data of this nature is available.In this paper, we present some preliminary measurements of network traffic for a cluster of workstations connected by Ethernet running the V distributed operating system. We claim that this system, with its use of a high-speed local area network and a request-response transport protocol tuned for RPC, provides some indication of the performance characteristics for systems in the next generation of communication systems. In particular, these measurements provide an indication of network traffic patterns, usage characteristics for request-response protocols, and the behavior of the request-response protocol itself. These measurements suggest in general that a key design focus must be on minimizing network latency and that a request-response protocol is well-suited for this goal. This focus has implications for protocol design and implementation as well as for the design of networks and network interfaces.
ID:810
CLASS:6
Title: Dummynet: a simple approach to the evaluation of network protocols
Abstract: Network protocols are usually tested in operational networks or in simulated environments. With the former approach it is not easy to set and control the various operational parameters such as bandwidth, delays, queue sizes. Simulators are easier to control, but they are often only an approximate model of the desired setting, especially for what regards the various traffic generators (both producers and consumers) and their interaction with the protocol itself.In this paper we show how a simple, yet flexible and accurate network simulator - dummynet - can be built with minimal modifications to an existing protocol stack, allowing experiments to be run on a standalone system. dummynet works by intercepting communications of the protocol layer under test and simulating the effects of finite queues, bandwidth limitations and communication delays. It runs in a fully operational system, hence allowing the use of real traffic generators and protocol implementations, while solving the problem of simulating unusual environments. With our tool, doing experiments with network protocols is as simple as running the desired set of applications on a workstation.A FreeBSD implementation of dummynet, targeted to TCP, is available from the author. This implementation is highly portable and compatible with other BSD-derived systems, and takes less than 300 lines of kernel code.
ID:811
CLASS:6
Title: Signatures for a network protocol stack: a systems application of Standard ML
Abstract: Advanced programming languages such as Standard ML have rarely been used for systems programming tasks such as operating systems and network communications. In order to understand more fully the requirements of systems programming, we have implemented a suite of industry-standard network communication protocols in a completely type-safe extension of Standard ML. While the implementation has only recently become operational, we already observe acceptable communications throughput. We make careful use of the Standard ML modules system, with the core component of the implementation being a signature which is generic to all communications protocols. This generic protocol is then specialized for specific protocols, and these are implemented by functors parameterized by generic protocols.  This leads naturally to a layered system structure and also provides an important and useful &ldquo;mix-and-match&rdquo; capability in composing protocols into complex networking systems.We have found the advanced features of Standard ML, in particular the modules system, static typing, and higher-order functions, to be extremely useful in building complex communications systems. The type compatibility of the various components of a system is guaranteed by the compiler. Furthermore, we find it significant that most of the information needed to understand the structure and interactions in our code can be obtained from a study of the signatures alone. Perhaps most important is that we have been able to use the expressive power of Standard ML modules to give concrete expression to  previously ad hoc system-structuring concepts developed by other researchers in the field of network communications. For language designers and implementors, our experience has also pointed out specific areas for further work that may lead to advanced languages that are useful for systems programming.
ID:812
CLASS:6
Title: Cluster-based routing protocol for mobile sensor networks
Abstract: Mobility in wireless sensor networks has attracted a lot of attention in the recent years [6] and has introduced unique challenges in aspects like resource management, coverage, routing protocols, security, etc. The next evolutionary step for sensor networks is to handle the mobility effect in all its forms. In this paper, we propose a mobility-aware routing protocol, using zone-base information and a cluster-like communication between nodes. The routing protocol has two different stages: Route Creation and Route Preservation. Route creation is used to discover a route from source to destination. Route preservation is used to repair the route when it is defective.
ID:813
CLASS:6
Title: UARTP: a unicast--based self--adaptive reliable transmission protocol for wireless and mobile ad-hoc networks
Abstract: Mobile ad hoc wireless networks are characterized by highly variable bandwidth and latency, as well as unpredictable topology changes. Under such unstable environment, it is a great challenge for network designers to devise mechanisms that provide not only good transmission performance but also can guarantee a reliable communication service. In this paper, a novel and effective Unicast-based self-Adaptive Reliable Transmission Protocol (UARTP), is proposed for mobile ad hoc wireless networks. UARTP uses a combination of Automatic Repeat reQuest (ARQ) and probabilistic Forward Error Correction (FEC) mech-anisms to provide low overhead, high delivery rate, and low retransmission. Simulation experiments were implemented in the NS-2 simulator. Our results were compared to TCP and UDP protocols and shows that UARTP outperformed these protocols on the delivery rate, packet loss rate and delay what makes it a good candidate as a transmission protocol for mobile ad hoc wireless networks.
ID:814
CLASS:6
Title: Transmission power control in MAC protocols for wireless sensor networks
Abstract: Medium access control (MAC) protocols manage energy consumption on the network element during communication, which is the most energy-consuming event on Wireless Sensor Networks (WSNs). One method to mitigate energy consumption is to adjust transmission power. This paper presents two approaches to adjust transmission power in WSNs. The first approach employs dynamic adjustments by exchange of information among nodes, and the second one calculates the ideal transmission power according to signal attenuation in the link. The proposed algorithms were implemented and evaluated with experiments, comparing their results with B-MAC, the standard MAC protocol in the Mica Motes 2 platform. Results show that transmission power control is an effective method to decrease energy consumption, and incurs in a negligible loss in packet delivery rates. For node distances of 5m, the proposed transmission power control techniques decrease energy consumption by 27% over B-MAC.
ID:815
CLASS:6
Title: The dynamic behavior of a data dissemination protocol for network programming at scale
Abstract: To support network programming, we present Deluge, a reliable data dissemination protocol for propagating large data objects from one or more source nodes to many other nodes over a multihop, wireless sensor network. Deluge builds from prior work in density-aware, epidemic maintenance protocols. Using both a real-world deployment and simulation, we show that Deluge can reliably disseminate data to all nodes and characterize its overall performance. On Mica2-dot nodes, Deluge can push nearly 90 bytes/second, one-ninth the maximum transmission rate of the radio supported under TinyOS. Control messages are limited to 18% of all transmissions. At scale, the protocol exposes interesting propagation dynamics only hinted at by previous dissemination work. A simple model is also derived which describes the limits of data propagation in wireless networks. Finally, we argue that the rates obtained for dissemination are inherently lower than that for single path propagation. It appears very hard to significantly improve upon the rate obtained by Deluge and we identify establishing a tight lower bound as an open problem.
ID:816
CLASS:6
Title: A routing protocol for power constrained networks with asymmetric links
Abstract: In many instances, an ad hoc network consists of nodes with different hardware and software capabilities as well as power limitations. This is the case of ad hoc grids where devices such as desktops, laptops, robots, palmtops, sensors, and actuators collaborate to solve computational problems. In such a heterogeneous environment, the nodes have various degrees of mobility and range and the communication links are asymmetric: node i may be able to reach node j, but j may not be able to reach i. A4LP, is a Location-Aware and Power-Aware routing protocol designed primarily for heterogeneous Ad hoc networks with Asymmetric links.
ID:817
CLASS:7
Title: Towards pattern-based design recovery
Abstract: A method and a corresponding tool is described which assist design recovery and program understanding by recognising instances of design patterns semi-automatically. The approach taken is specifically designed to overcome the existing scalability problems caused by many design and implementation variants of design pattern instances. Our approach is based on a new recognition algorithm which works incrementally rather than trying to analyse a possibly large software system in one pass without any human intervention. The new algorithm exploits domain and context knowledge given by a reverse engineer and by a special underlying data structure, namely a special form of an annotated abstract syntax graph. A comparative and quantitative evaluation of applying the approach to the Java AWT and JGL libraries is also given.
ID:818
CLASS:7
Title: Modeling naturalistic affective states via facial and vocal expressions recognition
Abstract: Affective and human-centered computing are two areas related to HCI which have attracted attention during the past years. One of the reasons that this may be attributed to, is the plethora of devices able to record and process multimodal input from the part of the users and adapt their functionality to their preferences or individual habits, thus enhancing usability and becoming attractive to users less accustomed with conventional interfaces. In the quest to receive feedback from the users in an unobtrusive manner, the visual and auditory modalities allow us to infer the users' emotional state, combining information both from facial expression recognition and speech prosody feature extraction. In this paper, we describe a multi-cue, dynamic approach in naturalistic video sequences. Contrary to strictly controlled recording conditions of audiovisual material, the current research focuses on sequences taken from nearly real world situations. Recognition is performed via a 'Simple Recurrent Network' which lends itself well to modeling dynamic events in both user's facial expressions and speech. Moreover this approach differs from existing work in that it models user expressivity using a dimensional representation of activation and valence, instead of detecting the usual 'universal emotions' which are scarce in everyday human-machine interaction. The algorithm is deployed on an audiovisual database which was recorded simulating human-human discourse and, therefore, contains less extreme expressivity and subtle variations of a number of emotion labels.
ID:819
CLASS:7
Title: American sign language recognition in game development for deaf children
Abstract: CopyCat is an American Sign Language (ASL) game, which uses gesture recognition technology to help young deaf children practice ASL skills. We describe a brief history of the game, an overview of recent user studies, and the results of recent work on the problem of continuous, user-independent sign language recognition in classroom settings. Our database of signing samples was collected from user studies of deaf children playing aWizard of Oz version of the game at the Atlanta Area School for the Deaf (AASD). Our data set is characterized by disfluencies inherent in continuous signing, varied user characteristics including clothing and skin tones, and illumination changes in the classroom. The dataset consisted of 541 phrase samples and 1,959 individual sign samples of five children signing game phrases from a 22 word vocabulary. Our recognition approach uses color histogram adaptation for robust hand segmentation and tracking. The children wear small colored gloves with wireless accelerometers mounted on the back of their wrists. The hand shape information is combined with accelerometer data and used to train hidden Markov models for recognition. We evaluated our approach by using leave-one-out validation; this technique iterates through each child, training on data from four children and testing on the remaining child's data. We achieved average word accuracies per child ranging from 91.75% to 73.73% for the user-independent models.
ID:820
CLASS:7
Title: Analysis of emotion recognition using facial expressions, speech and multimodal information
Abstract: The interaction between human beings and computers will be more natural if computers are able to perceive and respond to human non-verbal communication such as emotions. Although several approaches have been proposed to recognize human emotions based on facial expressions or speech, relatively limited work has been done to fuse these two, and other, modalities to improve the accuracy and robustness of the emotion recognition system. This paper analyzes the strengths and the limitations of systems based only on facial expressions or acoustic information. It also discusses two approaches used to fuse these two modalities: decision level and feature level integration. Using a database recorded from an actress, four emotions were classified: sadness, anger, happiness, and neutral state. By the use of markers on her face, detailed facial motions were captured with motion capture, in conjunction with simultaneous speech recordings. The results reveal that the system based on facial expression gave better performance than the system based on just acoustic information for the emotions considered. Results also show the complementarily of the two modalities and that when these two modalities are fused, the performance and the robustness of the emotion recognition system improve measurably.
ID:821
CLASS:7
Title: A vision-based sign language recognition system using tied-mixture density HMM
Abstract: In this paper, a vision-based medium vocabulary Chinese sign language recognition (SLR) system is presented. The proposed recognition system consists of two modules. In the first module, techniques of robust hands detection, background subtraction and pupils detection are efficiently combined to precisely extract the feature information with the aid of simple colored gloves in the unconstrained environment. Meanwhile, an effective and efficient hierarchical feature description scheme with different scale features to characterize sign language is proposed, where principal component analysis (PCA) is employed to characterize the finger features more elaborately. In the second part, a Tied-Mixture Density Hidden Markov Models (TMDHMM) framework for SLR is proposed, which can speed up the recognition without the significant loss of recognition accuracy compared with the continuous hidden Markov models (CHMM). Experimental results based on 439 frequently used Chinese sign language (CSL) words show that the proposed methods can work well for the medium vocabulary SLR in the environment without special constraints and the recognition accuracy is up to 92.5%.
ID:822
CLASS:7
Title: System level design of real time face recognition architecture based on composite PCA
Abstract: Design and implementation of a fast parallel architecture based on an improved principal component analysis (PCA) method called Composite PCA suitable for real-time face recognition is presented in this paper. The proposed architecture performs the tasks of both feature extraction and classification. Composite PCA takes in to consideration the local features of face images, which do not vary widely between face images of the same person taken under varying expression, illumination and pose. Hence it leads to a better recognition rate than PCA. Composite PCA has more parallelism than conventional PCA and this parallelism is utilized to design an efficient architecture capable of performing real-time face recognition. The face recognition system is implemented in an FPGA environment and tested using standard databases. The system is able to recognize a person from a database of 110 images of 10 individuals in approximately 4 ms.
ID:823
CLASS:7
Title: Machine interpretation of CAD data for manufacturing applications
Abstract: Machine interpretation of the shape of a component for CAD databases is an important problem in CAD/CAM, computer vision, and intelligent manufacturing. It can be used in CAD/CAM for evaluation of designs, in computer vision for machine recognition and machine inspection of objects, and in intelligent manufacturing for automating and integrating the link between design and manufacturing. This topic has been an active area of research since the late '70s, and a significant number of computational methods have been proposed to identify portions of the geometry of a part having engineering significance (here called &ldquo;features&rdquo;). However, each proposed mechanism has been able to solve the problem only for components within a restricted geometric domain (such as polyhedral   components), or only for components whose features interact with each other in a restricted manner. The purposes of this article are to review and summarize the development of research on machine recognition of features from CAD data, to discuss the advantages and potential problems of each approach, and to point out some of the promising directions future investigations may take. Since most work in this field has focused on machining features, the article primarily covers those features associated with the manufacturing domain. In order to better understand the state of the art, methods of automated feature recognition are divided into the following categories of methods based on their approach: graph-based, syntactic pattern recognition, rule-based, and volumetric. Within each category  we have studied issues such as the definition of features, mechanisms developed for recognition of features, the application scope, and the assumptions made. In addition, the problem is addressed from the perspective of information input requirements and the advantages and disadvantages of boundary representation, constructive solid geometry (CSG), and 2D drawings with respect to machine recognition of features are examined. Emphasis is placed on the mechanisms for attacking problems associated with interacting features.
ID:824
CLASS:7
Title: Automatic discovery of term similarities using pattern mining
Abstract: Term recognition and clustering are key topics in automatic knowledge acquisition and text mining. In this paper we present a novel approach to the automatic discovery of term similarities, which serves as a basis for both classification and clustering of domain-specific concepts represented by terms. The method is based on automatic extraction of significant patterns in which terms tend to appear. The approach is domain independent: it needs no manual description of domain-specific features and it is based on knowledge-poor processing of specific term features. However, automatically collected patterns are domain specific and identify significant contexts in which terms are used. Beside features that represent contextual patterns, we use lexical and functional similarities between terms to define a combined similarity measure. The approach has been tested and evaluated in the domain of molecular biology, and preliminary results are presented.
ID:825
CLASS:7
Title: Recognition of sign language subwords based on boosted hidden Markov models
Abstract: Sign language recognition (SLR) plays an important role in human-computer interaction (HCI), especially for the convenient communication between deaf and hearing society. How to enhance the traditional hidden Markov models (HMM) based SLR is an important issue in the SLR community. And how to refine the boundaries of the classifiers to effectively characterize the property of spread-out of the training samples is another significant issue. In this paper, a new classification framework applying adaptive boosting (AdaBoost) strategy to continuous HMM (CHMM) training procedure at the subwords classification level for SLR is presented. The ensemble of multiple composite CHMMs for each subword trained in boosting iterations tends to concentrate more on the hard-to-classify samples so as to generate more complex decision boundary than that of the single HMM classifier. Experimental results on the vocabulary of frequently used Chinese sign language (CSL) subwords show that the proposed boosted CHMM outperforms the conventional CHMM for SLR.
ID:826
CLASS:7
Title: A cost minimization approach to human behavior recognition
Abstract: This paper presents a cost minimization approach to the problem of human behavior recognition. Using full-body motion capture data acquired from human subjects, our system recognizes the behaviors that a human subject is performing from a set of military maneuvers, based on the subject's motion type and proximity to landmarks. Low-level motion classification is performed using support vector machines (SVMs) and a hidden Markov Model (HMM); output from the classifier is used as an input feature for the behavior recognizer. Given the dynamic and highly reactive nature of the domain, our system must handle behavior sequences that are frequently interrupted and often interleaved. To recognize such behavior sequences, we employ dynamic programming in conjunction with a behavior transition cost function to efficiently select the most parsimonious explanation for the human's actions. We demonstrate that our system is robust to action classification errors and deviations by the human subject from the expected set of behaviors. Our approach is well suited for incorporation into synthetic agents that cooperate or compete against human subjects in virtual reality training environments.
ID:827
CLASS:7
Title: Debugging heterogeneous distributed systems using event-based models of behavior
Abstract: Event Based Behavioral Abstraction (EBBA) is a high-level debugging approach which treats debugging as a process of creating models of actual behavior from the activity of the system and comparing these to models of expected system behavior. The differences between the actual and expected models are used to characterize erroneous system behavior and direct further investigation.A set of EBBA-based tools has been implemented that users can employ to construct libraries of behavior models and investigate the behavior of an errorful system through these models. EBBA evolves naturally as a cooperative distributed program that can take better advantage of computational power available in a network computer system to enhance debugging tool transparency, reduce latency and uncertainty for fundamental debugging activities and accommodate diverse, heterogeneous architectures.
ID:828
CLASS:7
Title: Data clustering: a review
Abstract: Clustering is the unsupervised classification of patterns (observations, data items, or feature vectors) into groups (clusters). The clustering problem has been addressed in many contexts and by researchers in many disciplines; this reflects its broad appeal and usefulness as one of the steps in exploratory data analysis. However, clustering is a difficult problem combinatorially, and differences in assumptions and contexts in different communities has made the transfer of useful generic concepts and methodologies slow to occur. This paper presents an overviewof pattern clustering methods from a statistical pattern recognition perspective, with a goal of providing useful advice and references to fundamental concepts accessible to the broad community of clustering practitioners. We present a taxonomy of clustering techniques, and identify cross-cutting themes and recent advances. We also describe some important applications of clustering algorithms such as image segmentation, object recognition, and information retrieval.
ID:829
CLASS:7
Title: Technique for automatically correcting words in text
Abstract: Research aimed at correcting words in text has focused on three progressively more difficult problems:(1) nonword error detection; (2) isolated-word error correction; and (3) context-dependent work correction. In response to the first problem, efficient pattern-matching and n-gram analysis techniques have been developed for detecting strings that do not appear in a given word list. In response to the second problem, a variety of general and application-specific spelling correction techniques have been developed. Some of them were based on detailed studies of spelling error patterns. In response to the third problem, a few experiments using natural-language-processing tools or statistical-language models have been carried out. This article surveys documented findings on spelling error patterns, provides descriptions of various nonword detection and isolated-word error correction techniques, reviews the state of the art of context-dependent word correction techniques, and discusses research issues related to all three areas of automatic error correction in text.
ID:830
CLASS:7
Title: On the recognition of information with a digital computer
Abstract: There exists a vast discrepancy in the power of discrimination exercised by a digital computer and in that of a human being. The recognition of information or data patterns is a simple task for the least experienced human clerk. Most people possess sufficiently sophisticated recognition capabilities so that a variation in the pattern of the data under scrutiny will not cause undue difficulty in the discrimination process. The recognition powers of a digital computer, however, are best demonstrated in an elementary table lookup operation, wherein the subject information is required to match exactly with a portion of the master list in order to be &ldquo;recognized&rdquo;. Machine recognition of data which is allowed to vary from the predetermined digital pattern is a vastly more complex problem. Since digital computers are inherently devices which are capable of only YES or NO answers, all MAYBE or PERHAPS responses are obtained only through painstaking effort. If the variations in the subject data are allowed a reasonable range in both position and type, there is no complete solution of the recognition problem available with present techniques and equipments. This paper will outline the general recognition problem in terms of a set of definitions and a mathematical model. I believe that a useful formulation of the problem, and a comprehension of the difficulties involved in discrimination, are prerequisites to any effort at obtaining a complete solution to the problem of data recognition.
ID:831
CLASS:7
Title: Statistical techniques for free-text processing
Abstract: Over the past eight years we have developed statistical methods for characterizing, classifying, and retrieving brief natural-language messages. Our goal was to provide a tool for people who had to deal with enormous numbers of heterogeneous documents, using ill-defined criteria of relevance and interest. Initially, we worked with a large, general-purpose system, the On-Line Pattern Analysis and Recogition System (OLPARS). More recently, we have developed a system called Message Extraction Through Estimation of Relevance (METER). Our present aim is the construction of a Testbed system for further studies and the development of more complex systems.
ID:832
CLASS:7
Title: Multimodal event parsing for intelligent user interfaces
Abstract: Many intelligent interfaces must recognize patterns of user activity that cross a variety of different input channels. These multimodal interfaces offer significant challenges to both the designer and the software engineer. The designer needs a method of expressing interaction patterns that has the power to capture real use cases and a clear semantics. The software engineer needs a processing model that can identify the described interaction patterns efficiently while maintaining meaningful intermediate state to aid in debugging and system maintenanceIn this paper, we describe an input model, a general recognition model, and a series of important classes of recognition parsers with useful computational characteristics; that is, we can say with some certainty how efficient the recognizers will be, and the kind of patterns the recognizers will accept. Examples illustrate the ability of these recognizers to integrate information from multiple channels across varying time intervals.
ID:833
CLASS:7
Title: An evaluation of color patterns for imaging of warning signals in cockpit displays
Abstract: The quality of information perception in an aircraft cockpit depends on the way of interacting with display units, including modality, interface structure, and external exploitation conditions. The goal of this work is to find a solution that would allow real-time imaging or doubling of audible warning signals through spatial-temporal color coding. Software emulation of the peripheral display was built. The development and pilot evaluation of the method were both performed. Presentation of visual signals in paracentral field is efficient, but their optical and temporal parameters are critical in relation to distraction effect.
ID:834
CLASS:7
Title: Parsing of Graph-Representable Pictures
Abstract: A syntax-directed picture analysis system based on a formal picture description scheme is described. The system accepts a description of a set of pictures in terms of a grammar generating strings in a picture description language; the grammar is explicitly used to direct the analysis or parse, and to control the calls on pattern classification routines for primitive picture components. Pictures are represented by directed graphs with labeled edges, where the edges denote elementary picture components and the graph connectivity mirrors the picture component connectivity; blank and don't care &ldquo;patterns&rdquo; allow the description of simple relations between visible patterns. The bulk of the paper is concerned with the picture parsing algorithm which is an n-dimensional analog of a classical top-down string parser, and an application of an implemented system to the analysis of spark chamber film. The potential benefits of this approach, as demonstrated by the application, include ease of implementation and modification of picture processing systems, and simplification of the pattern recognition problem by automatically taking advantage of contextual information.
ID:835
CLASS:7
Title: On Robustness Properties of Convex Risk Minimization Methods for Pattern Recognition
Abstract: The paper brings together methods from two disciplines: machine learning theory and robust statistics. We argue that robustness is an important aspect and we show that many existing machine learning methods based on the convex risk minimization principle have - besides other good properties - also the advantage of being robust. Robustness properties of machine learning methods based on convex risk minimization are investigated for the problem of pattern recognition. Assumptions are given for the existence of the influence function of the classifiers and for bounds on the influence function. Kernel logistic regression, support vector machines, least squares and the AdaBoost loss function are treated as special cases. Some results on the robustness of such methods are also obtained for the sensitivity curve and the maxbias, which are two other robustness criteria. A sensitivity analysis of the support vector machine is given.
ID:836
CLASS:7
Title: Oops! silly me! errors in a handwriting recognition-based text entry interface for children
Abstract: This paper describes an empirical study in which children aged 7 and 8 used handwriting recognition software and hardware to input their own unconstrained text into the computer. The children were observed using the software, and the behaviour of both the children and the system is described.Handwriting recognition is a 'disobedient' technology; that is, it behaves erroneously, sometimes failing to generate correct representations of the child's intentions. This presents problems for the child, and these problems, and the strategies which the children adopted, are considered. Previous work on error correction with disobedient interfaces is used to provide grounding for the discussion.Two models are proposed, one describing user-states, the second introducing the notion of 'tidal' error repair. These models are then used to suggest some strategies for the design of more usable handwriting recognition interfaces for children.
ID:837
CLASS:7
Title: Regret-based optimal recommendation sets in conversational recommender systems
Abstract: Current conversational recommender systems are unable to offer guarantees on the quality of their recommendations due to a lack of principled user utility models. We develop an approach to recommender systems that incorporates an explicit utility model into the recommendation process in a decision-theoretically sound fashion. The system maintains explicit constraints on user utility based on preferences revealed by the user's actions. We investigate a new decision criterion,  setwise minimax regret (SMR) , for constructing optimal recommendation sets: we develop algorithms for computing SMR, and prove that SMR determines choice sets for queries that are myopically optimal. This provides a natural basis for generating compound critiques in conversational recommender systems. Our simulation results suggest that this utility-theoretically sound approach to user modeling allows much more effective navigation of a product space than traditional approaches based on, for example, heuristic utility models and product similarity measures.
ID:838
CLASS:7
Title: A simplex Armijo downhill algorithm for optimizing statistical machine translation decoding parameters
Abstract: We propose a variation of simplex-downhill algorithm specifically customized for optimizing parameters in statistical machine translation (SMT) decoder for better end-user automatic evaluation metric scores for translations, such as versions of BLEU, TER and mixtures of them. Traditional simplex-downhill has the advantage of derivative-free computations of objective functions, yet still gives satisfactory searching directions in most scenarios. This is suitable for optimizing translation metrics as they are not differentiable in nature. On the other hand, Armijo algorithm usually performs line search efficiently given a searching direction. It is a deep hidden fact that an efficient line search method will change the iterations of simplex, and hence the searching trajectories. We propose to embed the Armijo inexact line search within the simplex-downhill algorithm. We show, in our experiments, the proposed algorithm improves over the widely-applied Minimum Error Rate training algorithm for optimizing machine translation parameters.
ID:839
CLASS:1
Title: Adapting appearance models of semantic concepts to particular videos via transductive learning
Abstract: The detection of high-level concepts in video data is an essential processing step of a video retrieval system. The meaning and the appearance of certain events or concepts are strongly related to contextual information. For example, the appearance of semantic concepts, such as e.g. entertainment or news anchors, is determined by the used editing layout which usually is typical for a certain broadcasting station. In recent years, supervised machine learning approaches have been extensively used to learn and detect high-level concepts in video shots. The class of semi-supervised learning methods incorporates unlabeled data in the learning process. Transductive learning is a subclass of semi-supervised learning: In the transductive setting, all training samples are labeled, but the unlabeled test samples are considered in the learning process as well. Up to now, transductive learning has not been applied for the purpose of video indexing and retrieval. In this paper, we propose transductive learning, realized by transductive support vector machines (TSVM), for the detection of those high-level concepts whose appearance is strongly related to a particular video. For each video and each concept, a transductive model is learned separately and adapted to the appearance of a specific concept in the particular test video. Experimental results on TRECVID 2005 video data demonstrate the feasibility of the proposed transductive learning approach for several high-level concepts.
ID:840
CLASS:2
Title: Clinical evaluations and collaborative design: developing new technologies for mental healthcare interventions
Abstract: Ethical requirements, severe constraints on access to end users and the necessity of real-world clinical evaluations represent significant challenges to designers of new technologies in mental healthcare (MHC) settings. This paper describes the collaborative approaches, incorporating HCI methods with input for MHC professionals and MHC theory, which were applied in the development of Personal Investigator (PI), a 3D computer game developed to support adolescent mental health interventions. Different stages in the evaluation of PI are discussed and the lessons learned through a multi-site clinical evaluation are presented. This evaluation has provided strong initial evidence that games such as PI offer the potential to improve adolescent engagement in talk-based interventions. It has also provided an insight into factors which should be considered in future designs in the MHC domain, e.g. the need to incorporate high levels of adaptability in future systems. Based on the difficulties encountered and lessons learned critical aims for future research are outlined.
